<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2022-11-10T19:11:44+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 2.1.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released/" rel="alternate" type="text/html" title="Debezium 2.1.0.Alpha1 Released"/><published>2022-11-10T00:00:00+00:00</published><updated>2022-11-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 2.1 series, &lt;strong&gt;2.1.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 2.1.0.Alpha1 release includes quite a number of bug fixes but also some noteworthy improvements and new features including but not limited to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for PostgreSQL 15&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Single Message Transformation (SMT) predicate support in Debezium engine&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Capturing TRUNCATE as change event in MySQL table topics&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle LogMiner performance improvements&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;New Redis-based storage module&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a few moments and dive into some of these in more detail!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;smt_predicate_support_in_debezium_engine&quot;&gt;SMT predicate support in Debezium engine&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Single Message Transformations (SMTs) are a critical part of a change event&amp;#8217;s lifecycle and they can apply any number of messaging patterns to the emitted change event. For example, a database table may have a specific column that gets emitted as a part of Debezium&amp;#8217;s change events, but you want this field to be excluded so that the field isn&amp;#8217;t present in the persisted event inside Kafka. This can be done using a single message transformation (SMT).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, Debezium emits a number of different event types such as heartbeat, schema change, and data change events. Each of these events have their own event structure and there may come a point where a specific SMT should only be applied to a specific event type or if a specific event has a certain criteria. One way to evaluate whether the SMT should be applied was to do this evaluation inside the SMT itself, checking its event type or all the criteria to see whether the SMT should be applied or if the SMT should return the event unchanged.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Kafka Connect later introduced a concept called &lt;em&gt;predicates&lt;/em&gt;, which is where a set of external rules can be specified in the connector configuration and must be evaluated to determine whether the SMT should be fired for an event or whether the SMT is skipped. This has enormous benefits because it allows developers to write very specific transformations that focus on a singular mutation and its entirely up to the user to determine whether that SMT should be applied or not using &lt;em&gt;predicates&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting in Debezium 2.1, the power of Single Message Transformation (SMT) predicates can be harnessed when using the Debezium Engine or Debezium Server. An example configuration might like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;# Define the filter transformation, linking it to the IsFoo predicate/rule debezium.transforms=Filter debezium.transforms.Filter.type=org.apache.kafka.connect.transforms.Filter debezium.transforms.Filter.predicate=IsFoo # Define the IsFoo predicate/rule debezium.predicates=IsFoo debezium.predicates.IsFoo.type=org.apache.kafka.connect.transforms.predicates.TopicNameMatches debezium.predicates.IsFoo.pattern=foo&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With these additional &lt;code&gt;debezium.predicates.*&lt;/code&gt; configuration properties, it is possible to define a set of rules that must be evaluated to determine whether the &lt;code&gt;Filter&lt;/code&gt; SMT will be fired or skipped in the transformation chain. In the example above, the predicate checks to see whether the event&amp;#8217;s topic name matches &lt;code&gt;foo&lt;/code&gt; and if it does, the &lt;code&gt;Filter&lt;/code&gt; transformation will be fired. If the topic name does not match &lt;code&gt;foo&lt;/code&gt;, the &lt;code&gt;Filter&lt;/code&gt; transformation is skipped.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To read more about applying Single Message Transformations (SMTs) selectively using predicates, see:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://debezium.io/documentation/reference/2.1/transformations/applying-transformations-selectively.html&quot;&gt;Using SMT predicates to selectively apply transformations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://debezium.io/documentation/reference/2.1/operations/debezium-server.html#debezium-predicates-configuration-options&quot;&gt;Debezium Server predicates configuration and set up&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;capture_mysql_truncate_as_change_event&quot;&gt;Capture MySQL TRUNCATE as change event&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium has supported the concept of emitting a change event to signal a &lt;code&gt;TRUNCATE TABLE&lt;/code&gt; scenario for PostgreSQL and Oracle for quite a while. Starting with Debezium 2.1, this behavior has been extended to the MySQL connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, the connector configuration option, &lt;code&gt;skipped.operations&lt;/code&gt;, automatically skips &lt;code&gt;TRUNCATE&lt;/code&gt; events if they&amp;#8217;re detected. This means that by default, there will not be anything emitted when the connector detects this pattern. In order to support emission of such events, the &lt;code&gt;skipped.operations&lt;/code&gt; configuration property must be specified with a value of &lt;code&gt;none&lt;/code&gt; or other operation types that do not include the &lt;code&gt;t&lt;/code&gt; (truncate) type.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once the connector is configured to emit events for &lt;code&gt;TRUNCATE&lt;/code&gt; operations, a new data change event type will be emitted to the table topics. These event types signal that the table or collection has been truncated. The event&amp;#8217;s payload will looking like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1465581029523&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The most notable point here is that truncate events do not contain a &lt;code&gt;before&lt;/code&gt; or &lt;code&gt;after&lt;/code&gt; state.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;new_redis_based_storage_module&quot;&gt;New Redis-based storage module&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium recently modularized parts of its codebase around persisting offsets and schema history into a set of modules supporting File and Kafka -based implementation. In Debezium 2.1, a new module was introduced to support persisting to Redis data stores.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following fully-qualified class names can be used to persist offsets or schema history to Redis data stores:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;io.debezium.storage.redis.offset.RedisOffsetBackingStore&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;io.debezium.storage.redis.history.RedisSchemaHistory&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you have manually installed Debezium, be sure to include the &lt;code&gt;debezium-storage-redis&lt;/code&gt; artifact on your classpath if it does not exist in order to gain access to these new implementations.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For information about what options can be configured with this new implementation, please see the &lt;a href=&quot;https://debezium.io/documentation/reference/2.1/operations/debezium-server.html#debezium-source-configuration-properties&quot;&gt;source configuration&lt;/a&gt; section of the Debezium Server documentation and look for configuration options prefixed with:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;debezium.source.offset.storage.redis.*&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;debezium.source.schema.history.internal.redis.*&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Missing snapshot pending transactions &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5482&quot;&gt;DBZ-5482&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Using snapshot.mode ALWAYS uses SCN from offsets &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5626&quot;&gt;DBZ-5626&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MongoDB multiple tasks monitor misalignment &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5629&quot;&gt;DBZ-5629&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;UNIQUE INDEX with NULL value throws exception when lob.enabled is true &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5682&quot;&gt;DBZ-5682&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Columns are not excluded when doing incremental snapshots &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5727&quot;&gt;DBZ-5727&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NullPointerException thrown during snapshot of tables in Oracle source connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5738&quot;&gt;DBZ-5738&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hostname not available for load balanced ocp services in ARO &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5753&quot;&gt;DBZ-5753&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exclude Oracle Compression Advisor tables from capture to avoid infinite loop &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5756&quot;&gt;DBZ-5756&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Message with LSN 'LSN{XYZ}' not present among LSNs seen in the location phase &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5792&quot;&gt;DBZ-5792&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.1.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;55 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/adasari&quot;&gt;Anil Dasari&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/enzo-cappa&quot;&gt;Enzo Cappa&lt;/a&gt;, &lt;a href=&quot;https://github.com/ggaborg&quot;&gt;Gabor Andras&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/BetaCat0&quot;&gt;Helong Zhang&lt;/a&gt;, &lt;a href=&quot;https://github.com/hdulay&quot;&gt;Hubert Dulay&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/janjwerner-confluent&quot;&gt;Jan Werner&lt;/a&gt;, &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/dude0001&quot;&gt;Mark Lambert&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/obabec&quot;&gt;Ondrej Babec&lt;/a&gt;, &lt;a href=&quot;https://github.com/rajdangwal&quot;&gt;Rajendra Dangwal&lt;/a&gt;, &lt;a href=&quot;https://github.com/chtitux&quot;&gt;Théophile Helleboid&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ywu-stripe&quot;&gt;Yang Wu&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So as we continue to work on Debezium 2.1, we&amp;#8217;ve been able to include a number of the expected changes in today&amp;#8217;s release, but we still do intend to deliver on a new Single Message Transformation (SMT) for generating change event deltas before the end of the year. There is also some much anticipated changes for Debezium UI, such as supporting editing of connector configurations and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can find this information and what else to expect as a part of Debezium in 2023 in our recently updated &lt;a href=&quot;/roadmap/&quot;&gt;road map&lt;/a&gt;. We have quite a lot of new features planned for next year, and we would love to hear your feedback or suggestions on things that may not be on the roadmap you&amp;#8217;d like to see. Be sure to get in touch with us on the mailing list if there is.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until next time&amp;#8230;&amp;#8203;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 2.1 series, 2.1.0.Alpha1! The Debezium 2.1.0.Alpha1 release includes quite a number of bug fixes but also some noteworthy improvements and new features including but not limited to: Support for PostgreSQL 15 Single Message Transformation (SMT) predicate support in Debezium engine Capturing TRUNCATE as change event in MySQL table topics Oracle LogMiner performance improvements New Redis-based storage module</summary></entry><entry><title type="html">Debezium 1.9.7.Final Released</title><link href="https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.7.Final Released"/><published>2022-10-26T00:00:00+00:00</published><updated>2022-10-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.9.7.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+1.9.7.Final&quot;&gt;22 resolved issues&lt;/a&gt; overall.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;changes&quot;&gt;Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A few noteworthy bug fixes and stability improvements include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Debezium connectors ship with an old version of google-protobuf vulnerable to CVE-2022-3171 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5747&quot;&gt;DBZ-5747&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ORA-01289: cannot add duplicate logfile &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5276&quot;&gt;DBZ-5276&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Using snapshot boundary mode &quot;all&quot; causes DebeziumException on Oracle RAC &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5302&quot;&gt;DBZ-5302&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Missing snapshot pending transactions &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5482&quot;&gt;DBZ-5482&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox pattern nested payload leads to connector crash &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5654&quot;&gt;DBZ-5654&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Keyword virtual can be used as an identifier &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5674&quot;&gt;DBZ-5674&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MongoDB Connector with DocumentDB errors with &quot;{$natural: -1} is not supported&quot; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5677&quot;&gt;DBZ-5677&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Function DATE_ADD can be used as an identifier &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5679&quot;&gt;DBZ-5679&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;UNIQUE INDEX with NULL value throws exception when lob.enabled is true &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5682&quot;&gt;DBZ-5682&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySqlConnector parse create view statement failed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5708&quot;&gt;DBZ-5708&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Server 1.9.6 is using MSSQL JDBC 7.2.2 instead of 9.4.1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5711&quot;&gt;DBZ-5711&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Vitess: Handle Vstream error: unexpected server EOF &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5722&quot;&gt;DBZ-5722&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ParsingException: DDL statement couldn&amp;#8217;t be parsed (index hints) &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5724&quot;&gt;DBZ-5724&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle SQL parsing error when collation used &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5726&quot;&gt;DBZ-5726&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Unparseable DDL statement &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5734&quot;&gt;DBZ-5734&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.7-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community who contributed to Debezium 1.9.7.Final: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/xinbinhuang&quot;&gt;Bin Huang&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/janjwerner-confluent&quot;&gt;Jan Werner&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/joschi&quot;&gt;Jochen Schalanda&lt;/a&gt;, &lt;a href=&quot;https://github.com/nilshartmann&quot;&gt;Nils Hartmann&lt;/a&gt;, &lt;a href=&quot;https://github.com/thangdc94&quot;&gt;Phạm Ngọc Thắng&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sage-Pierce&quot;&gt;Sage Pierce&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, and &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook_whats_next&quot;&gt;Outlook, What&amp;#8217;s next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This past year has been packed full of tons of changes. This makes the eighth and likely final stable release for Debezium 1.9 as we begin to turn our attention fully to Debezium 2.0 moving forward.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With Debezium 2.0 released on October 17th, just last week, the team is now hard at work addressing your feedback, so keep that coming. We&amp;#8217;re also actively working on the next installment of Debezium, 2.1, which will be released later this year. Be sure to keep an eye on our &lt;a href=&quot;/roadmap&quot;&gt;road map&lt;/a&gt; in the coming week as we intend to debut what is planned for Debezium 2.1 and what&amp;#8217;s to come in 2023!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until then, stay safe!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.9.7.Final! This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains 22 resolved issues overall.</summary></entry><entry><title type="html">Debezium Evolving</title><link href="https://debezium.io/blog/2022/10/26/debezium-evolving/" rel="alternate" type="text/html" title="Debezium Evolving"/><published>2022-10-26T00:00:00+00:00</published><updated>2022-10-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/26/debezium-evolving</id><content type="html" xml:base="https://debezium.io/blog/2022/10/26/debezium-evolving/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some time in early 2017, I got a meeting invite from Debezium&amp;#8217;s founder, &lt;a href=&quot;https://twitter.com/rhauch&quot;&gt;Randall Hauch&lt;/a&gt;. He was about to begin a new chapter in his professional career and was looking for someone to take over as the project lead for Debezium. So we hopped on a call to talk things through, and I was immediately sold on the concept of change data capture, its large number of potential use cases and applications, and the idea of making this available to the community as open-source. After some short consideration I decided to take up this opportunity, and without a doubt this has been one of the best decisions I&amp;#8217;ve ever made in my job.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today, five years and two major releases (&lt;a href=&quot;/blog/2019/12/18/debezium-1-0-0-final-released/&quot;&gt;1.0&lt;/a&gt;, &lt;a href=&quot;/blog/2022/10/17/debezium-2-0-final-released/&quot;&gt;2.0&lt;/a&gt;) later, I am feeling really proud of what the Debezium community has accomplished, having established itself as &lt;em&gt;the&lt;/em&gt; leading open-source platform for change data capture. The number of officially supported databases has grown from three to eight. Further Debezium-based CDC connectors are developed externally by database vendors like &lt;a href=&quot;https://docs.scylladb.com/stable/using-scylla/integrations/scylla-cdc-source-connector.html&quot;&gt;ScyllaDB&lt;/a&gt; and &lt;a href=&quot;https://docs.yugabyte.com/preview/explore/change-data-capture/debezium-connector-yugabytedb/&quot;&gt;Yugabyte&lt;/a&gt;, making Debezium&amp;#8217;s change event format kind of a de-facto standard for CDC. The project is used in production by companies such as Reddit, Shopify, Ubisoft, and Zalando. Debezium became part of Red Hat&amp;#8217;s commercially supported product offerings (&lt;a href=&quot;https://access.redhat.com/documentation/en-us/red_hat_integration/2022.q3/html/getting_started_with_debezium/index&quot;&gt;on-prem&lt;/a&gt;, as well as &lt;a href=&quot;https://www.redhat.com/en/technologies/cloud-computing/openshift/connectors&quot;&gt;fully managed&lt;/a&gt; in the cloud), with multiple other vendors providing Debezium-backed offers as well. During the keynote of this year&amp;#8217;s Current conference, Debezium was &lt;a href=&quot;https://twitter.com/gunnarmorling/status/1577318988836642816&quot;&gt;recognized&lt;/a&gt; as one of the most impactful open-source projects in the Apache Kafka space.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The most important part to me though is the tremendous growth of the Debezium community itself. To this day, more than &lt;a href=&quot;https://github.com/debezium/debezium/blob/main/COPYRIGHT.txt&quot;&gt;450 individuals&lt;/a&gt; have contributed to the code base. A big thank you to all the people and organizations who&amp;#8217;ve worked tirelessly to make the vision of open-source change data capture a reality and continue to improve it every day: Red Hat&amp;#8201;&amp;#8212;&amp;#8201;as the project&amp;#8217;s main sponsor&amp;#8201;&amp;#8212;&amp;#8201;Stripe, Instaclustr, SugarCRM, Redis, and many other companies and individual contributors!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After ten amazing years at Red Hat, I felt that it was about time for a change for me and start some new adventure, and I am going to join a start-up in the data streaming space next month. As part of this transition, I am also stepping down from the role as the project lead for Debezium. While I&amp;#8217;ll be less active in the project on a daily basis, I definitely plan to stay involved and hopefully still send the one or other pull request.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;My partner in crime &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt; will take over as the acting engineering lead. Or, I should say, has taken over, since in fact he has had that role since earlier this year already. Jiri has been a member of the project for many years, working on several key features such as &lt;a href=&quot;/blog/2021/10/07/incremental-snapshots/&quot;&gt;incremental snapshots&lt;/a&gt; and MongoDB change streams support. He&amp;#8217;s an outstanding software engineer, with a unique insight into the problem space of CDC and decades of experience working in open source, and he will be an amazing lead for the Debezium project and community.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the Debezium 2.0 release just through the door, addressing several consistency issues and getting rid of a fair chunk of technical debt, the project is in an excellent position for its future evolution. There are plans for another community-led connector which should be announced very soon, there&amp;#8217;ll be support for exactly-once semantics as recently introduced in Kafka Connect (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-618%3A+Exactly-Once+Support+for+Source+Connectors&quot;&gt;KIP -618&lt;/a&gt;), a Kubernetes operator for Debezium Server, a JDBC sink connector, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The best is yet to come, and I can&amp;#8217;t wait to see what this amazing community will build next!&lt;/p&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community"/><category term="news"/><summary type="html">Some time in early 2017, I got a meeting invite from Debezium&amp;#8217;s founder, Randall Hauch. He was about to begin a new chapter in his professional career and was looking for someone to take over as the project lead for Debezium. So we hopped on a call to talk things through, and I was immediately sold on the concept of change data capture, its large number of potential use cases and applications, and the idea of making this available to the community as open-source. After some short consideration I decided to take up this opportunity, and without a doubt this has been one of the best decisions I&amp;#8217;ve ever made in my job.</summary></entry><entry><title type="html">Debezium 2.0.0.Final Released</title><link href="https://debezium.io/blog/2022/10/17/debezium-2-0-final-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Final Released"/><published>2022-10-17T00:00:00+00:00</published><updated>2022-10-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/17/debezium-2-0-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/17/debezium-2-0-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today it&amp;#8217;s my great pleasure to announce the availability of Debezium &lt;strong&gt;2.0.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since our 1.0 release in December 2019, the community has worked vigorously to build a comprehensive open-source low-latency platform for change data capture (CDC). Over the past three years, we have extended Debezium&amp;#8217;s portfolio to include a stable connector for Oracle, a community led connector for Vitess, the introduction of incremental snapshots, multi-partition support, and so much more. With the help of our active community of contributors and committers, Debezium is the de facto leader in the CDC space, deployed to production within lots of organizations from across multiple industries, using hundreds of connectors to stream data changes out of thousands of database platforms.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The 2.0 release marks a new milestone for Debezium, one that we are proud to share with each of you.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this post, we&amp;#8217;re going to take a deep dive into all changes in Debezium 2.0, discussing the new features and explaining all the possible breaking changes that could have an impact during the upgrade process. As always we highly recommend that you take a look at the &lt;a href=&quot;/releases/2.0/release-notes#release-2.0.0-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc. [release notes], especially when upgrading from an older release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#core-changes&quot;&gt;Changes to core Debezium&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#cassandra-changes&quot;&gt;Changes to Cassandra connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#mongodb-changes&quot;&gt;Changes to MongoDB connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#mysql-changes&quot;&gt;Changes to MySQL connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#oracle-changes&quot;&gt;Changes to Oracle connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#postgres-changes&quot;&gt;Changes to PostgreSQL connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#vitess-changes&quot;&gt;Changes to Vitess connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#container-changes&quot;&gt;Changes for Debezium container images&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#community-spaces&quot;&gt;Community spaces&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;core-changes&quot;&gt;Changes to core Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The fundamental core of Debezium has changed quite a bit in Debezium 2.0. In this section, we&amp;#8217;re going to dive into the changes with Debezium&amp;#8217;s core, and discuss how those changes impact all users of Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;java_11_is_required&quot;&gt;Java 11 is required&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have wanted to make the leap to Java 11 for quite some time, and we felt that with Debezium 2.0 this was the right moment. With Java 11, this enables us to take advantage of new language features, such as the new &lt;code&gt;String&lt;/code&gt; API and &lt;code&gt;Predicate&lt;/code&gt; support changes within the code base, while also benefiting from many of the Java peformance improvements.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our very own Vojtech Juranek published &lt;a href=&quot;/blog/2022/05/04/switch-to-java-11/&quot;&gt;this blog&lt;/a&gt; where he discusses the switch to Java 11 in detail. The Java 11 runtime will be required moving forward to use Debezium, so be sure that Java 11 is available prior to upgrading.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;improved_incremental_snapshots&quot;&gt;Improved Incremental Snapshots&lt;/h3&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;stopping&quot;&gt;Stopping&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since we first introduced incremental snapshots, users have asked for a way to stop an in-progress snapshot. To accomplish this, we have added a new signal, &lt;code&gt;stop-snapshot&lt;/code&gt;, which allows stopping an in-progress incremental snapshot. This signal is to be sent just like any other, by inserting a row into the signal table/collection, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; schema.signal_table (id, type,data) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;unique-id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stop-snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_&amp;lt;signal payload&amp;gt;_`);&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;stop-snapshot&lt;/code&gt; payload looks very similar to its &lt;code&gt;execute-snapshot&lt;/code&gt; counterpart. An example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema1.table1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema2.table2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This example removes both &lt;code&gt;schema1.table1&lt;/code&gt; and &lt;code&gt;schema2.table2&lt;/code&gt; from the incremental snapshot, so long as the table or collection had not already finished its incremental snapshot. If other tables or collections remain outstanding after the removal of those specified by &lt;code&gt;data-collections&lt;/code&gt;, the incremental snapshot will continue to process those that are outstanding. If no other table or collection remains, the incremental snapshot will stop.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Another example of a &lt;code&gt;stop-snapshot&lt;/code&gt; payload is quite simply:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This example does not specify the &lt;code&gt;data-collections&lt;/code&gt; property, it is optional for the &lt;code&gt;stop-snapshot&lt;/code&gt; signal. When this property isn&amp;#8217;t specified, the signal implies the current in-progress incremental snapshot should be stopped entirely. This gives the ability to stop an incremental snapshot without knowledge of the current or outstanding tables or collections yet to be captured.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;pausing_and_resuming&quot;&gt;Pausing and Resuming&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshots have become an integral feature in Debezium. The incremental snapshot feature allows users to re-run a snapshot on one or more collections/tables for a variety of reasons. Incremental snapshots were originally introduced with just a &lt;em&gt;start&lt;/em&gt; signal. We eventually added the ability to &lt;em&gt;stop&lt;/em&gt; an ongoing incremental snapshot or to be able to remove a subset of collections/tables from an in-progress incremental snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we&amp;#8217;ve built on top of the existing signal foundation and we&amp;#8217;ve introduced two new signals, one to &lt;em&gt;pause&lt;/em&gt; an in-progress incremental snapshot and then another to &lt;em&gt;resume&lt;/em&gt; the incremental snapshot if it has previously been paused. To pause an incremental snapshot, a &lt;code&gt;pause-snapshot&lt;/code&gt; signal must be sent, and to resume, a &lt;code&gt;resume-snapshot&lt;/code&gt; signal can be used.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These two new signals can be sent using the signal table strategy or the Kafka signal topic strategy for MySQL. Please refer to the &lt;a href=&quot;https://debezium.io/documentation/reference/2.0/configuration/signalling.html#_signal_actions&quot;&gt;signal support documentation&lt;/a&gt; for more details on signals and how they work.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;using_regular_expressions&quot;&gt;Using Regular Expressions&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshot signals have required the use of explicit table/collection names in the &lt;code&gt;data-collections&lt;/code&gt; payload attribute. While this worked well, there may be situations where broad capture configurations could take advantage of regular expression usage. We already support regular expressions in connector configuration options, such as include/exclude lists, so it made sense to extend that to incremental snapshots as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting in Debezium 2.0, all incremental snapshot signals can use regular expressions in the &lt;code&gt;data-collections&lt;/code&gt; payload property. Using one of the stop signal examples from above, the payload can be rewritten using regular expressions:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema[1|2].table[1|2]&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Just like the explicit usage, this signal with regular expressions would also stop both &lt;code&gt;schema1.table1&lt;/code&gt; and &lt;code&gt;schema2.table2&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;applying_filters_with_sql_conditions&quot;&gt;Applying filters with SQL conditions&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Although uncommon, there may be scenarios such as a connector misconfiguration, where a specific record or subset of records needs to be re-emitted to the topic. Unfortunately, incremental snapshots have traditionally been an all-or-nothing type of process, where we would re-emit all records from a collection or table as a part of the snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a new &lt;code&gt;additional-condition&lt;/code&gt; property can be specified in the signal payload, allowing the signal to dictate a SQL-based predicate to control what subset of records should be included in the incremental snapshot instead of the default behavior of &lt;em&gt;all rows&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following example illustrates sending an incremental snapshot signal for the &lt;code&gt;products&lt;/code&gt; table, but instead of sending all rows from the table to the topic, the &lt;code&gt;additional-condition&lt;/code&gt; property has been specified to restrict the snapshot to only send events that relate to product id equal to &lt;code&gt;12&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;execute-snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory.products&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;INCREMENTAL&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;additional-condition&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;product_id=12&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We believe this new incremental snapshot feature will be tremendously helpful for a variety of reasons, without always having to re-snapshot all rows when only a subset of data is required.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;signal_database_collection_added_to_inclusion_filter_automatically&quot;&gt;Signal database collection added to inclusion filter automatically&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In prior releases of Debezium, the signal collection/table used for incremental snapshots had to be manually added to your &lt;code&gt;table.include.list&lt;/code&gt; connector property. A big theme in this release was improvements on incremental snapshots, so we&amp;#8217;ve taken this opportunity to streamline this as well. Starting in this release, Debezium will automatically add the signal collection/table to the table inclusion filters, avoiding the need for users to manually add it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This change does not impose any compatibility issues. Connector configurations that already include the signal collection/table in the &lt;code&gt;table.include.list&lt;/code&gt; property will continue to work without requiring any changes. However, if you wish to align your configuration with current behavior, you can also safely remove the signal collection/table from the &lt;code&gt;table.include.list&lt;/code&gt;, and Debezium will begin to handle this for you automatically.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;transaction_metadata_changes&quot;&gt;Transaction Metadata changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A transaction metadata event describes the &lt;em&gt;beginning&lt;/em&gt; and the &lt;em&gt;end&lt;/em&gt; (commit) of a database transaction. These events are useful for a variety of reasons, including auditing. By default, transaction metadata events are not generated by a connector and to enable this feature, the &lt;code&gt;provide.transaction.metadata&lt;/code&gt; option must be enabled.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Debezium 2.0, both &lt;code&gt;BEGIN&lt;/code&gt; and &lt;code&gt;END&lt;/code&gt; events include a new field, &lt;code&gt;ts_ms&lt;/code&gt;, which is the database timestamp of when the transaction either began or committed depending on the event type. An example of such an event now looks like:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;12345&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1657033173441&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s1.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; }, { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s2.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; } ] }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are already using the transaction metadata feature, new events will contain this field after upgrading.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are not using the transaction metadata feature but find this useful, simply add the &lt;code&gt;provide.transaction.metadata&lt;/code&gt; option set to &lt;em&gt;true&lt;/em&gt; to your connector configuration. By default, metadata events are emitted to a topic named after your &lt;code&gt;topic.prefix&lt;/code&gt; option. This can be overridden by specifying the &lt;code&gt;transaction.topic&lt;/code&gt; option, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;topic.prefix=server1 provide.transaction.metadata=true transaction.topic=my-transaction-events&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this example, all transaction metadata events will be emitted to &lt;code&gt;my-transaction-events&lt;/code&gt;. Please see your connector specific configuration for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;multi_partition_mode_now_the_default&quot;&gt;Multi-partition mode now the default&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many database platforms support multi-tenancy out of the box, meaning you can have one installation of the database engine and have many unique databases. In cases like SQL Server, this traditionally required a separate connector deployment for each unique database. Over the last year, a large effort has been made to break down that barrier and to introduce a common way that any single connector deployment could connect and stream changes from multiple databases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The first notable change is with the SQL Server connector&amp;#8217;s configuration option, &lt;code&gt;database.dbname&lt;/code&gt;. This option has been replaced with a new option called &lt;code&gt;database.names&lt;/code&gt;. As multi-partition mode is now default, this new &lt;code&gt;database.names&lt;/code&gt; option can be specified using a comma-separated list of database names, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;database.names=TEST1,TEST2&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this example, the connector is being configured to capture changes from two unique databases on the same host installation. The connector will start two unique tasks in Kafka Connect and each task will be responsible for streaming changes from its respective database concurrently.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The second notable change is with connector metrics naming. A connector exposes JMX metrics via beans that are identified with a unique name. With multi-partition mode the default with multiple tasks, each task requires its own metrics bean and so a change in the naming strategy was necessary.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In older versions of Debezium using SQL Server as an example, metrics were available using the following naming strategy:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sql_server:type=connector-metrics,server=&amp;lt;sqlserver.server.name&amp;gt;,context=&amp;lt;context&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, the naming strategy now includes a new &lt;code&gt;task&lt;/code&gt; component in the JMX MBean name:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sql_server:type=connector-metrics,server=&amp;lt;sqlserver.server.name&amp;gt;,task=&amp;lt;task.id&amp;gt;,context=&amp;lt;context&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please review your metrics configurations as the naming changes could have an impact when collecting Debezium metrics.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;new_storage_module&quot;&gt;New storage module&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we have introduced a new &lt;code&gt;debezium-storage&lt;/code&gt; set of artifacts for file- and kafka- based database history and offset storage. This change is the first of several future implementations set to support platforms such as Amazon S3, Redis, and possibly JDBC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For users who install connectors via plugin artifacts, this should be a seamless change as all dependencies are bundled in those plugin downloadable archives. For users who may embed Debezium in their applications or who may be building their own connector, be aware you may need to add a new storage dependency depending on which storage implementations used.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;pluggable_topic_selector&quot;&gt;Pluggable topic selector&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium&amp;#8217;s default topic naming strategy emits change events to topics named &lt;code&gt;database.schema.table&lt;/code&gt;. If you require that topics be named differently, an SMT would normally be added to the connector configuration to adjust this behavior. But, this presents a challenge in situations where one of the components of this topic name, perhaps the database or table name, contains a dot (&lt;code&gt;.&lt;/code&gt;) and perhaps an SMT doesn&amp;#8217;t have adequate context.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a new &lt;code&gt;TopicNamingStrategy&lt;/code&gt; was introduced to allow fully customizing this behavior directly inside Debezium. The default naming strategy implementation should suffice in most cases, but if you find that it doesn&amp;#8217;t you can provide a custom implementation of the &lt;code&gt;TopicNamingStrategy&lt;/code&gt; contract to fully control various namings used by the connector. To provide your own custom strategy, you would specify the &lt;code&gt;topic.naming.strategy&lt;/code&gt; connector option with the fully-qualified class name of the strategy, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;topic.naming.strategy=org.myorganization.MyCustomTopicNamingStrategy&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This custom strategy is not just limited to controlling the names of topics for table mappings, but also for schema changes, transaction metadata, and heartbeats. You can refer to the &lt;code&gt;DefaultTopicNamingStrategy&lt;/code&gt; found &lt;a href=&quot;https://github.com/debezium/debezium/blob/main/debezium-core/src/main/java/io/debezium/schema/DefaultTopicNamingStrategy.java&quot;&gt;here&lt;/a&gt; as an example. This feature is still incubating, and we&amp;#8217;ll continue to improve and develop it as feedback is received.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;improved_unique_index_handling&quot;&gt;Improved unique index handling&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A table does not have to have a primary key to be captured by a Debezium connector. In cases where a primary key is not defined, Debezium will inspect a table&amp;#8217;s unique indices to see whether a reasonable key substitution can be made. In some situations, the index may refer to columns such as &lt;code&gt;CTID&lt;/code&gt; for PostgreSQL or &lt;code&gt;ROWID&lt;/code&gt; in Oracle. These columns are not visible nor user-defined, but instead are hidden synthetic columns generated automatically by the database. In addition, the index may also use database functions to transform the column value that is stored, such as &lt;code&gt;UPPER&lt;/code&gt; or &lt;code&gt;LOWER&lt;/code&gt; for example.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, indices that rely on hidden, auto-generated columns, or columns wrapped in database functions are no longer eligible as primary key alternatives. This guarantees that when relying on an index as a primary key rather than a defined primary key itself, the generated message&amp;#8217;s primary key value tuple directly maps to the same values used by the database to represent uniqueness.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;new_configuration_namespaces&quot;&gt;New configuration namespaces&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the largest overhauls going into Debezium 2.0 is the introduction of new connector property namespaces. Starting in Debezium 2.0 Beta2 and onward, many connector properties have been relocated with new names. This is a breaking change and affects most, if not all, connector deployments during the upgrade process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium previously used the prefix &quot;database.&quot; with a plethora of varied connector properties. Some of these properties were meant to be passed directly to the JDBC driver and in other cases to the database history implementations, and so on. Unfortunately, we identified situations where some properties were being passed to underlying implementations that weren&amp;#8217;t intended. While this wasn&amp;#8217;t creating any type of regression or problem, it could potentially introduce a future issue if there were property name collisions, for example, a JDBC driver property that matched with a &quot;database.&quot; prefixed Debezium connector property.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following describes the changes to the connector properties&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;All configurations previously prefixed as &lt;code&gt;database.history.&lt;/code&gt; are now to be prefixed using &lt;code&gt;schema.history.internal.&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;All JDBC pass-thru options previously specified using &lt;code&gt;database.&lt;/code&gt; prefix should now be prefixed using &lt;code&gt;driver.&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The &lt;code&gt;database.server.name&lt;/code&gt; connector property renamed to &lt;code&gt;topic.prefix&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The MongoDB &lt;code&gt;mongodb.name&lt;/code&gt; connector property aligned to use &lt;code&gt;topic.prefix&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Again, please review your connector configurations prior to deployment and adjust accordingly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;all_schemas_named_and_versioned&quot;&gt;All schemas named and versioned&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium change events are emitted with a schema definition, which contains metadata about the fields such as the type, whether it&amp;#8217;s required, and so on. In previous iterations of Debezium, some schema definitions did not have explicit names nor were they being explicitly versioned. In this release, we&amp;#8217;ve moved to making sure that all schema definitions have an explicit name and version associated with them. The goal of this change is to help with future event structure compatibility, particularly for those who are using schema registries. However, if you are currently using a schema registry, be aware that this change may lead to schema compatibility issues during the upgrade process.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;truncate_events_are_skipped_by_default&quot;&gt;Truncate events are skipped by default&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium supports skipping specific event types by including the &lt;code&gt;skipped.operations&lt;/code&gt; connector property in the connector&amp;#8217;s configuration. This feature can be useful if you&amp;#8217;re only interested in a subset of operations, such as only inserts and updates but not deletions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One specific event type, truncates (&lt;code&gt;t&lt;/code&gt;), is only supported by a subset of relational connectors and whether these events were to be skipped wasn&amp;#8217;t consistent. In this release, we have aligned the &lt;code&gt;skipped.operations&lt;/code&gt; behavior so that if the connector supports truncate events, these events are skipped by default.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please review the following rule-set:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Connector supports truncate events and isn&amp;#8217;t the Oracle connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connector configuration does not specify the &lt;code&gt;skipped.operations&lt;/code&gt; in the configuration&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If all the above are true, then the connector&amp;#8217;s behavior will change after the upgrade. If you wish to continue to emit truncate events, the &lt;code&gt;skipped.operations=none&lt;/code&gt; configuration will be required.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;change_in_schema_name_adjustment_behavior&quot;&gt;Change in &lt;code&gt;schema.name.adjustment&lt;/code&gt; behavior&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;schema.name.adjustment.mode&lt;/code&gt; configuration property controls how schema names should be adjusted for compatibility with the message converter used by the connector. This configuration option can be one of two values:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;avro&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Replicates the characters that cannot be used in the Avro type name with an underscore.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;none&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Does not adjust the names, even when non-Avro compliant characters are detected.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In prior releases, Debezium always defaulted to the safe value of &lt;code&gt;avro&lt;/code&gt;; however, starting with Debezium 2.0.0.CR1 the default value will now be &lt;code&gt;none&lt;/code&gt;. We believe that given that the use of Avro serialization is something opted in by users based on their needs, this option should align with the same opt-in behavior.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The safe upgrade path would be to adjust your configuration and explicitly use &lt;code&gt;schema.name.adjustment.mode&lt;/code&gt; as &lt;code&gt;avro&lt;/code&gt; and use the default for new connector deployments. But you can also review your topic names and configurations, checking that no underscore substitutions are happening and ergo this change will have no impact.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra-changes&quot;&gt;Changes to Cassandra connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;cassandra_4_incremental_commit_log_support&quot;&gt;Cassandra 4 incremental commit log support&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://cassandra.apache.org/doc/latest/cassandra/operating/cdc.html&quot;&gt;Cassandra 4&lt;/a&gt; has improved the integration with CDC by adding a feature that when the fsync operation occurs, Cassandra will update a CDC-based index file to contain the latest offset values. This index file allows CDC implementations to read up to the offset that is considered durable in Cassandra.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, Debezium now uses this CDC-based index file to eliminate the inherent delay in processing CDC events from Cassandra that previously existed. This should provide Cassandra users a substantial improvement in CDC with Debezium, and gives an incentive to consider Cassandra 4 over Cassandra 3.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb-changes&quot;&gt;Changes to MongoDB connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;removal_of_the_oplog_implementation&quot;&gt;Removal of the oplog implementation&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Debezium 1.8, we introduced the new MongoDB change stream feature while also deprecating the oplog implementation. The transition to change streams offers a variety of benefits, such as being able to stream changes from non-primary nodes, the ability to emit update events with a full document representation for downstream consumers, and so much more. In short, change streams is just a much more superior way to perform change data capture with MongoDB.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The removal of the oplog implementation also means that MongoDB 3.x is no longer supported. If you are using MongoDB 3.x, you will need to upgrade to at least MongoDB 4.0 or later with Debezium 2.0.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;before_state_support_mongodb_6_0&quot;&gt;Before state support (MongoDB 6.0)&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MongoDB 6 supports capturing the state of the document before the change is applied. This has long since been a feature that has been available only to the relational-based connectors, but this now enables Debezium to also include the &lt;code&gt;before&lt;/code&gt; field as part of the event&amp;#8217;s payload for MongoDB.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To enable this new MongoDB 6+ behavior, the &lt;code&gt;capture.mode&lt;/code&gt; setting has been adjusted to include two new values:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_with_pre_image&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The change event will also contain the full document from &lt;em&gt;before&lt;/em&gt; the change as well as the final state of the document fields that were changed as a part of the change event.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_update_full_with_pre_image&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;When an update occurs, not only will the full document be present to represent the current state after the update, but the event will also contain the full document from &lt;em&gt;before&lt;/em&gt; the change as well.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MongoDB &lt;code&gt;before&lt;/code&gt; field behavior is only available on MongoDB 6 or later. If you are using a version of MongoDB before 6.0, the &lt;code&gt;before&lt;/code&gt; field is omitted from the event output, even if configured.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mysql-changes&quot;&gt;Changes to MySQL connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;legacy_mysql_implementation_removed&quot;&gt;Legacy MySQL implementation removed&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As some of you may or may not know, we implemented the MySQL connector based on the common-connector framework back in Debezium 1.5 (Feb 2021). As a part of that re-write, we introduced the ability for MySQL users to enable the legacy connector behavior using the configuration option &lt;code&gt;internal.implementation&lt;/code&gt; set as &lt;code&gt;legacy&lt;/code&gt;. This legacy implementation was deprecated in favor of the new common-connector framework behavior. With Debezium 2.0, this &lt;code&gt;internal.implementation&lt;/code&gt; configuration option and the legacy connector implementation have been removed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If your current connector deployment relies on this legacy implementation, you should be aware that by upgrading to Debezium 2.0, the connector will no longer use that older implementation and will use the common-connector implementation only. Feature-wise, both implementations are on-par with one another with one exception: the legacy implementation had experimental support for changing filter configurations. If you have relied on this legacy behavior, be aware that feature is no longer available.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;binlog_compression_support&quot;&gt;Binlog Compression Support&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, Debezium now supports reading of binlog entries that have been written with compression enabled. In version 8.0.20, MySQL adds the ability to compress binlog events using the ZSTD algorithm. To enable compression, you must toggle the &lt;code&gt;binlog.transaction_compression&lt;/code&gt; variable on the MySQL server to &lt;code&gt;ON&lt;/code&gt;. When compression is enabled, the binlog behaves as usual, except that the contents of the binlog entries are compressed to save space, and are replicated to in compressed format to replicas, significantly reducing network overhead for larger transactions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you&amp;#8217;re interested in reading more about MySQL binlog compression, you can refer to the &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/binary-log-transaction-compression.html&quot;&gt;Binary Log Transaction Compression&lt;/a&gt; section of the MySQL documentation for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle-changes&quot;&gt;Changes to Oracle connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;oracle_source_info_changes&quot;&gt;Oracle source info changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;source&lt;/code&gt; information block is a section in the change event&amp;#8217;s payload that describes the database attributes of what generated the change event. For example, this section includes the system change number, the database timestamp of the change, and the transaction the change was part of.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we identified a regression where the &lt;code&gt;scn&lt;/code&gt; field did not correctly reflect the right &lt;code&gt;source&lt;/code&gt; of where the change event occurred. While it isn&amp;#8217;t abnormal for Oracle to generate multiple changes with the same system change number, we did find a regression that caused the wrong system change number to get assigned to each individual event within a scoped transaction, which made it difficult for some to use this information for auditing purposes. The &lt;code&gt;source.scn&lt;/code&gt; field should now correctly reflect the system change number from Oracle LogMiner or Oracle Xstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Additionally, several new fields were added to the &lt;code&gt;source&lt;/code&gt; information block to improve integration with the LogMiner implementation and Oracle RAC. An example of the new source information block:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2.0.0.Alpha3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;server1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1520085154000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;6.28.807&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2122184&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2122185&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;001234.00012345.0124&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ssn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;redo_thread&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The newly added fields are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;rs_id&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the rollback segment identifier associated with the change.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;ssn&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the SQL sequence number, this combined with the &lt;code&gt;rs_id&lt;/code&gt; represent a unique tuple for a change.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;redo_thread&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the actual database redo thread that managed the change&amp;#8217;s lifecycle.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Whether using Oracle Standalone or RAC, these values will always be provided when using Oracle LogMiner. These values have more importance on an Oracle RAC installation because you have multiple database servers manipulating the shared database concurrently. These fields specifically annotate which node and at what position on that node that the change originated.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;oracle_connector_offset_changes&quot;&gt;Oracle connector offset changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In an Oracle Real Application Clusters (RAC) environment, multiple nodes access and manipulate the Oracle database concurrently. Each node maintains its own redo log buffers and executes its own redo writer thread. This means that at any given moment, each node has its own unique &quot;position&quot; and these will differ entirely on the activity that takes place on each respective node.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a small change was necessary in &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5245&quot;&gt;DBZ-5245&lt;/a&gt; to support Oracle RAC. Previously, the connector offsets maintained a field called &lt;code&gt;scn&lt;/code&gt; which represented this &quot;position&quot; of where the connector should stream changes from. But since each node could be at different positions in the redo, a single &lt;code&gt;scn&lt;/code&gt; value was inadequate for Oracle RAC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The old Oracle connector offsets looked like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1234567890&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2345678901&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lcr_position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting in Debezium 2.0, the new offset structure now has this form:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1234567890:00124.234567890.1234:0:1,1234567891:42100.0987656432.4321:0:2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2345678901&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lcr_position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You will notice that the &lt;code&gt;scn&lt;/code&gt; field now consists of a comma-separated list of values, where each entry represents a tuple of values. This new tuple has the format of &lt;code&gt;scn:rollback-segment-id:ssn:redo-thread&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This change is forward compatible, meaning that once you have upgraded to Debezium 2.0, an older version of the connector will be unable to read the offsets. If you do upgrade and decide to rollback, be aware the offsets will require manually adjusting the offset&amp;#8217;s &lt;code&gt;scn&lt;/code&gt; field to simply contain a string of the most recent &lt;code&gt;scn&lt;/code&gt; value across all redo threads.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;oracle_commit_user_in_change_events&quot;&gt;Oracle commit user in change events&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The source information block of change events carry a variety of context about where the change event originated. In this release, the Oracle connector now includes the user who made the database change in the captured change event. A new field, &lt;code&gt;user_name&lt;/code&gt;, can now be found in the source info block with this new information. This field is optional, and is only available when changes are emitted using the LogMiner-based implementation. This field may also contain the value of &lt;code&gt;UNKNOWN&lt;/code&gt; if the user associated with a change is dropped prior to the change being captured by the connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;postgres-changes&quot;&gt;Changes to PostgreSQL connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;support_for_wal2json_removed&quot;&gt;Support for wal2json removed&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Throughout Debezium&amp;#8217;s lifecycle, the PostgreSQL connector has supported multiple decoder implementations, including &lt;code&gt;decoderbufs&lt;/code&gt;, &lt;code&gt;wal2json&lt;/code&gt;, and &lt;code&gt;pgoutput&lt;/code&gt;. Both the &lt;code&gt;decoderbufs&lt;/code&gt; and &lt;code&gt;wal2json&lt;/code&gt; plugins have required special libraries to be installed on the database server to capture changes from PostgreSQL.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With PostgreSQL 9.6 marked as &lt;a href=&quot;https://www.postgresql.org/support/versioning/&quot;&gt;end of life&lt;/a&gt; in November 2021, we felt now was a great opportunity to streamline the number of supported decoders. With PostgreSQL 10 and later supporting the &lt;code&gt;pgoutput&lt;/code&gt; decoder natively, we concluded that it made sense to remove support for the &lt;code&gt;wal2json&lt;/code&gt; plugin in Debezium 2.0.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are still using PostgreSQL 9.6 or the &lt;code&gt;wal2json&lt;/code&gt; decoder, you will be required to upgrade to PostgreSQL 10+ or to either to the &lt;code&gt;decoderbufs&lt;/code&gt; or the native &lt;code&gt;pgoutput&lt;/code&gt; plugin to use Debezium going forward.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess-changes&quot;&gt;Changes to Vitess connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;multitasking_support_for_vitess&quot;&gt;Multitasking support for Vitess&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess connector previously allowed operation in two different modes that depended entirely on whether the connector configuration specified any shard details. Unfortunately in both cases, each resulted in a single task responsible for performing the VStream processing. For larger Vitess installations with many shards, this architecture could begin to show latency issues as it may not be able to keep up with all the changes across all shards. And even more complex, when specifying the shard details, this required manually resolving the shards across the cluster and starting a single Debezium connector per shard, which is both error-prone and more importantly could result in deploying many Debezium connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess community recognized this and sought to find a solution that addresses all these problems, both from a maintenance and error perspective. In Debezium 2.0 Beta2, the Vitess connector now automatically resolves the shards via a discovery mechanism, quite similar to that of MongoDB. This discovery mechanism will then split the load across multiple tasks, allowing for a single deployment of Debezium running a task per shard or shard lists, depending on the maximum number of allowed tasks for the connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During the upgrade, the Vitess connector will automatically migrate the offset storage to the new format used with the multitasking behavior. But be aware that once you&amp;#8217;ve upgraded, you won&amp;#8217;t be able to downgrade to an earlier version as the offset storage format will have changed.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;container-changes&quot;&gt;Changes for Debezium container images&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;support_for_arm64&quot;&gt;Support for ARM64&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There has been a shift in recent years with the performance of ARM64, even at AWS where their 64-bit ARM processors have projected performance over the latest x86-64 processors. This has helped put an emphasis across the industry at looking at the cost benefits of supporting both architectures with containers.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since Debezium has traditionally released &lt;code&gt;linux/amd64&lt;/code&gt; -based container images, this required that you either run the images using emulation of inside a Virtual Machine. This leads to unnecessary overhead and potential performance concerns and the goal of Debezium is low-latency and hyper speed! Starting with Debezium 2.0, Debezium is now also released using &lt;code&gt;ARM64&lt;/code&gt; -based container images, reducing the overhead needed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We hope the new ARM64 container images improve the adoption of Debezium, and show that we&amp;#8217;re committed to delivering the best change data capture experience across the industry universally.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;community-spaces&quot;&gt;Community spaces&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Later this week, there will be several new &lt;em&gt;community-driven&lt;/em&gt; discussion spaces available on our Zulip chat platform. We will be publishing a blog post that discusses the purpose of these new channels and their goals, but we wanted to also include a note here about this new feature.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Unlike the &lt;code&gt;#users&lt;/code&gt; channel that is meant to provide community-driven support, these spaces are meant to provide a place for the community to discuss experiences with specific database technologies, Debezium services, and topics that are substantially broader than just support. These spaces will be divided by technology, allowing the user community to target specific areas of interest easily, and engage in discussions that pertain to specific databases and services.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These spaces are not meant to be support venues, we will still expect those to continue to foster in the &lt;code&gt;#users&lt;/code&gt; channel going forward, so keep an eye out for these new community spaces later this week and the blog to follow.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were many bugfixes, stability changes, and improvements throughout the development of Debezium 2.0. Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(2.0.0.Alpha1%2C%202.0.0.Alpha2%2C%202.0.0.Alpha3%2C%202.0.0.Beta1%2C%202.0.0.Beta2%2C%202.0.0.CR1%2C%202.0.0.Final)%20ORDER%20BY%20component%20ASC&quot;&gt;463 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this major release: Wang Min Chao, Rotem[Adhoh], &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed ELJAMI&lt;/a&gt;, &lt;a href=&quot;https://github.com/almartino&quot;&gt;Alberto Martino&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/aloubyansky&quot;&gt;Alexey Loubyansky&lt;/a&gt;, &lt;a href=&quot;https://github.com/AlexMiroshnikov&quot;&gt;Alexey Miroshnikov&lt;/a&gt;, Gabor[Andras], &lt;a href=&quot;https://github.com/ajunwalker&quot;&gt;Andrew Walker&lt;/a&gt;, &lt;a href=&quot;https://github.com/jchipmunk&quot;&gt;Andrey Pustovetov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/avis408&quot;&gt;Avinash Vishwakarma&lt;/a&gt;, &lt;a href=&quot;https://github.com/xinbinhuang&quot;&gt;Bin Huang&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/bmorganpa&quot;&gt;Brad Morgan&lt;/a&gt;, &lt;a href=&quot;https://github.com/calinilie&quot;&gt;Calin Laurentiu Ilie&lt;/a&gt;, &lt;a href=&quot;https://github.com/chadthman&quot;&gt;Chad Marmon&lt;/a&gt;, &lt;a href=&quot;https://github.com/ProofOfPizza&quot;&gt;Chai Stofkoper&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/Chrisss93&quot;&gt;Chris Lee&lt;/a&gt;, &lt;a href=&quot;https://github.com/davsclaus&quot;&gt;Claus Ibsen&lt;/a&gt;, &lt;a href=&quot;https://github.com/connorszczepaniak-wk&quot;&gt;Connor Szczepaniak&lt;/a&gt;, &lt;a href=&quot;https://github.com/cmartinez-enve&quot;&gt;César Martínez&lt;/a&gt;, &lt;a href=&quot;https://github.com/debjeetsarkar&quot;&gt;Debjeet Sarkar&lt;/a&gt;, Mikhail[Dubrovin], &lt;a href=&quot;https://github.com/elirag&quot;&gt;Eliran Agranovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/EthanZ328&quot;&gt;Ethan Zou&lt;/a&gt;, &lt;a href=&quot;https://github.com/ezerk&quot;&gt;Ezer Karavani&lt;/a&gt;, &lt;a href=&quot;https://github.com/ggaborg&quot;&gt;Gabor Andras&lt;/a&gt;, &lt;a href=&quot;https://github.com/giljae&quot;&gt;Giljae Joo&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/ruanhang1993&quot;&gt;Hang Ruan&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/Himanshu-LT&quot;&gt;Himanshu Mishra&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/nicholas-fwang&quot;&gt;Inki Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/domsj&quot;&gt;Jan Doms&lt;/a&gt;, &lt;a href=&quot;https://github.com/DerGut&quot;&gt;Jannik Steinmann&lt;/a&gt;, &lt;a href=&quot;https://github.com/jerrinot&quot;&gt;Jaromir Hamala&lt;/a&gt;, &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/joschi&quot;&gt;Jochen Schalanda&lt;/a&gt;, &lt;a href=&quot;https://github.com/yannickzj&quot;&gt;Jun Zhao&lt;/a&gt;, &lt;a href=&quot;https://github.com/kanha-gupta&quot;&gt;Kanha Gupta&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/LarsWerkman&quot;&gt;Lars Werkman&lt;/a&gt;, &lt;a href=&quot;https://github.com/winklerm&quot;&gt;Marek Winkler&lt;/a&gt;, &lt;a href=&quot;https://github.com/markallanson&quot;&gt;Mark Allanson&lt;/a&gt;, &lt;a href=&quot;https://github.com/alwaysbemark&quot;&gt;Mark Bereznitsky&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/mimaison&quot;&gt;Mickael Maison&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/yzia2000&quot;&gt;Mohammad Yousuf Minhaj Zia&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-bradshaw-at&quot;&gt;Nathan Bradshaw&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/nilshartmann&quot;&gt;Nils Hartmann&lt;/a&gt;, &lt;a href=&quot;https://github.com/nirolevy&quot;&gt;Nir Levy&lt;/a&gt;, &lt;a href=&quot;https://github.com/nitinitt&quot;&gt;Nitin Chhabra&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/ypt&quot;&gt;Paul Tzen&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/smallYellowCat&quot;&gt;Pengwei Dou&lt;/a&gt;, &lt;a href=&quot;https://github.com/thangdc94&quot;&gt;Phạm Ngọc Thắng&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, Oskar[Polak], &lt;a href=&quot;https://github.com/rahulkhanna2&quot;&gt;Rahul Khanna&lt;/a&gt;, &lt;a href=&quot;https://github.com/rajdangwal&quot;&gt;Rajendra Dangwal&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/druud&quot;&gt;Ruud H.G. van Tol&lt;/a&gt;, &lt;a href=&quot;https://github.com/sagarrao12&quot;&gt;Sagar Rao&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sage-Pierce&quot;&gt;Sage Pierce&lt;/a&gt;, &lt;a href=&quot;https://github.com/jaegwonseo&quot;&gt;Seo Jae-kwon&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/tim-patterson&quot;&gt;Tim Patterson&lt;/a&gt;, &lt;a href=&quot;https://github.com/troeselereos&quot;&gt;Timo Roeseler&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/xinbinhuang&quot;&gt;Xinbin Huang&lt;/a&gt;, &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, &lt;a href=&quot;https://github.com/GOODBOY008&quot;&gt;Zhongqiang Gong&lt;/a&gt;, &lt;a href=&quot;https://github.com/gmouss&quot;&gt;moustapha mahfoud&lt;/a&gt;, &lt;a href=&quot;https://github.com/yangrong688&quot;&gt;yangrong688&lt;/a&gt;, &lt;a href=&quot;https://github.com/BetaCat0&quot;&gt;合龙 张&lt;/a&gt;, &lt;a href=&quot;https://github.com/comil4444&quot;&gt;崔世杰&lt;/a&gt;, and &lt;a href=&quot;https://github.com/pkgonan&quot;&gt;민규 김&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While we are heading into the holiday season, we have started the work on Debezium 2.1, which will be out later this year. Some potential features you can expect include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Truncate support for MySQL&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;PostgreSQL 15 support&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;JDBC history and offset storage support&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, this roadmap is heavily influenced by the community, i.e. you. So if you would like to see any particular items here, please let us know. For now, lets celebrate the hard work in the release of Debezium 2.0 and look forward to what&amp;#8217;s coming later this year and in 2023!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Onwards and Upwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="mongodb"/><summary type="html">Today it&amp;#8217;s my great pleasure to announce the availability of Debezium 2.0.0.Final! Since our 1.0 release in December 2019, the community has worked vigorously to build a comprehensive open-source low-latency platform for change data capture (CDC). Over the past three years, we have extended Debezium&amp;#8217;s portfolio to include a stable connector for Oracle, a community led connector for Vitess, the introduction of incremental snapshots, multi-partition support, and so much more. With the help of our active community of contributors and committers, Debezium is the de facto leader in the CDC space, deployed to production within lots of organizations from across multiple industries, using hundreds of connectors to stream data changes out of thousands of database platforms. The 2.0 release marks a new milestone for Debezium, one that we are proud to share with each of you.</summary></entry><entry><title type="html">Debezium 2.0.0.CR1 Released</title><link href="https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.CR1 Released"/><published>2022-10-10T00:00:00+00:00</published><updated>2022-10-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am excited to announce the release of Debezium &lt;strong&gt;2.0.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release contains breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.CR1%20ORDER%20BY%20component%20ASC&quot;&gt;53 issues&lt;/a&gt; that were fixed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you intend to upgrade to 2.0.0.CR1, we strongly recommend that you read the release notes before the upgrade to understand all breaking changes. There was one noteworthy breaking changes with the 2.0.0.CR1 release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[breaking] &lt;a href=&quot;#schema-name-adjustment-mode&quot;&gt;Behavior of &lt;code&gt;schema.name.adjustment.mode&lt;/code&gt; has changed&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;schema-name-adjustment-mode&quot;&gt;Behavior of schema.name.adjustment.mode has changed&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;schema.name.adjustment.mode&lt;/code&gt; configuration property controls how schema names should be adjusted for compatibility with the message converter used by the connector. This configuration option can be one of two values:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;avro&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Repliaces the characters that cannot be used in the Avro type name with an underscore.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;none&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Does not adjust the names, even when non-Avro compliant characters are detected.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In prior releases, Debezium always defaulted to the safe value of &lt;code&gt;avro&lt;/code&gt;; however, starting with Debezium 2.0.0.CR1 the default value will now be &lt;code&gt;none&lt;/code&gt;. We believe that given that the use of Avro serialization is something opted in by users based on their needs, this option should align with the same opt-in behavior.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The safe upgrade path would be to adjust your configuration and explicitly use &lt;code&gt;schema.name.adjustment.mode&lt;/code&gt; as &lt;code&gt;avro&lt;/code&gt; and use the default for new connector deployments. But you can also review your topic names and configurations, checking that no underscore substitutions are happening and ergo this change will have no impact.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_6_0_before_state_support&quot;&gt;MongoDB 6.0 - before state support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MongoDB 6 supports capturing the state of the document before the change is applied. This has long since been a feature that has been available only to the relational-based connectors, but this now enables Debezium to also include the &lt;code&gt;before&lt;/code&gt; field as part of the event&amp;#8217;s payload for MongoDB.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To enable this new MongoDB 6+ behavior, the &lt;code&gt;capture.mode&lt;/code&gt; setting has been adjusted to include two new values:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_with_pre_image&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The change event will also contain the full document from &lt;em&gt;before&lt;/em&gt; the change as well as the final state of the document fields that were changed as a part of the change event.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_update_full_with_pre_image&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;When an update occurs, not only will the full document be present to represent the current state after the update, but the event will also contain the full document from &lt;em&gt;before&lt;/em&gt; the change as well.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MongoDB &lt;code&gt;before&lt;/code&gt; field behavior is only available on MongoDB 6 or later. If you are using a version of MongoDB before 6.0, the &lt;code&gt;before&lt;/code&gt; field is omitted from the event output, even if configured.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are many bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Implement retries for Debezium embedded engine &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4629&quot;&gt;DBZ-4629&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Traditional snapshot process setting source.ts_ms &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5591&quot;&gt;DBZ-5591&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade Kafka client to 3.3.1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5600&quot;&gt;DBZ-5600&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support READ ONLY/ENCRYPTION options for alter database statment &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5622&quot;&gt;DBZ-5622&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Clarify semantics of include/exclude options &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5625&quot;&gt;DBZ-5625&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Added support for Mongo pre-image in change stream &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5628&quot;&gt;DBZ-5628&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for using any expression in kill statements &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5636&quot;&gt;DBZ-5636&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Db2 Connector fails to handle default values in schema when is making the snapshot &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4990&quot;&gt;DBZ-4990&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector parsing SELECT_LOB_LOCATOR event missing constant &lt;code&gt;unavailable.value.placeholder&lt;/code&gt; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5581&quot;&gt;DBZ-5581&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Starting Embedded Engine swallows ClassNotFoundException so user cannot see why engine does not work &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5583&quot; class=&quot;bare&quot;&gt;https://issues.redhat.com/browse/DBZ-5583&lt;/a&gt;[DBZ-558&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hardcoded driver task properties are not being passed to underlying connections &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5670&quot;&gt;DBZ-5670&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MongoDB Connector with DocumentDB errors with &quot;{$natural: -1} is not supported&quot; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5677&quot;&gt;DBZ-5677&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade apicurio to 2.2.5.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5549&quot;&gt;DBZ-5549&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade binary log client to 0.27.2 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5620&quot;&gt;DBZ-5620&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Beta2%20ORDER%20BY%20component%20ASC&quot;&gt;53 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, Gabor Andras, &lt;a href=&quot;https://github.com/avis408&quot;&gt;Avinash Vishwakarma&lt;/a&gt;, &lt;a href=&quot;https://github.com/xinbinhuang&quot;&gt;Bin Huang&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/ezerk&quot;&gt;Ezer Karavani&lt;/a&gt;, &lt;a href=&quot;https://github.com/ggaborg&quot;&gt;Gabor Andras&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jerrinot&quot;&gt;Jaromir Hamala&lt;/a&gt;, &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/nirolevy&quot;&gt;Nir Levy&lt;/a&gt;, &lt;a href=&quot;https://github.com/rajdangwal&quot;&gt;Rajendra Dangwal&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sage-Pierce&quot;&gt;Sage Pierce&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/xinbinhuang&quot;&gt;Xinbin Huang&lt;/a&gt;, and &lt;a href=&quot;https://github.com/gmouss&quot;&gt;moustapha mahfoud&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the release of Debezium 2.0 CR1, the release of 2.0.0.Final is just around the corner. The community should expect the Final release soon, barring any bug reports. In addition, we are also working on wrapping up the last installation of the 1.9 release stream, 1.9.7.Final which should will be released toward the end of this month.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the holiday season fast approaching, we will soon begin work on Debezium 2.1. We do intend to have a normal release cycle this quarter despite being behind on Debezium 2.0, so expect that sometime just before the end of the year.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the meantime, happy capturing!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="mongodb"/><summary type="html">I am excited to announce the release of Debezium 2.0.0.CR1! This release contains breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of 53 issues that were fixed.</summary></entry><entry><title type="html">Debezium for Oracle - Part 2: Running the connector</title><link href="https://debezium.io/blog/2022/10/06/debezium-oracle-series-part-2/" rel="alternate" type="text/html" title="Debezium for Oracle - Part 2: Running the connector"/><published>2022-10-06T12:00:00+00:00</published><updated>2022-10-06T12:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/06/debezium-oracle-series-part-2</id><content type="html" xml:base="https://debezium.io/blog/2022/10/06/debezium-oracle-series-part-2/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This post is part of a 3-part series to explore using Debezium to ingest changes from an Oracle database using Oracle LogMiner. In case you missed it, the first part of this series is &lt;a href=&quot;/blog/2022/09/30/debezium-oracle-series-part-1/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this second installment, we will build on what we did in part one by deploying the Oracle connector using Zookeeper, Kafka, and Kafka Connect. We are going to discuss a variety of configuration options for the connector and why they&amp;#8217;re essential. And finally, we&amp;#8217;re going to see the connector in action!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;setting_up_kafka_connect_and_prerequisites&quot;&gt;Setting up Kafka Connect and prerequisites&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use Debezium, three separate services need to be started:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#start-zookeeper&quot;&gt;Zookeeper&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#start-kafka&quot;&gt;Kafka broker&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#start-kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will use &lt;a href=&quot;https://www.docker.com&quot;&gt;Docker&lt;/a&gt; containers to run the above services. Using separate containers simplifies the deployment process so you can see Debezium in action. In addition, we will also download the &lt;a href=&quot;#download-oracle-jdbc-driver&quot;&gt;Oracle JDBC driver&lt;/a&gt; and mount it as part of the Kafka Connect container.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using multiple instances of these services in production provides performance, reliability, and fault tolerance. The deployment would typically involve a platform like OpenShift or Kubernetes to manage multiple containers, or you would use dedicated hardware and manage this manually.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For this blog, we will use a single instance of each service to keep it simple.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Zookeeper and Kafka containers are ephemeral. Typically, volumes would be mounted on the host machine so that when the container stops, data managed by the container persists. For the sake of simplicity, we are skipping this step so that when the container stops, data is lost.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;start-zookeeper&quot;&gt;Prerequisites: Starting Zookeeper&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Zookeeper service is the first service that&amp;#8217;s started. The Kafka broker uses Zookeeper to handle the leadership election of Kafka brokers and manages the service discovery within the cluster so that each broker knows when a sibling has joined or left when a broker terminates, and whom the new leader is for a given topic/partition tuple.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Open a new terminal window and run the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;docker run -it --rm --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 \ quay.io/debezium/zookeeper:1.9&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;em&gt;zookeeper&lt;/em&gt; container is started in interactive mode and destroyed when stopped. The container is named &lt;code&gt;zookeeper&lt;/code&gt;, which will be important when starting future containers.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;start-kafka&quot;&gt;Prerequisites: Starting Kafka&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Kafka service is the second service that must be started and depends on the Zookeeper service. Debezium produces change events sent to topics managed by the Kafka broker.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Open a new terminal window and run the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;docker run -it --rm --name kafka -p 9092:9092 --link zookeeper:zookeeper \ quay.io/debezium/kafka:1.9&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;em&gt;kafka&lt;/em&gt; container is started in interactive mode and destroyed when stopped. The container is named &lt;code&gt;kafka&lt;/code&gt;, which will be important starting future containers. Additionally, the &lt;em&gt;kafka&lt;/em&gt; service also links to the &lt;em&gt;zookeeper&lt;/em&gt; service, meaning that the canonical name &lt;code&gt;zookeeper&lt;/code&gt; will resolve to the container running the &lt;em&gt;zookeeper&lt;/em&gt; service.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;download-oracle-jdbc-driver&quot;&gt;Prerequisites: Download Oracle JDBC driver&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium Kafka Connect image does not ship with the Oracle JDBC driver. To use Debezium for Oracle, the JDBC driver must be manually downloaded and mounted into the Debezium Kafka Connect image.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Navigate to the &lt;a href=&quot;https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html&quot;&gt;Oracle Database JDBC driver&lt;/a&gt; downloads page. At the time of this publication, the latest Oracle database is Oracle 21, so click on the &lt;code&gt;ojdbc8.jar&lt;/code&gt; link under the Oracle 21c section. The downloaded jar will be used in the next section, adding the driver to the base image of Debezium&amp;#8217;s Kafka Connect container.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;start-kafka-connect&quot;&gt;Prerequisites: Starting Kafka Connect&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Kafka Connect service is the third and final service that must be started and depends on the Kafka service. Kafka Connect is responsible for managing all connectors and their related workloads and is the runtime environment accountable for running the Debezium Connector for Oracle when we deploy it shortly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Open a new terminal window and run the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;docker run -it --rm --name connect -p 8083:8083 \ -e GROUP_ID=1 \ -e CONFIG_STORAGE_TOPIC=my_connect_configs \ -e OFFSET_STORAGE_TOPIC=my_connect_offsets \ -e STATUS_STORAGE_TOPIC=my_connect_statuses \ --link kafka:kafka \ --link dbz_oracle21:dbz_oracle21 \ -v /path/to/ojdbc8.jar:/kafka/libs/ojdbc8.jar \ quay.io/debezium/connect:1.9&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;em&gt;connect&lt;/em&gt; container is started in interactive mode and destroyed when stopped. The container is named &lt;code&gt;connect&lt;/code&gt;, and several environment variables control the naming of several required topics and some required configuration parameters. Additionally, the &lt;em&gt;connect&lt;/em&gt; container links to the &lt;em&gt;kafka&lt;/em&gt; container, meaning that the canonical name &lt;code&gt;kafka&lt;/code&gt; will resolve to the container running the &lt;em&gt;kafka&lt;/em&gt; broker service.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Unlike prior containers, we mount a volume using the &lt;code&gt;-v&lt;/code&gt; command. The argument takes the format of &lt;code&gt;local-path:container-path&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;em&gt;local-path&lt;/em&gt; represents where the &lt;code&gt;ojdbc8.jar&lt;/code&gt; file exists on the host machine. The &lt;em&gt;container-path&lt;/em&gt; should remain &lt;code&gt;/kafka/libs/ojdbc8.jar&lt;/code&gt;, installing the driver on the Kafka Connect classpath.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;create_some_initial_test_data&quot;&gt;Create some initial test data&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If the Oracle database created in part one of this series uses the Oracle container registry image, no initial data exists in the database. While this doesn&amp;#8217;t necessarily present a problem, we&amp;#8217;d ideally like to snapshot some data when deploying the Oracle connector; ergo, some initial data must exist before deployment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In a new terminal, let&amp;#8217;s connect to the database using SQL*Plus and create a new table with some initial data. The following uses the common user, connecting to the pluggable database &lt;code&gt;ORCLPDB1&lt;/code&gt;. You can safely skip this step when connecting to an existing environment with tables to be captured.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;docker exec -it -e ORACLE_SID=ORCLPDB1 dbz_oracle21 sqlplus c##dbzuser@ORCLPDB1&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once connected, use the following SQL to create a table and some initial data:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; customers (id number(&lt;span class=&quot;integer&quot;&gt;9&lt;/span&gt;,&lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;directive&quot;&gt;primary&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;key&lt;/span&gt;, name &lt;span class=&quot;predefined-type&quot;&gt;varchar2&lt;/span&gt;(&lt;span class=&quot;integer&quot;&gt;50&lt;/span&gt;)); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; customers &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Salles Thomas&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; customers &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1002&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;George Bailey&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; customers &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1003&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Edward Walker&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; customers &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1004&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Anne Kretchmar&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;COMMIT&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, the redo logs only capture minimal information about changes in the &lt;code&gt;CUSTOMERS&lt;/code&gt; table because supplemental logging is set only at the database level.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are familiar with PostgreSQL&amp;#8217;s &lt;code&gt;REPLICA IDENTITY&lt;/code&gt; or MySQL&amp;#8217;s &lt;code&gt;binlog_format&lt;/code&gt;, Oracle provides a similar mechanism called table-level supplemental logging, which we mentioned in part one of this series. Supplemental logging at the table level controls the columns captured in the redo logs when users modify rows. Setting the table&amp;#8217;s supplemental log level to &lt;code&gt;(ALL) COLUMNS&lt;/code&gt; guarantees that Oracle captures changes associated with &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, and &lt;code&gt;DELETE&lt;/code&gt; operations in the redo logs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Use the following SQL to set the table&amp;#8217;s supplemental log level:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; customers &lt;span class=&quot;class&quot;&gt;ADD&lt;/span&gt; SUPPLEMENTAL LOG DATA (&lt;span class=&quot;keyword&quot;&gt;ALL&lt;/span&gt;) &lt;span class=&quot;type&quot;&gt;COLUMNS&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Suppose a captured table&amp;#8217;s supplemental log level is incorrectly set. In that case, the connector will log a warning letting you know there is a problem so that you can adjust the table&amp;#8217;s settings to capture all changes.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It is worth pointing out that while this example uses the same user account to create this &lt;code&gt;CUSTOMERS&lt;/code&gt; table that the connector uses to connect, it&amp;#8217;s not at all uncommon for the user used by the connector to differ from the user who owns the tables in the Oracle database. In this case, the connector user must have permission to read the captured tables, requiring the &lt;code&gt;SELECT&lt;/code&gt; permission per table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;deploying_the_oracle_connector&quot;&gt;Deploying the Oracle connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are now ready to deploy the Debezium Oracle connector. Before registering the connector with Kafka Connect, let&amp;#8217;s look at the configuration in-depth.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Below is a sample configuration we will use in this example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight nowrap&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers-connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector.class&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.oracle.OracleConnector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tasks.max&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.hostname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbz_oracle21&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.port&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1521&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.user&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;c##dbzuser&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.password&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbz&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.dbname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ORCLCDB&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.pdb.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ORCLPDB1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.server.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;server1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;C##DBZUSER.CUSTOMERS&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.history.kafka.bootstrap.servers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;kafka:9092&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.history.kafka.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema-changes&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a dive into what each of these configuration options mean.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;name&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the name assigned to the connector, which must be unique across the Kafka connect cluster.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;connector.class&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the class implementation of the deployed connector. Each of the Debezium source connectors have a unique class name to identify which connector is being deployed.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;tasks.max&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the maximum number of tasks that will be assigned to the connector deployment in Kafka Connect. Most Debezium connectors read changse from the source database sequentially, therefore, a value of &lt;code&gt;1&lt;/code&gt; often makes sense.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.hostname&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the database hostname or IP address. Since we specified a link to &lt;code&gt;dbz_oracle21&lt;/code&gt; container when starting Kafka Connect, we can use that name here to identify the container running the Oracle database. If you have a pre-existing Oracle environment on another host, specify the name of that host in this configuration property.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.port&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the port the database uses to listen for connections. Oracle&amp;#8217;s default port is &lt;code&gt;1521&lt;/code&gt; but a database administrator can configure this to be any available port. If you are connecting to a pre-existing Oracle instance, use the port the database uses.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.user&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the database user account used for JDBC connections. This should be the common user created in part one of this series, the &lt;code&gt;c##dbzuser&lt;/code&gt; user. If you are connecting to an environment that doesn&amp;#8217;t support multi-tenancy, this will be the user you created in the root database without the common-user prefix.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.password&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the database user account password.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.dbname&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the database service that the connector communications with. Regardless of whether multi-tenancy is enabled or not, this will always be the singular or root container database.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.pdb.name&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the optional pluggable database system identifier. This property must be provided when connecting to a database that supports multi-tenancy and refers to the PDB. If this field is omitted, the connector assumes the database does not support multi-tenancy.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.server.name&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The prefix used for all topics created by the connector. This value must be unique across all topic deployments within the Kafka Connect cluster.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;table.include.list&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;A comma-separated list of regular expression or simple table names using the format of &lt;code&gt;&amp;lt;schema&amp;gt;.&amp;lt;table&amp;gt;&lt;/code&gt; identifying what tables will be captured by the connector.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.history.kafka.bootstrap.servers&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the URL to the Kafka broker where the database history topic will be stored. Since we specified a link to &lt;code&gt;kafka&lt;/code&gt; container when starting Kafka Connect, we can use that name here to point to the broker and its port.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;database.history.kafka.topic&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This is the name of the topic that will store the database schema history. This topic will be recovered when the connector restarts, populating the in-memory relational model from this topic.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;All Debezium connectors, except PostgreSQL, use a schema history to store the schemas of all tables. This is often not ideal for Oracle databases, especially when deploying the connector without multi-tenancy.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To restrict the storage to only tables in the include list, modify the connector&amp;#8217;s configuration by setting the &lt;code&gt;database.history.store.only.captured.tables.ddl&lt;/code&gt; property to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For more information on other connector properties, you can review the Oracle &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-connector-properties&quot;&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To deploy the connector, save the above configuration to a file called &lt;code&gt;register-oracle.json&lt;/code&gt;. Now, open a new terminal window and use the &lt;code&gt;curl&lt;/code&gt; command to register the connector with Kafka Connect:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; \ -H &amp;quot;Content-Type:application/json&amp;quot; \ localhost:8083/connectors \ -d @register-oracle.json&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If the registration is successful, the terminal where the &lt;em&gt;connect&lt;/em&gt; container is running will start performing a snapshot of the data in the &lt;code&gt;CUSTOMERS&lt;/code&gt; table. We can also confirm that the data exists in Kafka by using the Kafka console consumer tool and reading the topic&amp;#8217;s contents to the local terminal.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To check the contents of the topic, use the same terminal where the connector was registered and execute the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;docker exec -it kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server 0.0.0.0:9092 \ --from-beginning \ --property print.key=true \ --topic server1.C__DBZUSER.CUSTOMERS&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic converts the schema name from &lt;code&gt;C##DBZUSER&lt;/code&gt; to &lt;code&gt;C__DBZUSER&lt;/code&gt; because the topic naming strategy automatically guarantees that the topic&amp;#8217;s name is compatible with Avro, which does not allow the hash sign character.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The output of the above command should look similar to the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:{ &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;before&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1001&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Salles Thomas&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.9.6.Final&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;server1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;integer&quot;&gt;1665102121000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ORCLPDB1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;C##DBZUSER&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;CUSTOMERS&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2868546&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lcr_position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ssn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;redo_thread&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;integer&quot;&gt;1665102126961&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;:&lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } } &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can now use the SQLPlus terminal where you created the initial test data to &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, or &lt;code&gt;DELETE&lt;/code&gt; records within the &lt;code&gt;CUSTOMERS&lt;/code&gt; table. You will see corresponding change events in the terminal that is presently tailing the &lt;code&gt;server1.C__DBZUSER.CUSTOMERS&lt;/code&gt; topic.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Be mindful that SQLPlus does not enable &lt;code&gt;auto-commit&lt;/code&gt; by default, so be sure that you automatically commit changes when you change data in the &lt;code&gt;CUSTOMERS&lt;/code&gt; table so that it will be visible to the connector&amp;#8217;s mining process.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During part one of this series, we discussed what Oracle is, why it&amp;#8217;s so popular in the database world, and how to install and configure the database. During this part of the series, we&amp;#8217;ve discussed how to install all the prerequisite services, including Zookeeper, Apache Kafka, and Apache Kafka Connect. In addition, we have also deployed a sample Oracle connector captured changes for the &lt;code&gt;CUSTOMERS&lt;/code&gt; table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next part of this series, I will discuss performance, how to monitor the connector, and the most critical metrics and why they are essential. We may even build a small dashboard with metrics.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="debezium"/><category term="oracle"/><category term="examples"/><summary type="html">This post is part of a 3-part series to explore using Debezium to ingest changes from an Oracle database using Oracle LogMiner. In case you missed it, the first part of this series is here. In this second installment, we will build on what we did in part one by deploying the Oracle connector using Zookeeper, Kafka, and Kafka Connect. We are going to discuss a variety of configuration options for the connector and why they&amp;#8217;re essential. And finally, we&amp;#8217;re going to see the connector in action!</summary></entry><entry><title type="html">Debezium for Oracle - Part 1: Installation and Setup</title><link href="https://debezium.io/blog/2022/09/30/debezium-oracle-series-part-1/" rel="alternate" type="text/html" title="Debezium for Oracle - Part 1: Installation and Setup"/><published>2022-09-30T12:00:00+00:00</published><updated>2022-09-30T12:00:00+00:00</updated><id>https://debezium.io/blog/2022/09/30/debezium-oracle-series-part-1</id><content type="html" xml:base="https://debezium.io/blog/2022/09/30/debezium-oracle-series-part-1/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This post is part of a 3-part series to explore using Debezium to ingest changes from an Oracle database using Oracle LogMiner. Throughout the series, we&amp;#8217;ll examine all the steps to setting up a proof of concept (POC) deployment for Debezium for Oracle. We will discuss setup and configurations as well as the nuances of multi-tenancy. We will also dive into any known pitfalls and concerns you may need to know and how to debug specific problems. And finally, we&amp;#8217;ll talk about performance and monitoring to maintain a healthy connector deployment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Throughout this exercise, we hope that this will show you just how simple it is to deploy Debezium for Oracle. This installation and setup portion of the series may seem quite complicated, but many of these steps likely already exist in a pre-existing environment. We will dive into each step, explaining it is essential should you use a container image deployment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So without any further delay, let&amp;#8217;s dive right in!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;what_is_oracle&quot;&gt;What is Oracle?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As ironic as the question may seem, some people may not know what an Oracle database is. An Oracle database is a relational database management system (RBDMS), a database that stores and provides access to data points that are often related. The database is developed and marketed by Oracle Corporation and is one of the most trusted and widely used relational database engines in the market, providing a scalable relational database architecture.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;An Oracle database consists of a collection of schemas that represent a collection of logical structures of data or schema objects. A schema object can be anything from a trigger, view, table, data type, sequence, procedure, function, and others. Furthermore, Oracle 12 introduced a multi-tenant architecture, allowing a single database instance to function as a multi-tenant container database (CDB) that houses zero, one, or many customer-created pluggable databases (PDBs).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The goal, install an Oracle database, connect Debezium to Oracle, and convert ingested changes into change events stored in Apache Kafka.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;install-oracle&quot;&gt;Installing Oracle&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To get started, we will need a running Oracle database environment. One of the easiest ways to do this is to use &lt;a href=&quot;https://www.docker.com&quot;&gt;Docker&lt;/a&gt; by deploying a container running the Oracle database. Oracle has published such containers in their &lt;a href=&quot;https://container-registry.oracle.com/&quot;&gt;container registry&lt;/a&gt;, allowing anyone to run the database and test-drive it.the dat You can skip this section if you intend to ingest changes from an existing Oracle database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle container images are all pre-built using Oracle with multi-tenancy. This means we will follow the setups according to a multi-tenant architecture. Some minor adjustments may be needed if you&amp;#8217;re using an installation that does not use multi-tenancy.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For this exercise, we&amp;#8217;re going to use &lt;a href=&quot;https://container-registry.oracle.com/ords/f?p=113:4:11477241761337:::4:P4_REPOSITORY,AI_REPOSITORY,AI_REPOSITORY_NAME,P4_REPOSITORY_NAME,P4_EULA_ID,P4_BUSINESS_AREA_ID:9,9,Oracle%20Database%20Enterprise%20Edition,Oracle%20Database%20Enterprise%20Edition,1,0&amp;amp;cs=318vPzAxLqFaC2tslO9ao27bihoUQ6MP-WvtaqYfx_ifILYwLl_2hLJU5hG8HeJv8G5w9JXbcv4i-DZD7zgTDtg&quot;&gt;this container image&lt;/a&gt;. Using &lt;code&gt;docker pull&lt;/code&gt;, the image is pulled after authenticating with the Oracle container registry using the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;docker pull container-registry.oracle.com/database/enterprise:latest&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To start the container, use the &lt;code&gt;docker run&lt;/code&gt; command. Several environment variables, such as the database SID, pluggable database name, and password, are required since the database container image must first install the Oracle database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;docker run -d \ --name dbz_oracle21 \ -p 1521:1521 \ -e ORACLE_SID=ORCLCDB \ -e ORACLE_PDB=ORCLPDB1 \ -e ORACLE_PWD=oraclepw \ container-registry.oracle.com/database/enterprise:latest&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;ORACLE_SID&lt;/code&gt; refers to the system/service ID used to identify the database. Since we are using multi-tenancy, we will use the name &lt;code&gt;ORCLCDB&lt;/code&gt; to represent the &lt;em&gt;container database&lt;/em&gt;, or CDB. In Oracle&amp;#8217;s multi-tenant architecture, the &lt;code&gt;ORACLE_PDB&lt;/code&gt; refers to the system/service ID used to identify the &lt;em&gt;pluggable database&lt;/em&gt;, or PDB. And finally, the &lt;code&gt;ORACLE_PWD&lt;/code&gt; refers to the password used for the &lt;code&gt;SYS&lt;/code&gt; and &lt;code&gt;SYSTEM&lt;/code&gt; users, which we&amp;#8217;ll use later.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The container will persist data to database files on the container&amp;#8217;s filesystem. The data will be lost when removing the container. To persist the data outside the container, please refer to the Oracle registry&amp;#8217;s README to understand how to set a volume on the &lt;code&gt;docker run&lt;/code&gt; command.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We explicitly started the docker container as a daemon, a background process. If you wish to see what is happening within the container, you can use the command &lt;code&gt;docker logs -f dbz_oracle21&lt;/code&gt; to tail the container&amp;#8217;s database log.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the next few minutes, the database will be configured and installed inside the container, which happens when a new container starts and no initial configuration and database exists. You will know whether the installation was successful by looking for a banner in the logs that would look similar to the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;######################### DATABASE IS READY TO USE! #########################&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At this point, the installation has concluded, and it&amp;#8217;s safe to move on to the next section.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configuring_oracle&quot;&gt;Configuring Oracle&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Several database configurations are necessary to ingest changes from an Oracle database. If you are using a pre-existing environment, you may be able to skip some of these steps.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following configurations are necessary:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#configure-oracle-archive-logs&quot;&gt;Archive logs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#configure-oracle-redo-logs&quot;&gt;Redo logs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#configure-oracle-logging&quot;&gt;Supplemental logging&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#configure-oracle-users&quot;&gt;Users and tablespaces/schemas in CDB and PDB&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;configure-oracle-archive-logs&quot;&gt;Configure Oracle: Archive logs&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle saves filled groups of redo logs (the database transaction logs) to one or more offline destinations, collectively known as the archived redo log or the archive logs. Changes main in a primary database are replicated to logical or physical standby environments using archive logs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A log switch happens when a redo log fills up and is archived. Debezium ingests changes across both redo and archive logs. Debezium requires access to the archive log to finish processing redo entries when the redo log is archived.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle container registry image used in the &lt;a href=&quot;#install_oracle&quot;&gt;Install Oracle&lt;/a&gt; section does not have archive logging enabled. If you use another image or a pre-existing environment, you must check whether archive logging is enabled. To check the status, use the &lt;code&gt;SYS&lt;/code&gt; user and the password defined during the installation for &lt;code&gt;ORACLE_PWD&lt;/code&gt; to connect to the &lt;code&gt;ORCLCDB&lt;/code&gt; database and execute the following query:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;SELECT LOG_MODE FROM V$DATABASE&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If the column contains &lt;code&gt;ARCHIVELOG&lt;/code&gt;, then archive logging is enabled. If the column contains the value &lt;code&gt;NOARCHIVELOG&lt;/code&gt;, archive logging isn&amp;#8217;t enabled, and further configuration is necessary.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When setting up the Oracle archive log, not only do we need to enable the logging feature, but we&amp;#8217;ll also need to specify a location on the disk to store the logs. If you are using a pre-existing environment, you will need to consult with your database administrator for this. Most database servers store archive log files using special paths, and you will need to know if Oracle Automatic Storage Management (ASM) is used or what volume has adequate space on the database server.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s open a terminal to the Oracle database container. We want to connect to the database container using SQL*Plus to use a client that allows easy unmounting and restarting of the database. So in a new terminal, execute:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;docker exec -it dbz_oracle21 -e ORACLE_SID=ORCLCDB sqlplus sys as sysdba&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you connect to an existing Oracle environment, you can also &lt;code&gt;ssh&lt;/code&gt; to the database server&amp;#8217;s shell to run SQL*Plus.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The above command will start Oracle&amp;#8217;s SQL*Plus, a command line Oracle SQL client. The client will ask for your password, which will be the same as the &lt;code&gt;ORACLE_PWD&lt;/code&gt; environment variable or &lt;code&gt;oraclepw&lt;/code&gt; if you&amp;#8217;re using the Oracle registry container. Use your environment&amp;#8217;s &lt;code&gt;SYS&lt;/code&gt; user password when connecting to an existing Oracle environment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We need to set two database parameters:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;db_recovery_file_dest_size&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The number of bytes available to store archive logs.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Suppose the size of the existing archive logs and the next log to be archived exceeds this configured value. In that case, the Oracle database archiver process will block. If all redo logs require archiving and the archiver process is blocked, the database prevents changes until the archiver process unblocks. Deleting older archive logs using the &lt;code&gt;RMAN&lt;/code&gt; utility unblocks the archiver process, allowing any pending redo logs to be archived. So it&amp;#8217;s generally a good idea to pick a decent size based on your database retention policy.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;db_recovery_file_dest&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The location on the disk where the archive logs are stored.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This location must be readable and writable by the Oracle database user, often called the &lt;code&gt;oracle&lt;/code&gt; user.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To set these values, we&amp;#8217;ll execute the following SQL commands inside the SQL*Plus terminal window where we&amp;#8217;ve already connected to the database as the &lt;code&gt;SYS&lt;/code&gt; user. Again, if you&amp;#8217;re connecting to a pre-existing environment, please consult your database administrator before you proceed here.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; SYSTEM &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; db_recovery_file_dest_size = &lt;span class=&quot;integer&quot;&gt;10&lt;/span&gt;G; &lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; SYSTEM &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; db_recovery_file_dest = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;/opt/oracle/oradata/ORCLCDB&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; scope=spfile; SHUTDOWN &lt;span class=&quot;directive&quot;&gt;IMMEDIATE&lt;/span&gt; STARTUP MOUNT &lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;DATABASE&lt;/span&gt; ARCHIVELOG; &lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;DATABASE&lt;/span&gt; OPEN; ARCHIVE LOG LIST;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The above &lt;code&gt;ALTER&lt;/code&gt; statements adjust the database parameters, specifying that the retention of archive logs is up to a maximum of 10GB and that &lt;code&gt;/opt/oracle/oradata/ORCLCDB&lt;/code&gt; is where the logs are stored.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The final output from SQL*Plus should show the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;SQL&amp;gt; Database log mode Archive Mode Automatic archival Enabled Archive destination USE_DB_RECOVERY_FILE_DEST Oldest online log sequence 1 Next log sequence to archive 3 Current log sequence 3&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The configuration of the archive logs is complete, and when a database log switch occurs, the Oracle ARCH Process will convert the redo log to an archive log stored in the location specified on the disk.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle supports the notion of multiple archive log destinations, allowing the storage of a redo log at different file locations. Multiple storage locations are common when using Oracle DataGuard to transfer copies of the archive logs to a secondary server for disaster recovery or business intelligence. We will not cover how to configure this in this blog post, but it is worth noting that functionality exists and can be helpful.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;configure-oracle-redo-logs&quot;&gt;Configure Oracle: Redo logs&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle&amp;#8217;s transaction log is known as a redo log. These logs are vital as they&amp;#8217;re used in a database crash or media failure to recover to a checkpoint. Unfortunately, Oracle container images often use a redo log configuration that isn&amp;#8217;t useful for Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are two &lt;a href=&quot;/documentation/reference/stable/connectors/oracle.html#oracle-property-log-mining-strategy&quot;&gt;log mining strategies&lt;/a&gt; for Debezium&amp;#8217;s Oracle connector. The strategy controls how the connector interacts with Oracle LogMiner and how the connector ingests schema and table changes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;redo_log_catalog&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The data dictionary will be written periodically to the redo logs, causing a higher generation of archive logs over time. This setting enables tracking DDL changes, so if a table&amp;#8217;s schema changes, this will be the ideal strategy for that purpose.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;online_catalog&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;The data dictionary will not be written periodically to the redo logs, leaving the generation of archive logs consistent with current behavior. Oracle LogMiner will mine changes substantially faster; however, this performance comes at the cost of &lt;strong&gt;not&lt;/strong&gt; tracking DDL changes. If a table&amp;#8217;s schema remains constant, this will be the ideal strategy for that purpose.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the &lt;code&gt;online_catalog&lt;/code&gt; mode, you can safely skip this step entirely.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the &lt;code&gt;redo_log_catalog&lt;/code&gt; mode (the default), the redo log size is critical to reducing the frequency of log switches. The LogMiner session restarts and the data dictionary is rebuilt in the redo logs when a log switch occurs. The dictionary is read back by LogMiner and used to track DDL changes when the session restarts, which can lead to a slight initial session delay while the dictionary tables are populated. Overall you gain better performance when the redo log is large enough to write the data dictionary to a single log file.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle container registry images come configured with a redo log size of &lt;code&gt;200MB&lt;/code&gt;. This default size is too small when using the default mining strategy, so we will adjust this so that the logs use a size of &lt;code&gt;400MB&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When working with Oracle installed without multi-tenancy, using &lt;code&gt;400MB&lt;/code&gt; may still be slightly small since a host of base tables exist in the root database but do not exist in the pluggable databases when multi-tenancy is enabled. Please use &lt;code&gt;500MB&lt;/code&gt; instead if you&amp;#8217;re ingesting changes from an Oracle environment without multi-tenancy at a minimum.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Regardless of multi-tenancy, these values should be much more significant in your production environment. Your DBA will be able to use Oracle&amp;#8217;s sizing guide to determine the best value based on the log switch frequency and load on the system.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Before making any changes, it&amp;#8217;s essential to examine the current state of your environment. In the same terminal where you enabled archive logging, execute the following SQL to determine the current log sizes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;SELECT GROUP#, BYTES/1024/1024 SIZE_MB, STATUS FROM V$LOG ORDER BY 1;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle container registry image will return the following output:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt; GROUP# SIZE_MB STATUS ---------- ---------- ---------------- 1 200 INACTIVE 2 200 INACTIVE 3 200 CURRENT&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This output tells us there are 3 log groups, and each group consumes &lt;code&gt;200MB&lt;/code&gt; of space per log. Additionally, the status associated with each group is crucial as it represents the current state of that log.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following describes the log statues in detail:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;INACTIVE&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This means Oracle has initialized the log and isn&amp;#8217;t currently in use.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;ACTIVE&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This means Oracle has initialized the log and is currently in use. The redo log is required and in use in case of a failure so the database can safely recover.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;CURRENT&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This means Oracle is currently writing to this log. When working with Oracle Real Application Clusters (RAC), multiple logs can be marked as current, representing a log per cluster node.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;UNUSED&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;This means Oracle has not initialized the log and isn&amp;#8217;t in use.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now, using the same terminal window, execute the following SQL to determine the filenames and locations of the redo logs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;SELECT GROUP#, MEMBER FROM V$LOGFILE ORDER BY 1, 2;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle container registry image will return the following output:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt; GROUP# MEMBER ---------- --------------------------------------------------- 1 /opt/oracle/oradata/ORCLCDB/redo01.log 2 /opt/oracle/oradata/ORCLCDB/redo02.log 3 /opt/oracle/oradata/ORCLCDB/redo03.log&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We can glean from this that each log group consists of a single redo log. Oracle does support the notion of multiple logs per group, allowing for what is called multiplexing. You will generally only see this in a production environment and occasionally in a test environment, but it&amp;#8217;s rare to see this in a development or container environment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The goal is to adjust the &lt;code&gt;BYTES&lt;/code&gt; column in the &lt;code&gt;V$LOG&lt;/code&gt; table to have a value of &lt;code&gt;400MB&lt;/code&gt;. Unfortunately, the only way to make this adjustment is to drop and re-create the log group, and this is only possible if the &lt;code&gt;STATUS&lt;/code&gt; of the group is either &lt;code&gt;INACTIVE&lt;/code&gt; or &lt;code&gt;UNUSED&lt;/code&gt;. Since log group 1 was &lt;code&gt;INACTIVE&lt;/code&gt; above, we&amp;#8217;ll start with it, but you can safely perform this procedure on the log groups in any order.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the terminal where SQL*Plus is running, execute the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;ALTER DATABASE CLEAR LOGFILE GROUP 1; ALTER DATABASE DROP LOGFILE GROUP 1; ALTER DATABASE ADD LOGFILE GROUP 1 ('/opt/oracle/oradata/ORCLCDB/redo01.log') size 400M REUSE;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This will drop and re-create the log group with the size of &lt;code&gt;400MB&lt;/code&gt;. We will use the same log file name in the &lt;code&gt;MEMBER&lt;/code&gt; column from the &lt;code&gt;VLOGFILE&lt;/code&gt; table. If the database uses multiplexing, with multiple log files per log group, use a comma-delimited list of filenames to register each log file.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Continue the above procedure for all log groups, changing the log group and filenames accordingly until all &lt;code&gt;INACTIVE&lt;/code&gt; or &lt;code&gt;UNUSED&lt;/code&gt; groups have a size of &lt;code&gt;400MB&lt;/code&gt;. Once all that remains to be changed are those that are &lt;code&gt;CURRENT&lt;/code&gt;, you can issue a log switch on the database to advance the database to the next redo log using the following SQL:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;ALTER SYSTEM SWITCH LOGFILE;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you recheck the size of the logs in the &lt;code&gt;V$LOG&lt;/code&gt;, you&amp;#8217;ll see the output looks like the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;SQL&gt; SELECT GROUP#, BYTES/1024/1024 SIZE_MB, STATUS FROM V$LOG ORDER BY 1; GROUP# SIZE_MB STATUS ---------- ---------- ---------------- 1 400 CURRENT 2 400 UNUSED 3 200 ACTIVE&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We now need to wait for the database to eventually switch the status of log group 3 to &lt;code&gt;INACTIVE&lt;/code&gt;. The switch could take several minutes, so be patient and recheck the size periodically. Once the status reaches &lt;code&gt;INACTIVE&lt;/code&gt;, modify the final log group and filename using the same procedure.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One last check of the &lt;code&gt;V$LOG&lt;/code&gt; table after the final log group, we&amp;#8217;ll see everything looks in order:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;SQL&gt; SELECT GROUP#, BYTES/1024/1024 SIZE_MB, STATUS FROM V$LOG ORDER BY 1; GROUP# SIZE_MB STATUS ---------- ---------- ---------------- 1 400 CURRENT 2 400 UNUSED 3 400 UNUSED&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At this point, we have modified all redo log sizes, reducing the frequency of log switches when Debezium executes the data dictionary build steps.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;configure-oracle-logging&quot;&gt;Configure Oracle: Supplemental Logging&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle redo logs are used primarily for instance and media recovery because the data required for those operations gets recorded automatically. LogMiner cannot be used by default because Oracle does not provide any supplemental log data out of the box. Since Debezium relies on LogMiner, supplemental logging must be enabled at a minimum for Debezium to perform any change data capture for Oracle.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Two different strategies can be used to set supplemental logging:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;Database supplemental logging&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Table supplemental logging&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For Debezium to interface with LogMiner and work with chained rows and various storage arrangements, database supplemental logging must be enabled at a minimum level. To enable this level, execute the following SQL in the current SQL*Plus terminal:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;ADD&lt;/span&gt; SUPPLEMENTAL LOG DATA;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will cover table-based supplemental logging in a later section when we discuss configuring the connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;configure-oracle-users&quot;&gt;Configure Oracle: User setup&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the Debezium connector to capture change events, it must establish a JDBC connection to the database and execute a series of LogMiner APIs. A user account will require specific permissions to access these LogMiner APIs and gather data from the captured tables.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using multi-tenant architecture, as is found with the Oracle container registry image, there are effectively two databases that we will have to work with, &lt;code&gt;ORCLCDB&lt;/code&gt; (the container or root database) and &lt;code&gt;ORCLPDB1&lt;/code&gt; (the pluggable database). All captured tables will be created and maintained from within the PDB, but there will be moments when the connector will need to access the root database to read specific system tables.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Therefore in a multi-tenant architecture, we must first set up the two tablespaces that our user account will use. To create these tablespaces, execute the following SQL from within the SQL*Plus terminal:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;CONNECT sys/oraclepw&lt;span class=&quot;variable&quot;&gt;@ORCLCDB&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; sysdba; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; TABLESPACE logminer_tbs DATAFILE &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;/opt/oracle/oradata/ORCLCDB/logminer_tbs.dbf&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; SIZE &lt;span class=&quot;integer&quot;&gt;25&lt;/span&gt;M REUSE AUTOEXTEND &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; MAXSIZE UNLIMITED; CONNECT sys/oraclepw&lt;span class=&quot;variable&quot;&gt;@ORCLPDB1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; sysdba; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; TABLESPACE logminer_tbs DATAFILE &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;/opt/oracle/oradata/ORCLCDB/ORCLPDB1/logminer_tbs.dbf&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; SIZE &lt;span class=&quot;integer&quot;&gt;25&lt;/span&gt;M REUSE AUTOEXTEND &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; MAXSIZE UNLIMITED;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If the deployment is not on an Oracle database with multi-tenancy enabled, creating the second tablespace within the &lt;code&gt;ORCLPDB1&lt;/code&gt; database is unnecessary. Additionally, ensure the path provided for the tablespace, credentials, and database SID are all correct for your installation. You may need to consult with your DBA to have the tablespace created correctly.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once the tablespaces exist, it is now time to create the user account itself. If you are using a multi-tenant environment, the user name must use the common-user prefix so that Oracle creates it in both the CDB root database and the PDB pluggable database; otherwise, the user name can be anything. Since we are working with a multi-tenant database installation with our container, we will create a user account called &lt;code&gt;c##dbzuser&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;CONNECT sys/oraclepw&lt;span class=&quot;variable&quot;&gt;@ORCLCDB&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; sysdba; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; USER c&lt;span class=&quot;comment&quot;&gt;##dbzuser IDENTIFIED BY dbz DEFAULT TABLESPACE LOGMINER_TBS&lt;/span&gt; QUOTA UNLIMITED &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; LOGMINER_TBS CONTAINER=&lt;span class=&quot;keyword&quot;&gt;ALL&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The user account requires several permissions. At the time of this publication, the list of permissions included the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; SESSION &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; CONTAINER &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$DATABASE &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; FLASHBACK &lt;span class=&quot;keyword&quot;&gt;ANY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ANY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; SELECT_CATALOG_ROLE &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; EXECUTE_CATALOG_ROLE &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ANY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TRANSACTION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ANY&lt;/span&gt; DICTIONARY &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; LOGMINING &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; LOCK &lt;span class=&quot;keyword&quot;&gt;ANY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; SEQUENCE &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; EXECUTE &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; DBMS_LOGMNR &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; EXECUTE &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; DBMS_LOGMNR_D &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOG &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOG_HISTORY &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOGMNR_LOGS &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOGMNR_CONTENTS &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOGMNR_PARAMETERS &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$LOGFILE &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$ARCHIVED_LOG &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$ARCHIVE_DEST_STATUS &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; V_$TRANSACTION &lt;span class=&quot;keyword&quot;&gt;TO&lt;/span&gt; c&lt;span class=&quot;comment&quot;&gt;##dbzuser CONTAINER=ALL;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can refer to the latest &lt;a href=&quot;/documentation/reference/stable/connectors/oracle.html#creating-users-for-the-connector&quot;&gt;documentation&lt;/a&gt; to review whether the required grants may have changed. We have created the connector user we will use in the configuration and given the user all the necessary database permissions.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this part of the series, we have covered what Oracle is and why it is so popular. We&amp;#8217;ve also covered installing an Oracle database using a container and configuring the Oracle instance to allow Debezium to ingest changes. In the &lt;a href=&quot;/blog/2022/10/06/debezium-oracle-series-part-2/&quot;&gt;next part&lt;/a&gt; of the series, we&amp;#8217;ll dive into deploying the Debezium Oracle connector on Apache Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="debezium"/><category term="oracle"/><category term="examples"/><summary type="html">This post is part of a 3-part series to explore using Debezium to ingest changes from an Oracle database using Oracle LogMiner. Throughout the series, we&amp;#8217;ll examine all the steps to setting up a proof of concept (POC) deployment for Debezium for Oracle. We will discuss setup and configurations as well as the nuances of multi-tenancy. We will also dive into any known pitfalls and concerns you may need to know and how to debug specific problems. And finally, we&amp;#8217;ll talk about performance and monitoring to maintain a healthy connector deployment. Throughout this exercise, we hope that this will show you just how simple it is to deploy Debezium for Oracle. This installation and setup portion of the series may seem quite complicated, but many of these steps likely already exist in a pre-existing environment. We will dive into each step, explaining it is essential should you use a container image deployment.</summary></entry><entry><title type="html">Debezium 1.9.6.Final Released</title><link href="https://debezium.io/blog/2022/09/26/debezium-1-9-6-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.6.Final Released"/><published>2022-09-26T00:00:00+00:00</published><updated>2022-09-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/09/26/debezium-1-9-6-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/09/26/debezium-1-9-6-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.9.6.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+1.9.6.Final&quot;&gt;78 resolved issues&lt;/a&gt; overall.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;changes&quot;&gt;Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A few noteworthy bug fixes and stability improvements include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Oracle SCAN VIP support &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3987&quot;&gt;DBZ-3987&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Memory leak in EventDeserializer caused by tableMapEventByTableId &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5126&quot;&gt;DBZ-5126&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Postgres Incremental Snapshot on parent partitioned table not working &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5240&quot;&gt;DBZ-5240&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Lob type data is inconsistent between source and sink, after modifying the primary key &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5295&quot;&gt;DBZ-5295&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Unsigned tinyint conversion fails for MySQL 8.x &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5343&quot;&gt;DBZ-5343&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NullPointerException thrown when unique index based on both system and non-system generated columns &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5356&quot;&gt;DBZ-5356&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;AWS DocumentDB (with MongoDB Compatibility) Connect Fail &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5371&quot;&gt;DBZ-5371&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;org.postgresql.util.PSQLException: Bad value for type timestamp/date/time: CURRENT_TIMESTAMP &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5384&quot;&gt;DBZ-5384&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Timestamp with time zone column&amp;#8217;s default values not in GMT &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5403&quot;&gt;DBZ-5403&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;OffsetStore not stopped if it fails to fully start &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5433&quot;&gt;DBZ-5433&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Duplicate SCNs on same thread Oracle RAC mode incorrectly processed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5439&quot;&gt;DBZ-5439&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox doesn&amp;#8217;t check array consistecy properly when it detemines its schema &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5475&quot;&gt;DBZ-5475&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium connector task didn&amp;#8217;t retry when failover in mongodb 5 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5479&quot;&gt;DBZ-5479&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Use TCCL as the default classloader to load interface implementations &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5561&quot;&gt;DBZ-5561&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Vitess: Handle VStream close unepectedly &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5579&quot;&gt;DBZ-5579&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector parsing SELECT_LOB_LOCATOR event missing constant &lt;code&gt;unavailable.value.placeholder&lt;/code&gt; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5581&quot;&gt;DBZ-5581&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Message with LSN foo larger than expected LSN bar &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5597&quot;&gt;DBZ-5597&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Continuously WARNs about undo transactions when LOB is enabled &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5635&quot;&gt;DBZ-5635&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Large numbers of ROLLBACK transactions can lead to memory leak when LOB is not enabled. &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5645&quot;&gt;DBZ-5645&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, there were quite a number of SQL parser fixes for both MySQL and Oracle, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5472&quot;&gt;DBZ-5472&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5488&quot;&gt;DBZ-5488&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5499&quot;&gt;DBZ-5499&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5508&quot;&gt;DBZ-5508&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5521&quot;&gt;DBZ-5521&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5522&quot;&gt;DBZ-5522&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5526&quot;&gt;DBZ-5526&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5550&quot;&gt;DBZ-5550&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5592&quot;&gt;DBZ-5592&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5595&quot;&gt;DBZ-5595&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5605&quot;&gt;DBZ-5605&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5630&quot;&gt;DBZ-5630&lt;/a&gt;, and &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5643&quot;&gt;DBZ-5643&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.6-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community who contributed to Debezium 1.9.6.Final: &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/aloubyansky&quot;&gt;Alexey Loubyansky&lt;/a&gt;, Gabor Andras, &lt;a href=&quot;https://github.com/ajunwalker&quot;&gt;Andrew Walker&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/ggaborg&quot;&gt;Gabor Andras&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/nicholas-fwang&quot;&gt;Inki Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/domsj&quot;&gt;Jan Doms&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/nirolevy&quot;&gt;Nir Levy&lt;/a&gt;, &lt;a href=&quot;https://github.com/thangdc94&quot;&gt;Phạm Ngọc Thắng&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/GOODBOY008&quot;&gt;Zhongqiang Gong&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook_whats_next&quot;&gt;Outlook, What&amp;#8217;s next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium 1.9 will continue to receive bug fix and maintenance changes throughout the early part of the next quarter. I expect there to be at least a 1.9.7.Final in the middle to late October timeframe, potentially wrapping up the 1.9 release stream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium 2.0 is wrapping up with the latest 2.0.0.Beta2 build released just last week. We are currently focusing on bug fixes, stability, and polishing the Debezium 2.0 release stream. We expect to have 2.0.0.CR1 released in about another week or so with 2.0.0.Final scheduled for mid-October.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until next time, keep an eye out as we&amp;#8217;ll soon be discussing what&amp;#8217;s to come in Debezium 2.1 later this year!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.9.6.Final! This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains 78 resolved issues overall.</summary></entry><entry><title type="html">Debezium 2.0.0.Beta2 Released</title><link href="https://debezium.io/blog/2022/09/16/debezium-2.0-beta2-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Beta2 Released"/><published>2022-09-16T00:00:00+00:00</published><updated>2022-09-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/09/16/debezium-2.0-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2022/09/16/debezium-2.0-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am excited to announce the release of Debezium &lt;strong&gt;2.0.0.Beta2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release contains several breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Beta2%20ORDER%20BY%20component%20ASC&quot;&gt;107 issues&lt;/a&gt; that were fixed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you intend to upgrade to 2.0.0.Beta2, we strongly recommend that you read the release notes before the upgrade to understand all breaking changes. The following noteworthy list of changes are those we&amp;#8217;ll cover in this blog post, some of which are breaking:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[breaking] &lt;a href=&quot;#new-connector-property-namespaces&quot;&gt;New connector property namespaces&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[potentially breaking] &lt;a href=&quot;#all-debezium-schemas-are-named&quot;&gt;All event schemas properly named and versioned&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[potentially breaking] &lt;a href=&quot;#skipped-operations&quot;&gt;Skipped operations now includes truncate events by default&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#mysql-binlog-compression-support&quot;&gt;MySQL binlog compression support&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#cassandra4-incremental-commit-log-support&quot;&gt;Cassandra 4 incremental commit log support&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#pause-and-resume-incremental-snapshots&quot;&gt;Pausing and resuming paused incremental snapshots&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#custom-sql-filtering-incremental-snapshots&quot;&gt;Custom SQL filtering for incremental snapshots&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#signal-collection-automatically-registered&quot;&gt;Signal collection now added to table include list automatically&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;#multitasking-vitess&quot;&gt;Multitasking support for the Vitess connector&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;new-connector-property-namespaces&quot;&gt;New connector property namespaces&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the largest overhauls going into Debezium 2.0 is the introduction of new connector property namespaces. Starting in Debezium 2.0 Beta2 and onward, many connector properties have been relocated with new names. This is a breaking change and affects most, if not all, connector deployments during the upgrade process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium previously used the prefix &quot;database.&quot; with a plethora of varied connector properties. Some of these properties were meant to be passed directly to the JDBC driver and in other cases to the database history implementations, and so on. Unfortunately, we identified situations where some properties were being passed to underlying implementations that weren&amp;#8217;t intended. While this wasn&amp;#8217;t creating any type of regression or problem, it could potentially introduce a future issue if there were property name collisions, for example, a JDBC driver property that matched with a &quot;database.&quot; prefixed Debezium connector property.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following describes the changes to the connector properties&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;All configurations previously prefixed as &lt;code&gt;database.history.&lt;/code&gt; are now to be prefixed using &lt;code&gt;schema.history.internal.&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;All JDBC pass-thru options previously specified using &lt;code&gt;database.&lt;/code&gt; prefix should now be prefixed using &lt;code&gt;driver.&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The &lt;code&gt;database.server.name&lt;/code&gt; connector property renamed to &lt;code&gt;topic.prefix&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The MongoDB &lt;code&gt;mongodb.name&lt;/code&gt; connector property aligned to use &lt;code&gt;topic.prefix&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Again, please review your connector configurations prior to deployment and adjust accordingly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;all-debezium-schemas-are-named&quot;&gt;All Debezium event schemas are named and versioned&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium change events are emitted with a schema definition, which contains metadata about the fields such as the type, whether it&amp;#8217;s required, and so on. In previous iterations of Debezium, some schema definitions did not have explicit names nor were they being explicitly versioned. In this release, we&amp;#8217;ve moved to making sure that all schema definitions have an explicit name and version associated with them. The goal of this change is to help with future event structure compatibility, particularly for those who are using schema registries. However, if you are currently using a schema registry, be aware that this change may lead to schema compatibility issues during the upgrade process.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;skipped-operations&quot;&gt;Skipped operations default to truncate events&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium supports skipping specific event types by including the &lt;code&gt;skipped.operations&lt;/code&gt; connector property in the connector&amp;#8217;s configuration. This feature can be useful if you&amp;#8217;re only interested in a subset of operations, such as only inserts and updates but not deletions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One specific event type, truncates (&lt;code&gt;t&lt;/code&gt;), is only supported by a subset of relational connectors and whether these events were to be skipped wasn&amp;#8217;t consistent. In this release, we have aligned the &lt;code&gt;skipped.operations&lt;/code&gt; behavior so that if the connector supports truncate events, these events are skipped by default.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please review the following rule-set:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Connector supports truncate events and isn&amp;#8217;t the Oracle connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connector configuration does not specify the &lt;code&gt;skipped.operations&lt;/code&gt; in the configuration&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If all the above are true, then the connector&amp;#8217;s behavior will change after the upgrade. If you wish to continue to emit truncate events, the &lt;code&gt;skipped.operations=none&lt;/code&gt; configuration will be required.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mysql-binlog-compression-support&quot;&gt;MySQL binlog compression support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, Debezium now supports reading of binlog entries that have been written with compression enabled. In version 8.0.20, MySQL adds the ability to compress binlog events using the ZSTD algorithm. To enable compression, you must toggle the &lt;code&gt;binlog.transaction_compression&lt;/code&gt; variable on the MySQL server to &lt;code&gt;ON&lt;/code&gt;. When compression is enabled, the binlog behaves as usual, except that the contents of the binlog entries are compressed to save space, and are replicated to in compressed format to replicas, significantly reducing network overhead for larger transactions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you&amp;#8217;re interested in reading more about MySQL binlog compression, you can refer to the &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/binary-log-transaction-compression.html&quot;&gt;Binary Log Transaction Compression&lt;/a&gt; section of the MySQL documentation for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra4-incremental-commit-log-support&quot;&gt;Cassandra 4 incremental commit log support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://cassandra.apache.org/doc/latest/cassandra/operating/cdc.html&quot;&gt;Cassandra 4&lt;/a&gt; has improved the integration with CDC by adding a feature that when the fsync operation occurs, Cassandra will update a CDC-based index file to contain the latest offset values. This index file allows CDC implementations to read up to the offset that is considered durable in Cassandra.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, Debezium now uses this CDC-based index file to eliminate the inherent delay in processing CDC events from Cassandra that previously existed. This should provide Cassandra users a substantial improvement in CDC with Debezium, and gives an incentive to consider Cassandra 4 over Cassandra 3.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;pause-and-resume-incremental-snapshots&quot;&gt;Pause and resume incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshots have become an integral feature in Debezium. The incremental snapshot feature allows users to re-run a snapshot on one or more collections/tables for a variety of reasons. Incremental snapshots were originally introduced with just a &lt;em&gt;start&lt;/em&gt; signal. We eventually added the ability to &lt;em&gt;stop&lt;/em&gt; an ongoing incremental snapshot or to be able to remove a subset of collections/tables from an in-progress incremental snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we&amp;#8217;ve built on top of the existing signal foundation and we&amp;#8217;ve introduced two new signals, one to &lt;em&gt;pause&lt;/em&gt; an in-progress incremental snapshot and then another to &lt;em&gt;resume&lt;/em&gt; the incremental snapshot if it has previously been paused. To pause an incremental snapshot, a &lt;code&gt;pause-snapshot&lt;/code&gt; signal must be sent, and to resume, a &lt;code&gt;resume-snapshot&lt;/code&gt; signal can be used.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These two new signals can be sent using the signal table strategy or the Kafka signal topic strategy for MySQL. Please refer to the &lt;a href=&quot;https://debezium.io/documentation/reference/2.0/configuration/signalling.html#_signal_actions&quot;&gt;signal support documentation&lt;/a&gt; for more details on signals and how they work.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;custom-sql-filtering-incremental-snapshots&quot;&gt;Custom SQL filtering for incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Although uncommon, there may be scenarios such as a connector misconfiguration, where a specific record or subset of records needs to be re-emitted to the topic. Unfortunately, incremental snapshots have traditionally been an all-or-nothing type of process, where we would re-emit all records from a collection or table as a part of the snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a new &lt;code&gt;additional-condition&lt;/code&gt; property can be specified in the signal payload, allowing the signal to dictate a SQL-based predicate to control what subset of records should be included in the incremental snapshot instead of the default behavior of &lt;em&gt;all rows&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following example illustrates sending an incremental snapshot signal for the &lt;code&gt;products&lt;/code&gt; table, but instead of sending all rows from the table to the topic, the &lt;code&gt;additional-condition&lt;/code&gt; property has been specified to restrict the snapshot to only send events that relate to product id equal to &lt;code&gt;12&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;execute-snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory.products&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;INCREMENTAL&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;additional-condition&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;product_id=12&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We believe this new incremental snapshot feature will be tremendously helpful for a variety of reasons, without always having to re-snapshot all rows when only a subset of data is required.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;signal-collection-automatically-registered&quot;&gt;Signal collection automatically added to include filters&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In prior releases of Debezium, the signal collection/table used for incremental snapshots had to be manually added to your &lt;code&gt;table.include.list&lt;/code&gt; connector property. A big theme in this release was improvements on incremental snapshots, so we&amp;#8217;ve taken this opportunity to streamline this as well. Starting in this release, Debezium will automatically add the signal collection/table to the table inclusion filters, avoiding the need for users to manually add it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This change does not impose any compatibility issues. Connector configurations that already include the signal collection/table in the &lt;code&gt;table.include.list&lt;/code&gt; property will continue to work without requiring any changes. However, if you wish to align your configuration with current behavior, you can also safely remove the signal collection/table from the &lt;code&gt;table.include.list&lt;/code&gt;, and Debezium will begin to handle this for you automatically.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;multitasking-vitess&quot;&gt;Multitasking support for Vitess connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess connector previously allowed operation in two different modes that depended entirely on whether the connector configuration specified any shard details. Unfortunately in both cases, each resulted in a single task responsible for performing the VStream processing. For larger Vitess installations with many shards, this architecture could begin to show latency issues as it may not be able to keep up with all the changes across all shards. And even more complex, when specifying the shard details, this required manually resolving the shards across the cluster and starting a single Debezium connector per shard, which is both error-prone and more importantly could result in deploying many Debezium connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess community recognized this and sought to find a solution that addresses all these problems, both from a maintenance and error perspective. In Debezium 2.0 Beta2, the Vitess connector now automatically resolves the shards via a discovery mechanism, quite similar to that of MongoDB. This discovery mechanism will then split the load across multiple tasks, allowing for a single deployment of Debezium running a task per shard or shard lists, depending on the maximum number of allowed tasks for the connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During the upgrade, the Vitess connector will automatically migrate the offset storage to the new format used with the multitasking behavior. But be aware that once you&amp;#8217;ve upgraded, you won&amp;#8217;t be able to downgrade to an earlier version as the offset storage format will have changed.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are many bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Source info of incremental snapshot events exports wrong data &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4329&quot;&gt;DBZ-4329&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Deprecate internal key/value converter options &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4617&quot;&gt;DBZ-4617&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&quot;No maximum LSN recorded&quot; log message can be spammed on low-activity databases &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4631&quot;&gt;DBZ-4631&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Redis Sink config properties are not passed to DB history &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5035&quot;&gt;DBZ-5035&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade SQL Server driver to 10.2.1.jre8 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5290&quot;&gt;DBZ-5290&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;HTTP sink not retrying failing requests &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5307&quot;&gt;DBZ-5307&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Translation from mongodb document to kafka connect schema fails when nested arrays contain no elements &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5434&quot;&gt;DBZ-5434&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Duplicate SCNs on same thread Oracle RAC mode incorrectly processed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5439&quot;&gt;DBZ-5439&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Deprecate legacy topic selector for all connectors &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5457&quot;&gt;DBZ-5457&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Remove the dependency of JdbcConnection on DatabaseSchema &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5470&quot;&gt;DBZ-5470&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Missing the regex properties validation before start connector of DefaultRegexTopicNamingStrategy &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5471&quot;&gt;DBZ-5471&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create Index DDL fails to parse when using TABLESPACE clause with quoted identifier &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5472&quot;&gt;DBZ-5472&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox doesn&amp;#8217;t check array consistency properly when it determines its schema &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5475&quot;&gt;DBZ-5475&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Misleading statistics written to the log &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5476&quot;&gt;DBZ-5476&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Remove SQL Server SourceTimestampMode &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5477&quot;&gt;DBZ-5477&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium connector task didn&amp;#8217;t retry when failover in mongodb 5 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5479&quot;&gt;DBZ-5479&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Better error reporting for signal table failures &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5484&quot;&gt;DBZ-5484&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle DATADUMP DDL cannot be parsed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5488&quot;&gt;DBZ-5488&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade PostgreSQL driver to 42.4.1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5493&quot;&gt;DBZ-5493&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mysql connector parser the ddl statement failed when including keyword &quot;buckets&quot; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5499&quot;&gt;DBZ-5499&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;duplicate call to config.validateAndRecord() in RedisDatabaseHistory &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5506&quot;&gt;DBZ-5506&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DDL statement couldn&amp;#8217;t be parsed : mismatched input 'ENGINE' &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5508&quot;&gt;DBZ-5508&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Use “database.dbnames” in SQL Server docs &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5516&quot;&gt;DBZ-5516&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;LogMiner DML parser incorrectly interprets concatenation operator inside quoted column value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5521&quot;&gt;DBZ-5521&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mysql Connector DDL Parser does not parse all privileges &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5522&quot;&gt;DBZ-5522&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CREATE TABLE with JSON-based CHECK constraint clause causes MultipleParsingExceptions &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5526&quot;&gt;DBZ-5526&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Disable preferring DDL before logical schema in history recovery &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5535&quot;&gt;DBZ-5535&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;EmbeddedEngine should initialize Connector using SourceConnectorContext &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5534&quot;&gt;DBZ-5534&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support EMPTY column identifier &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5550&quot;&gt;DBZ-5550&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Use TCCL as the default classloader to load interface implementations &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5561&quot;&gt;DBZ-5561&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;max.queue.size.in.bytes is invalid &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5569&quot;&gt;DBZ-5569&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Language type for listings in automatic topic creation &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5573&quot;&gt;DBZ-5573&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade mysql-binlog-connector-java library version &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5574&quot;&gt;DBZ-5574&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Vitess: Handle VStream close unexpectedly &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5579&quot;&gt;DBZ-5579&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Error when parsing alter sql &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5587&quot;&gt;DBZ-5587&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Field validation errors are misleading for positive, non-zero expectations &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5588&quot;&gt;DBZ-5588&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mysql connector can&amp;#8217;t handle the case-sensitive of rename/change column statement &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5589&quot;&gt;DBZ-5589&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;LIST_VALUE_CLAUSE not allowing TIMESTAMP LITERAL &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5592&quot;&gt;DBZ-5592&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle DDL does not support comments on materialized views &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5595&quot;&gt;DBZ-5595&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle DDL does not support DEFAULT ON NULL &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5605&quot;&gt;DBZ-5605&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Datatype mdsys.sdo_geometry not supported &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5609&quot;&gt;DBZ-5609&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Beta2%20ORDER%20BY%20component%20ASC&quot;&gt;107 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed ELJAMI&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/aloubyansky&quot;&gt;Alexey Loubyansky&lt;/a&gt;, Gabor[Andras], &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/davsclaus&quot;&gt;Claus Ibsen&lt;/a&gt;, &lt;a href=&quot;https://github.com/debjeetsarkar&quot;&gt;Debjeet Sarkar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ggaborg&quot;&gt;Gabor Andras&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/ruanhang1993&quot;&gt;Hang Ruan&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/nicholas-fwang&quot;&gt;Inki Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/DerGut&quot;&gt;Jannik Steinmann&lt;/a&gt;, &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/winklerm&quot;&gt;Marek Winkler&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/nitinitt&quot;&gt;Nitin Chhabra&lt;/a&gt;, &lt;a href=&quot;https://github.com/thangdc94&quot;&gt;Phạm Ngọc Thắng&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/druud&quot;&gt;Ruud H.G. van Tol&lt;/a&gt;, &lt;a href=&quot;https://github.com/jaegwonseo&quot;&gt;Seo Jae-kwon&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/GOODBOY008&quot;&gt;Zhongqiang Gong&lt;/a&gt;, &lt;a href=&quot;https://github.com/BetaCat0&quot;&gt;合龙 张&lt;/a&gt;, &lt;a href=&quot;https://github.com/comil4444&quot;&gt;崔世杰&lt;/a&gt;, and &lt;a href=&quot;https://github.com/pkgonan&quot;&gt;민규 김&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the release of Debezium 2.0 Beta2, we&amp;#8217;re in the home stretch toward 2.0.0.Final. The community should expect a CR1 by the end of September and 2.0.0.Final released by the middle of October.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, our very own Gunnar Morling and I will be guests on the upcoming &lt;a href=&quot;https://quarkus.io/insights&quot;&gt;Quarkus Insights&lt;/a&gt; podcast, episode #103. We will be discussing Debezium and Quarkus, how Debezium leverages the power of Quarkus, a virtual how-to on embedding Debezium in a Quarkus-based application, and discussing all new features in Debezium 2.0. Be sure to check out the podcast and let us what you think!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am excited to announce the release of Debezium 2.0.0.Beta2! This release contains several breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of 107 issues that were fixed.</summary></entry><entry><title type="html">Debezium 2.0.0.Beta1 Released</title><link href="https://debezium.io/blog/2022/07/27/debezium-2.0-beta1-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Beta1 Released"/><published>2022-07-27T00:00:00+00:00</published><updated>2022-07-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/07/27/debezium-2.0-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/07/27/debezium-2.0-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am thrilled to share that Debezium &lt;strong&gt;2.0.0.Beta1&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release contains several new features including a pluggable topic selector, the inclusion of database user who committed changes for Oracle change events, and improved handling of table unique indices as primary keys. In addition, there are several breaking changes such as the move to multi-partition mode as default and the introduction of the &lt;code&gt;debezium-storage&lt;/code&gt; module and its implementations. So lets take a look at all these in closer detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;multi_partition_mode_now_default&quot;&gt;Multi-partition mode now default&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many database platforms support multi-tenancy out of the box, meaning you can have one installation of the database engine and have many unique databases. In cases like SQL Server, this traditionally required a separate connector deployment for each unique database. Over the last year, a large effort has been made to break down that barrier and to introduce a common way that any single connector deployment could connect and stream changes from multiple databases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The first notable change is with the SQL Server connector&amp;#8217;s configuration option, &lt;code&gt;database.dbname&lt;/code&gt;. This option has been replaced with a new option called &lt;code&gt;database.names&lt;/code&gt;. As multi-partition mode is now default, this new &lt;code&gt;database.names&lt;/code&gt; option can be specified using a comma-separated list of database names, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;database.names=TEST1,TEST2&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this example, the connector is being configured to capture changes from two unique databases on the same host installation. The connector will start two unique tasks in Kafka Connect and each task will be responsible for streaming changes from its respective database concurrently.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The second notable change is with connector metrics naming. A connector exposes JMX metrics via beans that are identified with a unique name. With multi-partition mode the default with multiple tasks, each task requires its own metrics bean and so a change in the naming strategy was necessary.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In older versions of Debezium using SQL Server as an example, metrics were available using the following naming strategy:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sql_server:type=connector-metrics,server=&amp;lt;sqlserver.server.name&amp;gt;,context=&amp;lt;context&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, the naming strategy now includes a new &lt;code&gt;task&lt;/code&gt; component in the JMX MBean name:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sql_server:type=connector-metrics,server=&amp;lt;sqlserver.server.name&amp;gt;,task=&amp;lt;task.id&amp;gt;,context=&amp;lt;context&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please review your metrics configurations as the naming changes could have an impact when collecting Debezium metrics.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_storage_module&quot;&gt;Debezium storage module&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we have introduced a new &lt;code&gt;debezium-storage&lt;/code&gt; set of artifacts for file- and kafka- based database history and offset storage. This change is the first of several future implementations set to support platforms such as Amazon S3, Redis, and possibly JDBC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For users who install connectors via plugin artifacts, this should be a seamless change as all dependencies are bundled in those plugin downloadable archives. For users who may embed Debezium in their applications or who may be building their own connector, be aware you may need to add a new storage dependency depending on which storage implementations used.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;pluggable_topic_selector&quot;&gt;Pluggable topic selector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium&amp;#8217;s default topic naming strategy emits change events to topics named &lt;code&gt;database.schema.table&lt;/code&gt;. If you require that topics be named differently, an SMT would normally be added to the connector configuration to adjust this behavior. But, this presents a challenge in situations where one of the components of this topic name, perhaps the database or table name, contains a dot (&lt;code&gt;.&lt;/code&gt;) and perhaps an SMT doesn&amp;#8217;t have adequate context.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a new &lt;code&gt;TopicNamingStrategy&lt;/code&gt; was introduced to allow fully customizing this behavior directly inside Debezium. The default naming strategy implementation should suffice in most cases, but if you find that it doesn&amp;#8217;t you can provide a custom implementation of the &lt;code&gt;TopicNamingStrategy&lt;/code&gt; contract to fully control various namings used by the connector. To provide your own custom strategy, you would specify the &lt;code&gt;topic.naming.strategy&lt;/code&gt; connector option with the fully-qualified class name of the strategy, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;topic.naming.strategy=org.myorganization.MyCustomTopicNamingStrategy&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This custom strategy is not just limited to controlling the names of topics for table mappings, but also for schema changes, transaction metadata, and heartbeats. You can refer to the &lt;code&gt;DefaultTopicNamingStrategy&lt;/code&gt; found &lt;a href=&quot;https://github.com/debezium/debezium/blob/main/debezium-core/src/main/java/io/debezium/schema/DefaultTopicNamingStrategy.java&quot;&gt;here&lt;/a&gt; as an example. This feature is still incubating and we&amp;#8217;ll continue to improve and develop it as feedback is received.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_commit_user_in_change_events&quot;&gt;Oracle commit user in change events&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The source information block of change events carry a variety of context about where the change event originated. In this release, the Oracle connector now includes the user who made the database change in the captured change event. A new field, &lt;code&gt;user_name&lt;/code&gt;, can now be found in the source info block with this new information. This field is optional, and is only available when changes are emitted using the LogMiner-based implementation. This field may also contain the value of &lt;code&gt;UNKNOWN&lt;/code&gt; if the user associated with a change is dropped prior to the change being captured by the connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improved_table_unique_index_handling&quot;&gt;Improved table unique index handling&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A table does not have to have a primary key to be captured by a Debezium connector. In cases where a primary key is not defined, Debezium will inspect a table&amp;#8217;s unique indices to see whether a reasonable key substitution can be made. In some situations, the index may refer to columns such as &lt;code&gt;CTID&lt;/code&gt; for PostgreSQL or &lt;code&gt;ROWID&lt;/code&gt; in Oracle. These columns are not visible nor user-defined, but instead are hidden synthetic columns generated automatically by the database. In addition, the index may also use database functions to transform the column value that is stored, such as &lt;code&gt;UPPER&lt;/code&gt; or &lt;code&gt;LOWER&lt;/code&gt; for example.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, indices that rely on hidden, auto-generated columns, or columns wrapped in database functions are no longer eligible as primary key alternatives. This guarantees that when relying on an index as a primary key rather than a defined primary key itself, the generated message&amp;#8217;s primary key value tuple directly maps to the same values used by the database to represent uniqueness.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are several bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;MongoConnector&amp;#8217;s field exclusion configuration does not work with fields with the same name but from different collections &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4846&quot;&gt;DBZ-4846&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Remove redundant setting of last events &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5047&quot;&gt;DBZ-5047&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Rename &lt;code&gt;docker-images&lt;/code&gt; repository and JIRA component to &lt;code&gt;container-images&lt;/code&gt; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5048&quot;&gt;DBZ-5048&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Read Debezium Metrics From Debezium Server Consumer &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5235&quot;&gt;DBZ-5235&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;User input are not consistent on Filter step for the DBZ connectors &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5246&quot;&gt;DBZ-5246&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;KafkaDatabaseHistory without check database history topic create result caused UnknowTopicOrPartitionException &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5249&quot;&gt;DBZ-5249&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Treat SQLServerException with &quot;Broken pipe (Write failed)&quot; exception message as a retriable exception &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5292&quot;&gt;DBZ-5292&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Lob type data is inconsistent between source and sink, after modifying the primary key &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5295&quot;&gt;DBZ-5295&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Caused by: java.io.EOFException: Failed to read next byte from position 2005308603 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5333&quot;&gt;DBZ-5333&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental Snapshot: Oracle table name parsing does not support periods in DB name &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5336&quot;&gt;DBZ-5336&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support PostgreSQL default value function calls with schema prefixes &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5340&quot;&gt;DBZ-5340&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Unsigned tinyint conversion fails for MySQL 8.x &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5343&quot;&gt;DBZ-5343&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Log a warning when an unsupported LogMiner operation is detected for a captured table &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5351&quot;&gt;DBZ-5351&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NullPointerException thrown when unique index based on both system and non-system generated columns &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5356&quot;&gt;DBZ-5356&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL Connector column hash v2 does not work &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5366&quot;&gt;DBZ-5366&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox JSON expansion fails when nested arrays contain no elements &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5367&quot;&gt;DBZ-5367&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;docker-maven-plugin needs to be upgraded for Mac Apple M1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5369&quot;&gt;DBZ-5369&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;AWS DocumentDB (with MongoDB Compatibility) Connect Fail &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5371&quot;&gt;DBZ-5371&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle Xstream does not propagate commit timestamp to transaction metadata &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5373&quot;&gt;DBZ-5373&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;UI View connector config in non-first cluster return 404 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5378&quot;&gt;DBZ-5378&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CommitScn not logged in expected format &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5381&quot;&gt;DBZ-5381&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;org.postgresql.util.PSQLException: Bad value for type timestamp/date/time: CURRENT_TIMESTAMP &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5384&quot;&gt;DBZ-5384&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Missing &quot;previousId&quot; property with parsing the rename statement in kafka history topic &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5386&quot;&gt;DBZ-5386&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Check constraint introduces a column based on constraint in the schema change event. &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5390&quot;&gt;DBZ-5390&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support storing extended attributes in relational model and JSON schema history topic &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5396&quot;&gt;DBZ-5396&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The column is referenced as PRIMARY KEY, but a matching column is not defined in table &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5398&quot;&gt;DBZ-5398&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Clarify which database name to use for signal.data.collection when using Oracle with pluggable database support &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5399&quot;&gt;DBZ-5399&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Timestamp with time zone column&amp;#8217;s default values not in GMT &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5403&quot;&gt;DBZ-5403&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Kafka 3.1 broke build compatibility with Kafka 2.x and Kafka 3.0 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5404&quot;&gt;DBZ-5404&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Remove the duplicated SimpleDdlParserListener from mysql connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5425&quot;&gt;DBZ-5425&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;59 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/ajunwalker&quot;&gt;Andrew Walker&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/giljae&quot;&gt;Giljae Joo&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/domsj&quot;&gt;Jan Doms&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/smallYellowCat&quot;&gt;Pengwei Dou&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/GOODBOY008&quot;&gt;Zhongqiang Gong&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In these last few months, the team has made some incredible progress on Debezium 2.0, and we can begin to see the finish line in the distance. A large of this is in part to the grew work the community has done to contribute changes, provide feedback, and to test and help make new features stable. But we&amp;#8217;re not done, so you can continue to expect another 2.0.0.Beta2 release in approximately 3 weeks, sticking with our usual cadence.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, we do continue to backport changes to the 1.9 branch and will likely look at a 1.9.6.Final release sometime in August to round out that release stream just before we wrap up Debezium 2.0.0.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So stay cool and safe and happy capturing!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am thrilled to share that Debezium 2.0.0.Beta1 has been released! This release contains several new features including a pluggable topic selector, the inclusion of database user who committed changes for Oracle change events, and improved handling of table unique indices as primary keys. In addition, there are several breaking changes such as the move to multi-partition mode as default and the introduction of the debezium-storage module and its implementations. So lets take a look at all these in closer detail.</summary></entry><entry><title type="html">Debezium 1.9.5.Final Released</title><link href="https://debezium.io/blog/2022/07/11/debezium-1-9-5-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.5.Final Released"/><published>2022-07-11T00:00:00+00:00</published><updated>2022-07-11T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/07/11/debezium-1-9-5-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/07/11/debezium-1-9-5-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the summer in full swing, the team is pleased to announce the release of Debezium &lt;strong&gt;1.9.5.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugfixes and stability; and is the recommended update for all users from earlier versions. This release contains &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+1.9.5.Final&quot;&gt;24 resolved issues&lt;/a&gt; overall.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;changes&quot;&gt;Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release focused entirely on stability and bugfixes. A few noteworthy changes include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Data duplication problem using postgresql source on debezium server &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5070&quot;&gt;DBZ-5070&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Duplicate SCNs on Oracle RAC installations incorrectly processed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5245&quot;&gt;DBZ-5245&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NPE when using Debezium Embedded in Quarkus &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5251&quot;&gt;DBZ-5251&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;No changes to commit_scn when oracle-connector got new lob data &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5266&quot;&gt;DBZ-5266&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;database.history.store.only.captured.tables.ddl not suppressing logs &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5270&quot;&gt;DBZ-5270&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium server fail when connect to Azure Event Hubs &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5279&quot;&gt;DBZ-5279&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Enabling database.history.store.only.captured.tables.ddl does not restrict history topic records &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5285&quot;&gt;DBZ-5285&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Snapshot fails when table&amp;#8217;s relational model is created using an abstract data type as unique index &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5300&quot;&gt;DBZ-5300&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental Snapshot: Oracle table name parsing does not support periods in DB name &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5336&quot;&gt;DBZ-5336&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support PostgreSQL default value function calls with schema prefixes &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5340&quot;&gt;DBZ-5340&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Log a warning when an unsupported LogMiner operation is detected for a captured table &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5351&quot;&gt;DBZ-5351&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL Connector column hash v2 does not work &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5366&quot;&gt;DBZ-5366&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox JSON expansion fails when nested arrays contain no elements &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5367&quot;&gt;DBZ-5367&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;docker-maven-plugin needs to be upgraded for Mac Apple M1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5369&quot;&gt;DBZ-5369&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.5-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community which contributed to Debezium 1.9.5.Final: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/ProofOfPizza&quot;&gt;Chai Stofkoper&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, Mikhail Dubrovin, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/HenryCaiHaiying&quot;&gt;Henry Cai&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/yangrong688&quot;&gt;yangrong688&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 1.9 release stream will remain the current long-running version for the next three months. During this time, we will continue to evaluate user reports and do micro-releases to address bugs and regressions depending on severity.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The development on Debezium 2.0 is moving along quite nicely. We have entered the second half of the development cycle, and we&amp;#8217;ll begin beta releases with the next release toward the end of July.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Stay tuned for more in the coming weeks, stay cool out there, and happy capturing!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">With the summer in full swing, the team is pleased to announce the release of Debezium 1.9.5.Final! This release primarily focuses on bugfixes and stability; and is the recommended update for all users from earlier versions. This release contains 24 resolved issues overall.</summary></entry><entry><title type="html">Debezium 2.0.0.Alpha3 Released</title><link href="https://debezium.io/blog/2022/07/05/debezium-2.0-alpha3-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Alpha3 Released"/><published>2022-07-05T00:00:00+00:00</published><updated>2022-07-05T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/07/05/debezium-2.0-alpha3-released</id><content type="html" xml:base="https://debezium.io/blog/2022/07/05/debezium-2.0-alpha3-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am thrilled to share that Debezium &lt;strong&gt;2.0.0.Alpha3&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While this release contains a plethora of bugfixes, there are a few noteworthy improvements, which include providing a timestamp in transaction metadata events, the addition of several new fields in Oracle&amp;#8217;s change event source block, and a non-backward compatible change to the Oracle connector&amp;#8217;s offsets.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Lets take a look at these in closer detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;transaction_metadata_changes&quot;&gt;Transaction metadata changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A transaction metadata event describes the &lt;em&gt;beginning&lt;/em&gt; and the &lt;em&gt;end&lt;/em&gt; (commit) of a database transaction. These events are useful for a variety of reasons, including auditing. By default, transaction metadata events are not generated by a connector and to enable this feature, the &lt;code&gt;provide.transaction.metadata&lt;/code&gt; option must be enabled.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, both &lt;code&gt;BEGIN&lt;/code&gt; and &lt;code&gt;END&lt;/code&gt; events include a new field, &lt;code&gt;ts_ms&lt;/code&gt;, which is the database timestamp of when the transaction either began or committed depending on the event type. An example of such an event now looks like:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;12345&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1657033173441&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s1.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; }, { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data_collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s2.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;event_count&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; } ] }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are already using the transaction metadata feature, new events will contain this field after upgrading.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are not using the transaction metadata feature but find this useful, simply add the &lt;code&gt;provide.transaction.metadata&lt;/code&gt; option set to &lt;em&gt;true&lt;/em&gt; to your connector configuration. By default, metadata events are emitted to a topic named after your &lt;code&gt;database.server.name&lt;/code&gt; option. This can be overridden by specifying the &lt;code&gt;transaction.topic&lt;/code&gt; option, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;database.server.name=server1 provide.transaction.metadata=true transaction.topic=my-transaction-events&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this example, all transaction metadata events will be emitted to &lt;code&gt;my-transaction-events&lt;/code&gt;. Please see your connector specific configuration for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_source_info_changes&quot;&gt;Oracle source info changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;source&lt;/code&gt; information block is a section in the change event&amp;#8217;s payload that describes the database attributes of what generated the change event. For example, this section includes the system change number, the database timestamp of the change, and the transaction the change was part of.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we identified a regression where the &lt;code&gt;scn&lt;/code&gt; field did not correctly reflect the right &lt;code&gt;source&lt;/code&gt; of where the change event occurred. While it isn&amp;#8217;t abnormal for Oracle to generate multiple changes with the same system change number, we did find a regression that caused the wrong system change number to get assigned to each individual event within a scoped transaction, which made it difficult for some to use this information for auditing purposes. The &lt;code&gt;source.scn&lt;/code&gt; field should now correctly reflect the system change number from Oracle LogMiner or Oracle Xstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Additionally, several new fields were added to the &lt;code&gt;source&lt;/code&gt; information block to improve integration with the LogMiner implementation and Oracle RAC. An example of the new source information block:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2.0.0.Alpha3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;server1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1520085154000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;6.28.807&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2122184&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2122185&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;001234.00012345.0124&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ssn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;redo_thread&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The newly added fields are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;rs_id&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the rollback segment identifier associated with the change.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;ssn&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the SQL sequence number, this combined with the &lt;code&gt;rs_id&lt;/code&gt; represent a unique tuple for a change.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;redo_thread&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies the actual database redo thread that managed the change&amp;#8217;s lifecycle.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Whether using Oracle Standalone or RAC, these values will always be provided when using Oracle LogMiner. These values have more importance on an Oracle RAC installation because you have multiple database servers manipulating the shared database concurrently. These fields specifically annotate which node and at what position on that node that the change originated.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_connector_offset_changes&quot;&gt;Oracle connector offset changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In an Oracle Real Application Clusters (RAC) environment, multiple nodes access and manipulate the Oracle database concurrently. Each node maintains its own redo log buffers and executes its own redo writer thread. This means that at any given moment, each node has its own unique &quot;position&quot; and these will differ entirely on the activity that takes place on each respective node.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, a small change was necessary in &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5245&quot;&gt;DBZ-5245&lt;/a&gt; to support Oracle RAC. Previously, the connector offsets maintained a field called &lt;code&gt;scn&lt;/code&gt; which represented this &quot;position&quot; of where the connector should stream changes from. But since each node could be at different positions in the redo, a single &lt;code&gt;scn&lt;/code&gt; value was inadequate for Oracle RAC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The old Oracle connector offsets looked like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1234567890&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2345678901&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lcr_position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting in 2.0.0.Alpha3, the new offset structure now has this form:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1234567890:00124.234567890.1234:0:1,1234567891:42100.0987656432.4321:0:2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;commit_scn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2345678901&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lcr_position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You will notice that the &lt;code&gt;scn&lt;/code&gt; field now consists of a comma-separated list of values, where each entry represents a tuple of values. This new tuple has the format of &lt;code&gt;scn:rollback-segment-id:ssn:redo-thread&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While this change is forward compatible, meaning you can safely upgrade to 2.0.0.Alpha3 and the old format can be read, once the new format is written to the offsets, the older versions of the connector will be unable to read the offsets. If you upgrade and decide you need to roll back, be aware you&amp;#8217;ll need to manually adjust the connector offset&amp;#8217;s &lt;code&gt;scn&lt;/code&gt; field to simply contain a string of the most recent &lt;code&gt;scn&lt;/code&gt; value across all redo threads.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are several bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Incorrect loading of LSN from offsets &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3942&quot;&gt;DBZ-3942&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Database history recovery will retain old tables after they&amp;#8217;ve been renamed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4451&quot;&gt;DBZ-4451&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Adding new table with incremental snapshots not working &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4834&quot;&gt;DBZ-4834&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;BigDecimal has mismatching scale value for given Decimal schema &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4890&quot;&gt;DBZ-4890&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium has never found starting LSN &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5031&quot;&gt;DBZ-5031&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Data duplication problem using postgresql source on debezium server &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5070&quot;&gt;DBZ-5070&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cursor fetch is used for all results during connection &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5084&quot;&gt;DBZ-5084&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezuim connector fails at parsing select statement overrides when table name has space &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5198&quot;&gt;DBZ-5198&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DDL statement couldn&amp;#8217;t be parsed 2 - Oracle connector 1.9.3.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5230&quot;&gt;DBZ-5230&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium server duplicates scripting jar files &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5232&quot;&gt;DBZ-5232&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cannot convert field type tinyint(1) unsigned to boolean &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5236&quot;&gt;DBZ-5236&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle unparsable ddl create table &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5237&quot;&gt;DBZ-5237&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Postgres Incremental Snapshot on parent partitioned table not working &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5240&quot;&gt;DBZ-5240&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Character set influencers are not properly parsed on default values &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5241&quot;&gt;DBZ-5241&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NPE when using Debezium Embedded in Quarkus &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5251&quot;&gt;DBZ-5251&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle LogMiner may fail with an in-progress transaction in an archive log that has been deleted &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5256&quot;&gt;DBZ-5256&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Order of source block table names in a rename schema change event is not deterministic &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5257&quot;&gt;DBZ-5257&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium fails to connect to replicaset if a node is down &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5260&quot;&gt;DBZ-5260&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;No changes to commit_scn when oracle-connector got new lob data &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5266&quot;&gt;DBZ-5266&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Invalid date 'SEPTEMBER 31' &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5267&quot;&gt;DBZ-5267&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;database.history.store.only.captured.tables.ddl not suppressing logs &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5270&quot;&gt;DBZ-5270&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;io.debezium.text.ParsingException: DDL statement couldn&amp;#8217;t be parsed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5271&quot;&gt;DBZ-5271&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Deadlock during snapshot with Mongo connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5272&quot;&gt;DBZ-5272&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mysql parser is not able to handle variables in KILL command &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5273&quot;&gt;DBZ-5273&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium server fail when connect to Azure Event Hubs &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5279&quot;&gt;DBZ-5279&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ORA-01086 savepoint never established raised when database history topic cannot be created or does not exist &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5281&quot;&gt;DBZ-5281&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Enabling database.history.store.only.captured.tables.ddl does not restrict history topic records &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5285&quot;&gt;DBZ-5285&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Alpha3%20ORDER%20BY%20component%20ASC&quot;&gt;66 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/ProofOfPizza&quot;&gt;Chai Stofkoper&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, Mikhail Dubrovin, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/yannickzj&quot;&gt;Jun Zhao&lt;/a&gt;, &lt;a href=&quot;https://github.com/kanha-gupta&quot;&gt;Kanha Gupta&lt;/a&gt;, &lt;a href=&quot;https://github.com/alwaysbemark&quot;&gt;Mark Bereznitsky&lt;/a&gt;, &lt;a href=&quot;https://github.com/mimaison&quot;&gt;Mickael Maison&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, Oskar Polak, &lt;a href=&quot;https://github.com/rahulkhanna2&quot;&gt;Rahul Khanna&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/tim-patterson&quot;&gt;Tim Patterson&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/yangrong688&quot;&gt;yangrong688&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can expect a 1.9.5.Final release in the next week. This release will include many of the bugfixes that are part of this release, as we continue to improve the stability of 1.9 in micro-releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can also expect 2.0.0.Beta1 in the next 3 weeks, keeping with our usual release cadence. The next major milestones includes unifying snapshot modes across connectors, a new &lt;code&gt;Snapshotter&lt;/code&gt; API for all connectors, compactable JSON database history, offset unification, offset storage API and much more.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am thrilled to share that Debezium 2.0.0.Alpha3 has been released! While this release contains a plethora of bugfixes, there are a few noteworthy improvements, which include providing a timestamp in transaction metadata events, the addition of several new fields in Oracle&amp;#8217;s change event source block, and a non-backward compatible change to the Oracle connector&amp;#8217;s offsets. Lets take a look at these in closer detail.</summary></entry><entry><title type="html">Debezium 1.9.4.Final Released</title><link href="https://debezium.io/blog/2022/06/21/debezium-1-9-4-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.4.Final Released"/><published>2022-06-21T00:00:00+00:00</published><updated>2022-06-21T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/06/21/debezium-1-9-4-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/06/21/debezium-1-9-4-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.9.4.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugfixes and stability; and is the recommended update for all users from earlier versions. This release contains &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+1.9.4.Final&quot;&gt;32 resolved issues&lt;/a&gt; overall.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;fixes&quot;&gt;Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release focused entirely on stability and bugfixes. A few noteworthy changes include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Include event scn in Oracle records &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5225&quot;&gt;DBZ-5225&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Redis Store does not work with GCP Managed Redis &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5268&quot;&gt;DBZ-5268&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Database history recovery will retain old tables after they&amp;#8217;ve been renamed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4451&quot;&gt;DBZ-4451&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Adding new table with incremental snapshots not working &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4834&quot;&gt;DBZ-4834&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium has never found starting LSN &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5031&quot;&gt;DBZ-5031&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cursor fetch is used for all results during connection &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5084&quot;&gt;DBZ-5084&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Postgres v1.9.3 fails in Materialize CI &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5204&quot;&gt;DBZ-5204&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cannot convert field type tinyint(1) unsigned to boolean &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5236&quot;&gt;DBZ-5236&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle LogMiner may fail with an in-progress transaction in an archive log that has been deleted &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5256&quot;&gt;DBZ-5256&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Order of source block table names in a rename schema change event is not deterministic &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5257&quot;&gt;DBZ-5257&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium fails to connect to replicaset if a node is down &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5260&quot;&gt;DBZ-5260&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Deadlock during snapshot with Mongo connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5272&quot;&gt;DBZ-5272&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, there were several SQL parser fixes for both Oracle and MySQL.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.4-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community which contributed to Debezium 1.9.4.Final: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/yannickzj&quot;&gt;Jun Zhao&lt;/a&gt;, Oskar Polak, &lt;a href=&quot;https://github.com/rahulkhanna2&quot;&gt;Rahul Khanna&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/tim-patterson&quot;&gt;Tim Patterson&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 1.9 release stream will remain the current long-running version for the next three months. During this time, we will continue to evaluate user reports and do micro-releases to address bugs and regressions depending on severity.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also, quite a lot of work has gone into Debezium 2.0. We are currently actively working on Debezium 2.0.0.Alpha3 and should have an update on this in the next week.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Stay tuned for more in the coming weeks and stay cool out there!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.9.4.Final! This release primarily focuses on bugfixes and stability; and is the recommended update for all users from earlier versions. This release contains 32 resolved issues overall.</summary></entry><entry><title type="html">Debezium 2.0.0.Alpha2 Released</title><link href="https://debezium.io/blog/2022/06/09/debezium-2.0-alpha2-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Alpha2 Released"/><published>2022-06-09T00:00:00+00:00</published><updated>2022-06-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/06/09/debezium-2.0-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2022/06/09/debezium-2.0-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am thrilled to share that Debezium &lt;strong&gt;2.0.0.Alpha2&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is packed with tons of bugfixes and improvements, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Alpha2%20ORDER%20BY%20component%20ASC&quot;&gt;110 issues&lt;/a&gt; resolved in total. Just, WOW!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A few noteworthy changes include incremental snapshots gaining support for regular expressions and a new stop signal. We also did some housekeeping and removed a number of deprecated configuration options and as well as the legacy MongoDB oplog implementation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Lets take a look at these in closer detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshot_changes&quot;&gt;Incremental snapshot changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, incremental snapshots has been a tremendous success. The feedback we&amp;#8217;ve gotten from the community has been overwhelmingly positive about how this process works and how its helped streamline capturing changes, particularly for users with very large datasets. So we took an opportunity in this release to build upon that momentum and introduced several new options:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The ability to stop an in-progress incremental snapshot&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support the use of regular expressions&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;stopping_incremental_snapshots&quot;&gt;Stopping incremental snapshots&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since we first introduced incremental snapshots, users have asked for a way to stop an in-progress snapshot. To accomplish this, we have added a new signal, &lt;code&gt;stop-snapshot&lt;/code&gt;, which allows stopping an in-progress incremental snapshot. This signal is to be sent just like any other, by inserting a row into the signal table/collection, as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; schema.signal_table (id, type,data) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;unique-id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stop-snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_&amp;lt;signal payload&amp;gt;_`);&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;stop-snapshot&lt;/code&gt; payload looks very similar to its &lt;code&gt;execute-snapshot&lt;/code&gt; counterpart. An example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema1.table1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema2.table2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This example removes both &lt;code&gt;schema1.table1&lt;/code&gt; and &lt;code&gt;schema2.table2&lt;/code&gt; from the incremental snapshot, so long as the table or collection had not already finished its incremental snapshot. If other tables or collections remain outstanding after the removal of those specified by &lt;code&gt;data-collections&lt;/code&gt;, the incremental snapshot will continue to process those that are outstanding. If no other table or collection remains, the incremental snapshot will stop.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Another example of a &lt;code&gt;stop-snapshot&lt;/code&gt; payload is quite simply:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This example does not specify the &lt;code&gt;data-collections&lt;/code&gt; property, it is optional for the &lt;code&gt;stop-snapshot&lt;/code&gt; signal. When this property isn&amp;#8217;t specified, the signal implies the current in-progress incremental snapshot should be stopped entirely. This gives the ability to stop an incremental snapshot without knowledge of the current or outstanding tables or collections yet to be captured.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;signals_support_regular_expressions&quot;&gt;Signals support regular expressions&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshot signals have required the use of explicit table/collection names in the &lt;code&gt;data-collections&lt;/code&gt; payload attribute. While this worked well, there may be situations where broad capture configurations could take advantage of regular expression usage. We already support regular expressions in connector configuration options, such as include/exclude lists, so it made sense to extend that to incremental snapshots as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting in Debezium 2.0, all incremental snapshot signals can use regular expressions in the &lt;code&gt;data-collections&lt;/code&gt; payload property. Using one of the stop signal examples from above, the payload can be rewritten using regular expressions:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema[1|2].table[1|2]&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;incremental&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Just like the explicit usage, this signal with regular expressions would also stop both &lt;code&gt;schema1.table1&lt;/code&gt; and &lt;code&gt;schema2.table2&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;removal_of_mongodb_oplog_support&quot;&gt;Removal of MongoDB oplog support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Debezium 1.8, we introduced the new MongoDB change stream feature while also deprecating the oplog implementation. The transition to change streams offers a variety of benefits, such as being able to stream changes from non-primary nodes, the ability to emit update events with a full document representation for downstream consumers, and so much more. In short, change streams is just a much more superior way to perform change data capture with MongoDB.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The removal of the oplog implementation also means that MongoDB 3.x is no longer supported. If you are using MongoDB 3.x, you will need to upgrade to at least MongoDB 4.0 or later with Debezium 2.0.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configuration_option_clean_up&quot;&gt;Configuration option clean-up&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium 1.x has seen a lot of evolution over the years. We added connector-specific options to handle migration or specific features that have been deprecated or even replaced by common options that are universal for all connectors. One of the major tasks for Debezium 2.0 is to do some internal housekeeping on configuration options as many have been deprecated.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With that, there is also more configuration housekeeping coming in the future when we look at option namespaces. Suffice to say, it will be important as a part of the upgrade path to review the connector&amp;#8217;s documentation on its relevant options with current connector configurations. You just might find that you can streamline your configurations with fewer options or that some option names have changed entirely.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are several bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Postgres existing publication is not updated with the new table &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3921&quot;&gt;DBZ-3921&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL connector increment snapshot failed parse datetime column length when connector set &quot;snapshot.fetch.size&quot;: 20000 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4939&quot;&gt;DBZ-4939&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DateTimeParseException: Text 'infinity' could not be parsed in Postgres connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5014&quot;&gt;DBZ-5014&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;PostgreSQL ENUM default values are missing from generated schema &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5038&quot;&gt;DBZ-5038&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;All connectors now use multi-partitioned codebase &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5042&quot;&gt;DBZ-5042&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle LogMiner: records missed during switch from snapshot to streaming mode &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5085&quot;&gt;DBZ-5085&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Introduce a new field &quot;ts_ms&quot; to identify the process time for schema change event &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5098&quot;&gt;DBZ-5098&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Parsing zero-day fails &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5099&quot;&gt;DBZ-5099&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, an amazing &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Alpha2%20ORDER%20BY%20component%20ASC&quot;&gt;110 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: Rotem Adhoh, &lt;a href=&quot;https://github.com/AlexMiroshnikov&quot;&gt;Alexey Miroshnikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ajunwalker&quot;&gt;Andrew Walker&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/Chrisss93&quot;&gt;Chris Lee&lt;/a&gt;, &lt;a href=&quot;https://github.com/connorszczepaniak-wk&quot;&gt;Connor Szczepaniak&lt;/a&gt;, &lt;a href=&quot;https://github.com/cmartinez-enve&quot;&gt;César Martínez&lt;/a&gt;, &lt;a href=&quot;https://github.com/elirag&quot;&gt;Eliran Agranovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/EthanZ328&quot;&gt;Ethan Zou&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/Himanshu-LT&quot;&gt;Himanshu Mishra&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/markallanson&quot;&gt;Mark Allanson&lt;/a&gt;, &lt;a href=&quot;https://github.com/alwaysbemark&quot;&gt;Mark Bereznitsky&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-bradshaw-at&quot;&gt;Nathan Bradshaw&lt;/a&gt;, &lt;a href=&quot;https://github.com/sagarrao12&quot;&gt;Sagar Rao&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/troeselereos&quot;&gt;Timo Roeseler&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So while this release is a bit behind schedule, Debezium 2.0 is shaping up quite well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next major milestones includes unifying snapshot modes across connectors, a new &lt;code&gt;Snapshotter&lt;/code&gt; API for all connectors, compactable JSON database history, offset unification, offset storage API and much more. So the coming weeks do have a lot in store, as we continue to work on Debezium 2.0. And as usual, you can expect some (hopefully all) of these in approximately 3-weeks, sticking to our usual release cadence.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until then, let the data capturing continue!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am thrilled to share that Debezium 2.0.0.Alpha2 has been released! This release is packed with tons of bugfixes and improvements, 110 issues resolved in total. Just, WOW! A few noteworthy changes include incremental snapshots gaining support for regular expressions and a new stop signal. We also did some housekeeping and removed a number of deprecated configuration options and as well as the legacy MongoDB oplog implementation. Lets take a look at these in closer detail.</summary></entry><entry><title type="html">Debezium 1.9.3.Final Released</title><link href="https://debezium.io/blog/2022/06/02/debezium-1-9-3-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.3.Final Released"/><published>2022-06-02T00:00:00+00:00</published><updated>2022-06-02T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/06/02/debezium-1-9-3-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/06/02/debezium-1-9-3-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the summer nears, I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.9.3.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugfixes and stability; however, there are some notable feature enhancements. Lets take a moment to cool off and &quot;dive&quot; into these new features in a bit of detail :).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;decoding_binary_payloads_with_mongodb_and_outbox&quot;&gt;Decoding binary payloads with MongoDB and Outbox&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Databases have had support for storing binary data since the beginning, and there are a number of reasons that applications favor using a database for this over other alternatives. Binary data doesn&amp;#8217;t always have to be information like images, thumbnails, or binary documents like PDFs, it can also include serialized objects too.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the outbox pattern with MongoDB and Avro serialization, the outbox&amp;#8217;s payload field is the only value that is emitted in the message&amp;#8217;s value. When the payload consists of binary data, as shown below, it is emitted as-is and can lead to some serialization issues with consumers of the topic.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$binary&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;integer&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt; } }&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, we&amp;#8217;ve deprecated the &lt;code&gt;ByteBufferConverter&lt;/code&gt; and we&amp;#8217;ve introduced two new converters in its place:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;ByteArrayConverter&lt;/code&gt;: converts payload to be delivered as it is, a &lt;code&gt;byte[]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;BinaryDataConverter&lt;/code&gt;: converts payload to be delivered as either a &lt;code&gt;ByteBuffer&lt;/code&gt; or &lt;code&gt;Byte[]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For this use case, we&amp;#8217;re going to make use of the new &lt;code&gt;ByteArrayConverter&lt;/code&gt; as we want to emit this payload&amp;#8217;s value as the raw &lt;code&gt;byte[]&lt;/code&gt;. In the connector configuration, the &lt;code&gt;value.converter&lt;/code&gt; configuration option must be set to handle this use case.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;transforms=outbox,... transforms.outbox.type=io.debezium.connector.monogdb.transforms.outbox.MongoEventRouter value.converter=io.debezium.converters.ByteArrayConverter&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now the data will be emitted to the broker as-is, as a byte-array that can be safely consumed by consumers. Thanks to Nathan Bradshaw for this excellent contribution!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;heartbeat_action_queries_with_oracle&quot;&gt;Heartbeat action queries with Oracle&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The heartbeat action query is a feature that allows a Debezium connector to write records to the source database and to capture those records during the event processing loop. This was first introduced for PostgreSQL to deal with situations when captured tables change less frequently than other non-captured tables, causing unintended WAL growth.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For Oracle using the LogMiner implementation, a similar problem occurs that impacts the connector&amp;#8217;s ability to restart due to the offset SCN not being advanced on a regular interval due to changes being made to other tables that are not captured, whether they are part of the same pluggable database or another.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To enable heartbeat action queries, the connector must be configured with:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;heartbeat.interval.ms=1000 heartbeat.action.query=INSERT INTO heartbeat (id) values (SYSDATE) table.include.list=MYSCHEMA.HEARTBEAT,...&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The heartbeat functionality must first be enabled by specifying the &lt;code&gt;heartbeat.interval.ms&lt;/code&gt;. This controls how often the connector generates heartbeat events. If this value is not greater-than &lt;code&gt;0&lt;/code&gt;, then heartbeats are disabled.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Next, to specifically use the action query feature, the &lt;code&gt;heartbeat.action.query&lt;/code&gt; option must be given. This specifies a SQL statement that will be executed on each heartbeat interval. This statement can be either an &lt;code&gt;INSERT&lt;/code&gt; or an &lt;code&gt;UPDATE&lt;/code&gt;, as long as the resulting SQL operation generates a row change.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Finally, the action query must operate on a table that is included in the connector&amp;#8217;s filter configuration. Like any other captured table, the table must also be configured with the correct supplemental logging so that the event is captured.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With this configuration in place, and assuming no long-running transaction, the offset SCN will advance on each heartbeat.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_logminer_session_duration_is_now_controllable&quot;&gt;Oracle LogMiner session duration is now controllable&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium Oracle connector&amp;#8217;s LogMiner session duration has always been based on how often the redo log switches. Generally, this behavior has worked well for most environments; however, in low traffic environments or during off-peak hours, this has the potential to re-use the same LogMiner session for a longer period of time that can lead to ORA-04030 exceptions when the PGA memory is exhausted.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A new configuration option has been added, &lt;code&gt;log.mining.session.max.ms&lt;/code&gt;, allowing full control over the maximum duration of an Oracle LogMiner session. When set to a value greater-than &lt;code&gt;0&lt;/code&gt;, the connector will automatically close and restart the mining session if the maximum duration is reached or a log switch occurs, whichever comes first. Oracle environments with low volume, particularly during off-peak hours, should no longer notice any PGA memory concerns when enabling this new option. Coordinate with your database administrator team to determine the best value based on your environment&amp;#8217;s configuration and activity.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_changes&quot;&gt;Further Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But that&amp;#8217;s not all, there were also a number of bugfixes that are noteworthy, including but not limited to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;MySQL connector increment snapshot failed parse datetime column lenth when connector set &quot;snapshot.fetch.size&quot;: 20000 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4939&quot;&gt;DBZ-4939&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;InstanceAlreadyExistsException during MongoDb connector metrics registration &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5011&quot;&gt;DBZ-5011&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DateTimeParseException: Text 'infinity' could not be parsed in Postgres connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5014&quot;&gt;DBZ-5014&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;4 Connections per connector (postgres) &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5074&quot;&gt;DBZ-5074&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle Logminer: records missed during switch from snapshot to streaming mode &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5085&quot;&gt;DBZ-5085&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cannot Set debezium.sink.kafka.producer.ssl.endpoint.identification.algorithm to empty value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5105&quot;&gt;DBZ-5105&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MilliSecondsBehindSource is not reported by SQL Server connector &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5137&quot;&gt;DBZ-5137&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ExtractNewRecordState SMT Replaces Null Value with Column&amp;#8217;s Default Value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5166&quot;&gt;DBZ-5166&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector metrics tracking of rollback and abandoned transactions may cause high memory usage &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5179&quot;&gt;DBZ-5179&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We strongly recommend upgrading to 1.9.3.Final to get the latest improvements both in performance and stability.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20and%20fixVersion%20%3D%201.9.3.Final&quot;&gt;47 issues&lt;/a&gt; were fixed in this release. Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.3-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community which contributed to Debezium 1.9.3.Final: &lt;a href=&quot;https://github.com/AlexMiroshnikov&quot;&gt;Alexey Miroshnikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/connorszczepaniak-wk&quot;&gt;Connor Szczepaniak&lt;/a&gt;, &lt;a href=&quot;https://github.com/cmartinez-enve&quot;&gt;César Martínez&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/Himanshu-LT&quot;&gt;Himanshu Mishra&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/markallanson&quot;&gt;Mark Allanson&lt;/a&gt;, &lt;a href=&quot;https://github.com/alwaysbemark&quot;&gt;Mark Bereznitsky&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-bradshaw-at&quot;&gt;Nathan Bradshaw&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, and &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 1.9 release stream will remain the current long-running version for the next three months. During this time, we will continue to evaluate user reports and do micro-releases to address bugs and regressions depending on severity.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also, quite a lot of work has gone into Debezium 2.0. We intend to release Debezium 2.0.0.Alpha2 next week, will releases to follow about every three weeks thereafter.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Stay tuned for more in the coming weeks and stay cool out there!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">As the summer nears, I&amp;#8217;m excited to announce the release of Debezium 1.9.3.Final! This release primarily focuses on bugfixes and stability; however, there are some notable feature enhancements. Lets take a moment to cool off and &quot;dive&quot; into these new features in a bit of detail :).</summary></entry><entry><title type="html">Switching to Java 11/17</title><link href="https://debezium.io/blog/2022/05/04/switch-to-java-11/" rel="alternate" type="text/html" title="Switching to Java 11/17"/><published>2022-05-04T00:00:00+00:00</published><updated>2022-05-04T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/05/04/switch-to-java-11</id><content type="html" xml:base="https://debezium.io/blog/2022/05/04/switch-to-java-11/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As you probably noticed, we have started work on Debezium 2.0. One of &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;the planned changes&lt;/a&gt; for the 2.0 release is &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4949&quot;&gt;to switch to Java 11 as a baseline&lt;/a&gt;. While some Java build providers still support Java 8, other Java 8 distributions already reached their end of life/support. Users are moving to Java 11 anyways, as surveys like New Relic&amp;#8217;s &lt;a href=&quot;https://newrelic.com/resources/report/2022-state-of-java-ecosystem&quot;&gt;State of the Java Ecosystem Report&lt;/a&gt; indicate. But it is not only matter of support: Java 11 comes with various performance improvements, useful tools like JDK Flight Recorder, which was open-sourced in Java 11, and more. So we felt it was about time to start thinking about using a more recent JDK as the baseline for Debezium, and the new major release is a natural milestone when to do the switch.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting with the first release of Debezium 2.0, &lt;a href=&quot;/blog/2022/04/28/debezium-2.0-alpha1-released/&quot;&gt;2.0.0.Alpha1&lt;/a&gt;, Debezium bits will be compiled to Java 11 byte code. Therefore, Java 11 will be required to run Debezium in the next major update. Also, if you use any of the Debezium bits as a library in your project (using the Debezium &lt;a href=&quot;/documentation/reference/stable/development/engine.html&quot;&gt;embedded engine&lt;/a&gt;), you will have to switch to Java 11.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But wait, what does Java 11/17 in the title mean? Is it there just to scare you, or we are going to actually switch to Java 17 right away?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&amp;lt;dramatic pause here&amp;gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;No, we don&amp;#8217;t want to scare you. We are actually planning to switch to Java 17, but only for the test suite. Please note that both Java 11 and 17 are long term support (LTS) releases. We don&amp;#8217;t want to move Java 17 for the actual Debezium artifacts just yet, as it can be an issue for substantial amount of Debezium users; as e.g. the aforementioned New Relic report shows that most of the users are still on Java 11 and of course we don&amp;#8217;t want to exclude them. However, using Java 17 for tests doesn&amp;#8217;t affect users in any way, and will allow us to use some more recent Java features in the tests, like e.g. * &lt;a href=&quot;https://openjdk.java.net/jeps/378&quot;&gt;text blocks&lt;/a&gt;, which for instance simplify the usage of multi-line JSON or SQL strings, * &lt;a href=&quot;https://openjdk.java.net/jeps/384&quot;&gt;records&lt;/a&gt;, which can improve readability of the stream operations heavily used in our tests, * &lt;a href=&quot;https://openjdk.java.net/jeps/361&quot;&gt;switch expressions&lt;/a&gt;, and more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Pretty sweet, right?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Setting different byte code levels for code and tests is pretty easy with Maven, you just need to set the following properties:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;maven.compiler.release&amp;gt;&lt;/span&gt;11&lt;span class=&quot;tag&quot;&gt;&amp;lt;/maven.compiler.release&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;maven.compiler.testRelease&amp;gt;&lt;/span&gt;17&lt;span class=&quot;tag&quot;&gt;&amp;lt;/maven.compiler.testRelease&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please note that we&amp;#8217;re using the &lt;code&gt;release&lt;/code&gt; option instead of the legacy &lt;code&gt;source&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; options, which prevents the accidental usage of Java APIs not present in the targeted Java version. See e.g. Gunnar&amp;#8217;s blog post &lt;a href=&quot;https://www.morling.dev/blog/bytebuffer-and-the-dreaded-nosuchmethoderror/&quot;&gt;ByteBuffer and the Dreaded NoSuchMethodError&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After switching to Java 11, the &lt;a href=&quot;https://maven.apache.org/plugins/maven-checkstyle-plugin/&quot;&gt;Maven Checkstyle plug-in&lt;/a&gt; and the &lt;a href=&quot;https://code.revelc.net/impsort-maven-plugin/&quot;&gt;ImpSort plug-in&lt;/a&gt; (a plug-in which takes care of proper import ordering) started to fail. However, bumping their versions to the latest releases has solved all the issues.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This was the easy part. The most difficult part was the Debezium &lt;a href=&quot;/documentation/reference/stable/connectors/cassandra.html&quot;&gt;connector for Apache Cassandra&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra_connector_tests&quot;&gt;Cassandra Connector Tests&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since &lt;a href=&quot;/blog/2022/04/06/debezium-1.9-final-released/&quot;&gt;version 1.9&lt;/a&gt;, the Cassandra connector provides support for Cassandra 3 as well as for Cassandra 4. Cassandra 4 &lt;a href=&quot;https://cassandra.apache.org/doc/4.0/cassandra/new/java11.html&quot;&gt;works like a charm with Java 11&lt;/a&gt;, but running Cassandra 3 with Java 11 is not possible (or at least requires some hacking). The existing test implementation for this connector didn&amp;#8217;t run Cassandra in a container as we do it in tests for all other DB connectors, but instead runs Cassandra in embedded mode, i.e. within the same JVM and process as the tests themselves. Therefore if you wanted to run the tests with Java 11 (or 17), tests for the Cassandra 3 connector module would fail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The obvious solution is to run Cassandra in a container with Java 8. This sounds good, but this approach has one pitfall. The Cassandra connector needs access to Cassandra log files as it obtains CDC events from them, so the tests need to access Cassandra files in the container. This can be solved quite easily using a temporary directory, for instance within the &lt;code&gt;target&lt;/code&gt; directory, mounting it as a volume into the container running Cassandra. Cassandra running in the container can later on use this mounted volume for storing its data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The real issue starts when you try to do the cleanup after the tests. As Cassandra runs in the container under a dedicated user named &lt;code&gt;cassandra&lt;/code&gt;, which is very likely not present on the test machine (or with a different UID/GID), cleanup fails when it tries to delete the temporary directory with Cassandra files. These files were created in that temporal directory mounted into the container and not in Docker FS overlay, so that are present in the &lt;code&gt;target&lt;/code&gt; directory. As the files were created by the &lt;code&gt;cassandra&lt;/code&gt; user, which is very likely different user than one who runs the tests, user running the tests has insufficient rights to delete files created by &lt;code&gt;cassandra&lt;/code&gt; user. Trying to delete them from Cassandra&amp;#8217;s container on Cassandra exit in some wrapper script turned out to be quite cumbersome and not very reliable.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The most promising solution proved to involve starting a second container with the same &lt;code&gt;cassandra&lt;/code&gt; user with access to the mounted volume and cleaning up the files after the first Cassandra container had already stopped.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We considered two options for running containers:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://dmp.fabric8.io/&quot;&gt;Fabric8 Docker Maven plugin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.testcontainers.org/&quot;&gt;Testcontainers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We use the Fabric8 plugin in the rest of the project, which suggests to use it also in this case to have uniformity across the project. On the other hand, using Testcontainers would make tests more convenient for the developers (who actually use tests after all!), as it allows to run the tests directly from IDE without starting the container manually.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the end, the decision was driven by the fact that running a cleanup container is not possible with the Fabric8 plugin. Maven doesn&amp;#8217;t allow to execute different configurations in the same phase and therefore it&amp;#8217;s not possible to stop the Cassandra container in the &lt;code&gt;post-integration-test&lt;/code&gt; phase and at the same time run a cleanup container in this phase. Testcontainers allow starting and stopping containers programmatically when needed, letting us define the images directly in the test code so we don&amp;#8217;t need any additional &lt;code&gt;Dockerfile&lt;/code&gt; , and cleaning up the container is just an implementation detail hidden in the test itself. Having the ability to run the tests directly from an IDE, without having to manually start and stop a container with the database, is a nice benefit on top of these things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The only tricky thing when using Testcontainers was that when we tried to remove the log files using Docker&amp;#8217;s &lt;code&gt;cmd&lt;/code&gt; command, Testcontainers randomly failed, stating that the container didn&amp;#8217;t start in spite of the fact that all Cassandra files were actually deleted. The container probably ran so fast that it finished before Testcontainers noticed it. Finally, we solved it by adding a short &lt;code&gt;sleep&lt;/code&gt; in the container and executing an additional command in the container which does the cleanup.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The final cleanup code using Testcontainers looks like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;@AfterClass public static void tearDownClass() throws IOException, InterruptedException { destroyTestKeyspace(); cassandra.stop(); GenericContainer cleanup = new GenericContainer(new ImageFromDockerfile() .withDockerfileFromBuilder(builder -&lt;span class=&quot;error&quot;&gt;&amp;gt;&lt;/span&gt; builder .from(&amp;quot;eclipse-temurin:8-jre-focal&amp;quot;) .volume(&amp;quot;/var/lib/cassandra&amp;quot;) .cmd(&amp;quot;sleep&amp;quot;, &amp;quot;10&amp;quot;) // Give TC some time to find out container is running. .build())) .withFileSystemBind(cassandraDir, CASSANDRA_SERVER_DIR, BindMode.READ_WRITE); cleanup.start(); cleanup.execInContainer( &amp;quot;rm&amp;quot;, &amp;quot;-rf&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/data&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/cdc_raw_directory&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/commitlog&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/hints&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/saved_caches&amp;quot;); cleanup.stop(); }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once we solved the issue with the Cassandra tests, we were mostly done and were ready to use Java 11 in the main Debezium code and Java 17 for our tests.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;open_issues&quot;&gt;Open Issues&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We need more battle testing to be sure that everything works well with Java 11/17. Your help with testing and bug reports would be very valuable here and more than welcome. Currently we are aware of one minor unsolved issue related to the Java update. Some IDEs cannot distinguish between &lt;code&gt;maven.compiler.release&lt;/code&gt; and &lt;code&gt;maven.compiler.testRelease&lt;/code&gt; (or it&amp;#8217;s not very clear to us how to set it up). For example this test using a &lt;a href=&quot;https://openjdk.java.net/jeps/378&quot;&gt;text block&lt;/a&gt; is marked as an error in the IDE:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-05-04-switch-to-java-11/idea_error.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Test using text block in IntelliJ Idea.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can manually set the Java level to 17, but in this case you may unintentionally use Java &amp;gt; 11 features in non-test code without the IDE letting you know (which admittedly isn&amp;#8217;t too much of a problem, as the next Maven build, e.g. on CI, would catch that issue). Moreover, e.g. Idea resets the code level upon any changes in the &lt;code&gt;pom.xml&lt;/code&gt; files. Have you solved this issue? Or do you use an IDE which doesn&amp;#8217;t have issues with mixing different Java levels? Please share your experiences in the discussion!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Vojtěch Juránek</name></author><category term="community"/><category term="news"/><summary type="html">As you probably noticed, we have started work on Debezium 2.0. One of the planned changes for the 2.0 release is to switch to Java 11 as a baseline. While some Java build providers still support Java 8, other Java 8 distributions already reached their end of life/support. Users are moving to Java 11 anyways, as surveys like New Relic&amp;#8217;s State of the Java Ecosystem Report indicate. But it is not only matter of support: Java 11 comes with various performance improvements, useful tools like JDK Flight Recorder, which was open-sourced in Java 11, and more. So we felt it was about time to start thinking about using a more recent JDK as the baseline for Debezium, and the new major release is a natural milestone when to do the switch.</summary></entry><entry><title type="html">Debezium 2.0.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Alpha1 Released"/><published>2022-04-28T00:00:00+00:00</published><updated>2022-04-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am excited to share that Debezium &lt;strong&gt;2.0.0.Alpha1&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is the first of several planned pre-releases of Debezium 2.0 over the next five months. Each pre-release plans to focus on strategic changes in the hope that as we move forward, changes can be easily tested and regressions addressed quickly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, some of the most notable changes include requiring Java 11 to use Debezium or any of its components, the removal of &lt;code&gt;wal2json&lt;/code&gt; support for PostgreSQL and the legacy MySQL connector implementation, as well as some notable features such as improved Debezium Server Google Pub/Sub sink support, and a multitude of bugfixes. Let&amp;#8217;s take a look at a few of these.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;java_11_required&quot;&gt;Java 11 required&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have wanted to make the jump to using Java 11 as a build requirement for quite some time now, and with Debezium 2.0 this is now possible. With Java 11, this enables us to take advantage of new language features, such as the new &lt;code&gt;String&lt;/code&gt; API and &lt;code&gt;Predicate&lt;/code&gt; support changes in the codebase, while also benefiting from many Java performance improvements.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our very own Vojtech Juranek will be publishing a blog post next week that discusses the switch to Java 11 and 17 in greater detail. I highly recommend giving it a read as it provides a deep dive into the technical background &amp;amp; effort that went into making this possible.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So before migrating to Debezium 2.0, be sure that Java 11 is available.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;postgresql_wal2json_support_removed&quot;&gt;PostgreSQL wal2json support removed&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The PostgreSQL connector has supported several plugins throughout Debezium 1.x, including &lt;code&gt;decoderbufs&lt;/code&gt;, &lt;code&gt;wal2json&lt;/code&gt;, and &lt;code&gt;pgoutput&lt;/code&gt;. PostgreSQL 9.6 recently reached &lt;a href=&quot;https://www.postgresql.org/support/versioning/&quot;&gt;end of life&lt;/a&gt; on November 11, 2021. This presented a great opportunity for us to review the supported decoders and to see whether we could streamline those options.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since &lt;code&gt;pgoutput&lt;/code&gt; is a native decoder supported by all non-EOL versions of PostgreSQL (PG10+), it made sense to remove &lt;code&gt;wal2json&lt;/code&gt;. Reducing the number of decoders to 2 (down from 3), allows us to streamline the code for PostgreSQL, reduces the overall maintenance cost of the connector, and gives us a much more narrow target for overall support.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are still using PostgreSQL 9.6 or were using &lt;code&gt;wal2json&lt;/code&gt; previously, you will need to migrate to at least PostgreSQL 10.0 or to &lt;code&gt;decoderbufs&lt;/code&gt; or &lt;code&gt;pgougput&lt;/code&gt; respectively before upgrading to Debezium 2.0.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;legacy_mysql_implementation_removed&quot;&gt;Legacy MySQL implementation removed&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As some of you may or may not know, we implemented the MySQL connector based on the common-connector framework back in Debezium 1.5 (Feb 2021). As a part of that re-write, we introduced the ability for MySQL users to enable the legacy connector behavior using the configuration option &lt;code&gt;internal.implementation&lt;/code&gt; set as &lt;code&gt;legacy&lt;/code&gt;. This legacy implementation was deprecated in favor of the new common-connector framework behavior. With Debezium 2.0, this &lt;code&gt;internal.implementation&lt;/code&gt; configuration option and the legacy connector implementation have been removed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If your current connector deployment relies on this legacy implementation, you should be aware that by upgrading to Debezium 2.0, the connector will no longer use that older implementation and will use the common-connector implementation only. Feature-wise, both implementations are on-par with one another with one exception: the legacy implementation had experimental support for changing filter configurations. If you have relied on this legacy behavior, be aware that feature is no longer available.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are several bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Implement Pub/Sub Lite change consumer &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4450&quot;&gt;DBZ-4450&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add Google Pub/Sub emulator support &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4491&quot;&gt;DBZ-4491&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Making Postgres &lt;code&gt;PSQLException: This connection has been closed.&lt;/code&gt; retriable &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4948&quot;&gt;DBZ-4948&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Should store event header timestamp in HistoryRecord &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4998&quot;&gt;DBZ-4998&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Getting java.sql.SQLException: ORA-01291: missing logfile while running with archive log only &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4879&quot;&gt;DBZ-4879&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium uses wrong LCR format for Oracle 12.1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4932&quot;&gt;DBZ-4932&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NPE caused by io.debezium.connector.oracle.antlr.listener.ColumnDefinitionParserListener.resolveColumnDataType &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4976&quot;&gt;DBZ-4976&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox Transform does not allow expanded payload with additional fields in the envelope &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4989&quot;&gt;DBZ-4989&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CLOB with single quotes causes parser exception &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4994&quot;&gt;DBZ-4994&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cassandra 3 handler does not process partition deletions correctly &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5022&quot;&gt;DBZ-5022&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SQL Server in multi-partition mode fails if a new database is added to an existing configuration &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5033&quot;&gt;DBZ-5033&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Quarkus 2.8.2.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5062&quot;&gt;DBZ-5062&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;55 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: Wang Min Chao, &lt;a href=&quot;https://github.com/jchipmunk&quot;&gt;Andrey Pustovetov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bmorganpa&quot;&gt;Brad Morgan&lt;/a&gt;, &lt;a href=&quot;https://github.com/calinilie&quot;&gt;Calin Laurentiu Ilie&lt;/a&gt;, &lt;a href=&quot;https://github.com/chadthman&quot;&gt;Chad Marmon&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/domsj&quot;&gt;Jan Doms&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/LarsWerkman&quot;&gt;Lars Werkman&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/yzia2000&quot;&gt;Mohammad Yousuf Minhaj Zia&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/ypt&quot;&gt;Paul Tzen&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have resolved the runtime problem with Debezium Server in the 1.9.1.Final release, so you can expect a 1.9.2.Final later this week which will also address other bugfixes. You can continue to expect updates to 1.9 in the weeks that follow as bugs are reported and fixes are made to address those.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we continue our efforts on Debezium 2.0, you can expect a second pre-release in the coming weeks, sticking to our regular 3-week cadence. In this next pre-release, we plan to focus on message schema versioning/naming, connector configuration changes with new pass-thru namespaces, removal of deprecated options, as well as unifying default value handling, just to name a few on the roadmap.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And speaking of Debezium&amp;#8217;s roadmap, stay tuned as we&amp;#8217;ll have more to share about Debezium 2.0, its future releases of 2.x, all on our roadmap soon!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am excited to share that Debezium 2.0.0.Alpha1 has been released! This release is the first of several planned pre-releases of Debezium 2.0 over the next five months. Each pre-release plans to focus on strategic changes in the hope that as we move forward, changes can be easily tested and regressions addressed quickly. In this release, some of the most notable changes include requiring Java 11 to use Debezium or any of its components, the removal of wal2json support for PostgreSQL and the legacy MySQL connector implementation, as well as some notable features such as improved Debezium Server Google Pub/Sub sink support, and a multitude of bugfixes. Let&amp;#8217;s take a look at a few of these.</summary></entry><entry><title type="html">Debezium 1.9.1.Final Released</title><link href="https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.1.Final Released"/><published>2022-04-21T00:00:00+00:00</published><updated>2022-04-21T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.9.1.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugfixes and stability concerns after the 1.9.0.Final release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the more critical changes addresses a problem with the Oracle connector when stopping and restarting the connector. More specifically, the last committed transaction&amp;#8217;s events would be re-emitted upon restart and should not have been (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4936&quot;&gt;DBZ-4936&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A second critical problem was that incremental snapshots were not working correctly for MongoDB. When an incremental snapshot signal was sent, a JSON parsing error was raised and should not have been (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5015&quot;&gt;DBZ-5015&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And finally, there were numerous SQL parsing errors for both MySQL and Oracle that were also addressed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4976&quot;&gt;DBZ-4976&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4979&quot;&gt;DBZ-4979&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4980&quot;&gt;DBZ-4980&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4994&quot;&gt;DBZ-4994&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4996&quot;&gt;DBZ-4996&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We strongly recommend upgrading to 1.9.1.Final to avoid these issues as well as the other bugfixes that were included as a part of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20and%20fixVersion%20%3D%201.9.1.Final&quot;&gt;29 issues&lt;/a&gt; were fixed in this release. Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community which contributed to Debezium 1.9.1.Final: &lt;a href=&quot;https://github.com/LarsWerkman&quot;&gt; Lars Werkman&lt;/a&gt;, &lt;a href=&quot;https://github.com/jchipmunk&quot;&gt;Andrey Pustovetov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bmorganpa&quot;&gt;Brad Morgan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/yzia2000&quot;&gt;Mohammad Yousuf Minhaj Zia&lt;/a&gt;, &lt;a href=&quot;https://github.com/ypt&quot;&gt;Paul Tzen&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, and &lt;a href=&quot;https://github.com/chadthman&quot;&gt;chadthamn&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 1.9 release stream will remain the current long-running version for the next five months. During this time, we will continue to evaluate user reports and do micro-releases to address bugs and regressions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also in the coming week, expect to hear updates about Debezium&amp;#8217;s &lt;a href=&quot;/roadmap&quot;&gt;roadmap&lt;/a&gt; as well as a clear plan on Debezium 2.0, it&amp;#8217;s preview releases and what lies ahead for the future. We have a lot in store to share, so be sure to stay tuned!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.9.1.Final! This release primarily focuses on bugfixes and stability concerns after the 1.9.0.Final release.</summary></entry><entry><title type="html">Read-only Incremental Snapshots for MySQL</title><link href="https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots/" rel="alternate" type="text/html" title="Read-only Incremental Snapshots for MySQL"/><published>2022-04-07T00:00:00+00:00</published><updated>2022-04-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots</id><content type="html" xml:base="https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The engineering team at Shopify recently improved the Debezium MySQL connector so that it supports incremental snapshotting for databases without write access by the connector, which is required when pointing Debezium to read-only replicas. In addition, the Debezium MySQL connector now also allows schema changes during an incremental snapshot. This blog post explains the implementation details of those features.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;why_read_only&quot;&gt;Why read-only?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium added the &lt;a href=&quot;/documentation/reference/stable/connectors/mysql.html#mysql-incremental-snapshots&quot;&gt;incremental snapshotting feature&lt;/a&gt; in the 1.6 release, after Netflix had announced &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;their change data capture framework&lt;/a&gt;. At Shopify, &lt;a href=&quot;https://shopify.engineering/capturing-every-change-shopify-sharded-monolith&quot;&gt;we use Debezium for change data capture (CDC)&lt;/a&gt;, and we were looking forward to being the early adopters. Besides, we wished to have a solution that is writes and locks-free.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The no writes solution allows to capture changes from read-replicas and provides the highest guarantee that CDC won&amp;#8217;t cause data corruption on the database side.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ve had to coordinate the snapshotting with migrations in the past since schema migrations blockades have affected other projects' development. The solution was to run snapshots only on weekends and as a result, we tried to snapshot as rarely as possible. We saw the opportunity to improve this part of the process as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This blog post dives into technical details of the read-only incremental snapshots implementation including lock-free schema changes handling during the incremental snapshot in MySQL connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshots&quot;&gt;Incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;a href=&quot;/blog/2021/10/07/incremental-snapshots/&quot;&gt;Incremental Snapshots in Debezium&lt;/a&gt; blog post covers the default implementation in detail. The algorithm utilizes a signaling table for two types of signals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;snapshot-window-open/snapshot-window-close&lt;/code&gt; as watermarks&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;execute-snapshot&lt;/code&gt; as a way to trigger an incremental snapshot&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the read-only scenario, we needed to replace both types of signals with alternatives.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;show_master_status_for_high_and_low_watermarks&quot;&gt;SHOW MASTER STATUS for high and low watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The solution is specific to MySQL and relies on &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/replication-gtids-concepts.html&quot;&gt;global transaction identifiers (GTIDs)&lt;/a&gt;. Therefore, you need to set &lt;code&gt;gtid_mode&lt;/code&gt; to &lt;code&gt;ON&lt;/code&gt; and configure the database to preserve GTID ordering if you&amp;#8217;re reading from the read replica.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Prerequisites:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;gtid_mode = ON enforce_gtid_consistency = ON if replica_parallel_workers &amp;gt; 0 set replica_preserve_commit_order = ON&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm runs a &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/show-master-status.html&quot;&gt;SHOW MASTER STATUS&lt;/a&gt; query to get the executed GTID set before and after the chunk selection:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;low watermark = executed_gtid_set high watermark = executed_gtid_set - low watermark&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the read-only implementation, the watermarks have a form of GTID sets, e.g. like this: &lt;code&gt;2174B383-5441-11E8-B90A-C80AA9429562:1-3, 24DA167-0C0C-11E8-8442-00059A3C7B00:1-19&lt;/code&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Such watermarks do not appear in the binlog stream. Instead, the algorithm compares each event&amp;#8217;s GTID against the in-memory watermarks. The implementation ensures there are no stale reads and that a chunk only has changes that are not older than events up to low watermark.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;deduplication_algorithm_with_read_only_watermarks&quot;&gt;Deduplication algorithm with read-only watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In pseudo-code, the algorithm for deduplicating events read from the binlog and events retrieved via snapshot chunks looks like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt; (1) pause log event processing (2) GtidSet lwGtidSet := executed_gtid_set from SHOW MASTER STATUS (3) chunk := select next chunk from table (4) GtidSet hwGtidSet := executed_gtid_set from SHOW MASTER STATUS subtracted by lwGtidSet (5) resume log event processing inwindow := false // other steps of event processing loop while true do e := next event from changelog append e to outputbuffer if not inwindow then if not lwGtidSet.contains(e.gtid) //reached the low watermark inwindow := true else if hwGtidSet.contains(e.gtid) //haven't reached the high watermark yet if chunk contains e.key then remove e.key from chunk else //reached the high watermark for each row in chunk do append row to outputbuffer // other steps of event processing loop&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;watermark_checks&quot;&gt;Watermark checks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A database transaction can change several rows. In this case, multiple binlog events will have the same GTID. Due to GTIDs not being unique, it affects the logic of computing a chunk selection window. An event updates a window state when the watermark&amp;#8217;s GTID set doesn&amp;#8217;t contain its GTID. After the events like transaction completion and heartbeat, there won&amp;#8217;t be any further binlog events with the same GTID. For those events, it&amp;#8217;s enough to reach the watermark&amp;#8217;s upper bound to trigger a window open/close.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/window.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. A chunk selection window&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The deduplication happens within the chunk selection window as in the default implementation. Finally, the algorithm inserts a deduplicated chunk right after the high watermark:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/deduplication.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. A chunk deduplication&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_updates_for_included_tables&quot;&gt;No updates for included tables&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s crucial to receive binlog events for the snapshot to make progress. So the algorithm checks GTIDs of &lt;em&gt;all&lt;/em&gt; the events together with not included tables.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_binlog_events&quot;&gt;No binlog events&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MySQL server sends a heartbeat event after the replication connection was idle for x-seconds. The read-only implementation utilizes heartbeats when the rate of binlog updates is low.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The heartbeat has the same GTID as the latest binlog event. Thus, for a heartbeat, it&amp;#8217;s enough to reach the upper bound of the high watermark.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm uses the &lt;code&gt;server_uuid&lt;/code&gt; part of a heartbeat&amp;#8217;s GTID to get the max transaction id from the high watermark. The implementation makes sure the high watermark contains a single &lt;code&gt;server_uuid&lt;/code&gt;. An unchanged &lt;code&gt;server_uuid&lt;/code&gt; allows to avoid the scenario when the window is closed too early by a heartbeat. See the image below as an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/heartbeat.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 3. A scenario when the window would have been closed too early by a heartbeat&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat comparison against the low watermark isn&amp;#8217;t needed since it doesn&amp;#8217;t matter if the window was open or not. This simplifies the checks when there are no new events between the high and low watermarks.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_changes_between_watermarks&quot;&gt;No changes between watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A binlog event can open and close a window right away when there were no binlog events during the chunk selection. In this case, a high watermark will be an empty set. In this case, the snapshot chunk gets inserted right after the low watermark without deduplication.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/empty_window.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 4. An empty chunk selection window&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_topic_based_signals&quot;&gt;Kafka topic based signals&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium supports ad-hoc incremental snapshots triggered via inserts to the signaling table. A read-only alternative is to send signals through a specific Kafka topic. The format of the message mimics the signaling table structure. An execute-snapshot Kafka message includes the parameters&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;data-collections&lt;/code&gt; - list of tables to be captured&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;type&lt;/code&gt; - set to INCREMENTAL&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;Key: dbserver1 Value: {&amp;quot;type&amp;quot;:&amp;quot;execute-snapshot&amp;quot;,&amp;quot;data&amp;quot;: {&amp;quot;data-collections&amp;quot;: [&amp;quot;inventory.orders&amp;quot;], &amp;quot;type&amp;quot;: &amp;quot;INCREMENTAL&amp;quot;}}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MySQL connector&amp;#8217;s config has a new &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mysql.html#mysql-property-signal-kafka-topic&quot;&gt;&lt;code&gt;signal.kafka.topic&lt;/code&gt;&lt;/a&gt; property. The topic has to have one partition and the delete retention policy.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A separate thread retrieves the signal messages from the Kafka topic. The key of the Kafka message needs to match the connector&amp;#8217;s name as set in &lt;code&gt;database.server.name&lt;/code&gt;. The connector will skip events that don&amp;#8217;t correspond to the connector&amp;#8217;s name with a log entry. The message key check allows reusing a signal topic for multiple connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The connector&amp;#8217;s offsets include incremental snapshot context when an incremental snapshot is running. The read-only implementation adds the Kafka signal offset to the incremental snapshot context. Keeping track of the offset allows it not to miss or double process the signal when the connector restarts.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, it&amp;#8217;s not required to use Kafka to execute a read-only incremental snapshot and the default &lt;code&gt;execute-snapshot&lt;/code&gt; signal written into a signaling table will also work. Going forward, a REST API for triggering ad-hoc incremental snapshots may be envisioned as well, either exposed through Debezium Server, or as an additional REST resource deployed to Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;schema_changes_during_incremental_snapshots&quot;&gt;Schema changes during incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium MySQL connector &lt;a href=&quot;/documentation/reference/stable/connectors/mysql.html#mysql-property-incremental-snapshot-allow-schema-changes&quot;&gt;allows schema changes during an incremental snapshot&lt;/a&gt;. The connector will detect schema change during an incremental snapshot and re-select a current chunk to avoid locking DDLs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Note that changes to a primary key are not supported and can cause incorrect results if performed during an incremental snapshot.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Historized Debezium connectors like the MySQL one parse Data Definition Language (DDL) events such as &lt;code&gt;ALTER TABLE&lt;/code&gt; from the binlog stream. Connectors keep an in-memory representation of each table&amp;#8217;s schema and use those schemas to produce the appropriate change events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The incremental snapshot implementation uses binlog schema twice:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;at the moment of the chunk selection from the database&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;at the moment of the chunk insertion to the binlog stream&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The chunk&amp;#8217;s schema has to match the binlog schema at both times. Let&amp;#8217;s explore how the algorithm achieves matching schemas in detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;matching_chunk_and_binlog_schema_on_selection&quot;&gt;Matching chunk and binlog schema on selection&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When the incremental snapshot queries a database, the rows have the table&amp;#8217;s latest schema. If the binlog stream is behind, the in-memory schema may be different from the latest schema. The solution is to wait for the connector to receive the DDL event in the binlog stream. After that, the connector can use the cached table&amp;#8217;s structure to produce the correct incremental snapshot events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A snapshot chunk is selected using the JDBC API. &lt;a href=&quot;https://docs.oracle.com/en/java/javase/17/docs/api/java.sql/java/sql/ResultSetMetaData.html&quot;&gt;ResultSetMetaData&lt;/a&gt; stores the chunk&amp;#8217;s schema. The challenge is that the schema from ResultSetMetaData and the schema from binlog DDL have different formats, making it hard to determine if they are identical.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm uses two steps to obtain the matching ResultSet-based and DDL-based schemas. First, the connector queries a table&amp;#8217;s schema between low and high watermarks. As soon as the connector detects the window closure, the binlog schema is up to date with the ResultSetMetaData. After that, the connector queries the database to verify that the schema remains the same. If the schema has changed, then the connector repeats the process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm keeps the matching ResultSet and binlog schemas in memory to allow the connector to compare each chunk&amp;#8217;s schema against the cached ResultSet schema.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a chunk&amp;#8217;s schema doesn&amp;#8217;t match the cached ResultSet schema, the connector drops the selected chunk. Then the algorithm repeats the verification process of matching ResultSet and binlog schemas. After that, the connector re-selects the same chunk from the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/schema_change.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 5. Binlog schema doesn&amp;#8217;t match chunk schema on chunk selection&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;matching_chunk_and_binlog_schema_on_insertion&quot;&gt;Matching chunk and binlog schema on insertion&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A DDL event also triggers a chunk re-read for the affected table. A re-read prevents a scenario when a chunk has an older schema than the binlog stream has by the window closure. For example, the picture below illustrates the chunk selection that happened before the schema change:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/ddl.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 6. Binlog schema doesn&amp;#8217;t match chunk schema on chunk insertion&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will use the standard &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial&quot;&gt;tutorial deployment&lt;/a&gt; to demonstrate read-only ad-hoc incremental snapshotting. We are using &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#using-mysql&quot;&gt;MySQL&lt;/a&gt; as the source database. For this demo, you will need to open multiple terminal windows.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the beginning we will start the deployment, create the signaling Kafka topic, and start the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 1 - start the deployment # Start the deployment export DEBEZIUM_VERSION=1.9 docker-compose -f docker-compose-mysql.yaml up # Terminal 2 # Enable enforce_gtid_consistency and gtid_mode docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'mysql -p$MYSQL_ROOT_PASSWORD inventory -e &amp;quot;SET GLOBAL enforce_gtid_consistency=ON; SET GLOBAL gtid_mode=OFF_PERMISSIVE; SET GLOBAL gtid_mode=ON_PERMISSIVE; SET GLOBAL gtid_mode=ON;&amp;quot;' # Confirm the changes docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'mysql -p$MYSQL_ROOT_PASSWORD inventory -e &amp;quot;show global variables like \&amp;quot;%GTID%\&amp;quot;;&amp;quot;' # Create a signaling topic docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-topics.sh \ --create \ --bootstrap-server kafka:9092 \ --partitions 1 \ --replication-factor 1 \ --topic dbz-signals # Start MySQL connector, capture only customers table and enable signaling curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; -H &amp;quot;Content-Type:application/json&amp;quot; http://localhost:8083/connectors/ -d @- &amp;lt;&amp;lt;EOF { &amp;quot;name&amp;quot;: &amp;quot;inventory-connector&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.debezium.connector.mysql.MySqlConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;database.hostname&amp;quot;: &amp;quot;mysql&amp;quot;, &amp;quot;database.port&amp;quot;: &amp;quot;3306&amp;quot;, &amp;quot;database.user&amp;quot;: &amp;quot;debezium&amp;quot;, &amp;quot;database.password&amp;quot;: &amp;quot;dbz&amp;quot;, &amp;quot;database.server.id&amp;quot;: &amp;quot;184054&amp;quot;, &amp;quot;database.server.name&amp;quot;: &amp;quot;dbserver1&amp;quot;, &amp;quot;database.include.list&amp;quot;: &amp;quot;inventory&amp;quot;, &amp;quot;database.history.kafka.bootstrap.servers&amp;quot;: &amp;quot;kafka:9092&amp;quot;, &amp;quot;database.history.kafka.topic&amp;quot;: &amp;quot;schema-changes.inventory&amp;quot;, &amp;quot;table.include.list&amp;quot;: &amp;quot;inventory.customers&amp;quot;, &amp;quot;read.only&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;incremental.snapshot.allow.schema.changes&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;incremental.snapshot.chunk.size&amp;quot;: &amp;quot;5000&amp;quot;, &amp;quot;signal.kafka.topic&amp;quot;: &amp;quot;dbz-signals&amp;quot;, &amp;quot;signal.kafka.bootstrap.servers&amp;quot;: &amp;quot;kafka:9092&amp;quot; } } EOF&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the log we see that as per the &lt;code&gt;table.include.list&lt;/code&gt; setting only one table is snapshotted, &lt;code&gt;customers&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;tutorial-connect-1 | 2022-02-21 04:30:03,936 INFO MySQL|dbserver1|snapshot Snapshotting contents of 1 tables while still in transaction [io.debezium.relational.RelationalSnapshotChangeEventSource]&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next step we will simulate continuous activity in the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 3 # Continuously consume messages from Debezium topic for customers table docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.customers # Terminal 4 # Modify records in the database via MySQL client docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'i=0; while true; do mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory -e &amp;quot;INSERT INTO customers VALUES(default, \&amp;quot;name$i\&amp;quot;, \&amp;quot;surname$i\&amp;quot;, \&amp;quot;email$i\&amp;quot;);&amp;quot;; ((i++)); done'&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic &lt;code&gt;dbserver1.inventory.customers&lt;/code&gt; receives a continuous stream of messages. Now the connector will be reconfigured to also capture the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;# Terminal 5 # Add orders table among the captured curl -i -X PUT -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/inventory-connector/config -d @- &amp;lt;&amp;lt;EOF { &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;, &quot;tasks.max&quot;: &quot;1&quot;, &quot;database.hostname&quot;: &quot;mysql&quot;, &quot;database.port&quot;: &quot;3306&quot;, &quot;database.user&quot;: &quot;debezium&quot;, &quot;database.password&quot;: &quot;dbz&quot;, &quot;database.server.id&quot;: &quot;184054&quot;, &quot;database.server.name&quot;: &quot;dbserver1&quot;, &quot;database.include.list&quot;: &quot;inventory&quot;, &quot;database.history.kafka.bootstrap.servers&quot;: &quot;kafka:9092&quot;, &quot;database.history.kafka.topic&quot;: &quot;schema-changes.inventory&quot;, &quot;table.include.list&quot;: &quot;inventory.customers,inventory.orders&quot;, &quot;read.only&quot;: &quot;true&quot;, &quot;incremental.snapshot.allow.schema.changes&quot;: &quot;true&quot;, &quot;incremental.snapshot.chunk.size&quot;: &quot;5000&quot;, &quot;signal.kafka.topic&quot;: &quot;dbz-signals&quot;, &quot;signal.kafka.bootstrap.servers&quot;: &quot;kafka:9092&quot; } EOF&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As expected, there are no messages for the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now let&amp;#8217;s start an incremental ad-hoc snapshot by sending a signal. The snapshot messages for the &lt;code&gt;orders&lt;/code&gt; table are delivered to the &lt;code&gt;dbserver1.inventory.orders&lt;/code&gt; topic. Messages for the &lt;code&gt;customers&lt;/code&gt; table are delivered without interruption.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 # Send the signal docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-producer.sh \ --broker-list kafka:9092 \ --property &amp;quot;parse.key=true&amp;quot; \ --property &amp;quot;key.serializer=org.apache.kafka.common.serialization.StringSerializer&amp;quot; \ --property &amp;quot;value.serializer=custom.class.serialization.JsonSerializer&amp;quot; \ --property &amp;quot;key.separator=;&amp;quot; \ --topic dbz-signals dbserver1;{&amp;quot;type&amp;quot;:&amp;quot;execute-snapshot&amp;quot;,&amp;quot;data&amp;quot;: {&amp;quot;data-collections&amp;quot;: [&amp;quot;inventory.orders&amp;quot;], &amp;quot;type&amp;quot;: &amp;quot;INCREMENTAL&amp;quot;}} # Check messages for orders table docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you were to modify any record in the &lt;code&gt;orders&lt;/code&gt; table while the snapshot is running, this would be either emitted as a &lt;code&gt;read&lt;/code&gt; event or as an &lt;code&gt;update&lt;/code&gt; event, depending on the exact timing and sequence of things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the last step, let&amp;#8217;s terminate the deployed systems and close all terminals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Shut down the cluster docker-compose -f docker-compose-mysql.yaml down&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is an excellent change data capture tool under active development, and it&amp;#8217;s a pleasure to be a part of its community. We&amp;#8217;re excited to use incremental snapshots in production here at Shopify. If you have similar database usage restrictions, check out the read-only incremental snapshots feature. Many thanks to my team and the Debezium team without whom this project wouldn&amp;#8217;t happen.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Kate Galieva</name></author><category term="mysql"/><category term="snapshots"/><summary type="html">The engineering team at Shopify recently improved the Debezium MySQL connector so that it supports incremental snapshotting for databases without write access by the connector, which is required when pointing Debezium to read-only replicas. In addition, the Debezium MySQL connector now also allows schema changes during an incremental snapshot. This blog post explains the implementation details of those features.</summary></entry><entry><title type="html">Debezium 1.9.0.Final Released</title><link href="https://debezium.io/blog/2022/04/06/debezium-1.9-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Final Released"/><published>2022-04-06T00:00:00+00:00</published><updated>2022-04-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/06/debezium-1.9-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/06/debezium-1.9-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am very happy to share the news that Debezium &lt;strong&gt;1.9.0.Final&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides the usual set of bug fixes and improvements, key features of this release are support for Apache Cassandra 4, multi-database support for the Debezium connector for SQL Server, the ability to use Debezium Server as a Knative event source, as well as many improvements to the integration of Debezium Server with Redis Streams.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Exactly &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.9.0.Alpha1%2C%201.9.0.Alpha2%2C%201.9.0.Beta1%2C%201.9.0.CR1%2C%201.9.0.Final)%20ORDER%20BY%20key%20ASC%2C%20status%20DESC&quot;&gt;276 issues&lt;/a&gt; have been fixed by the community for the 1.9 release; a big thank you to each and everyone who helped to make this happen!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_apache_cassandra_4&quot;&gt;Support for Apache Cassandra 4&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Added right in time for the &lt;a href=&quot;/blog/2022/03/25/debezium-1-9-cr1-released/&quot;&gt;candidate release&lt;/a&gt; of Debezium 1.9, support for Cassandra 4 has been added to the &lt;a href=&quot;/documentation/reference/1.9/connectors/cassandra.html&quot;&gt;Debezium Cassandra connector&lt;/a&gt;. Or, more specifically, a &lt;em&gt;new&lt;/em&gt; connector has been added. I.e. you should now either download the &lt;em&gt;debezium-connector-cassandra-3&lt;/em&gt; or the &lt;em&gt;debezium-connector-cassandra-4&lt;/em&gt; connector archive, depending on your database version. While we usually strive for multi-version support within indvidual connectors, the code changes required to support the new version were that substantial, that we decided to have two separate code bases for the two connector versions (with commonalities extracted into a shared module).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Both connectors, for Cassandra 3 and 4, remain in incubating state for the time being and you can expect further improvements to them within the near feature. A massive thank you to &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Štefan Miklošovič&lt;/a&gt; and &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt; for this huge piece of work, which also paves the road towards moving to Java 11 as the baseline for Debezium in the near future.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;sql_server_multi_database_support&quot;&gt;SQL Server Multi-Database Support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;SQL Server allows for setting up multiple logical databases on one physical host, which for instance comes in handy for separating the data of different tenants of a multi-tenant capable application. Historically, this required to set up one instance of the Debezium connector for SQL Server per logical database, which could become a bit cumbersome when dealing with tens or even hundreds of databases, as often the case for multi-tenancy use cases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Over the last year, &lt;a href=&quot;/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/&quot;&gt;Sergei Morozov&lt;/a&gt; and his team at SugarCRM reworked the &lt;a href=&quot;/documentation/reference/stable/connectors/sqlserver.html&quot;&gt;Debezium SQL Server connector&lt;/a&gt; and the Debezium connector framework to be &lt;em&gt;multi-partition aware&lt;/em&gt; for address sitations like this: the framework is now capable of streaming changes from multiple &lt;em&gt;source partitions&lt;/em&gt;, which are split up between &lt;em&gt;connector tasks&lt;/em&gt; (in Kafka Connect terminology), which in turn can be distributed amongst the worker nodes of a Kafka Connect cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In case of the SQL Server connector, a logical database equates to one such source partition, so that you now can stream for instance 20 databases from one physical SQL Server host, spread across four source tasks running on five Kafka Connect worker nodes. To use the new multi-partition mode, configure the names of the databases to capture via the new &lt;a href=&quot;/documentation/reference/stable/connectors/sqlserver.html#sqlserver-property-database-names&quot;&gt;&lt;code&gt;database.names&lt;/code&gt;&lt;/a&gt; connector configuration property (rather than using the previously existing &lt;code&gt;database.dbname&lt;/code&gt;), and optionally set the value of &lt;code&gt;tasks.max&lt;/code&gt; to a value larger than 1. Note that the schema and topic names as well as the structure of connector metrics differs between single and multi-partition mode, so as to account for the name of the logical database and the id of the source task, respectively.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/multi_partition_metrics.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Multi-partition mode is experimental as of the 1.9 release and is planned to fully replace the legacy single partition mode for the SQL Server connector in a future release, i.e. also if you&amp;#8217;d capture changes from only one single logical database, you&amp;#8217;ll be using the multi-partition mode then. Multi-partition mode will also be rolled out for other connectors where it&amp;#8217;s possible, e.g. for the connectors for Oracle and IBM Db2.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks a lot to Sergei and team for their excellent collaboration around that feature!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_changes&quot;&gt;Further Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a look at some more features new in Debezium 1.9. First, Debezium Server now includes a &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#_http_client&quot;&gt;sink adaptor for HTTP&lt;/a&gt;, which means it can be used as a &quot;native&quot; event source for Knative Serving, without the need for sending messages through a message broker like Apache Kafka first.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Then, the friendly folks over at Redis stepped up and contributed several improvements to how Debezium (Server) integrates with &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#_redis_stream&quot;&gt;Redis Streams&lt;/a&gt;: besides several performance improvements, the database history for connectors like the MySQL one can now be stored in Redis, also offsets can be stored there now. But they didn&amp;#8217;t stop there: for instance, Debezium Server now supports custom configuration providers, as already provided in Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, the Redis team is planning to work on further cool improvements to Debezium at large, such as better retrying logic in case of failures. Looking forward to those!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about all the features, improvements and bug fixes shipped in Debezium 1.9, please check out the original release announcements (&lt;a href=&quot;/blog/2022/01/26/debezium-1-9-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2022/02/09/debezium-1-9-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2022/03/03/debezium-1-9-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, and &lt;a href=&quot;/blog/2022/03/25/debezium-1-9-cr1-released/&quot;&gt;CR1&lt;/a&gt;) as well as the &lt;a href=&quot;/releases/1.9/release-notes&quot;&gt;1.9 release notes&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to all the folks from the Debezium community which contributed code changes to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/samagonas&quot;&gt;Aidas&lt;/a&gt;, &lt;a href=&quot;https://github.com/isacandrei&quot;&gt;Andrei Isac&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/sormuras&quot;&gt;Christian Stein&lt;/a&gt;, &lt;a href=&quot;https://github.com/clement-loiselet-talend&quot;&gt;Clément Loiselet&lt;/a&gt;, &lt;a href=&quot;https://github.com/daha&quot;&gt;David Haglund&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/EthanZ328&quot;&gt;Ethan Zou&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuyar&quot;&gt;Farid Uyar&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/hjwalt&quot;&gt;Hady Willi&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/jmks&quot;&gt;Jason Schweier&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis Sánchez&lt;/a&gt;, &lt;a href=&quot;https://github.com/jribera-sugarcrm&quot;&gt;Josh Ribera&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/limer2&quot;&gt;Li Mo&lt;/a&gt;, &lt;a href=&quot;https://github.com/sazzad16&quot;&gt;M Sazzadul Hoque&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/wndemon&quot;&gt;Nansen&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/nenad&quot;&gt;Nenad Stojanovikj&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/0sc&quot;&gt;Oscar Romero&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/poonam-meghnani&quot;&gt;Poonam Meghnani&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhongqishang&quot;&gt;Qishang Zhong&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarumont&quot;&gt;Richard Kolkovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sebruck&quot;&gt;Sebastian Bruckner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtěch Juránek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;, &lt;a href=&quot;https://github.com/yingyingtang-brex&quot;&gt;Yingying Tang&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, and &lt;a href=&quot;https://github.com/AChangFeng&quot;&gt;胡琴&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;coming_up&quot;&gt;Coming Up&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So what&amp;#8217;s next after 1.9? You may think 1.10, but that&amp;#8217;s not what we&amp;#8217;ll do; instead, we&amp;#8217;re planning to release Debezium 2.0 as a new major version later this year!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While we don&amp;#8217;t strictly adhere to semantic versioning (i.e. a new minor release like 1.9 may require some small degree of consideration), one of our key objectives with Debezium releases is to limit breaking changes for existing users as much as possible. That&amp;#8217;s why for instance configuration options that became superfluous are not just removed but deprecated. The same applies for changes to the change event format, which are rolled out gradually. Over time, this has led to a number of legacy options and other aspects which we finally want to iron out. Debezium 2.0 will be the release where we will get rid of this kind of legacy cruft. For instance, we are planning to&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Remove the legacy implementations of the connectors for MySQL and MongoDB (superseded by more capable and mature implementations based on Debezium&amp;#8217;s standard connector framework, which have been enabled by default for quite some time)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Drop wal2json support for Postgres (superseded by pgoutput)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Use Java 11 as a baseline (for instance allowing to emit JDK Flight Recorder events for better diagnostics)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Default to multi-partition mode metrics (improved consistency)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Make default topic names more consistent, for instance for the heartbeat topic&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Change the default type mappings for a small number of column types&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Planning for this is in full swing right now, and you are very much invited to join the discussion either on the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; or on the &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;DBZ-3899&lt;/a&gt; issue in Jira. Note that while we want to take the opportunity to clean up some odditities which have accumulated over time, backwards compatibility will be key concern as always, and we&amp;#8217;ll try to minimize the impact on existing users. But as you would expect it from a new major release, upgrading may take a slightly larger effort in comparison to the usual minor releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In terms of a timeline, due to the size and number of planned changes, we&amp;#8217;re going to deviate from the usual quarterly release cadence and instead reserve two quarters for working on Debezium 2.0, i.e. you can look forward to that release at the end of September. In the meantime, there will be bugfix releases of the 1.9 version, as needed per incoming bug reports.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Upwards and onwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am very happy to share the news that Debezium 1.9.0.Final has been released! Besides the usual set of bug fixes and improvements, key features of this release are support for Apache Cassandra 4, multi-database support for the Debezium connector for SQL Server, the ability to use Debezium Server as a Knative event source, as well as many improvements to the integration of Debezium Server with Redis Streams. Exactly 276 issues have been fixed by the community for the 1.9 release; a big thank you to each and everyone who helped to make this happen!</summary></entry></feed>