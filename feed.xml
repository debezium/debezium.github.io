<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://debezium.io/" rel="alternate" type="text/html" /><updated>2020-12-07T13:33:03+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 1.4.0.Alpha2 Released</title><link href="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha2 Released" /><published>2020-11-17T00:00:00+00:00</published><updated>2020-11-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This second pass of the 1.4 release line provides a few useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New API hook for the PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; interface&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Field renaming using &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT&amp;#8217;s &lt;code&gt;add.fields&lt;/code&gt; and &lt;code&gt;add.headers&lt;/code&gt; configurations&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;37 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;postgresql-snapshotter-completion-hook&quot;&gt;PostgreSQL Snapshotter completion hook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; API is a contract that allows for the customization of the snapshot process.
This API was introduced in 0.9.3.Final and has continued to evolve in the releases since.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A new backward compatible completion hook has been added:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;void snapshotCompleted()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This new hook is called by the snapshot process when the snapshot has concluded,
allowing implementations to clean-up any resources it may have allocated prior streaming changes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;extractnewrecordstate-smt-field-renaming-support&quot;&gt;ExtractNewRecordState SMT field renaming support&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the features of the &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT is that the transformation can retain parts of the original message in the transformed message&amp;#8217;s header or payload.
This release extends this feature to allow specifying a new name to be used for the field when added to the message header or payload.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, to add the source database&amp;#8217;s event timestamp to the message header using the new renaming feature, the SMT configuration would be:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;transforms=unwrap
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
transforms.unwrap.add.headers=source.ts_ms:timestamp&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The format of the &lt;code&gt;add.headers&lt;/code&gt; and &lt;code&gt;add.fields&lt;/code&gt; configuration options have been improved to support a comma-separated list of fields with the syntax &lt;code&gt;&amp;lt;OLD_FIELD&amp;gt;[:NEW_FIELD]&lt;/code&gt;.
The above emitted message&amp;#8217;s headers would now contain &lt;code&gt;__timestamp&lt;/code&gt; rather than the default &lt;code&gt;__source.ts_ms&lt;/code&gt; field.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This syntax improvement remains backward compatible.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Oracle throw &quot;no snapshot found based on specified time&quot; when running flashback query &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exception when PK definition precedes column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2580&quot;&gt;DBZ-2580&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Patroni can&amp;#8217;t stop PostgreSQL when Debezium is streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2617&quot;&gt;DBZ-2617&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChangeRecord informations don&amp;#8217;t connect with the TableSchema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2679&quot;&gt;DBZ-2679&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL connector fails on a zero date &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2682&quot;&gt;DBZ-2682&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle LogMiner doesn&amp;#8217;t support partition tables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2683&quot;&gt;DBZ-2683&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DB2 doesn&amp;#8217;t start reliably in OCP  &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2693&quot;&gt;DBZ-2693&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dropped columns cause NPE in SqlServerConnector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2716&quot;&gt;DBZ-2716&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timestamp default value in 'yyyy-mm-dd' format fails MySQL connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2726&quot;&gt;DBZ-2726&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout on write should retry &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2727&quot;&gt;DBZ-2727&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No viable alternative at input error on &quot;min&quot; column &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQLServer CI error in SqlServerConnectorIT.whenCaptureInstanceExcludesColumnsAndColumnsRenamedExpectNoErrors:1473 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2747&quot;&gt;DBZ-2747&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;debezium-connector-db2: DB2 SQL Error: SQLCODE=-206 on DB2 for z/OS &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2755&quot;&gt;DBZ-2755&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no viable alternative at input 'alter table &lt;code&gt;order&lt;/code&gt; drop CONSTRAINT' &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2760&quot;&gt;DBZ-2760&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tests are failing on macos &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2762&quot;&gt;DBZ-2762&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.4.0.Alpha2! This second pass of the 1.4 release line provides a few useful new features: New API hook for the PostgreSQL Snapshotter interface Field renaming using ExtractNewRecordState SMT&amp;#8217;s add.fields and add.headers configurations</summary></entry><entry><title type="html">Debezium 1.3.1.Final Released</title><link href="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.1.Final Released" /><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release primarily focuses on bugs that were reported after the 1.3 release.
Most importantly, the following bugs were fixed related to the &lt;a href=&quot;/docs/connectors/oracle&quot;&gt;Debezium connector for Oracle&lt;/a&gt; LogMiner adapter thanks to the continued feedback by the Debezium community.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SQLExceptions thrown when using Oracle LogMiner (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LogMiner mining session stopped due to WorkerTask killed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;)
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, there were other bugs identified and fixed in this release, including:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;[MongoDB] Sanitization of field names not applied to nested struct fields (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] MariaDB nextval function is not supported by grammar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MSSQL] Hide stack-trace when default value cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2642&quot;&gt;DBZ-2642&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Upgrade JDBC driver to 8.0.19 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2626&quot;&gt;DBZ-2626&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] ANTLR parser fails to interpret &lt;code&gt;BLOB(size)&lt;/code&gt; types (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Should allow non-ascii character in SQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Connector fails if non-existing view with same name as table is dropped (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] No viable alternative at input error when column uses aggregate function names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] No snapshot found based on specified time (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[PostgreSQL] WAL logs are not properly flushed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Server] Event Hubs plugin support (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.1.Final&quot;&gt;14 issues&lt;/a&gt; were resolved in this release.
Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to everyone who helped test and identify these bugs.
The team appreciates the invaluable feedback the community continually provides!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.1.Final! This release primarily focuses on bugs that were reported after the 1.3 release. Most importantly, the following bugs were fixed related to the Debezium connector for Oracle LogMiner adapter thanks to the continued feedback by the Debezium community. SQLExceptions thrown when using Oracle LogMiner (DBZ-2624) LogMiner mining session stopped due to WorkerTask killed (DBZ-2629)</summary></entry><entry><title type="html">Streaming Vitess at Bolt</title><link href="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/" rel="alternate" type="text/html" title="Streaming Vitess at Bolt" /><published>2020-11-04T16:19:59+00:00</published><updated>2020-11-04T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt</id><content type="html" xml:base="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&quot;https://medium.com/bolt-labs/streaming-vitess-at-bolt-f8ea93211c3f&quot;&gt;Bolt Labs Engineering blog&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Traditionally, MySQL has been used to power most of the backend services at &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt;. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once data is persisted to the database, we use the &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL Connector&lt;/a&gt; to &lt;a href=&quot;https://www.confluent.io/blog/how-bolt-adopted-cdc-with-confluent-for-real-time-data-and-analytics/&quot;&gt;capture data change events&lt;/a&gt; and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-at-bolt&quot;&gt;Vitess at Bolt&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bolt has grown considerably over the past few years, and so did the volume of data written to MySQL. Manual database sharding has become quite an expensive and long-lasting process prone to errors. So we started to evaluate more scalable databases, one of which is &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;. Vitess is an open-source database clustering system that is based on MySQL and provides horizontal scalability for it. Originated and battle-tested at YouTube, it was later open-sourced and is used by companies like Slack, Github, JD.com to power their backend storage. It combines important MySQL features with the scalability of a NoSQL database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the most important features that Vitess provides is its built-in sharding. It allows the database to grow horizontally by adding new shards in a way that is transparent to back-end application logic. To your application, Vitess appears like a giant single database, but in fact data is partitioned into multiple physical shards behind the scenes. For any table, an arbitrary column can be chosen as the sharding key, and all inserts and updates will be seamlessly directed to a proper shard by Vitess itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; below illustrates how back-end services interact with Vitess. At a high level, services connect to the stateless VTGate instances through a load balancer. Each VTGate has the Vitess cluster’s topology cached in its memory and redirects queries to the correct shards and the correct VTTablet (and its underlying MySQL instance) within the shards. More on VTTablet is written below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_architecture.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 1. Vitess architecture. Reference: &lt;a href=&quot;https://www.planetscale.com/vitess&quot; class=&quot;bare&quot;&gt;https://www.planetscale.com/vitess&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Other useful features provided by Vitess are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Failover (a.k.a. Reparenting) is easy and transparent for clients. Clients only talk to a VTGate who takes care of failover and service discovery of the new primary transparently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It automatically rewrites “problematic” queries that could potentially cause database performance degradation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has a caching mechanism that prevents duplicate queries to reach the underlying MySQL database simultaneously. Only one query will reach the database and its result will be cached and returned to answer duplicate queries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has its connection pool and eliminates the high-memory overhead of MySQL connections. As a result, it can easily handle thousands of connections at the same time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout and transaction timeout can be configured.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has minimal downtime when doing &lt;a href=&quot;https://vitess.io/docs/user-guides/configuration-advanced/resharding/&quot;&gt;resharding&lt;/a&gt; operations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its VStream feature can be used by downstream CDC applications to read change events from Vitess.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;streaming-vitess-options&quot;&gt;Streaming Vitess Options&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The ability to capture data changes and publish them to Apache Kafka was one of the requirements for adopting Vitess at Bolt. There were several different options we’ve considered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-1-using-debezium-mysql-connector&quot;&gt;Option 1: Using Debezium MySQL Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Applications connect to Vitess VTGate to send queries. VTGate supports the MySQL protocol and has a SQL parser. You can use any MySQL client (e.g. JDBC) to connect to VTGate, which redirects your query to the correct shard and returns the result to your client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, VTGate is not equal to a MySQL instance, it is rather a stateless proxy to various MySQL instances. For the MySQL connector to receive change events, the Debezium MySQL connector needs to connect to a real MySQL instance. To make it more obvious, VTGate also has some known &lt;a href=&quot;https://vitess.io/docs/reference/compatibility/mysql-compatibility/&quot;&gt;compatibility&lt;/a&gt; issues, which makes connecting to VTGate different from MySQL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another option is to use the Debezium MySQL Connector to connect directly to the underlying MySQL instances of different shards. It has its advantages and disadvantages.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One advantage is that for an unsharded keyspace (Vitess&amp;#8217;s terminology for a database), the MySQL Connector can continue to work correctly and we don&amp;#8217;t need to include additional logic or specific implementation. It should just work fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the biggest disadvantages is that resharding operations would become more complex. For example, the GTID of the original MySQL instance would change when resharded, and the MySQL connector depends on the GTID to work correctly. We also believe that having the MySQL connector connected directly to each underlying MySQL instance defies the purpose of Vitess&amp;#8217;s operational simplicity as a new connector has to be added (or removed) each time resharding is done. Not to mention that such operation would lead to data duplication inside Kafka brokers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-2-using-jdbc-source-connector&quot;&gt;Option 2: Using JDBC Source Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ve also considered using the &lt;a href=&quot;https://docs.confluent.io/current/connect/kafka-connect-jdbc/source-connector/index.html&quot;&gt;JDBC Source Connector&lt;/a&gt;. It allows sourcing data from any relational databases that support the JDBC driver into Kafka. Therefore, it is compatible with Vitess VTGate. It has its advantages and disadvantages as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is compatible with VTGate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It handles Vitess resharding operation better. During resharding operation, reads are simply automatically redirected (by VTGate) to the target shards. It won&amp;#8217;t generate any duplicates or lose any data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is poll-based, meaning that the connector polls the database for new change events on a defined interval (typically every few seconds). This means that we would have a much higher latency, compared to the Debezium MySQL Connector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its offsets are managed by either the table&amp;#8217;s incremental primary key or one of the table&amp;#8217;s timestamp columns. If we use the timestamp column for offset, we&amp;#8217;d have to create a secondary-index of the timestamp column for each table. This adds more constraints on our backend services. If we use the incremental primary key, we would miss the change events for row-updates because the primary key is simply not updated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The topic name created by the JDBC connector doesn&amp;#8217;t include the table&amp;#8217;s schema name. Using the &lt;code&gt;topic.prefix&lt;/code&gt; connector configuration would mean that we&amp;#8217;ll have one connector per schema. At Bolt, we have a large number of schemas, which means we would need to create a large number of JDBC Source Connectors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At Bolt, our downstream applications are already set up to use Debezium&amp;#8217;s data formats and topic naming conventions, e.g. we&amp;#8217;d need to change our downstream application&amp;#8217;s decoding logic to the new data formats.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Row deletes are not captured.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-3-using-vstream-grpc&quot;&gt;Option 3: Using VStream gRPC&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VTGate exposes a gRPC service called VStream. It is a server-side streaming service. Any gRPC client can subscribe to the &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;VStream&lt;/a&gt; service to get a continuous stream of change events from the underlying MySQL instances. The change events that VStream emits have similar information to the MySQL binary logs of the underlying MySQL instances. A single VStream can even subscribe to multiple shards for a given keyspace, making it quite a convenient API to build CDC tools.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Behind the scene, as shown in &lt;em&gt;Figure 2&lt;/em&gt;, VStream reads change events from multiple &lt;a href=&quot;https://vitess.io/docs/reference/programs/vttablet/&quot;&gt;VTTablets&lt;/a&gt;, one VTTablet per shard. Therefore, it doesn’t send duplicates from multiple VTTablets for a given shard. Each VTTablet is a proxy to its MySQL instance. A typical topology would include one master VTTablet and its corresponding MySQL instance, and multiple replica VTTablets, each of which is the proxy of its own replica MySQL instance. A VTTablet gets change events from its underlying MySQL instance and sends the change events back to VTGate, which in turn sends the change events back to VStream’s gRPC client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When subscribing to the VStream service, the client can specify a VGTID and &lt;a href=&quot;https://vitess.io/docs/concepts/tablet/#tablet-types&quot;&gt;Tablet Type&lt;/a&gt; (e.g. &lt;code&gt;MASTER&lt;/code&gt;, &lt;code&gt;REPLICA&lt;/code&gt;). The VGTID tells the position from which VStream starts to send change events. Essentially, VGTID includes a list of (keyspace, shard, shard GTID) tuples. The Tablet Type tells which MySQL instance (primary or replica) in each shard do we read change events from.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vstream.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 2. VStream architecture. Reference: &lt;a href=&quot;https://vitess.io/docs/concepts/vstream&quot; class=&quot;bare&quot;&gt;https://vitess.io/docs/concepts/vstream&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Some advantages of using VStream gRPC are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is a simple way to receive change events from Vitess. It is also recommended in Vitess’s &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;documentation&lt;/a&gt; to use VStream to build CDC processes downstream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VTGate hides the complexity of connecting to various source MySQL instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has low latency since change events are streamed to the client as soon as they happen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events include not only inserts and updates, but also deletes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probably one of the biggest advantages is that the change events contain the schema of each table. So you don’t have to worry about fetching each table’s schema in advance (by,  for example, parsing DDLs or querying the table’s definition).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events have VGTID included, which the CDC process can store and use as the offset from where to restart the CDC process next time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also importantly, VStream is designed to work well with Vitess operations such as &lt;a href=&quot;https://vitess.io/docs/user-guides/resharding/&quot;&gt;Resharding&lt;/a&gt; and &lt;a href=&quot;https://vitess.io/docs/user-guides/move-tables/&quot;&gt;Moving Tables&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are also some disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Although it includes table schemas, some important information is still missing. For example, the &lt;code&gt;Enum&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt; column types don’t provide all the allowed values yet. This should be fixed in the next major release (Vitess 9) though.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since VStream is a gRPC service, we cannot use the Debezium MySQL Connector out-of-the-box. However, it is quite straightforward to implement the gRPC client in other languages.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All things considered, we’ve decided to use VStream gRPC to capture change events from Vitess and implement our Vitess Connector based on all the best practices of Debezium.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-connector-deep-dive-and-open-source&quot;&gt;Vitess Connector Deep Dive and Open Source&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After we’ve decided to implement our Vitess Connector, we started looking into the implementation details of various Debezium source connectors (MySQL, Postgres, SQLServer), to borrow some ideas. Almost all of them are implemented using a common Connector development framework. So it was clear we should develop the Vitess connector on top of it. Given we are very active users of the MySql Connector and we benefit from it being open-sourced, as it allows us to contribute to it things we were missing ourselves. So we decided we want to give back to community and open-source the Vitess source connector code-base under the Debezium umbrella. Please feel free to learn more at &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Debezium Connector Vitess&lt;/a&gt;. We welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At a high level, as you can see below, connector instances are created in Kafka Connect workers. At the time of writing, you have two options to configure the connector to read from Vitess:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 1 (recommended):&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 3&lt;/em&gt;, each connector captures change events from all shards in a specific keyspace. If the keyspace is not sharded, the connector can still capture change events from the only shard in the keyspace. When it’s the first time that the connector starts, it reads from the current VGTID position of all shards in the keyspace. Because it subscribes to all shards, it continuously captures change events from all shards and sends them to Kafka. It automatically supports the Vitess Reshard operation, there is no data loss, nor duplication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_multi_shards.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 3. Each connector subscribes to all shards of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 4&lt;/em&gt;, each connector instance captures change events from a specific keyspace/shard pair. The connector instance gets the initial (the current) VGTID  position of the keyspace/shard pair from VTCtld gRPC, which is another Vitess component. Each connector instance, independently, uses the VGTID it gets to subscribe to VStream gRPC and continuously capture change events from VStream and sends them to Kafka. To support the Vitess Reshard operation, you would need more manual operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_single_shard.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 4. Each connector subscribes to one shard of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Internally, each connector task uses a gRPC thread to constantly receive change events from VStream and puts the events into an internal blocking queue. The connector task thread polls events out of the queue and sends them to Kafka, as can be seen in &lt;em&gt;Figure 5&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_internal.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 5. How each connector task works internally&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;replication-challenges&quot;&gt;Replication Challenges&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While we were implementing the Vitess Connector and digging deeper into Vitess, we’ve also realized a few challenges.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;vitess-reshard&quot;&gt;Vitess Reshard&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Vitess connector supports the Vitess Reshard operation when the connector is configured to subscribe to all shards of a given keyspace. VStream sends a VGTID that contains the shard GTID for all shards. Vitess Resharding is transparent to users. Once it’s completed, Vitess will send the VGTID of the new shards. Therefore, the connector will use the new VGTID after reshard. However, you need to make sure that the connector is up and running when the reshard operation takes place. Especially please check that the offset topic of the connector has the new VGTID before deleting the old shards. This is because in case the old shards are deleted, VStream will not be able to recognize the VGTID from the old shards.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you decide to subscribe to one shard per connector, the connector does not provide out-of-the-box support for Vitess resharding. One manual workaround to support resharding is creating one new connector per target shard. For example, one new connector for the &lt;code&gt;commerce/-80&lt;/code&gt; shard, and another new connector for the &lt;code&gt;commerce/80-&lt;/code&gt; shard. Bear in mind that because they’re new connectors, by default, new topics will be created, however, you could use the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/topic-routing.html&quot;&gt;Debezium logical topic router&lt;/a&gt; to route the records to the same Kafka topics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;offset-management&quot;&gt;Offset Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream includes a VGTID event in its response. We save the VGTID as the offset in the Kafka offset topic, so when the connector restarts, we can start from the saved VGTID. However, in rare cases when a transaction includes a huge amount of rows, VStream batches the change events into multiple responses, and only the last response has the VGTID. In such cases, we don’t have the VGTID for every change event we receive. We have a few options to solve this particular issue:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can buffer all the change events in memory and wait for the last response that contains the VGTID to arrive. So all events will have the correct VGTID associated with them. A few disadvantages are that we’ll have higher latency before events are sent to Kafka. Also, memory usage could potentially increase quite a lot due to buffering. Buffering also adds complexity to the logic. We also have no control over the number of events VStream sends to us.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can use the latest VGTID we have, which is the VGTID from the previous VStream response. If the connector fails and restarts when processing such a big transaction, it’ll restart from the VGTID of the previous VStream response, thus reprocessing some events. Therefore, it has at-least-once event delivery semantics and it expects the downstream to be idempotent. Since most transactions are not big enough, most VStream responses will have VGTID in the response, so the chance of having duplicates is low. In the end, we chose this approach for its at-least-once delivery guarantee and its design simplicity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;schema-management&quot;&gt;Schema Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream’s response also includes a &lt;code&gt;FIELD&lt;/code&gt; event. It’s a special event that contains the schemas of the tables of which the rows are affected. For example, let&amp;#8217;s assume we have 2 tables, &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. If we insert a few rows into table &lt;code&gt;A&lt;/code&gt;, the &lt;code&gt;FIELD&lt;/code&gt; event will only contain table &lt;code&gt;A&lt;/code&gt;’s schema. The VStream is smart enough to only include the &lt;code&gt;FIELD&lt;/code&gt; event whenever necessary. For example, when a VStream client reconnects, or when a table’s schema is changed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The older version of VStream includes only the column type (e.g. &lt;code&gt;Integer&lt;/code&gt;, &lt;code&gt;Varchar&lt;/code&gt;), no additional information such as whether the column is the primary key, whether the column has a default value, &lt;code&gt;Decimal&lt;/code&gt; type’s scale and precision, &lt;code&gt;Enum&lt;/code&gt; type’s allowed values, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The newer version (Vitess 8) of VStream starts to include more information on each column. This will help the connector to deserialize more accurately certain types and have a more precise schema in the change events sent to Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;future-development-work&quot;&gt;Future Development Work&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can use VStream&amp;#8217;s API to start streaming from the latest VGTID position, instead of getting the initial VGTID position from VTCtld gRPC. Doing so would eliminate the dependency from VTCtld.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We don’t support automatically extracting the primary keys from the change events yet. Currently, by default, all change events sent to Kafka have &lt;code&gt;null&lt;/code&gt; as the key, unless the &lt;code&gt;message.key.columns&lt;/code&gt; connector configuration is specified. Vitess recently added flags of each column in the VStream FIELD event, which allows us to implement this feature soon.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add support for initial snapshots to capture all existing data before streaming changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;MySQL has been used to power most of our backend services at Bolt. Due to the considerable growth of the volume of data and operational complexity, Bolt started to evaluate Vitess for its scalability and its built-in features such as resharding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To capture data changes from Vitess, as what we’ve been doing with Debezium MySQL Connector, we’ve considered a few options. In the end, we have implemented our own Vitess Connector based on the common Debezium connector framework. While implementing the Vitess connector, we’ve encountered a few challenges. For example, support for the Vitess reshard operation, offset management, and schema management. We reasoned about ways to address the challenges and what we worked out as solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We’ve also received quite some interest from multiple communities in this project and we’ve decided to open-source &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess Connector&lt;/a&gt; under the Debezium umbrella. Please feel free to learn more, and we welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>keweishang, rgibaiev</name></author><category term="vitess" /><summary type="html">This post originally appeared on the Bolt Labs Engineering blog. Traditionally, MySQL has been used to power most of the backend services at Bolt. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes. Once data is persisted to the database, we use the Debezium MySQL Connector to capture data change events and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.</summary></entry><entry><title type="html">Hello Debezium!</title><link href="https://debezium.io/blog/2020/10/27/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium!" /><published>2020-10-27T16:19:59+00:00</published><updated>2020-10-27T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/27/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/10/27/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;My work started under the Data Virtualization team with Teiid and then under the &lt;a href=&quot;https://graphqlcrud.org/&quot;&gt;GRAPHQLCRUD&lt;/a&gt; project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Can&amp;#8217;t wait to learn and explore awesome things. Happy to get started here!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;--Anisha&lt;/p&gt;
&lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="community" /><category term="news" /><summary type="html">Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team. I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat. My work started under the Data Virtualization team with Teiid and then under the GRAPHQLCRUD project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications. Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha1 Released" /><published>2020-10-23T16:19:59+00:00</published><updated>2020-10-23T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This first pass of the 1.4 release line provides a few useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New Vitess connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Allow fine-grained selection of snapshotted tables&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;41 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-connector&quot;&gt;Vitess Connector&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.vitess.io&quot;&gt;Vitess&lt;/a&gt; is a database solution for deploying, scaling, and managing large clusters of MySQL.
We are very happy that the development team around Ruslan Gibaiev and Kewei Shang of &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt Technology OÜ&lt;/a&gt; decided to build a CDC solution based on Debezium and to &lt;a href=&quot;https://www.github.com/debezium/debezium-connector-vitess&quot;&gt;open-source it&lt;/a&gt; under the Debezium umbrella.
This connector is released in &lt;strong&gt;incubating&lt;/strong&gt; state in Debezium 1.4.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ruslan and Kewei will follow up with a blog post with more details around this connector very soon;
in the mean time please refer to the connector &lt;a href=&quot;https://debezium.io/documentation/reference/1.4/connectors/vitess.html&quot;&gt;reference documentation&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;fine-grained-selection-of-snapshotted-tables&quot;&gt;Fine-grained Selection of Snapshotted Tables&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the major focus points for Debezium 1.4 is to explore more flexible snapshot options,
e.g. to re-snapshot chosen tables or parallelizing long-running snapshot operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A first improvement related to snapshotting is the new connector configuration &lt;code&gt;snapshot.include.collection.list&lt;/code&gt;,
which allows to snapshot only a subset of all the tables which the connector will capture later on during log reading.
This comes in handy if for instance you&amp;#8217;re interested in capturing changes to all your tables, but only need an initial snasphot of the data for some of them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For the Postgres connector, by creating a custom implementation of the &lt;code&gt;Snapshotter&lt;/code&gt; SPI contract, this also allows for a selective re-snapshot of specific tables.
After restarting the connector, such &lt;code&gt;Snapshotter&lt;/code&gt; would continue to read the log from the point where it left off previously until &quot;now&quot;,
then it would take a snapshot of the given tables, and finally continue to read the log for &lt;em&gt;all&lt;/em&gt; captured tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For more information on this option, please see the connector-specific &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/index.html&quot;&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a few other features coming with the 1.4.0.Alpha1 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Implement snapshot select override behavior for MongoDB &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2496&quot;&gt;DBZ-2496&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SqlServer - Skip processing of LSNs not associated with change table entries &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2582&quot;&gt;DBZ-2582&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cant override environment variables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2559&quot;&gt;DBZ-2559&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ConcurrentModificationException during exporting data for a mongodb collection in a sharded cluster &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2597&quot;&gt;DBZ-2597&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mysql connector didn&amp;#8217;t pass the default db charset to the column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2604&quot;&gt;DBZ-2604&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Doc] &quot;registry.redhat.io/amq7/amq-streams-kafka-25: unknown: Not Found&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2609&quot;&gt;DBZ-2609&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Doc] &quot;Error: no context directory and no Containerfile specified&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2610&quot;&gt;DBZ-2610&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SqlExceptions using dbz with Oracle on RDS online logs and LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mining session stopped - task killed/SQL operation cancelled - Oracle LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unparseable DDL: Using 'trigger' as table alias in view creation &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2639&quot;&gt;DBZ-2639&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Antlr DDL parser fails to interpret BLOB([size]) &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL Connector keeps stale offset metadata after snapshot.new.tables is changed &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2643&quot;&gt;DBZ-2643&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WAL logs are not flushed in Postgres Connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Server Event Hubs plugin support in v1.3 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra Connector doesn&amp;#8217;t use log4j for logging correctly &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2661&quot;&gt;DBZ-2661&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Should Allow NonAsciiCharacter in SQL &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MariaDB nextval function is not supported in grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sanitize field name do not sanitize sub struct field &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium fails if a non-existing view with the same name as existing table is dropped &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I am excited to announce the release of Debezium 1.4.0.Alpha1! This first pass of the 1.4 release line provides a few useful new features: New Vitess connector Allow fine-grained selection of snapshotted tables Overall, the community fixed 41 issues for this release. Let&amp;#8217;s take a closer look at some of the highlights.</summary></entry><entry><title type="html">Towards a Graphical Debezium User Interface</title><link href="https://debezium.io/blog/2020/10/22/towards-debezium-ui/" rel="alternate" type="text/html" title="Towards a Graphical Debezium User Interface" /><published>2020-10-22T16:19:59+00:00</published><updated>2020-10-22T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/22/towards-debezium-ui</id><content type="html" xml:base="https://debezium.io/blog/2020/10/22/towards-debezium-ui/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases.
Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors,
allowing to safely operate CDC pipelines also in huge installations with thousands of connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production.
We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today it&amp;#8217;s my great pleasure to introduce you to a proof-of-concept for a potential future &lt;strong&gt;Debezium graphical user interface&lt;/strong&gt;.
The goal for this PoC is to explore how a graphical UI could facilitate the getting started and operational experience of Debezium users.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The scope of the PoC is the set-up flow for configuring and instantiating a Debezium Postgres connector.
The user is guided through the required configuration steps in a wizard interface,
starting from mandatory information (e.g. database credentials), over selecting the tables to be captured, up to optional settings like different data mapping options.
After reviewing the final configuration, the UI will instantiate the connector in Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can see a short demo of how this looks like in this video:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;responsive-video&quot;&gt;
&lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/RZ_3DF7Ndnk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We focused on some core interaction patterns, e.g. the preview functionality for the selecting the captured tables.
Instead of solely taking key/value pairs of configuration parameters,
the UI should guide the user through the process, provide context and help, e.g. by showing the allowed options for settings in drop-downs, validating the provided settings after each step, and more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now this is just the beginning, there&amp;#8217;s many more things that could be done in such Debezium UI,
e.g. in the connection configuration step, we could validate whether the given user has all the required database permissions, whether the right WAL level is set in the database, etc.
There could be views for monitoring and trouble-shooting connectors.
When running on Kubernetes, the UI could produce resource definitions processed by a Kafka (Connector) operator like Strimzi (instead of calling the Kafka Connect REST API), and much more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But before further progressing with this, we&amp;#8217;d like to gather your feedback and opinions:
Do you consider a graphical UI for Debezium useful in general, and is it something you would use in your projects?
What is your feedback on the functionality currently implemented in the PoC?
Which other functionality besides connector configuration would you like to see in a Debezium UI?
We&amp;#8217;ve provided a short survey with these and a few other questions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph text-center&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSfEEqslTWSLX89gzIDmSE_4v8hH0mYg0YBRaXhfDrrBbCUJgQ/viewform?usp=sf_link&quot;&gt;Go to survey&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Before taking the questionnaire, please watch the video or run the PoC yourself (see below).
Answering these questions should take just a few minutes; your participation would be very helpful for us in order to decide whether and how we should move forward with this effort.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;trying-it-out-yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As everything in Debezium, the UI PoC is fully open source (Apache License Version 2.0);
you can find its &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;source code&lt;/a&gt; under the Debezium organization on Git Hub.
The PoC is implemented as a &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;-based web application,
using &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; as the frontend technology.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Quarkus backend is configured with the URL(s) of one more Kafka Connect clusters.
Note that there&amp;#8217;s currently no means of authentication or authorization implemented in the PoC,
so don&amp;#8217;t use it with your production Connect clusters just yet.
After starting the application, you can choose the cluster to work with from the drop-down to the top right.
Different from what&amp;#8217;s shown in the video recording, the &quot;Delete&quot; button is working in the PoC now, too ;)
There&amp;#8217;s an example &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/blob/master/docker-compose.yml&quot;&gt;Docker Compose file&lt;/a&gt;, which starts up all required components for getting started quickly.
Alternatively, you can obtain a &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui-poc&quot;&gt;pre-built container image&lt;/a&gt; with the Debezium UI PoC from Docker Hub.
Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/#debezium-ui-poc&quot;&gt;README file&lt;/a&gt; for more details on building and running the Debezium UI PoC.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;re looking forward very much to learning about your feedback on the Debezium UI PoC.
Try it out yourself and let us know about your thoughts in the comments below and by participating in the quick survey linked above.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;A big thank you to the team working on this PoC: Ashique Ansari, Indra Shukla, June Zhang, Mark Drilling, Na Ding, and René Kerner!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community" /><category term="discussion" /><summary type="html">Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases. Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more. When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors, allowing to safely operate CDC pipelines also in huge installations with thousands of connectors. All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production. We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily.</summary></entry><entry><title type="html">Debezium Community Stories With… Renato Mefi</title><link href="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/" rel="alternate" type="text/html" title="Debezium Community Stories With… Renato Mefi" /><published>2020-10-08T16:19:59+00:00</published><updated>2020-10-08T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi</id><content type="html" xml:base="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know.
In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;Renato Mefi&lt;/a&gt;, a long-time Debezium user and contributor.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/renatomefi.jpg&quot; style=&quot;max-width:50%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Renato, could you introduce yourself? What is your job, if you&amp;#8217;re not contributing to Debezium?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello all, I&amp;#8217;m Renato and my first Debezium commit was on Nov 12, 2018, it&amp;#8217;s been a long and fun ride so far, and I&amp;#8217;m glad to have the opportunity to share my story here with you all!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m a Staff Software Engineer at &lt;a href=&quot;https://www.surveymonkey.com/&quot;&gt;SurveyMonkey&lt;/a&gt; in Amsterdam, The Netherlands, within the Platform team for our CX (customer experience) suite, if you&amp;#8217;re curious about what that is, you can &lt;a href=&quot;https://usabilla.com/blog/introducing-the-getfeedback-suite/&quot;&gt;check it out here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;On the internet you&amp;#8217;re going to find me talking about Docker, Debezium, Kafka, Microservices and other things that I enjoy.
Although those amazing engineering pieces really excite me, at this moment I&amp;#8217;m also really passionate about Platform Engineering teams and how they can operate in an organization, the stories I&amp;#8217;m going to tell below represent my view of it, of how critical the role of a platform team can be when adopting new technologies and solving difficult problems for the whole, in this case powered by Debezium!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;What are your use cases for Debezium and CDC in your current project?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s a long and enjoyable story (long in terms of the internet), we&amp;#8217;ve been using Debezium since Q4 2018, it&amp;#8217;s been 2 years at the moment I&amp;#8217;m writing those answers here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I classify Debezium within our product, I say it is an architectural component, the idea behind this is to position it as a platform/infrastructure concern, in a way that it can reach multiple parts of the stack and services. I consider this abstraction of Debezium one of the key success factors it had in its adoption and growth within our platform, let me explain this better!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Our first use case is likely to be one of the most common ones for CDC, the &lt;a href=&quot;https://martinfowler.com/bliki/StranglerFigApplication.html&quot;&gt;strangler pattern&lt;/a&gt;, which for us came before Debezium; so let me tell this part of the story first: when I joined Usabilla (later acquired by SurveyMoney), there was already an effort to move our platform to a new architecture and the strangler pattern was already there. When the first couple of services started to grow, their primary way to bring data out of legacy was to poll the database, and needless to say, this could go very wrong! Our legacy database is a MongoDB cluster, and since I was pre-occupied with the polling approach, I started to dig into possibilities. I was hoping to find something like a streaming API for it, but what I ended up encountering was the database changelog (&lt;a href=&quot;https://en.wikipedia.org/wiki/Write-ahead_logging&quot;&gt;Write-ahead logging&lt;/a&gt;, &quot;oplog&quot; as it&amp;#8217;s called in Mongo!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It came to my mind right away: &quot;Oh, I could write something that queries the data from the oplog and sends it to Kafka&quot;. So I checked with our in-house Senior SRE and MongoDB expert &lt;a href=&quot;https://twitter.com/gwkunze&quot;&gt;Gijs Kunze&lt;/a&gt; who thought it could be a good idea; as a next step I went to talk to my colleague &lt;a href=&quot;https://twitter.com/rdohms&quot;&gt;Rafael Dohms&lt;/a&gt;, and we decided to do some extra Googling, and like that, we found Debezium! It was the perfect match to our needs and better than what we could have written by ourselves!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now back to our use case, what makes it an architecture component for us, is basically the approach, we abstracted and wrapped Debezium in a project called Legacy Data Syncer (LDS for us, because acronyms never get old). Although it might look simple to spin up a Kafka Connect with Debezium, running it production-ready, monitoring multiple collections within the database, exposing metrics, doing transformations and more, is not such an easy task. So how does it work? Every time an engineering team needs to capture data from our legacy system, to start strangling a feature, they only have to do two things, open a pull request which literally adds one line to LDS, and create their Kafka consumer!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_lds.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 1. The configuration file in LDS; a developer will open a PR adding a new line, the rest will be taken care of.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Upon merging the PR, our project will provision the whole configuration to Kafka Connect, it ensures the snapshot is executed, metrics are present and etc; We&amp;#8217;ve done the same thing for the outbox pattern and I talk a little bit more about it in this &lt;a href=&quot;https://twitter.com/renatomefi/status/1185098904745992197&quot;&gt;tweet thread&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Self-servicing the teams was a great way to remove resistance for adoption, no Jira tickets were necessary, no advanced ops knowledge or anything else to get it running. The other factors I consider to have contributed to Debezium&amp;#8217;s success in our platform is its reliability and straight forward value perception, in those two years we never had major outages or critical problems of any kind!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;You mention the outbox pattern; Could you tell more about why and how you&amp;#8217;re using this?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Absolutely! One more time, it&amp;#8217;s crazy how CDC and Debezium can simplify some of the most critical architectural parts of big platforms!
One year after using Debezium in the core of our architecture migration, we had another problem at our hands: how to reliably write data to our new source of truth databases and propagate messages to Kafka at the same time. Although it seems to be simple to answer and find a solution, each of them comes with a major drawback.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Which solutions do we have?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Embrace eventual consistency to its peak by adopting &lt;em&gt;event sourcing&lt;/em&gt;, by writing first to Kafka and reading our own writes; the drawbacks here are extra complexity and intensified eventual consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Dual writes&lt;/em&gt;, well, actually this is not an option, because as you know, &lt;a href=&quot;https://thorben-janssen.com/dual-writes/&quot;&gt;&quot;Friends Don&amp;#8217;t Let Friends Do Dual Writes&quot;&lt;/a&gt;!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Different approaches of &lt;em&gt;distributed transactions&lt;/em&gt; like 2PC and sagas; the costs here are performance and engineering effort, now every service we have has to either become a transaction coordinator or have rollback capabilities, also the cascade effect scared us quite a bit!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Well, what&amp;#8217;s left? We found that outbox was the right answer for us, but before we get there, let me get into the cost x benefit equation of our decision making!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Although some of the options were quite attractive technically, for instance event sourcing, the engineering effort and growth is immense. Also, it&amp;#8217;s not the kind of thing which comes ready to use, and there&amp;#8217;s a lot of discovery to be made along the way, so what were the constraints and desires:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Reliability&lt;/em&gt;; we want at least once semantics, exactly once isn&amp;#8217;t necessary as we can uniquely identify each message/event;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Eventual consistency only between services&lt;/em&gt;, but not within the services themselves. Being able to interact with a service which is the source of truth of a certain model, and get an immediate answer is not just handy, but incredibly powerful (and that&amp;#8217;s why monoliths are also so attractive);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Avoiding distributed transactions&lt;/em&gt; as much as we can, it&amp;#8217;s scary and we should be scared about it too!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Manageable effort&lt;/em&gt;; how can we &quot;easily&quot; get 30+ engineers to adopt a solution for this problem? At the same time, how can you ensure the implementation guarantees among every service and team?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We realized that the &lt;a href=&quot;https://microservices.io/patterns/data/transactional-outbox.html&quot;&gt;outbox pattern&lt;/a&gt; would help us meet those requirements: applications would publish events via an outbox table, which gets written to as part of business transactions in the database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As with the strangler pattern, we wanted to resort to an architecture component, something the teams could self-service. At first, we were exploring a home-grown solution which would look for the outbox tables among every service and publish the messages. The problem with this approach would be the polling databases problem, although in this case this is less harmful as we don&amp;#8217;t need to look for updates or deletes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Luckily, by that time I was closely following the work being done in Debezium and I read the blogpost about &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;reliable data exchange between microservices using the outbox pattern&lt;/a&gt;, and there was my answer! Well, I mean, parts of the answer, we still needed to implement it, and that&amp;#8217;s a story for the next question!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Fast forward a couple of months and we got a reliable way to exchange messages between services, with all the guarantees we wanted to have, and by applying some platform DevOps flavor to it, we also made it self-service and easy to plug in every service!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The user can specify which database their service is at, what&amp;#8217;s the table name, and which column to use as event router, you can find more details about it in the official &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html#outbox-event-router-property-route-by-field&quot;&gt;Debezium outbox event router docs&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_outbox.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 2. The configuration file for configuring outbox connectors&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;You&amp;#8217;re not only using Debezium but you&amp;#8217;ve also contributed to the project. How was your experience doing so? Are you doing other open-source work, too?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As I spoiled at the beginning, my usage and contributions to Debezium walked hand-to-hand. In both the use cases we have for Debezium in SurveyMonkey, I had great opportunities to contribute to both Debezium and Kafka (just a bug fix, but I&amp;#8217;m happy about it!).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At first, I was fixing bugs in the Debezium MongoDB connector; as we really scaled it up to all the teams, a lot of edge cases started to show up, mostly in the transformation which takes the raw database transaction log and transforms it into a nicely readable Kafka Connect struct. Also due to our architecture choice, we split the raw log and transformed data into two different steps, which go in separate topics and are configured as separate Kafka Connect connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Quick sidestep: the rationale behind this decision was to be able to survive transformation errors; MongoDB has a replication window which, if you lose it, means that you are going to have to make a new full snapshot of the collection and you might lose deletion events in this process. Because of this we opted for a safer approach, which was to split the logic of transformation from the raw logs like this:
The step we call &lt;code&gt;op&lt;/code&gt; (stands for operation), is the Debezium MongoDB source connector and outputs the raw data into the topic without any change or transformation, minimizing the chances of errors in the process. The second step called &lt;code&gt;cdc&lt;/code&gt;, is a &lt;a href=&quot;https://github.com/salesforce/mirus&quot;&gt;Salesforce Mirus&lt;/a&gt; source connector, which reads from the &lt;code&gt;op&lt;/code&gt; output topic, transforms the message using the &lt;a href=&quot;https://debezium.io/documentation/reference/1.3/configuration/mongodb-event-flattening.html&quot;&gt;Debezium document flattening SMT&lt;/a&gt; and outputs to the final topic, which the services can consume from. With this approach, we now have two main abilities: Resist to errors and crashes on the native/custom transformation process like mentioned above, and we have the chance to change the transformation to our desires without having to read from the database again, giving us more flexibility. That also created some extra features and challenges to be incorporated in Debezium itself!
As I kept contributing I noticed a few things that could be improved and started fixing them, including an almost full refactor of the build process of Debezium&amp;#8217;s container images, its scripts, and other smaller things!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s circle back to outbox; when the post about this appeared on the Debezium blog, it was mostly an idea and a proof-of-concept. But we really wanted it to run in production, in this case, why not partnership on it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I want to take the opportunity here to mention how helpful the Debezium community was for getting me started with contributing. As I showed the intent to work on this, they were super welcoming and we had a call about it, so I quickly felt productive working on the code base.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Almost immediately after the conversation I started a technical draft (which you can see &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1169&quot;&gt;here&lt;/a&gt;) and soon thereafter, the first implementation was done. I can almost certainly say we were the first ones to run the transactional outbox pattern powered by Debezium. I was running a custom build on our platform, which then finally became the official &lt;a href=&quot;https://debezium.io/documentation/reference/1.2/configuration/outbox-event-router.html&quot;&gt;outbox event router&lt;/a&gt; you see in the Debezium docs today.
I was lucky to be there at the right time and with the right people, so thanks again to the Debezium team for helping me throughout the whole process of drafting and making it happen!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Will I do more open source? Yes, but I must say most of my open source activity is &quot;selfish&quot;, I&amp;#8217;m developing solutions to problems I face at work but I&amp;#8217;m happy to take the extra step and make them to the OSS world, but it also makes it seasonal. One of the advantages to that is if I&amp;#8217;m doing something for a project, be sure I&amp;#8217;ll make it to production and likely be able to find more corner cases!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Is there anything you&amp;#8217;re missing in Debezium or you&amp;#8217;d like to see improved in the future?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I think of the Kafka and Debezium ecosystem, the next steps I consider important are the ones which will make it more accessible. Although there&amp;#8217;s a lot of content and examples online, there&amp;#8217;s still a big gap between reading those and getting to a production ready implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What I mean by that is abstracting the individual pieces away and giving them more meaning. The outbox pattern is a good example, it was not natural for people to think of CDC and know that it was such a good match to it, there are plenty of more use cases to be explored in this ecosystem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What if you could have everything out-of-the-box? An outbox implementation in your favorite framework, which knows how to integrate with the ORM, handle the transaction part, then, how to shape the messages and events? How to adopt the schema for it and how an evolution of it looks like. After that, getting closer to the consumer implementation, how can I handle the messages idempotently, respect the semantics, do retries, and project them to a database if need be? There are already initiatives like those, for instance, the &lt;a href=&quot;https://debezium.io/documentation/reference/integrations/outbox.html&quot;&gt;Quarkus Outbox extension&lt;/a&gt;, which takes care of framework and database integration. The future for me has those things, for multiple frameworks and tech stacks, going even broader and helping you design good events (maybe even powered by &lt;a href=&quot;https://www.asyncapi.com/&quot;&gt;AsyncAPI&lt;/a&gt;), giving everyone a kickstart!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Those are very complex things to do in a growing architecture, the patterns will keep repeating and hopefully the community will be able to come to consensus of design and implementations, and that&amp;#8217;s what I think the next step is, a place where the complexity of a good architecture doesn&amp;#8217;t live in the wires and plugs anymore, making it more accessible!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Bonus question: What&amp;#8217;s the next big thing in software engineering?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I think I handled clues for this one in many parts of my previous answers!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For me the next big thing is a methodology; I often say the evolution of DevOps is self-service, and it can go in many layers of the stack. The examples I gave about our Debezium implementation is what I call self-service between Platform/Ops and product development teams, but it can be applied in many, many places!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The idea is to facilitate the implementation of complex structures, something more end-to-end, taking care of the good practices in metrics, alerts, and diverse other guaranteed semantics for the use case!
We can see there&amp;#8217;s a convergence towards that path, for instance Kubernetes operators are a great example where you can abstract one use case which will be translated to many, if not dozens of internal resources in the infrastructure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I believe we already have the base technology to do so, all the Infrastructure as Code, containers, frameworks, observability systems are there, we just have to give meaning to them!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Where&amp;#8217;s the framework where I can: Handle a user request, validate, write to the source-of-truth, produce a message to my broker, consume at another end where my only concern is the payload itself? All the semantics should be taken care of, idempotency, retries, SerDes issues, dead letter queues, eventual consistency mitigations, metrics, alerts, SLOs, SLAs, etc!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And that&amp;#8217;s where I put my energy in everyday at work, giving all the engineering teams a more fun and safe way to develop their software, which also sums up my passion for Platform Engineering!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Renato, thanks a lot for taking your time, it was a pleasure to have you here!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;If you&amp;#8217;d like to stay in touch with Renato Mefi and discuss with him, please drop a comment below or follow and reach out to him &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;on Twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community" /><category term="outbox" /><summary type="html">Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know. In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to Renato Mefi, a long-time Debezium user and contributor.</summary></entry><entry><title type="html">Debezium 1.3.0.Final Released</title><link href="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Final Released" /><published>2020-10-01T16:19:59+00:00</published><updated>2020-10-01T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/01/debezium-1-3-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium &lt;strong&gt;1.3.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months.
Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.3.0.Final%2C%201.3.0.Alpha1%2C%201.3.0.Beta1%2C%201.3.0.Beta2%2C%201.3.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;138 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A new incubating &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based implementation&lt;/a&gt; for ingesting change events from Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for Azure Event Hubs in &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upgrade to Apache Kafka 2.6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revised &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;filter option names&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new SQL Server connector snapshot mode, &lt;code&gt;initial_only&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for database-filtered columns for SQL Server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional connection options for the MongoDB connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improvements to &lt;code&gt;ByteBufferConverter&lt;/code&gt; for implementing the &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;outbox pattern&lt;/a&gt; with Avro as the payload format&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the announcements of the preview releases (&lt;a href=&quot;https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/&quot;&gt;Beta2&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details.
Since last week&amp;#8217;s CR1 release, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;been focusing&lt;/a&gt; on ironing out some remaining bugs and improvements to the documentation.
To learn more about procedures for upgrading from earlier Debezium versions, please take a look the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-final1&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you to everyone testing the preview releases, this is of invaluable help for spotting and fixing short-comings in new features as well as regressions.
And of course I&amp;#8217;d also like to thank all the community members contributing to this release:
&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/abhirockzz&quot;&gt;Abhishek Gupta&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bjoernhaeuser&quot;&gt;Björn Häuser&lt;/a&gt;,
&lt;a href=&quot;https://github.com/coryharperbind&quot;&gt;Cory Harper&lt;/a&gt;,
&lt;a href=&quot;https://github.com/denisprog&quot;&gt;Denis Liseichykau&lt;/a&gt;,
&lt;a href=&quot;https://github.com/eric-weaver&quot;&gt;Eric Weaver&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt;,
&lt;a href=&quot;https://github.com/GuyIEX&quot;&gt;Guy Pascarella&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jfinzel&quot;&gt;Jeremy Finzel&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jonaslins&quot;&gt;Jonas Lins&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/korzenek&quot;&gt;Lukasz Korzeniowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/lga-zurich&quot;&gt;Luis Garcés-Erice&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/misaert&quot;&gt;Mickaël Isaert&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mtagle&quot;&gt;Moira Tagle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rivernate&quot;&gt;Nathan Mills&lt;/a&gt;,
&lt;a href=&quot;https://github.com/petoju&quot;&gt;Peter Junos&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Victor Xiang&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, more than 220 individuals have contributed to the Debezium project at this point.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But not only that, also the number of Debezium users is constantly growing,
as e.g. documented on our &lt;a href=&quot;/community/users/&quot;&gt;reference list of Debezium users&lt;/a&gt;
(let us know if you want to be added).
There&amp;#8217;s also several new entries in our compilation of &lt;a href=&quot;/documentation/online-resources/&quot;&gt;public talks and blog posts&lt;/a&gt; touching on Debezium,
e.g. a highly recommendable talk by Marta Paes about &lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;change data capture with Flink SQL and Debezium&lt;/a&gt;,
a blog post by Cemal Turkoglu about &lt;a href=&quot;https://turkogluc.com/postgresql-capture-data-change-with-debezium/&quot;&gt;[making sense of change data capture pipelines for Postgres with the Debezium Kafka Connector&lt;/a&gt;,
and a nice piece on &lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;implementing the outbox pattern with Debezium in Quarkus&lt;/a&gt; by Iain Porter.
Abdellatif Bouchama did an amazing job by creating a &lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;cheat sheet&lt;/a&gt; for running Debezium on OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With the 1.3 Final release out, planning for the 1.4 version (due by the end of the year) is happening right now.
The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; still is in flux, so make sure to chime in and let us know about your requirements and feature requests.
Some of the things we&amp;#8217;re likely going to work on include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;community-led connector&lt;/a&gt; for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;; the initial contribution has already been merged and we plan to ship the first release of this as part of Debezium 1.4 Alpha1 later this month&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improving the new LogMiner-based implementation for Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And lastly, there&amp;#8217;s one other area of activity which I&amp;#8217;m particularly excited to share here today for the first time:
a proof-of-concept of how a potential future Debezium user interface might look like.
In that PoC we&amp;#8217;re exploring how a graphical UI could help with the set-up and operation of Debezium connectors.
We&amp;#8217;ve got quite a few ideas in that field and will share more details in a blog post very soon.
If you feel adventureous in the meantime, you could grab the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;current PoC code&lt;/a&gt; and take it for spin!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Until then, happy change data streaming, onwards and upwards!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium 1.3.0.Final! As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months. Overall, the community has fixed 138 issues during that time, including the following key features and changes: A new incubating LogMiner-based implementation for ingesting change events from Oracle Support for Azure Event Hubs in Debezium Server Upgrade to Apache Kafka 2.6 Revised filter option names A new SQL Server connector snapshot mode, initial_only Support for database-filtered columns for SQL Server Additional connection options for the MongoDB connector Improvements to ByteBufferConverter for implementing the outbox pattern with Avro as the payload format</summary></entry><entry><title type="html">Debezium 1.3.0.CR1 Released</title><link href="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.CR1 Released" /><published>2020-09-24T16:19:59+00:00</published><updated>2020-09-24T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.3.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we approach the final stretch of Debezium 1.3 Final,
we took this opportunity to add delegate converter support for the &lt;code&gt;ByteBufferConverter&lt;/code&gt; and introduce a &lt;code&gt;debezium-scripting&lt;/code&gt; module.
In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish;
overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.CR1%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;15 issues&lt;/a&gt; have been resolved for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bytebufferconverter-improvements&quot;&gt;ByteBufferConverter improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;ByteBufferConverter&lt;/code&gt; is a converter that is used with the Outbox event router SMT to serialize an existing Avro payload column.
In a recent report (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2396&quot;&gt;DBZ-2396&lt;/a&gt;),
the &lt;code&gt;ByteBufferConverter&lt;/code&gt; was unable to serialize events emitted from a connector that was configured to emit heartbeat, transaction metadata, or schema change events.
In order to improve the converter&amp;#8217;s compatibility when these events are emitted,
the &lt;code&gt;ByteBufferConverter&lt;/code&gt; can now be configured to delegate event serialization to an additional converter.
This delegation is necessary so that heartbeat, transaction metadata, and schema change events (if applicable) can be serialized.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to use the Outbox event router SMT and the &lt;code&gt;ByteBufferConverter&lt;/code&gt; with these event types,
the connector configuration must be changed to reflect the delegate converter and its configurable options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As an example to use the Apache Kafka &lt;code&gt;JsonConverter&lt;/code&gt; as a delegate with schemas disabled,
the following configuration would need to be included in the connector:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;value.converter=io.debezium.converters.ByteBufferConverter
value.converter.delegate.converter.type=org.apache.kafka.connect.json.JsonConverter
value.converter.delegate.converter.type.schemas.enable=false&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For more information about using the &lt;code&gt;ByteBufferConverter&lt;/code&gt;,
please see the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/outbox-event-router.html#avro-as-payload-format&quot;&gt;Using Avro as the payload format&lt;/a&gt; section in the Outbox event router documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;scripting-module&quot;&gt;Scripting module&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this release, the SMTs for content-based routing and filtering that both use JSR 223 scripting engines have been moved out of &lt;code&gt;debezium-core&lt;/code&gt; and into a separate artifact &lt;code&gt;debezium-scripting&lt;/code&gt; (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2549&quot;&gt;DBZ-2549&lt;/a&gt;).
Any connector that previous used these SMTs requires that the new artifact be added to the plug-in directories for those connector(s).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When using the Debezium container image for Kafka Connect, set the environment variable &lt;code&gt;ENABLE_DEBEZIUM_SCRIPTING&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; to enable this feature.
This change is done to allow the scripting functionality to be available only in environments with an apppropriately secured Kafka Connect configuration interface.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;misc-features-and-bug-fixes&quot;&gt;Misc. Features and Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, the community has completed the work on some other features and fixes, too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Catch up streaming before snapshot may duplicate messages upon resuming streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2550&quot;&gt;DBZ-2550&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix Quarkus datasource configuration for Quarkus 1.9 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2558&quot;&gt;DBZ-2558&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement connection retry support for Oracle &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2531&quot;&gt;DBZ-2531&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-cr1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you so much to &lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt; and &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt; for their contributions to this release.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.3 Final should be out next week.
Until then, we&amp;#8217;ll focus on some more polishing.
The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;community-lead work&lt;/a&gt; towards a Debezium connector for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt; is also making good progress,
with an initial release of this new connector planned with Debezium 1.4 Alpha1 in late October.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.3.0.CR1! As we approach the final stretch of Debezium 1.3 Final, we took this opportunity to add delegate converter support for the ByteBufferConverter and introduce a debezium-scripting module. In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish; overall, not less than 15 issues have been resolved for this release.</summary></entry><entry><title type="html">Debezium 1.3.0.Beta2 Released</title><link href="https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Beta2 Released" /><published>2020-09-16T16:19:59+00:00</published><updated>2020-09-16T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.3.0.Beta2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this release we&amp;#8217;ve improved support for column filtering for the MySQL and SQL Server connectors,
and there&amp;#8217;s a brand-new implementation for ingesting change events from Oracle, using the LogMiner package.
As we&amp;#8217;re on the home stretch towards Debezium 1.3 Final,
there&amp;#8217;s also a wide range of smaller improvements, bug fixes and documentation clarifications;
overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Beta2%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;44 issues&lt;/a&gt; have been resolved for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;column-filtering-improvements&quot;&gt;Column Filtering Improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Addressing a long standing feature request (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1068&quot;&gt;DBZ-1068&lt;/a&gt;),
the Debezium connector for SQL Server supports now server-side column filtering:
capture instances in the database itself can be configured so to only contain a sub-set of the captured table&amp;#8217;s columns.
That way, specific columns can be excluded by the CDC process right away,
instead of only removing them in the Debezium connector,
which is much more efficient for large BLOB for instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The MySQL connector adds support for the &lt;code&gt;column.include.list&lt;/code&gt; option already known from the Debezium Postgres connector
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2508&quot;&gt;DBZ-2508&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Related to the matter of filtering,
following up on the work begun in the &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;1.3 Beta1 release&lt;/a&gt; around replacing the terms &quot;master/slave&quot;, &quot;blacklist&quot; and &quot;whitelist&quot; with more inclusive alternatives,
also all the incubating connectors (Oracle, Db2, Cassandra) use the new terms like &quot;database.include.list&quot;, &quot;primary/replica&quot;, etc. now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2462&quot;&gt;DBZ-2462&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;logminer-based-ingestion-engine-for-oracle&quot;&gt;LogMiner-based Ingestion Engine for Oracle&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium Oracle connector can now use the LogMiner package to ingest change events.
As this package comes with the Oracle database itself,
it&amp;#8217;s a very attractive alternative to the existing XStream-based implementation.
Discussions and work towards LogMiner support have been happening in the Debezium community for a long time
(as you already might have guessed from the very low issue number &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-137&quot;&gt;DBZ-137&lt;/a&gt;),
so we&amp;#8217;re particularly excited about this work being merged eventually and being part of this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Note that there&amp;#8217;s several follow-up tasks to be resolved related to the LogMiner-based ingestion implementation;
while it is not recommended for production usage at this point,
we&amp;#8217;d love to get your feedback from testing and evaluating!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A massive thank you to everyone involved with this:
Andrey Ignatenko and his team for the main work,
Andrey Pustovetov for his ideas around transaction buffering,
Chris Cranford for picking up the PR and preparing it to get merged,
Milo vd Zee for his extensive review,
as well as everyone else commenting and providing feedback on the PR and Jira issue.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;misc-features-and-bug-fixes&quot;&gt;Misc. Features and Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition to these key features, the community has completed the work on some other features and fixes, too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The MySQL connector supports the &lt;code&gt;LOCK TABLES FOR BACKUP&lt;/code&gt; lock mode when being used with Percona Server for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2466&quot;&gt;DBZ-2466&lt;/a&gt;),
which reduces contention during snapshots&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Postgres connector snapshot SPI got more flexible, allowing for custom implementations now that e.g. can re-snapshot selected tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2094&quot;&gt;DBZ-2094&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The prefix of additional headers and fields produced by the event flattening SMTs is customizeable now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2504&quot;&gt;DBZ-2504&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for JSON functions in MySQL DDL statements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2453&quot;&gt;DBZ-2453&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved exception logging for the Cassandra connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2498&quot;&gt;DBZ-2498&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-beta2&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you so much to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/eric-weaver&quot;&gt;Eric Weaver&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/GuyIEX&quot;&gt;Guy Pascarella&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/misaert&quot;&gt;Mickaël Isaert&lt;/a&gt;,
and &lt;a href=&quot;https://github.com/rivernate&quot;&gt;Nathan Mills&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With the first cut of LogMiner support being merged and released,
we&amp;#8217;re now planning to focus on stabilization and bug fixing,
with the Debezium 1.3 Final release to be expected around the end of the month.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In parallel, work is happening on a &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;new connector&lt;/a&gt; contributed by the community for the Vitess (which will - depending on progress of review - be released as an incubating connector either in Debezium 1.3 or 1.4),
and we&amp;#8217;re going to share some exciting efforts around a proof-of-concept for a potential future Debezium UI with you very soon!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.3.0.Beta2! In this release we&amp;#8217;ve improved support for column filtering for the MySQL and SQL Server connectors, and there&amp;#8217;s a brand-new implementation for ingesting change events from Oracle, using the LogMiner package. As we&amp;#8217;re on the home stretch towards Debezium 1.3 Final, there&amp;#8217;s also a wide range of smaller improvements, bug fixes and documentation clarifications; overall, not less than 44 issues have been resolved for this release.</summary></entry><entry><title type="html">Auto-creating Debezium Change Data Topics</title><link href="https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/" rel="alternate" type="text/html" title="Auto-creating Debezium Change Data Topics" /><published>2020-09-15T16:19:59+00:00</published><updated>2020-09-15T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/15/debezium-auto-create-topics</id><content type="html" xml:base="https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/">&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/new_pipes.jpg&quot; class=&quot;responsive-image&quot; alt=&quot;Create new topics / pipes&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you are working with Kafka Connect Distributed then you might have realized that once you start
Kafka Connect there are already some internal Kafka Connect related topics created for you:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --list

connect_configs
connect_offsets
connect_statuses&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is done automatically for you by Kafka Connect with a sane, customized default topic configuration
that fits the needs of these internal topics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you start a Debezium connector the topics for the captured events are created by the Kafka
broker based on a default, maybe customized, configuration in the broker if
&lt;code&gt;auto.create.topics.enable = true&lt;/code&gt; is enabled in the broker config:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;auto.create.topics.enable = true
default.replication.factor = 1
num.partitions = 1
compression.type = producer
log.cleanup.policy = delete
log.retention.ms = 604800000  ## 7 days&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But often, when you use Debezium and Kafka in a production environment you might choose to disable
Kafka&amp;#8217;s topic auto creation capability with &lt;code&gt;auto.create.topics.enable = false&lt;/code&gt;, or you want the
connector topics to be configured differently from the default. In this case you have to create
topics for Debezium&amp;#8217;s captured data sources upfront.&lt;br&gt;
But there&amp;#8217;s good news! Beginning with Kafka Connect version 2.6.0, this can be automated since
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics&quot;&gt;KIP-158&lt;/a&gt;
is implemented to enable customizable topic creation with Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;kafka-connect&quot;&gt;Kafka Connect&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;topic.creation.enable = true&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you don&amp;#8217;t want to allow automatic topic creation by connectors you can set this value to &lt;code&gt;false&lt;/code&gt;
in the Kafka Connect config (&lt;em&gt;connect-distributed.properties&lt;/em&gt; file or via environment variable
&lt;em&gt;CONNECT_TOPIC_CREATION_ENABLE&lt;/em&gt; when using &lt;a href=&quot;https://hub.docker.com/r/debezium/connect&quot;&gt;Debezium&amp;#8217;s container image for Kafka Connect&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;updating-connector-configuration&quot;&gt;Updating Connector Configuration&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Kafka Connect topic creation works with groups. There&amp;#8217;s always a &lt;code&gt;default&lt;/code&gt; group which is used when
there&amp;#8217;s no other group defined that matches the topic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Every group can specify a collection of topic configuration properties, and a regular expression list
of topic names that config should apply to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can specify all &lt;a href=&quot;https://kafka.apache.org/documentation/#topicconfigs&quot;&gt;&lt;strong&gt;topic level configuration parameters&lt;/strong&gt;&lt;/a&gt;
to customize how the matched topics of the group will be created.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s see how we can extend this Postgres config for the Kafka Connect topic creation:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;default-config&quot;&gt;Default Config&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All topics not matching other &lt;code&gt;topic.creation&lt;/code&gt; groups will apply the &lt;code&gt;default&lt;/code&gt; group
config.&lt;br&gt;
As default we want &lt;code&gt;replication.factor = 3&lt;/code&gt;, &lt;code&gt;partitions = 10&lt;/code&gt;, the topic should be key
compacted with &lt;code&gt;cleanup.policy = &quot;compact&quot;&lt;/code&gt;, and all messages should be LZ4 compressed
on harddisk with &lt;code&gt;compression.type = &quot;lz4&quot;&lt;/code&gt;.&lt;br&gt;
So we configure for the default group:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;,

        &quot;topic.creation.default.replication.factor&quot;: 3,
        &quot;topic.creation.default.partitions&quot;: 10,
        &quot;topic.creation.default.cleanup.policy&quot;: &quot;compact&quot;,
        &quot;topic.creation.default.compression.type&quot;: &quot;lz4&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;productlog-config&quot;&gt;Productlog Config&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the databases &lt;code&gt;inventory&lt;/code&gt; schema there are tables starting with &lt;code&gt;product&lt;/code&gt; as table name.&lt;br&gt;
As default the fully qualified table names are captured to the topic with the same name with Debezium,
for example the table &lt;code&gt;products&lt;/code&gt; in the &lt;code&gt;inventory&lt;/code&gt; schema of &lt;code&gt;dbserver1&lt;/code&gt; is captured to the
topic &lt;code&gt;dbserver1.inventory.products&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We want that all messages that go to a topic for table names starting with &lt;code&gt;product&lt;/code&gt; are stored
in a topic with a retention time of 3 months / 90 days with &lt;code&gt;cleanup.policy&quot;: &quot;delete&quot;&lt;/code&gt; and
&lt;code&gt;retention.ms = 7776000000&lt;/code&gt;, &lt;code&gt;replication.factor = 1&lt;/code&gt;, &lt;code&gt;partitions = 20&lt;/code&gt;, and just use the
compression format that&amp;#8217;s used by the producer &lt;code&gt;compression.type&quot;: &quot;producer&quot;&lt;/code&gt;.&lt;br&gt;
You can leave out properties that match the cluster defaults, but be careful once you
change the default config on your Kafka brokers the resulting topic config might differ!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First we need to register a &lt;code&gt;productlog&lt;/code&gt; group using the &lt;code&gt;topic.creation.groups&lt;/code&gt; property.&lt;br&gt;
Then we can define what topic names should be included in that group and specify the configuration
of our group like we did with the &lt;code&gt;default&lt;/code&gt; group:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;,
        &quot;topic.creation.default.replication.factor&quot;: 3,
        &quot;topic.creation.default.partitions&quot;: 10,
        &quot;topic.creation.default.cleanup.policy&quot;: &quot;compact&quot;,
        &quot;topic.creation.default.compression.type&quot;: &quot;lz4&quot;,

        &quot;topic.creation.groups&quot;: &quot;productlog&quot;,  //&lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;

        &quot;topic.creation.productlog.include&quot;: &quot;dbserver1\\.inventory\\.product.*&quot;,  //&lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
        &quot;topic.creation.productlog.replication.factor&quot;: 1,
        &quot;topic.creation.productlog.partitions&quot;: 20,
        &quot;topic.creation.productlog.cleanup.policy&quot;: &quot;delete&quot;,
        &quot;topic.creation.productlog.retention.ms&quot;: 7776000000,
        &quot;topic.creation.productlog.compression.type&quot;: &quot;producer&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt;
&lt;caption class=&quot;title&quot;&gt;Table 1. Connector Configuration for customized automatic topic creation&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 10%;&quot;&gt;
&lt;col style=&quot;width: 90%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Item&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;topic.creation.groups&lt;/code&gt; defines a comma-separated list of additional group names. Here we only
define our &lt;code&gt;productlog&lt;/code&gt; group.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;2&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;The &lt;code&gt;topic.creation.productlog.include&lt;/code&gt; field holds a comma-separated list of regular expressions
that match the topic names where the &lt;code&gt;productlog&lt;/code&gt; group config should be applied. The &lt;code&gt;productlog&lt;/code&gt;
group matches all topics starting with &lt;code&gt;dbserver1.inventory.product&lt;/code&gt;.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;exploring-the-results&quot;&gt;Exploring the Results&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When we now start our connector and use &lt;code&gt;kafka-topics.sh&lt;/code&gt; to see how the topics were created, we can
see that all worked as defined:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;## the `dbserver1.inventory.products` topic has the config from the `productlog` group:
$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --describe --topic dbserver1.inventory.products

Topic: dbserver1.inventory.products     PartitionCount: 20      ReplicationFactor: 1
Configs: compression.type=producer,cleanup.policy=delete,retention.ms=7776000000,segment.bytes=1073741824

## the `dbserver1.inventory.orders` topic has the config from the `default` group:
$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --describe --topic dbserver1.inventory.orders

Topic: dbserver1.inventory.orders       PartitionCount: 10       ReplicationFactor: 3
Configs: compression.type=lz4,cleanup.policy=compact,segment.bytes=1073741824,delete.retention.ms=2592000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In many, especially in production environments we often don&amp;#8217;t want topic auto creation to be enabled
on the Kafka broker side, or we need a different configuration than the default topic config.&lt;br&gt;
Prior Kafka 2.6 this was only possible when manually creating topics upfront or by some custom setup
process, maybe during deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since Kafka 2.6 Kafka Connect comes with built-in topic creation for connector topics and this article
shows how to use it with Debezium.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can find an example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/topic-auto-create&quot;&gt;here&lt;/a&gt;
in the Debezium examples repository on GitHub.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>René Kerner</name></author><category term="kafka" /><category term="topics" /><category term="production" /><category term="news" /><category term="discussion" /><summary type="html">When you are working with Kafka Connect Distributed then you might have realized that once you start Kafka Connect there are already some internal Kafka Connect related topics created for you: $ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --list connect_configs connect_offsets connect_statuses This is done automatically for you by Kafka Connect with a sane, customized default topic configuration that fits the needs of these internal topics. When you start a Debezium connector the topics for the captured events are created by the Kafka broker based on a default, maybe customized, configuration in the broker if auto.create.topics.enable = true is enabled in the broker config: auto.create.topics.enable = true default.replication.factor = 1 num.partitions = 1 compression.type = producer log.cleanup.policy = delete log.retention.ms = 604800000 ## 7 days But often, when you use Debezium and Kafka in a production environment you might choose to disable Kafka&amp;#8217;s topic auto creation capability with auto.create.topics.enable = false, or you want the connector topics to be configured differently from the default. In this case you have to create topics for Debezium&amp;#8217;s captured data sources upfront. But there&amp;#8217;s good news! Beginning with Kafka Connect version 2.6.0, this can be automated since KIP-158 is implemented to enable customizable topic creation with Kafka Connect.</summary></entry><entry><title type="html">Debezium 1.3.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Beta1 Released" /><published>2020-09-03T16:19:59+00:00</published><updated>2020-09-03T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.3.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release upgrades to the recently released Apache Kafka version 2.6.0, fixes several critical bugs and comes with a renaming of the connector configuration options for selecting the tables to be captured.
We&amp;#8217;ve also released Debezium 1.2.2.Final, which is a drop-in replacement for all users of earlier 1.2.x releases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;revised-filter-options-and-documentation-wording&quot;&gt;Revised Filter Options and Documentation Wording&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since the beginning of the Debezium project, there was support for specifying the tables and columns to capture.
This is done via a range of configuration options like &lt;code&gt;schema.whitelist&lt;/code&gt;, &lt;code&gt;column.blacklist&lt;/code&gt;, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While nothing was wrong with those options from a technical perspective,
we&amp;#8217;ve come to realize that the terms &quot;whitelist&quot; and &quot;blacklist&quot; are problematic and that they may even be hurtful to some members of our community.
This is why we&amp;#8217;ve decided to deprecate the existing option names and replace them with counterparts which are not only more inclusive, but also more expressive when it comes to describing their purpose.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The following changes have been made:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Old Name&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;New Name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The renaming has been done for all the stable Debezium connectors as of this release;
the options of the incubator connectors (Oracle, Db2, Cassandra) will be renamed in the next Debezium 1.3.x preview release.
Note that for the sake of backwards-compatibility, the old option names still can be used during a transition period.
In this case, e.g. when upgrading an existing connector instance to the new version,
a warning will be logged upon connector start-up, and you should update your configuration accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides renaming these filter options, we&amp;#8217;ve also updated our documentation;
in particular the description of supported database topologies has been updated from the previously used terms &quot;master&quot; and &quot;slave&quot; to &quot;primary&quot; (node) and &quot;replica&quot; (node).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This change is part of a larger effort &lt;a href=&quot;https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language&quot;&gt;across Red Hat&lt;/a&gt; and the industry as a whole,
and we&amp;#8217;re very happy that we can contribute our share for making the world of open-source projects and its communities more welcoming and inclusive.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bug-fixes&quot;&gt;Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release fixes a number of critical bugs:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Potentially lost change events with the Postgres connector, in case of connector restarts (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2338&quot;&gt;DBZ-2338&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2397&quot;&gt;DBZ-2397&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NullPointerException in the logical table router (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2412&quot;&gt;DBZ-2412&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Snapshot fails if table or schema contain hyphens (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2452&quot;&gt;DBZ-2452&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Misc. MySQL DDL parser fixes (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2413&quot;&gt;DBZ-2413&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2415&quot;&gt;DBZ-2415&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2425&quot;&gt;DBZ-2425&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%2012317320%20AND%20fixVersion%20%3D%2012346874%20ORDER%20BY%20priority%20DESC%2C%20key%20ASC&quot;&gt;20 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-beta1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to community members &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt; and &lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt; for their contributions to this release!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As you&amp;#8217;d expect it, things went a bit slower during the summer with several folks taking some well-deserved time off.
Now that everyone is back, Debezium development moves forward with full steam again,
and you can expect some exciting new features coming soon:
the &lt;a href=&quot;https://github.com/debezium/debezium-incubator/pull/185&quot;&gt;ongoing work&lt;/a&gt; by the community towards a LogMiner-based implementation for Oracle should soon reach a state where it can be merged into the upstream Debezium repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And a brand-new connector contributed by the community is showing up on the horizon, too;
&lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt; engineers &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt; and &lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt; have been working on a &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;CDC connector for the Vitess database&lt;/a&gt; and announced that they&amp;#8217;d like to open-source and continue to evolve it under the Debezium umbrella.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Exciting times for open-source change data capture and Debezium 🎉!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.3.0.Beta1! This release upgrades to the recently released Apache Kafka version 2.6.0, fixes several critical bugs and comes with a renaming of the connector configuration options for selecting the tables to be captured. We&amp;#8217;ve also released Debezium 1.2.2.Final, which is a drop-in replacement for all users of earlier 1.2.x releases.</summary></entry><entry><title type="html">Debezium 1.3.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Alpha1 Released" /><published>2020-08-06T16:19:59+00:00</published><updated>2020-08-06T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This initial pass in the 1.3 release line provides a number of useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A new Debezium Server sink adapter for Azure Event Hubs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new SQL Server connector snapshot mode, &lt;code&gt;initial_only&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional connection timeout options for the MongoDB Connector&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;31 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of them in the remainder of this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;azure-event-hubs-sink-adapter&quot;&gt;Azure Event Hubs sink adapter&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium&amp;#8217;s &lt;a href=&quot;/documentation/reference/1.3/operations/debezium-server.html&quot;&gt;standalone server&lt;/a&gt; is one of the newest features in the Debezium ecosystem.
The standalone server provides a ready-to-use application that can stream change events from a source database to a variety of messaging infrastructures.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Driven by the community, the Debezium Server now supports Azure Event Hubs (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2282&quot;&gt;DBZ-2282&lt;/a&gt;).
This now enables the Debezium Server to stream change events to Amazon Kinesis, Apache Pulsar, Google Cloud Pub/Sub, and Azure Event Hubs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;additional-mongodb-connection-options&quot;&gt;Additional MongoDB connection options&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium MongoDB connector has traditionally used the driver default connection options and timeouts.
There are use cases where customization of these defaults are necessary to support latency or performance concerns in your deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There additional configuration options are now available for MongoDB:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.connect.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver waits for a new conneciton before the attempt is aborted.&lt;br&gt;
Defaults to &lt;code&gt;10000&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.server.selection.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver will wait to select a server before it times out, throwing an error.&lt;br&gt;
Defaults to &lt;code&gt;30000&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.socket.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver waits before a send/receive on the socket may timeout.&lt;br&gt;
A value of &lt;code&gt;0&lt;/code&gt; disables this behavior.
Defaults to &lt;code&gt;0&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a number of other new features coming with the 1.3.0.Alpha1 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New SQL Server snapshot mode &lt;code&gt;initial_only&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2379&quot;&gt;DBZ-2379&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Postgres and possibly other DB connections are not properly shutdown when the task encounters thread interrupt (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2133&quot;&gt;DBZ-2133&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ignore non-existing table reported on Aurora via SHOW TABLES (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1939&quot;&gt;DBZ-1939&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra connector not getting events (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2086&quot;&gt;DBZ-2086&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PubSub Sink sends empty records (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2277&quot;&gt;DBZ-2277&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skipping LSN is inefficient and does not forward slot position (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2310&quot;&gt;DBZ-2310&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;message size is at least 68x larger for changes with bit varying columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2315&quot;&gt;DBZ-2315&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change events lost when connnector is restarted while processing transaction with PK update (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2329&quot;&gt;DBZ-2329&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Error when processing commitLogs related to list-type columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2345&quot;&gt;DBZ-2345&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix dependency groupId on Outbox Quarkus Extension documentation (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2367&quot;&gt;DBZ-2367&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cannot detect Azure Sql Version (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2373&quot;&gt;DBZ-2373&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ParallelSnapshotReader sometimes throws NPE  (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2387&quot;&gt;DBZ-2387&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-alpha1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/abhirockzz&quot;&gt;Abhishek Gupta&lt;/a&gt;,
&lt;a href=&quot;https://github.com/coryharperbind&quot;&gt;Cory Harper&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mtagle&quot;&gt;Moira Tagle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Victor Xiang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bjoernhaeuser&quot;&gt;Björn Häuser&lt;/a&gt;,
&lt;a href=&quot;https://github.com/korzenek&quot;&gt;Lukasz Korzeniowski&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/jonaslins&quot;&gt;Jonas Lins&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.0.Alpha1! This initial pass in the 1.3 release line provides a number of useful new features: A new Debezium Server sink adapter for Azure Event Hubs A new SQL Server connector snapshot mode, initial_only Additional connection timeout options for the MongoDB Connector Overall, the community fixed not less than 31 issues for this release. Let&amp;#8217;s take a closer look at some of them in the remainder of this post.</summary></entry><entry><title type="html">Hello Debezium Team!</title><link href="https://debezium.io/blog/2020/07/28/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium Team!" /><published>2020-07-28T16:19:59+00:00</published><updated>2020-07-28T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/07/28/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/07/28/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello everyone, my name is René Kerner and I recently joined Red Hat and the Debezium team.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I was working at trivago since 2011, and in 2016 we started using Debezium at version 0.4/0.5 for
capturing clickstreams in the offshore datacenters into Kafka and aggregate them in the central cluster.
We really intensified Debezium usage within one year and in 2017 we also used it for trivago&amp;#8217;s main data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In 2014 I did my first OSS contributions to Composer, PHP&amp;#8217;s dependency management and gave my first talk
on it at the Developer Conference (called code.talks for many years now).
Then in 2017 I did my first contributions to Debezium with work on the MySQL snapshot process
and fixing a MySQL TIME data type issue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In 2018 I left trivago and started working at Codecentric as a consultant for software architecture and
development (mainly JVM focus) and Apache Kafka, doing many trainings and workshops at German &quot;Fortune 500&quot;
companies (insurances, industrial sector, media). I was doing lots of networking at that time, where I
learned how awesome the community around Kafka is. I was always quite sad I didn&amp;#8217;t have more time
to focus on OSS projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let me share a bit more of trivago&amp;#8217;s story to Kafka and Debezium. Back in 2015/2016 we introduced Kafka
(version 0.9, 0.10 times) at trivago to handle the transport of our clickstream data from offshore
datacenters (US + Asia) into our central datacenter (EU).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first solution that we tried did its job, but getting messages in our desired
format, which was Google Protocol Buffers / Protobuf, into Kafka was relatively
hard. Furthermore the codebase of that tool wasn&amp;#8217;t very clean and extensions were
ugly and kind of hard.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With Kafka 0.9.0.0 Kafka Connect was introduced and stabilized over the next months. And in
winter 2016/2017 we discovered Debezium. A tool that was based on Kafka Connect, with a
much cleaner codebase and an easy, extendible way to apply our requirements regarding
Protobuf format and behaviour (with SMTs/Single Message Transforms, released in Kafka 0.10.2)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since these &quot;old times&quot; Debezium made very big development with many new connectors and
since July I&amp;#8217;m now part of the Debezium team, and I am proud and excited to work on such a great
OSS project because there are still awesome things on &lt;a href=&quot;https://debezium.io/roadmap/&quot;&gt;Debezium&amp;#8217;s Roadmap&lt;/a&gt;:
the new IBM Db2 connector will leave incubation state, Debezium Server will be easier to
operate on Kubernetes, and a PoC for a future Debezium management UI, and more and more to come.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Furthermore, I&amp;#8217;ve been dedicating my work to many things around OSS, Kafka and Debezium for years,
I always advocated people to use OSS, Kafka and Debezium, and supported them in different jobs and
roles to introduce it or extend its usage. That&amp;#8217;s why I&amp;#8217;m really excited that I am able to focus
my work to support Debezium and the Debezium community now!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;--René&lt;/p&gt;
&lt;/div&gt;</content><author><name>René Kerner</name></author><category term="community" /><category term="news" /><summary type="html">Hello everyone, my name is René Kerner and I recently joined Red Hat and the Debezium team. I was working at trivago since 2011, and in 2016 we started using Debezium at version 0.4/0.5 for capturing clickstreams in the offshore datacenters into Kafka and aggregate them in the central cluster. We really intensified Debezium usage within one year and in 2017 we also used it for trivago&amp;#8217;s main data. In 2014 I did my first OSS contributions to Composer, PHP&amp;#8217;s dependency management and gave my first talk on it at the Developer Conference (called code.talks for many years now). Then in 2017 I did my first contributions to Debezium with work on the MySQL snapshot process and fixing a MySQL TIME data type issue. In 2018 I left trivago and started working at Codecentric as a consultant for software architecture and development (mainly JVM focus) and Apache Kafka, doing many trainings and workshops at German &quot;Fortune 500&quot; companies (insurances, industrial sector, media). I was doing lots of networking at that time, where I learned how awesome the community around Kafka is. I was always quite sad I didn&amp;#8217;t have more time to focus on OSS projects.</summary></entry><entry><title type="html">Debezium 1.2.1.Final Released</title><link href="https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.2.1.Final Released" /><published>2020-07-16T16:19:59+00:00</published><updated>2020-07-16T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am happy to announce the release of Debezium &lt;strong&gt;1.2.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release includes several bug fixes to different Debezium connectors, and we highly recommend the upgrade from 1.2.0.Final and earlier versions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Debezium Postgres connector may have missed events from concurrent transactions when transitioning from snapshotting to streaming events from the WAL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2288&quot;&gt;DBZ-2288&lt;/a&gt;);
this is fixed now when using the &lt;a href=&quot;/documentation/reference/connectors/postgresql.html#postgresql-property-snapshot-mode&quot;&gt;exported snapshotting mode&lt;/a&gt;;
this mode should preferably be used, and for Debezium 1.3 we&amp;#8217;re planning for this to be the basis for all the existing snapshotting modes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Postgres JDBC driver got upgraded to 42.2.14 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2317&quot;&gt;DBZ-2317&lt;/a&gt;),
which fixes a CVE in the driver related to processing XML column values sourced from untrusted XML input&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium MySQL connector MariaDB&amp;#8217;s supports &lt;code&gt;ALTER TABLE&lt;/code&gt; statements with &lt;code&gt;IF EXISTS&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2219&quot;&gt;DBZ-2219&lt;/a&gt;);
it also handles single dimension &lt;code&gt;DECIMAL&lt;/code&gt; columns in &lt;code&gt;CAST&lt;/code&gt; expressions (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2305&quot;&gt;DBZ-2305&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The MySQL connector automatically filters out specific DML binlog entries from internal tables when using it with Amazon RDS (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2275&quot;&gt;DBZ-2275&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium MongoDB connector got more resilient against connection losses (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2141&quot;&gt;DBZ-2141&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;re using the &lt;a href=&quot;https://www.apicur.io/registry/&quot;&gt;Apicurio&lt;/a&gt; open-source API and schema registry for &lt;a href=&quot;/documentation/reference/configuration/avro.html&quot;&gt;managing the JSON and Avro schemas&lt;/a&gt; of your Debezium connectors,
then things got a bit simpler for you:
the Debezium container image for Kafka Connect comes with the required converters out of the box now
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2083&quot;&gt;DBZ-2083&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, 34 issues were fixed for this release; please refer to the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.1-final&quot;&gt;release notes&lt;/a&gt; for the full list of addressed issues, upgrade procedures, and notes on any backward compatibility changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the members from the Debezium community contributing to this release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/frankkoornstra&quot;&gt;Frank Koornstra&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgraf50&quot;&gt;John Graf&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/omarsmak&quot;&gt;Omar Al-Safi&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/rhauch&quot;&gt;Randall Hauch&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="testcontainers" /><category term="debezium-server" /><summary type="html">I am happy to announce the release of Debezium 1.2.1.Final! This release includes several bug fixes to different Debezium connectors, and we highly recommend the upgrade from 1.2.0.Final and earlier versions: The Debezium Postgres connector may have missed events from concurrent transactions when transitioning from snapshotting to streaming events from the WAL (DBZ-2288); this is fixed now when using the exported snapshotting mode; this mode should preferably be used, and for Debezium 1.3 we&amp;#8217;re planning for this to be the basis for all the existing snapshotting modes The Postgres JDBC driver got upgraded to 42.2.14 (DBZ-2317), which fixes a CVE in the driver related to processing XML column values sourced from untrusted XML input The Debezium MySQL connector MariaDB&amp;#8217;s supports ALTER TABLE statements with IF EXISTS (DBZ-2219); it also handles single dimension DECIMAL columns in CAST expressions (DBZ-2305) The MySQL connector automatically filters out specific DML binlog entries from internal tables when using it with Amazon RDS (DBZ-2275) The Debezium MongoDB connector got more resilient against connection losses (DBZ-2141)</summary></entry><entry><title type="html">Debezium 1.2.0.Final Released</title><link href="https://debezium.io/blog/2020/06/24/debezium-1-2-final-released/" rel="alternate" type="text/html" title="Debezium 1.2.0.Final Released" /><published>2020-06-24T16:19:59+00:00</published><updated>2020-06-24T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/06/24/debezium-1-2-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/06/24/debezium-1-2-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.2.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Over the last three months, the community has resolved nearly &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.2.0.Alpha1%2C%201.2.0.Beta1%2C%201.2.0.Beta2%2C%201.2.0.CR1%2C%201.2.0.CR2%2C%201.2.0.Final)&quot;&gt;200 issues&lt;/a&gt;. Key features of this release include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New Kafka Connect single message transforms (SMTs) for content-based event &lt;a href=&quot;/documentation/reference/1.2/configuration/content-based-routing.html&quot;&gt;routing&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/1.2/configuration/filtering.html&quot;&gt;filtering&lt;/a&gt;;
Upgrade to Apache Kafka 2.5&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Schema change topics for the Debezium connectors for &lt;a href=&quot;/documentation/reference/1.2/connectors/sqlserver.html&quot;&gt;SQL Server&lt;/a&gt;, &lt;a href=&quot;/documentation/reference/1.2/connectors/db2.html&quot;&gt;Db2&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/1.2/connectors/oracle.html&quot;&gt;Oracle&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for SMTs and message converters in the Debezium &lt;a href=&quot;/documentation/reference/1.2/development/engine.html&quot;&gt;embedded engine&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;/documentation/reference/1.2/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;, a brand-new runtime which allows to propagate data change events to a range of messaging infrastructures like Amazon Kinesis, Google Cloud Pub/Sub, and Apache Pulsar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new column masking mode &quot;consistent hashing&quot;, allowing to anonymize column values while still keeping them correlatable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New metrics for the MongoDB connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved re-connect capability for the SQL Server connector&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;debezium-server&quot;&gt;Debezium Server&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Should I pick one feature I&amp;#8217;m the most excited about, it would be Debezium Server.
It allows even more users to benefit from open-source change data capture with Debezium,
no matter which messaging infrastructure they are on.
Being able to propagate Debezium data change events via managed services such as Kinesis and Pub/Sub was a feature request we&amp;#8217;ve received again and again from the community,
and it&amp;#8217;s amazing to see that this feature eventually becomes a reality.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium Server will also be a great foundation for exposing Debezium as a native &lt;a href=&quot;https://knative.dev/docs/eventing/&quot;&gt;Knative Eventing&lt;/a&gt; event source, and you can expect to see more exciting developments in this area very soon.
With Debezium Server, there&amp;#8217;s now &lt;a href=&quot;/documentation/reference/1.2/architecture.html&quot;&gt;three ways&lt;/a&gt; for running Debezium:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Via &lt;em&gt;Kafka Connect&lt;/em&gt;, using its fantastic eco-system of connectors to set up low-latency data streaming pipelines with Apache Kafka&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;Debezium Server&lt;/em&gt;, sending data change events to a growing number of messaging platforms like Kinesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Through the &lt;em&gt;Debezium Engine&lt;/em&gt;, embedded as a library into custom JVM-based applications, e.g. addressing use cases like updating embedded caches&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m really excited about all the opportunties which this brings to the Debezium community.
Debezium Server is powered by the innovative &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt; framework, which also opens up many interesting technical possibilities.
E.g. we could explore running Debezium connectors as native binaries via &lt;a href=&quot;https://www.graalvm.org/&quot;&gt;GraalVM&lt;/a&gt;,
resulting in a largely reduced memory consumption, which could make this a very interesting deployment option for cloud environments.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;a-big-thank-you-to-the-community&quot;&gt;A Big Thank You to the Community!&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the original announcements (&lt;a href=&quot;/blog/2020/04/16/debezium-1-2-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/05/07/debezium-1-2-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/05/19/debezium-1-2-beta2-released/&quot;&gt;Beta2&lt;/a&gt;, &lt;a href=&quot;/blog/2020/06/11/debezium-1-2-cr1-released/&quot;&gt;CR1&lt;/a&gt;) to learn more about all the new features of Debezium 1.2.
You can find the complete list of addressed issues, upgrade procedures, and notes on any backward compatibility changes in the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.0-final&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;An open-source project would be nothing without its community of users in contributors;
thanks a lot to the following people from the community who worked on the Debezium 1.2 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/andersenleo&quot;&gt;Anders Engström&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ant0nk&quot;&gt;Anton Kondratev&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ateijelo&quot;&gt;Andy Teijelo Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/nbali&quot;&gt;Balázs Németh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bradengroom&quot;&gt;Braden Groom&lt;/a&gt;,
&lt;a href=&quot;https://github.com/brbrown25&quot;&gt;Brandon Brown&lt;/a&gt;,
&lt;a href=&quot;https://github.com/cobolbaby&quot;&gt;cobolbaby&lt;/a&gt;,
&lt;a href=&quot;https://github.com/dajerome&quot;&gt;David Jerome&lt;/a&gt;,
&lt;a href=&quot;https://github.com/dcumberland&quot;&gt;Dave Cumberland&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ebrard&quot;&gt;Emmanuel Brard&lt;/a&gt;,
&lt;a href=&quot;https://github.com/edbighead&quot;&gt;Ed Laur&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mozinator&quot;&gt;Fabian Aussems&lt;/a&gt;,
&lt;a href=&quot;https://github.com/fgakk&quot;&gt;Fatih Güçlü Akkaya&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gergof&quot;&gt;Fándly Gergő&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ivan-klass&quot;&gt;Ivan Klass&lt;/a&gt;,
&lt;a href=&quot;https://github.com/renardeinside&quot;&gt;Ivan Trusov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/JanHendrikDolling&quot;&gt;Jan-Hendrik Dolling&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jfinzel&quot;&gt;Jeremy Finzel&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgao54&quot;&gt;Joy Gao&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jantpedraza&quot;&gt;Juan Antonio Pedraza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jpsoroulas&quot;&gt;John Psoroulas&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hoanglinh0710&quot;&gt;Linh Nguyen Hoang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/lga-zurich&quot;&gt;Luis Garcés-Erice&lt;/a&gt;,
&lt;a href=&quot;https://github.com/metlos&quot;&gt;Lukas Krejci&lt;/a&gt;,
&lt;a href=&quot;https://github.com/lyidataminr&quot;&gt;lyidataminr&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kaplanmaxe&quot;&gt;Max Kaplan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/devzer01&quot;&gt;Nayana Hettiarachchi&lt;/a&gt;,
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;,
&lt;a href=&quot;https://github.com/RobertHana&quot;&gt;Robert B. Hanviriyapunt&lt;/a&gt;,
&lt;a href=&quot;https://github.com/TechnocratSid&quot;&gt;Siddhant Agnihotry&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/crazy-2020&quot;&gt;Xuan Shen&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This brings the total number of contributors to the main Debezium code repositories to over 200!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s close this post with an outlook to the next things to come.
We&amp;#8217;ll stick to our quarterly release cadence, i.e. you can expect Debezium 1.3 to be out by the end of September,
with preview releases in between every three weeks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;re currently updating the &lt;a href=&quot;/roadmap&quot;&gt;roadmap&lt;/a&gt; for the next release,
and your input and feedback on this will be very welcomed!
The things we&amp;#8217;ve planned so far include more flexible options for snapshotting (re-snapshotting specific tables, filter changes, parallelized snapshotting, etc.),
moving Db2 connector out of incubating state, and an exploration of what it&amp;#8217;d take to officially support MariaDB.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Onwards and upwards!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="debezium-server" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.2.0.Final! Over the last three months, the community has resolved nearly 200 issues. Key features of this release include: New Kafka Connect single message transforms (SMTs) for content-based event routing and filtering; Upgrade to Apache Kafka 2.5 Schema change topics for the Debezium connectors for SQL Server, Db2 and Oracle Support for SMTs and message converters in the Debezium embedded engine Debezium Server, a brand-new runtime which allows to propagate data change events to a range of messaging infrastructures like Amazon Kinesis, Google Cloud Pub/Sub, and Apache Pulsar A new column masking mode &quot;consistent hashing&quot;, allowing to anonymize column values while still keeping them correlatable New metrics for the MongoDB connector Improved re-connect capability for the SQL Server connector</summary></entry><entry><title type="html">Debezium 1.2.0.CR1 Released</title><link href="https://debezium.io/blog/2020/06/11/debezium-1-2-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.2.0.CR1 Released" /><published>2020-06-11T16:19:59+00:00</published><updated>2020-06-11T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/06/11/debezium-1-2-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/06/11/debezium-1-2-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.2.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release includes several notable features, enhancements, and fixes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PostgreSQL can restrict the set of tables with a publication while using pgoutput (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1813&quot;&gt;DBZ-1813&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Metrics MBean registration is skipped if a platform MBean server does not exist (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2089&quot;&gt;DBZ-2089&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQL Server reconnection improved during shutdown and connection resets (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2106&quot;&gt;DBZ-2106&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EventRouter SMT can now pass non-String based keys (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2152&quot;&gt;DBZ-2152&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PostgreSQL &lt;code&gt;include.unknown.datatypes&lt;/code&gt; can now return strings rather than hashes (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1266&quot;&gt;DBZ-1266&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Server now supports Google Cloud PubSub (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2092&quot;&gt;DBZ-2092&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Server now supports Apache Pulsar sink (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2112&quot;&gt;DBZ-2112&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can find the complete list of addressed issues, upgrade procedures, and notes on any backward compatibility changes in the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.0-cr&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/ateijelo&quot;&gt;Andy Teijelo Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/nbali&quot;&gt;Balázs Németh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/brbrown25&quot;&gt;Brandon Brown&lt;/a&gt;,
&lt;a href=&quot;https://github.com/cobolbaby&quot;&gt;cobolbaby&lt;/a&gt;,
&lt;a href=&quot;https://github.com/dcumberland&quot;&gt;Dave Cumberland&lt;/a&gt;,
&lt;a href=&quot;https://github.com/edbighead&quot;&gt;Ed Laur&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ebrard&quot;&gt;Emmanuel Brard&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mozinator&quot;&gt;Fabian Aussems&lt;/a&gt;,
&lt;a href=&quot;https://github.com/renardeinside&quot;&gt;Ivan Trusov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jfinzel&quot;&gt;Jeremy Finzel&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/metlos&quot;&gt;Lukas Krejci&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/RobertHana&quot;&gt;Robert B. Hanviriyapunt&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="testcontainers" /><category term="ebezium-server" /><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.2.0.CR1! This release includes several notable features, enhancements, and fixes: PostgreSQL can restrict the set of tables with a publication while using pgoutput (DBZ-1813). Metrics MBean registration is skipped if a platform MBean server does not exist (DBZ-2089). SQL Server reconnection improved during shutdown and connection resets (DBZ-2106). EventRouter SMT can now pass non-String based keys (DBZ-2152). PostgreSQL include.unknown.datatypes can now return strings rather than hashes (DBZ-1266). Debezium Server now supports Google Cloud PubSub (DBZ-2092). Debezium Server now supports Apache Pulsar sink (DBZ-2112). You can find the complete list of addressed issues, upgrade procedures, and notes on any backward compatibility changes in the release notes. Many thanks to all the community members contributing to this release: Andy Teijelo Pérez, Balázs Németh, Bingqin Zhou, Brandon Brown, cobolbaby, Dave Cumberland, Ed Laur, Emmanuel Brard, Fabian Aussems, Ivan Trusov, Justin Hiza, Jeremy Finzel, Kewei Shang, Lukas Krejci, and Robert B. Hanviriyapunt.</summary></entry><entry><title type="html">Debezium 1.2.0.Beta2 Released</title><link href="https://debezium.io/blog/2020/05/19/debezium-1-2-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.2.0.Beta2 Released" /><published>2020-05-19T16:19:59+00:00</published><updated>2020-05-19T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/05/19/debezium-1-2-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/05/19/debezium-1-2-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to share the news that Debezium &lt;strong&gt;1.2.0.Beta2&lt;/strong&gt; has been released!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Core feature of this release is &lt;em&gt;Debezium Server&lt;/em&gt;,
a dedicated stand-alone runtime for Debezium, opening up its open-source change data capture capabilities towards messaging infrastructure like Amazon Kinesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.2.0.Beta2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;25 issues&lt;/a&gt; since the Beta1 release,
some of which we&amp;#8217;re going to explore in more depth in the remainder of this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;debezium-server&quot;&gt;Debezium Server&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Adding the &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; runtime is a major milestone for the project.
It is a ready-to-use standalone application for executing Debezium connectors.
With Debezium Server, users can now choose from three different ways of operating Debezium,
matching their individual needs:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;As plug-ins for &lt;a href=&quot;https://kafka.apache.org/documentation/#connect&quot;&gt;Kafka Connect&lt;/a&gt;, ingesting data change events into an Apache Kafka cluster&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Through the &lt;a href=&quot;/documentation/reference/development/engine.html&quot;&gt;Debezium Engine&lt;/a&gt;, embedded as a library into bespoke JVM-based applications&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Via Debezium Server, sending data change events to a growing number of messaging platforms like Kinesis&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Which one of these modes of execution you should use depends on your specific prerequisites, requirements and CDC use cases.
Organizations running Apache Kafka and interested in setting up no-code data integration pipelines leveraging a rich connector eco-system, should go for the Kafka Connect approach.
In-application cache invalidation is an application benefitting from the Debezium embedded engine.
Debezium Server finally is meant for users who would like to take advantage of Debezium&amp;#8217;s CDC functionality,
using messaging platforms other than Apache Kafka.
While you could have done so before by means of the embedded engine and a bit of bespoke Java programming,
Debezium Server will greatly simplify this scenario.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Powered by the popular &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt; stack,
Debezium Server is a ready-made configurable Java application which runs a Debezium connector and propagates the produced change events to consumers via a chosen sink adapter.
Initially supporting Amazon Kinesis, the Debezium Server architecture is extensible,
and other adapters&amp;#8201;&amp;#8212;&amp;#8201;e.g. for Google Cloud Pub/Sub or Microsoft Azure Event Hubs&amp;#8201;&amp;#8212;&amp;#8201;will follow soon.
Through the Debezium Server extension API, you can also implement custom sink adapters for your preferred infrastructure of propagating change events to consumers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ultimately, Debezium Server also is means of realizing our vision of CDC-as-a-Service,
smoothly integrated with cloud-native infrastructure like Kubernetes and Knative.
This release marks the first step of this endavour, and we couldn&amp;#8217;t be more excited about the prospect of working together with the Debezium community towards this goal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Stay tuned for more sink adapters, a container image, support for &lt;a href=&quot;https://knative.dev/docs/eventing/&quot;&gt;Knative Eventing&lt;/a&gt;, an operator for running Debezium Server on Kubernetes, and more!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features-and-fixes&quot;&gt;Other Features and Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides Debezium Server, a few other improvements and fixes found their way into this release.
A number of improvements was done to the different single message transforms (SMTs) coming with Debezium:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The recently added SMTs for content-based change &lt;a href=&quot;/documentation/reference/configuration/filtering.html&quot;&gt;event filtering&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/configuration/content-based-routing.html&quot;&gt;routing&lt;/a&gt; can be applied to a sub-set of topics now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2024&quot;&gt;DBZ-2024&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Record headers and topic name are exposed to script expressions configured for these SMTs, so they can be evaluated by the filtering and routing logic (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2074&quot;&gt;DBZ-2074&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&quot;/documentation/reference/configuration/topic-routing.html&quot;&gt;logical topic routing&lt;/a&gt; SMT can optionally pass through message keys as-is, instead of enriching them with a source topic identifier (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2034&quot;&gt;DBZ-2034&lt;/a&gt;); this is very helpful when uniqueness of keys already is ensured across the different re-routed topics, e.g. when routing change events from the partition tables of a partitioned Postgres table into a single topic&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium&amp;#8217;s &lt;a href=&quot;/documentation/reference/integrations/testcontainers.html&quot;&gt;Testcontainers integration&lt;/a&gt; allows for the usage of custom container images for Kafka Connect now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2070&quot;&gt;DBZ-2070&lt;/a&gt;), which comes in handy if you want to leverage custom connectors, converters or SMTs in your integration tests.
For the SQL Server connector it&amp;#8217;s optionally possible now to skip the queries for obtaining LSN timestamps
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1988&quot;&gt;DBZ-1988&lt;/a&gt;).
This can help to signficantly increase through-put of the connector.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Several fixes relate to the MySQL DDL parser,
e.g. due to additional DDL capabilities in MySQL 8.0.x (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2080&quot;&gt;DBZ-2080&lt;/a&gt;, &quot;Unable to parse MySQL ALTER statement with named primary key&quot;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2067&quot;&gt;DBZ-2067&lt;/a&gt;; &quot;Error and connector stops when DDL contains algorithm=instant&quot;) and when being used with MariaDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2062&quot;&gt;DBZ-2062&lt;/a&gt;, &quot;DDL statement throws error if compression keyword contains backticks (``)&quot;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, you can find the complete list of all addressed issues and upgrading procedures in the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.0-beta2&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bradengroom&quot;&gt;Braden Groom&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gergof&quot;&gt;Fándly Gergő&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgao54&quot;&gt;Joy Gao&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jantpedraza&quot;&gt;Juan Antonio Pedraza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kaplanmaxe&quot;&gt;Max Kaplan&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/crazy-2020&quot;&gt;Xuan Shen&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="testcontainers" /><category term="debezium-server" /><summary type="html">I&amp;#8217;m very happy to share the news that Debezium 1.2.0.Beta2 has been released! Core feature of this release is Debezium Server, a dedicated stand-alone runtime for Debezium, opening up its open-source change data capture capabilities towards messaging infrastructure like Amazon Kinesis. Overall, the community has fixed 25 issues since the Beta1 release, some of which we&amp;#8217;re going to explore in more depth in the remainder of this post.</summary></entry><entry><title type="html">Debezium 1.2.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/05/07/debezium-1-2-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.2.0.Beta1 Released" /><published>2020-05-07T16:19:59+00:00</published><updated>2020-05-07T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/05/07/debezium-1-2-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/05/07/debezium-1-2-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With great happiness I&amp;#8217;m announcing the release of Debezium &lt;strong&gt;1.2.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release brings user-facing schema change topics for the SQL Server, Db2 and Oracle connectors,
a new message transformation for content-based change event routing,
support for a range of array column types in Postgres and much more.
We also upgraded the Debezium container images for Apache Kafka and Kafka Connect to version 2.5.0.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As it&amp;#8217;s the answer to all questions in life, the number of issues fixed for this release is &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.2.0.Beta1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;exactly 42&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;schema-change-topics&quot;&gt;Schema Change Topics&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Similarly to the MySQL connector, also the Debezium connectors for SQL Server, Db2 and Oracle optionally expose a public topic with schema change information now.
Unlike the connector-internal history topic, the schema change topics are meant for consumption by interested clients and for instance allow to seed the schema of downstream data stores.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Schema information is propagated in a typed structure,
sparing consumers from having to parse database specific DDL statements.
As an example, here&amp;#8217;s a schema event for the creation of the &lt;code&gt;customers&lt;/code&gt; table from the Debezium tutorial,
as produced by the SQL Server connector and using the JSON message converter:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{
  &quot;source&quot;: {
    &quot;version&quot;: &quot;1.2.0.Beta1&quot;,
    &quot;connector&quot;: &quot;sqlserver&quot;,
    &quot;name&quot;: &quot;server1&quot;,
    &quot;ts_ms&quot;: 1588252618953,
    &quot;snapshot&quot;: &quot;true&quot;,
    &quot;db&quot;: &quot;testDB&quot;,
    &quot;schema&quot;: &quot;dbo&quot;,
    &quot;table&quot;: &quot;customers&quot;,
    &quot;change_lsn&quot;: null,
    &quot;commit_lsn&quot;: &quot;00000025:00000d98:00a2&quot;,
    &quot;event_serial_no&quot;: null
  },
  &quot;databaseName&quot;: &quot;testDB&quot;,
  &quot;schemaName&quot;: &quot;dbo&quot;,
  &quot;ddl&quot;: null,
  &quot;tableChanges&quot;: [
    {
      &quot;type&quot;: &quot;CREATE&quot;,
      &quot;id&quot;: &quot;\&quot;testDB\&quot;.\&quot;dbo\&quot;.\&quot;customers\&quot;&quot;,
      &quot;table&quot;: {
        &quot;defaultCharsetName&quot;: null,
        &quot;primaryKeyColumnNames&quot;: [
          &quot;id&quot;
        ],
        &quot;columns&quot;: [
          {
            &quot;name&quot;: &quot;id&quot;,
            &quot;jdbcType&quot;: 4,
            &quot;nativeType&quot;: null,
            &quot;typeName&quot;: &quot;int identity&quot;,
            &quot;typeExpression&quot;: &quot;int identity&quot;,
            &quot;charsetName&quot;: null,
            &quot;length&quot;: 10,
            &quot;scale&quot;: 0,
            &quot;position&quot;: 1,
            &quot;optional&quot;: false,
            &quot;autoIncremented&quot;: false,
            &quot;generated&quot;: false
          },
          {
            &quot;name&quot;: &quot;first_name&quot;,
            &quot;jdbcType&quot;: 12,
            &quot;nativeType&quot;: null,
            &quot;typeName&quot;: &quot;varchar&quot;,
            &quot;typeExpression&quot;: &quot;varchar&quot;,
            &quot;charsetName&quot;: null,
            &quot;length&quot;: 255,
            &quot;scale&quot;: null,
            &quot;position&quot;: 2,
            &quot;optional&quot;: false,
            &quot;autoIncremented&quot;: false,
            &quot;generated&quot;: false
          },
          {
            &quot;name&quot;: &quot;last_name&quot;,
            &quot;jdbcType&quot;: 12,
            &quot;nativeType&quot;: null,
            &quot;typeName&quot;: &quot;varchar&quot;,
            &quot;typeExpression&quot;: &quot;varchar&quot;,
            &quot;charsetName&quot;: null,
            &quot;length&quot;: 255,
            &quot;scale&quot;: null,
            &quot;position&quot;: 3,
            &quot;optional&quot;: false,
            &quot;autoIncremented&quot;: false,
            &quot;generated&quot;: false
          },
          {
            &quot;name&quot;: &quot;email&quot;,
            &quot;jdbcType&quot;: 12,
            &quot;nativeType&quot;: null,
            &quot;typeName&quot;: &quot;varchar&quot;,
            &quot;typeExpression&quot;: &quot;varchar&quot;,
            &quot;charsetName&quot;: null,
            &quot;length&quot;: 255,
            &quot;scale&quot;: null,
            &quot;position&quot;: 4,
            &quot;optional&quot;: false,
            &quot;autoIncremented&quot;: false,
            &quot;generated&quot;: false
          }
        ]
      }
    }
  ]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To learn more about schema change topics, please refer to the connector-specific documentation,
e.g. for &lt;a href=&quot;/documentation/reference/connectors/sqlserver.html#_schema_change_topic&quot;&gt;SQL Server&lt;/a&gt;.
Note that this feature currently is in incubation state,
which means that e.g. details of the event format may change in future versions,
based on the feedback we receive from the community.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;content-based-topic-routing&quot;&gt;Content-Based Topic Routing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Using the new single message transformation (SMT) for &lt;a href=&quot;/documentation/reference/configuration/content-based-routing.html&quot;&gt;content-based topic routing&lt;/a&gt; you can control the topics specific change events get sent to based on their column values.
As an example consider a database table &lt;code&gt;purchase_orders&lt;/code&gt; which contains orders of two kinds, B2B and B2C.
Their change events should be sent to a distinct topic for each kind in Apache Kafka.
For that, simple script expressions in languages such as JavaScript or Groovy can be leveraged:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
transforms=route
transforms.route.type=io.debezium.transforms.Filter
transforms.route.language=jsr223.graal.js
transforms.route.topic.expression=value.after.ordertype == 'B2C' ? 'b2c_orders' : 'b2b_orders'
...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;further-changes-and-bugfixes&quot;&gt;Further Changes and Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Some other features and fixes of this release include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Support for Postgres &lt;code&gt;JSON&lt;/code&gt;, &lt;code&gt;JSONB&lt;/code&gt;, &lt;code&gt;TIME&lt;/code&gt; and &lt;code&gt;TIMESTAMP&lt;/code&gt; array columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1969&quot;&gt;DBZ-1969&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1990&quot;&gt;DBZ-1990&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Column whitelists for the Postgres connector, which comes in handy if you&amp;#8217;re interested in only capturing a small subset of table columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1962&quot;&gt;DBZ-1962&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL&amp;#8217;s &lt;code&gt;FLUSH TABLE&lt;/code&gt; statement is handled correctly (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2047&quot;&gt;DBZ-2047&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unique namespaces are used in routed outbox events (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1963&quot;&gt;DBZ-1963&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fixed a potential value overflow in Postgres &lt;code&gt;BIT VARYING&lt;/code&gt; columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1949&quot;&gt;DBZ-1949&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for the &lt;code&gt;eventType&lt;/code&gt; field has been removed from the outbox routing SMT (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2014&quot;&gt;DBZ-2014&lt;/a&gt;); if needed, please configure this field explicitly as header or message value attribute; this was done to allow for exporting this field using any custom name which was not easily possible before&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved start-up performance for the Postgres connector when using enum columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2038&quot;&gt;DBZ-2038&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.0-beta1&quot;&gt;release notes&lt;/a&gt; for the list of all addressed issues and upgrading procedures.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/andersenleo&quot;&gt;Anders Engström&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ant0nk&quot;&gt;Anton Kondratev&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bradengroom&quot;&gt;Braden Groom&lt;/a&gt;,
&lt;a href=&quot;https://github.com/dajerome&quot;&gt;David Jerome&lt;/a&gt;,
&lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ivan-klass&quot;&gt;Ivan Klass&lt;/a&gt;
&lt;a href=&quot;https://github.com/JanHendrikDolling&quot;&gt;Jan-Hendrik Dolling&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jpsoroulas&quot;&gt;John Psoroulas&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgao54&quot;&gt;Joy Gao&lt;/a&gt;
&lt;a href=&quot;https://github.com/lyidataminr&quot;&gt;lyidataminr&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/TechnocratSid&quot;&gt;Siddhant Agnihotry&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><summary type="html">With great happiness I&amp;#8217;m announcing the release of Debezium 1.2.0.Beta1! This release brings user-facing schema change topics for the SQL Server, Db2 and Oracle connectors, a new message transformation for content-based change event routing, support for a range of array column types in Postgres and much more. We also upgraded the Debezium container images for Apache Kafka and Kafka Connect to version 2.5.0. As it&amp;#8217;s the answer to all questions in life, the number of issues fixed for this release is exactly 42!</summary></entry><entry><title type="html">Debezium 1.2.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/04/16/debezium-1-2-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.2.0.Alpha1 Released" /><published>2020-04-16T16:19:59+00:00</published><updated>2020-04-16T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/04/16/debezium-1-2-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/04/16/debezium-1-2-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.2.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This first drop of the 1.2 release line provides a number of useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Support for message transformations (SMTs) and converters in the Debezium embedded engine API&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new SMT for filtering out change events using scripting languages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Automatic reconnects for the SQL Server connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new column masking mode using consistent hash values&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.2.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;41 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of them in the remainder of this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;embedded-engine-improvements&quot;&gt;Embedded Engine Improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium&amp;#8217;s &lt;a href=&quot;/documentation/reference/1.2/development/engine.html&quot;&gt;embedded engine&lt;/a&gt; is a very useful tool for handling change events in cases where Apache Kafka and Kafka Connect are not available.
For instance it allows to use Debezium&amp;#8217;s CDC capabilities and stream change events to alternative messaging infrastructure such as Amazon Kinesis or Google Pub/Sub.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To further improve the experience when working with this API, it supports the serialization of change events into different formats now
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1807&quot;&gt;DBZ-1807&lt;/a&gt;): JSON, Avro and CloudEvents.
This spares developers from having to deal with record serialization themselves.
As an example, here is how to use JSON as serialization format:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;Properties props = new Properties();

// don't include schema in message
props.setProperty(&quot;converter.schemas.enable&quot;, &quot;false&quot;); // &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
// further properties as needed...

DebeziumEngine&amp;lt;ChangeEvent&amp;lt;String&amp;gt;&amp;gt; engine = DebeziumEngine.create(Json.class) // &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
    .using(props)
    .notifying((records, committer) -&amp;gt; { // &lt;b class=&quot;conum&quot;&gt;(3)&lt;/b&gt;
        for (ChangeEvent&amp;lt;String&amp;gt; r : records) {
            System.out.println(&quot;Key = '&quot; + key + &quot;' value = '&quot; + value + &quot;'&quot;);
            committer.markProcessed(r);
        }
    })
    .build();&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;All the options of the underlying converter can be used&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Json.class&lt;/code&gt; is a type token requesting serialization into JSON&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;records&lt;/code&gt; is a batch of change events, represented as JSON strings&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The embedded engine now also supports the usage of Kafka Connect SMTs
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1930&quot;&gt;DBZ-1930&lt;/a&gt;).
They can be simply configured via the properties passed to the engine builder:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;Properties props = new Properties();

props.setProperty(&quot;transforms&quot;, &quot;router&quot;);
props.setProperty(&quot;transforms.router.type&quot;, &quot;org.apache.kafka.connect.transforms.RegexRouter&quot;);
props.setProperty(&quot;transforms.router.regex&quot;, &quot;(.*)&quot;);
props.setProperty(&quot;transforms.router.replacement&quot;, &quot;trf$1&quot;);&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This allows to use any existing Kafka Connect SMT, such as the ones coming with Kafka Connect itself, or Debezium&amp;#8217;s SMTs,
e.g. for &lt;a href=&quot;/documentation/reference/1.2/configuration/topic-routing.html&quot;&gt;topic routing&lt;/a&gt;,
&lt;a href=&quot;/documentation/reference/1.2/configuration/event-flattening.html&quot;&gt;new record state extraction&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/1.2/configuration/outbox-event-router.html&quot;&gt;outbox event routing&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;These improvements lay the foundation to the upcoming stand-alone Debezium runtime,
which will be based on the embedded engine and make its functionality available as a ready-to-use service.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;content-based-event-filtering&quot;&gt;Content-based Event Filtering&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release also adds another very versatile transformation to Debezium:
the &lt;a href=&quot;/documentation/reference/1.2/configuration/filtering.html&quot;&gt;message filter SMT&lt;/a&gt;.
Applied to the Debezium connectors on the source side of a Kafka Connect data streaming pipeline,
it allows to filter out specific change events based on their field values.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;E.g. you could use this to filter out any change events of a specific customer type or product category.
Filters are given as script expressions,
using any language compatible with the javax.scripting API
(&lt;a href=&quot;https://jcp.org/en/jsr/detail?id=223&quot;&gt;JSR 223&lt;/a&gt;).
Note Debezium doesn&amp;#8217;t provide any such scripting language implementation itself;
instead you can choose from a wide range of available options such as Groovy, MVEL or graal.js (JavaScript via GraalVM) and add it to the Kafka Connect plug-in path yourself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Here&amp;#8217;s an example using Groovy:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
transforms=filter
transforms.filter.type=io.debezium.transforms.Filter
transforms.filter.language=jsr223.groovy
transforms.filter.condition=value.after.customerType != 42
...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;value&lt;/code&gt; is the change event&amp;#8217;s value; you could also refer to the event&amp;#8217;s key and even the corresponding schema objects.
Groovy automatically resolves property paths such as &lt;code&gt;value.after.customerType&lt;/code&gt; to look-ups in map-like data structures such as Kafka Connect&amp;#8217;s &lt;code&gt;Struct&lt;/code&gt; type.
This allows for very concise filtering conditions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Note this SMT is incubating state for now, i.e. details around its API and configuration surface may still change.
Please give it a try and share your experiences.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a number of other new functionalities coming with the 1.2.0.Alpha1 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New metrics &lt;code&gt;NumberOfDisconnects&lt;/code&gt; and &lt;code&gt;NumberOfPrimaryElections&lt;/code&gt; for the MongoDB connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1859&quot;&gt;DBZ-1859&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for automatic reconnects after connection losses in the SQL Server connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1882&quot;&gt;DBZ-1882&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New column masking mode &quot;consistent hashing&quot; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1692&quot;&gt;DBZ-1692&lt;/a&gt;):
Debezium allows to mask specific column values,
e.g. to satisfy concerns around data privacy and protection.
Using the new &quot;consistent hashing&quot; mode it&amp;#8217;s now possible to not only use asterisks as masking characters,
but also hash values based on the masked data contents.
Quoting the original issue reporter, this &quot;will be useful for [anonymizing] data but in this case it still needs to be relatable between topics. It’s a typical requirement for warehouses where you want to anonymize sensitive data but still need to keep referential integrity of your data&quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Allowing to link update change events in case of primary key updates (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1531&quot;&gt;DBZ-1531&lt;/a&gt;): most relational Debezium connectors represent an update to the primary key of a record by a delete event using the old key and a subsequent insert event using the updated key; using the new record headers &lt;code&gt;__debezium.newkey&lt;/code&gt; and &lt;code&gt;__debezium.oldkey&lt;/code&gt;,
it is now possible for consumers to link these change events together when working with change data from the MySQL and Postgres connectors&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upgrade of Debezium&amp;#8217;s container images to Apache Kafka 2.4.1 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1925&quot;&gt;DBZ-1925&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;High CPU usage when the Postgres connector is idle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1960&quot;&gt;DBZ-1960&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Empty wal2json empty change event could cause NPE (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1922&quot;&gt;DBZ-1922&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra Connector: unable to deserialize column mutation with reversed type
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1967&quot;&gt;DBZ-1967&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Outbox Quarkus Extension throws NPE in quarkus:dev mode (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1966&quot;&gt;DBZ-1966&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validation of binlog_row_image is not compatible with MySQL 5.5 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1950&quot;&gt;DBZ-1950&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.0-alpha1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.
We&amp;#8217;ve also backported the critical bugfixes to the 1.1 branch and will release Debezium 1.1.1 tomorrow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/fgakk&quot;&gt;Fatih Güçlü Akkaya&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/JanHendrikDolling&quot;&gt;Jan-Hendrik Dolling&lt;/a&gt;,
&lt;a href=&quot;https://github.com/lga-zurich&quot;&gt;Luis Garcés-Erice&lt;/a&gt;,
&lt;a href=&quot;https://github.com/devzer01&quot;&gt;Nayana Hettiarachchi&lt;/a&gt; and
&lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.2.0.Alpha1! This first drop of the 1.2 release line provides a number of useful new features: Support for message transformations (SMTs) and converters in the Debezium embedded engine API A new SMT for filtering out change events using scripting languages Automatic reconnects for the SQL Server connector A new column masking mode using consistent hash values Overall, the community fixed not less than 41 issues for this release. Let&amp;#8217;s take a closer look at some of them in the remainder of this post.</summary></entry></feed>