<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2021-03-24T19:42:42+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 1.5.0.CR1 Released</title><link href="https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.CR1 Released"/><published>2021-03-24T00:00:00+00:00</published><updated>2021-03-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.5.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we begin moving toward finalizing the Debezium 1.5 release stream, the Oracle connector has been promoted to stable and there were some TLS improvements for the Cassandra connector, as well as numerous bugfixes. Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.CR1%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;50 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_connector_now_stable&quot;&gt;Oracle connector now stable&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Oracle connector has been in incubating status for a while but recent efforts have helped to bring new features and stability to the connector. We felt at this point, the connector is ready so with this release we&amp;#8217;re officially promoting the Oracle connector from &lt;em&gt;incubating&lt;/em&gt; to &lt;strong&gt;stable&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A tremendous effort by the community has made all this possible. The numerous contributions, bug reports, and testing has helped so much! The team and I cannot thank the community enough for all its insight, help, and dedication in making this milestone a reality so quickly!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra_connector_tls_improvements&quot;&gt;Cassandra connector TLS improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Cassandra connector uses the defaut available ciphers to establish SSL connections. For most use cases, this is more than satisfactory; however it does prevent the use of non-standard ciphers. In this release, the Cassandra connector property file can be configured to specify a list of ciphers in precedence order for use.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To use this new feature, add a line to the connector&amp;#8217;s property file like below:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;cipherSuites=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A number of bugs were fixed in this release, e.g.:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Debezium logs &quot;is not a valid Avro schema name&quot; can be too verbose &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2511&quot;&gt;DBZ-2511&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;message.key.columns Regex Validation Time Complexity &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2957&quot;&gt;DBZ-2957&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;OID values don&amp;#8217;t fit to INT32 schema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3033&quot;&gt;DBZ-3033&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connector automatically restart on ORA-26653 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3236&quot;&gt;DBZ-3236&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;UI container has no assets (JS artifacts, fonts, etc) and randomly fails building &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3247&quot;&gt;DBZ-3247&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Revert Clob behavior for Oracle LogMiner to avoid null values &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3257&quot;&gt;DBZ-3257&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SQL Server misses description for decimal.handling.mode &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3267&quot;&gt;DBZ-3267&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector ignores time.precision.mode and just uses adaptive mode &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3268&quot;&gt;DBZ-3268&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;commons-logging JAR is missing from Debezium Server distro &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3277&quot;&gt;DBZ-3277&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MongoDB timeouts crash the whole connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3278&quot;&gt;DBZ-3278&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Prefer archive logs over redo logs of the same SCN range &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3292&quot;&gt;DBZ-3292&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;LogMiner mining query may unintentionally skip records &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3295&quot;&gt;DBZ-3295&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;IndexOutOfBoundsException when LogMiner DML update statement contains a function as last column&amp;#8217;s value &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3305&quot;&gt;DBZ-3305&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Out of memory with mysql snapshots (regression of DBZ-94 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3309&quot;&gt;DBZ-3309&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Keyword ORDER is a valid identifier in MySQL grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3310&quot;&gt;DBZ-3310&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DDL statement couldn&amp;#8217;t be parsed for ROW_FORMAT=TOKUDB_QUICKLZ &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3311&quot;&gt;DBZ-3311&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;LogMiner can miss a log switch event if too many switches occur. &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3319&quot;&gt;DBZ-3319&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Function MOD is missing from MySQL grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3333&quot;&gt;DBZ-3333&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incorrect SR label names in OCP testusite &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3336&quot;&gt;DBZ-3336&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DB2 upstream tests are still using master as the default branch &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3337&quot;&gt;DBZ-3337&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.5/release-notes/#release-1.5.0-cr1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading to earlier Debezim versions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/frankkoornstra&quot;&gt;Frank Koornstra&lt;/a&gt; and &lt;a href=&quot;https://github.com/JeremyVigny&quot;&gt;Jeremy Vigny&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we begin to wrap up Debezium 1.5 and barring any unforeseen regressions or bug reports, we expect Debezium 1.5 Final to be released by the end of March. Once 1.5 Final is out, we&amp;#8217;ll begin our focus toward 1.6. We have quite a bit in store for Debezium 1.6 so stay tuned to learn what is lurking just around the corner!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.5.0.CR1! As we begin moving toward finalizing the Debezium 1.5 release stream, the Oracle connector has been promoted to stable and there were some TLS improvements for the Cassandra connector, as well as numerous bugfixes. Overall, 50 issues have been addressed for this release.</summary></entry><entry><title type="html">Understanding Non-Key Joins With the Quarkus Extension for Kafka Streams</title><link href="https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams/" rel="alternate" type="text/html" title="Understanding Non-Key Joins With the Quarkus Extension for Kafka Streams"/><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams</id><content type="html" xml:base="https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation/streams/&quot;&gt;Kafka Streams&lt;/a&gt; is a library for developing stream processing applications based on Apache Kafka. Quoting its docs, &quot;a Kafka Streams application processes record streams through a topology in real-time, processing data continuously, concurrently, and in a record-by-record manner&quot;. The Kafka Streams DSL provides a range of stream processing operations such as a map, filter, join, and aggregate.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;non_key_joins_in_kafka_streams&quot;&gt;Non-Key Joins in Kafka Streams&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium’s CDC source connectors make it easy to capture data changes in databases and push them towards sink systems such as Elasticsearch in near real-time. By default, this results in a 1:1 relationship between tables in the source database, the corresponding Kafka topics, and a representation of the data at the sink side, such as a search index in Elasticsearch.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In case of 1:n relationships, say between a table of customers and a table of addresses, consumers often are interested in a view of the data that is a single, nested data structure, e.g. a single Elasticsearch document representing a customer and all their addresses.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This is where &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-213+Support+non-key+joining+in+KTable&quot;&gt;KIP-213&lt;/a&gt; (&quot;Kafka Improvement Proposal&quot;) and its foreign key joining capabilities come in: it was introduced in &lt;a href=&quot;https://kafka.apache.org&quot;&gt;Apache Kafka&lt;/a&gt; 2.4 &quot;to close the gap between the semantics of KTables in streams and tables in relational databases&quot;. Before KIP-213, in order to join messages from two Debezium change event topics, you&amp;#8217;d typically have to manually re-key at least one of the topics, so to make sure the same key is used on both sides of the join.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to KIP-213, this isn&amp;#8217;t needed any longer, as it allows to join two Kafka topics on fields extracted from the Kafka message value, taking care of the required re-keying automatically, in a fully transparent way. Comparing to &lt;a href=&quot;/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/&quot;&gt;previous approaches&lt;/a&gt;, this drastically reduces the effort for creating aggregated events from Debezium’s CDC events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Non-key joins or rather &lt;a href=&quot;https://kafka.apache.org/27/documentation/streams/developer-guide/dsl-api.html#ktable-ktable-fk-join&quot;&gt;foreign-key joins&lt;/a&gt; are analogous to joins in SQL such as the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; CUSTOMER &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; ADDRESS &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; CUSTOMER.ID = ADDRESS.CUSTOMER_ID&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Kafka Streams terms, the output of such join is a new &lt;code&gt;KTable&lt;/code&gt; containing the join result.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;database_overview&quot;&gt;Database Overview&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Sticking to our earlier example of customers and address, let&amp;#8217;s consider an application with the following data model:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/kstreams_db_diagram.jpg&quot; class=&quot;responsive-image&quot; alt=&quot;Database Overview&quot;&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The two entities, customer and address, share a foreign key relationship from address to customer, i.e. a customer can have multiple addresses. As stated above, by default Debezium will emit events for each table on distinct topics. Using Kafka Streams, the change event topics for both tables will be loaded into two &lt;code&gt;KTable&lt;/code&gt;s, which are joined on the customer id. The Kafka Streams application is going to process data from the two Kafka topics. Whenever there&amp;#8217;s a new CDC event on either topic&amp;#8201;&amp;#8212;&amp;#8201;triggered by the insertion, update, or deletion of a record&amp;#8201;&amp;#8212;&amp;#8201;the join will be re-executed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As a runtime for the Kafka Streams application, we&amp;#8217;re going to use &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;, a stack for building cloud-native microservices, which (amongst many others) also provides an &lt;a href=&quot;https://quarkus.io/guides/kafka-streams&quot;&gt;extension&lt;/a&gt; for Kafka Streams. While it&amp;#8217;s general possible to run a Kafka Streams topology via a plain &lt;code&gt;main()&lt;/code&gt; method, using Quarkus and this extension as a foundation has a number of advantages:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Management of the topology (e.g. waiting for all input topics to be created)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Configurability via environment variables, system properties etc.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exposing health checks&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exposing metrics&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Dev Mode&lt;/em&gt;, a way of working on the stream topology with automatic hot code replacement after code changes&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for executing the Kafka Streams pipeline as a native binary via &lt;a href=&quot;https://www.graalvm.org/&quot;&gt;GraalVM&lt;/a&gt;, resulting in a signficantly reduced memory consumption and start-up times&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/kstreams_change_event_overview.png&quot; class=&quot;responsive-image&quot; alt=&quot;Change Event Overview&quot;&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This picture shows an overview of our solution.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;creating_an_application_using_the_quarkus_kafka_streams_extension&quot;&gt;Creating an Application using the Quarkus Kafka Streams Extension&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To create a new Quarkus project with the Kafka Streams extension, run the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;mvn io.quarkus:quarkus-maven-plugin:1.12.2.Final:create \ -DprojectGroupId=org.acme \ -DprojectArtifactId=customer-addresses-aggregator \ -Dextensions=&quot;kafka-streams&quot; cd customer-addresses-aggregator&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;understanding_the_stream_processing_topology&quot;&gt;Understanding the Stream Processing Topology&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have an aggregator application that will read from the two Kafka topics and process them in a streaming pipeline:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;the two topics are joined on customer id&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;each customer is enriched with its addresses&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;this aggregated data is written out to a third topic, &lt;code&gt;customersWithAddressesTopic&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the Quarkus extension for Kafka Streams, all we need to do for that is to declare a &lt;a href=&quot;http://www.cdi-spec.org/&quot;&gt;CDI producer method&lt;/a&gt;, which returns the topology of our stream processing application. This method must be annotated with &lt;code&gt;@Produces&lt;/code&gt;, and it must return a &lt;code&gt;Topology&lt;/code&gt; instance. The Quarkus extension is responsible for configuring, starting, and stopping the Kafka Streams engine. Now let&amp;#8217;s take a look at the actual streaming query implementation itself.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;&lt;span class=&quot;annotation&quot;&gt;@ApplicationScoped&lt;/span&gt; &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;TopologyProducer&lt;/span&gt; { &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt; &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; customersTopic; &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;addresses.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;) &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; addressesTopic; &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers.with.addresses.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;) &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; customersWithAddressesTopic; &lt;span class=&quot;annotation&quot;&gt;@Produces&lt;/span&gt; &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; Topology buildTopology() { StreamsBuilder builder = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; StreamsBuilder(); &lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt; Serde&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;&amp;gt; adressKeySerde = DebeziumSerdes.payloadJson(&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;.class); adressKeySerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.emptyMap(), &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;); Serde&amp;lt;Address&amp;gt; addressSerde = DebeziumSerdes.payloadJson(Address.class); addressSerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.singletonMap(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;from.field&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;), &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;); Serde&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;&amp;gt; customersKeySerde = DebeziumSerdes.payloadJson(&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;.class); customersKeySerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.emptyMap(), &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;); Serde&amp;lt;Customer&amp;gt; customersSerde = DebeziumSerdes.payloadJson(Customer.class); customersSerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.singletonMap(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;from.field&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;), &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;); JsonbSerde&amp;lt;AddressAndCustomer&amp;gt; addressAndCustomerSerde = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; JsonbSerde&amp;lt;&amp;gt;(AddressAndCustomer.class); &lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt; JsonbSerde&amp;lt;CustomerWithAddresses&amp;gt; customerWithAddressesSerde = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; JsonbSerde&amp;lt;&amp;gt;(CustomerWithAddresses.class); KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;, Address&amp;gt; addresses = builder.table( &lt;i class=&quot;conum&quot; data-value=&quot;4&quot;&gt;&lt;/i&gt;&lt;b&gt;(4)&lt;/b&gt; addressesTopic, Consumed.with(adressKeySerde, addressSerde) ); KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;, Customer&amp;gt; customers = builder.table( customersTopic, Consumed.with(customersKeySerde, customersSerde) ); KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;, CustomerWithAddresses&amp;gt; customersWithAddresses = addresses.join( &lt;i class=&quot;conum&quot; data-value=&quot;5&quot;&gt;&lt;/i&gt;&lt;b&gt;(5)&lt;/b&gt; customers, address -&amp;gt; address.customer_id, AddressAndCustomer::&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt;, Materialized.with(Serdes.Long(), addressAndCustomerSerde) ) .groupBy( &lt;i class=&quot;conum&quot; data-value=&quot;6&quot;&gt;&lt;/i&gt;&lt;b&gt;(6)&lt;/b&gt; (addressId, addressAndCustomer) -&amp;gt; KeyValue.pair( addressAndCustomer.customer.id, addressAndCustomer), Grouped.with(Serdes.Integer(), addressAndCustomerSerde) ) .aggregate( &lt;i class=&quot;conum&quot; data-value=&quot;7&quot;&gt;&lt;/i&gt;&lt;b&gt;(7)&lt;/b&gt; CustomerWithAddresses::&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt;, (customerId, addressAndCustomer, aggregate) -&amp;gt; aggregate.addAddress( addressAndCustomer), (customerId, addressAndCustomer, aggregate) -&amp;gt; aggregate.removeAddress( addressAndCustomer), Materialized.with(Serdes.Integer(), customerWithAddressesSerde) ); customersWithAddresses.toStream() &lt;i class=&quot;conum&quot; data-value=&quot;8&quot;&gt;&lt;/i&gt;&lt;b&gt;(8)&lt;/b&gt; .to( customersWithAddressesTopic, Produced.with(Serdes.Integer(), customerWithAddressesSerde) ); &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; builder.build(); } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;colist arabic&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt; &lt;td&gt;The topic names are injected using the &lt;a href=&quot;https://microprofile.io/project/eclipse/microprofile-config&quot;&gt;MicroProfile Config API&lt;/a&gt;, with the values being provided in the Quarkus &lt;code&gt;application.properties&lt;/code&gt; configuration file (they could be overridden using environment variables for instance)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt; &lt;td&gt;Create an instance of &lt;code&gt;StreamsBuilder&lt;/code&gt;, which helps us to build our topology&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt; &lt;td&gt;For serializing and deserializing Java types used in the streaming pipeline into/from JSON, Quarkus provides the &lt;code&gt;class io.quarkus.kafka.client.serialization.JsonbSerde&lt;/code&gt;; The Serde implementation based is on &lt;a href=&quot;https://github.com/quarkusio/quarkus/blob/master/extensions/kafka-client/runtime/src/main/java/io/quarkus/kafka/client/serialization/JsonbSerde.java&quot;&gt;JSON-B&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;4&quot;&gt;&lt;/i&gt;&lt;b&gt;4&lt;/b&gt;&lt;/td&gt; &lt;td&gt;The &lt;code&gt;KTable&lt;/code&gt;-&lt;code&gt;KTable&lt;/code&gt; foreign-key join functionality is used to extract the &lt;code&gt;customer#id&lt;/code&gt; and perform the join; &lt;code&gt;StreamsBuilder#table()&lt;/code&gt; is used to read the two Kafka topics into the KTable &lt;code&gt;addresses&lt;/code&gt; and &lt;code&gt;customers&lt;/code&gt;, respectively&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;5&quot;&gt;&lt;/i&gt;&lt;b&gt;5&lt;/b&gt;&lt;/td&gt; &lt;td&gt;The message from the &lt;code&gt;addresses&lt;/code&gt; topic is joined with the corresponding &lt;code&gt;customers&lt;/code&gt; topic; the join result contains the data of the customer with one of their addresses&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;6&quot;&gt;&lt;/i&gt;&lt;b&gt;6&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;code&gt;groupBy()&lt;/code&gt; operation will have the records to be grouped by &lt;code&gt;customer#id&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;7&quot;&gt;&lt;/i&gt;&lt;b&gt;7&lt;/b&gt;&lt;/td&gt; &lt;td&gt;To produce the nested structure of one customer and all their addresses, the &lt;code&gt;aggregate()&lt;/code&gt; operation is applied to each group of records (customer-address tuples), updating a &lt;code&gt;CustomerWithAddresses&lt;/code&gt; per customer&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;8&quot;&gt;&lt;/i&gt;&lt;b&gt;8&lt;/b&gt;&lt;/td&gt; &lt;td&gt;The results of the pipeline are written out to the &lt;code&gt;customersWithAddressesTopic&lt;/code&gt; topic&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;CustomerWithAddresses&lt;/code&gt; class keeps track of the aggregated values while the events are processed in the streaming pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;&lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;CustomerWithAddresses&lt;/span&gt; { &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; Customer customer; &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;predefined-type&quot;&gt;List&lt;/span&gt;&amp;lt;Address&amp;gt; addresses = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;predefined-type&quot;&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;(); &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; CustomerWithAddresses addAddress(AddressAndCustomer addressAndCustomer) { customer = addressAndCustomer.customer; addresses.add(addressAndCustomer.address); &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;local-variable&quot;&gt;this&lt;/span&gt;; } &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; CustomerWithAddresses removeAddress(AddressAndCustomer addressAndCustomer) { &lt;span class=&quot;predefined-type&quot;&gt;Iterator&lt;/span&gt;&amp;lt;Address&amp;gt; it = addresses.iterator(); &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (it.hasNext()) { Address a = it.next(); &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (a.id == addressAndCustomer.address.id) { it.remove(); &lt;span class=&quot;keyword&quot;&gt;break&lt;/span&gt;; } } &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;local-variable&quot;&gt;this&lt;/span&gt;; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Kafka Streams extension is configured via the Quarkus configuration file &lt;code&gt;application.properties&lt;/code&gt;. Along with the topic names, this file also has the information about the Kafka bootstrap server and several streams options:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;customers.topic=dbserver1.inventory.customers addresses.topic=dbserver1.inventory.addresses customers.with.addresses.topic=customers-with-addresses quarkus.kafka-streams.bootstrap-servers=localhost:9092 quarkus.kafka-streams.application-id=kstreams-fkjoin-aggregator quarkus.kafka-streams.application-server=${hostname}:8080 quarkus.kafka-streams.topics=${customers.topic},${addresses.topic} # streams options kafka-streams.cache.max.bytes.buffering=10240 kafka-streams.commit.interval.ms=1000 kafka-streams.metadata.max.age.ms=500 kafka-streams.auto.offset.reset=earliest kafka-streams.metrics.recording.level=DEBUG kafka-streams.consumer.session.timeout.ms=150 kafka-streams.consumer.heartbeat.interval.ms=100&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;building_and_running_the_application&quot;&gt;Building and Running the Application&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can now build the application like so:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;mvn clean package&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To run the application and all related components (Kafka, Kafka Connect with Debezium, a Postgres database), we&amp;#8217;ve created a &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/master/kstreams-fk-join/docker-compose.yaml&quot;&gt;Docker Compose file&lt;/a&gt;, which you can find in the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/kstreams-fk-join&quot;&gt;debezium-examples&lt;/a&gt; repo. To launch all the containers, also building the aggregator container image, run the the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;export DEBEZIUM_VERSION=1.4 docker-compose up --build&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To register the Debezium Connector with Kafka Connect, you need to specify the configuration properties like name of the connector, database hostname, user, password, port, name of the database, etc. Create a file &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/master/kstreams-fk-join/register-postgres.json&quot;&gt;register-postgres.json&lt;/a&gt; with the following contents:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector.class&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.postgresql.PostgresConnector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tasks.max&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.hostname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.port&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;5432&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.user&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.password&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.dbname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.server.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema.include&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;decimal.handling.mode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.json.JsonConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.json.JsonConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Configure the Debezium Connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;http PUT http://localhost:8083/connectors/inventory-connector/config &amp;lt; register-postgres.json&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now run an instance of the &lt;code&gt;debezium/tooling&lt;/code&gt; container image:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;docker run --tty --rm \ --network kstreams-fk-join-network \ debezium/tooling:1.1 \&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This image provides several useful tools such as &lt;a href=&quot;https://github.com/edenhill/kafkacat&quot;&gt;kafkacat&lt;/a&gt;. Within the tooling container, run kafkacat to examine the results of the streaming pipeline:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;kafkacat -b kafka:9092 -C -o beginning -q \ -t customers-with-addresses | jq .&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You should see records like the following, each containing all the data of one customer and all their addresses:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;addresses&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Hamburg&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Canada&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;100001&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;42 Main Street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;zipcode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;90210&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; }, { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Berlin&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Canada&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;100002&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;11 Post Dr.&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;zipcode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;90211&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } ], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sally.thomas@acme.com&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Sally&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Thomas&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Get a shell for the database, insert, update, or delete some records, and the join will be reprocessed automatically:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;error&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;:&lt;span class=&quot;float&quot;&gt;1.1&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;:&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;:&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;:&lt;span class=&quot;integer&quot;&gt;5432&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;: &lt;span class=&quot;error&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;running_natively&quot;&gt;Running Natively&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Kafka Streams applications can easily be scaled out i.e. the load is going to be shared amongst multiple instances of the application, each processing a sub-set of the partitions of the input topics. When the Quarkus application gets compiled into native code via GraalVM, it takes considerably less memory and has a very fast start-up time. Without any concern about the memory management, you can start multiple instances of a Kafka Streams pipeline in parallel.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you want to run this application in &lt;code&gt;native&lt;/code&gt; mode, set the &lt;code&gt;QUARKUS_MODE&lt;/code&gt; as &lt;code&gt;native&lt;/code&gt; and run the following (make sure to have the required GraalVM tooling installed):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;mvn clean package -Pnative&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about running Kafka Streams applications as a native binary, please refer to the &lt;a href=&quot;https://quarkus.io/guides/kafka-streams#running-natively&quot;&gt;reference guide&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;more_insights_on_the_kafka_streams_extension&quot;&gt;More Insights on the Kafka Streams Extension&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Quarkus extension can also help you address some of the common requirements when building microservices for stream processing. For running your Kafka Streams application in production, you can for instance easily add health checks and metrics for the data pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://quarkus.io/guides/microprofile-metrics&quot;&gt;Micrometer Metrics&lt;/a&gt; provides rich metrics about your Quarkus application, i.e. what is happening inside your application by monitoring and what are its performance characteristics. Quarkus lets you expose these metrics via HTTP using a JSON format or the OpenMetrics format. From there, they can be scraped by tools such as &lt;a href=&quot;https://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt; and stored for analysis and visualization.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once the application is started, the metrics will be exposed under &lt;code&gt;q/metrics&lt;/code&gt;, returning the data in the OpenMetrics format by default:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;# HELP kafka_producer_node_request_total The total number of requests sent # TYPE kafka_producer_node_request_total counter kafka_producer_node_request_total{client_id=&amp;quot;kstreams-fkjoin-aggregator-b4ac1384-0e0a-4f19-8d52-8cc1ee4c6dfe-StreamThread-1-producer&amp;quot;,kafka_version=&amp;quot;2.5.0&amp;quot;,node_id=&amp;quot;node--1&amp;quot;,status=&amp;quot;up&amp;quot;,} 83.0 # HELP kafka_producer_record_send_rate The average number of records sent per second. # TYPE kafka_producer_record_send_rate gauge kafka_producer_record_send_rate{client_id=&amp;quot;kstreams-fkjoin-aggregator-b4ac1384-0e0a-4f19-8d52-8cc1ee4c6dfe-StreamThread-1-producer&amp;quot;,kafka_version=&amp;quot;2.5.0&amp;quot;,status=&amp;quot;up&amp;quot;,} 0.0 # HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the (young) heap memory pool after one GC to before the next # TYPE jvm_gc_memory_allocated_bytes_total counter jvm_gc_memory_allocated_bytes_total 1.1534336E8 # ... # HELP http_requests_total # TYPE http_requests_total counter http_requests_total{status=&amp;quot;up&amp;quot;,uri=&amp;quot;/api/customers&amp;quot;,} 0.0 # ...&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you aren’t using Prometheus, you have a few options like Datadog, Stackdriver, and others. For a detailed guide check the &lt;a href=&quot;https://github.com/quarkiverse/quarkus-micrometer-registry&quot;&gt;Quarkiverse Extensions&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On the other hand, we have &lt;a href=&quot;https://quarkus.io/guides/microprofile-health&quot;&gt;MicroProfile Health&lt;/a&gt; spec, which provides information about the liveness of the application, i.e. signalling whether your application is running or not and whether your application is able to process requests. To monitor the health status of your existing Quarkus application you can add the &lt;code&gt;smallrye-health&lt;/code&gt; extension:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;mvn quarkus:add-extension -Dextensions=&quot;smallrye-health&quot;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Quarkus will expose all health checks via HTTP under &lt;code&gt;q/health&lt;/code&gt;, which in our case shows the status of the pipeline and any missing topics:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;DOWN&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;checks&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Kafka Streams topics health check&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;DOWN&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;missing_topics&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1.inventory.customers,dbserver1.inventory.addresses&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } } ] }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Quarkus extension for Kafka Streams comes with everything needed to run stream processing pipelines on the JVM as well as in native mode, along with additional bonuses of performing health checks, metrics, and more. For instance you could quite easily expose REST APIs for interactive queries using the Quarkus REST support, potentially retrieving data from other instances of scaled out Kafka Streams app using the &lt;a href=&quot;https://quarkus.io/guides/rest-client&quot;&gt;MicroProfile REST client API&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this article we have discussed a stream processing topology of foreign key joins in Kafka Streams, and how to use the Quarkus Kafka Streams extension for running and building your application in JVM mode. You can find the complete &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/kstreams-fk-join&quot;&gt;source code&lt;/a&gt; of the implementation in the Debezium examples repo. If you got any questions or feedback, please let us know in the comments below. We&amp;#8217;re looking forward to your suggestions!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://quarkus.io/guides/kafka-streams&quot;&gt;Building Kafka Streams applications with Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://speakerdeck.com/gunnarmorling/change-data-capture-pipelines-with-debezium-and-kafka-streams-jokerconf&quot;&gt;Change Data Capture Pipelines With Debezium and Kafka Streams&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://micrometer.io/docs/concepts&quot;&gt;Micrometer Application Monitor&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="kafka streams"/><category term="quarkus"/><category term="examples"/><summary type="html">Kafka Streams is a library for developing stream processing applications based on Apache Kafka. Quoting its docs, &quot;a Kafka Streams application processes record streams through a topology in real-time, processing data continuously, concurrently, and in a record-by-record manner&quot;. The Kafka Streams DSL provides a range of stream processing operations such as a map, filter, join, and aggregate. Non-Key Joins in Kafka Streams Debezium’s CDC source connectors make it easy to capture data changes in databases and push them towards sink systems such as Elasticsearch in near real-time. By default, this results in a 1:1 relationship between tables in the source database, the corresponding Kafka topics, and a representation of the data at the sink side, such as a search index in Elasticsearch. In case of 1:n relationships, say between a table of customers and a table of addresses, consumers often are interested in a view of the data that is a single, nested data structure, e.g. a single Elasticsearch document representing a customer and all their addresses. This is where KIP-213 (&quot;Kafka Improvement Proposal&quot;) and its foreign key joining capabilities come in: it was introduced in Apache Kafka 2.4 &quot;to close the gap between the semantics of KTables in streams and tables in relational databases&quot;. Before KIP-213, in order to join messages from two Debezium change event topics, you&amp;#8217;d typically have to manually re-key at least one of the topics, so to make sure the same key is used on both sides of the join. Thanks to KIP-213, this isn&amp;#8217;t needed any longer, as it allows to join two Kafka topics on fields extracted from the Kafka message value, taking care of the required re-keying automatically, in a fully transparent way. Comparing to previous approaches, this drastically reduces the effort for creating aggregated events from Debezium’s CDC events.</summary></entry><entry><title type="html">Debezium 1.5.0.Beta2 Released</title><link href="https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Beta2 Released"/><published>2021-03-15T00:00:00+00:00</published><updated>2021-03-15T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are very happy to announce the release of Debezium &lt;strong&gt;1.5.0.Beta2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The main features of this release is the new Debezium Signaling Table support, Vitess SET type support, and a continued focus to minor improvements, bugfixes, and polish as we sprint to the finish line for the 1.5 release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Beta2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;54 issues&lt;/a&gt; since the Beta1 release, some of which we&amp;#8217;ll explore more in-depth below.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;signaling_table&quot;&gt;Signaling Table&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The signal table feature is a huge milestone for Debezium. It provides a command pattern based on a source database table to send commands (aka signals) to Debezium so that specific actions may be taken. The framework is extendable, allowing a connector to implement custom commands beyond the common commands provided by Debezium core. There are several situations where this might be applicable, including but not limited to, PostgreSQL primary key column changes, changes to enum value-sets of a column definition, and schema changes with the Oracle connector. This is an incubating feature and therefore behavior is subject to change between releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use the signal table feature, the connector option &lt;code&gt;signal.data.collection&lt;/code&gt; must be specified in the connector&amp;#8217;s configuration. This option specifies the fully qualified name of the table from which signal requests will be sourced. If this option is not specified or empty, the signal table feature will be disabled.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The signal table itself must be created ahead of time and it must adhere to the following convention:&lt;/p&gt; &lt;/div&gt; &lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt; &lt;colgroup&gt; &lt;col style=&quot;width: 50%;&quot;&gt; &lt;col style=&quot;width: 50%;&quot;&gt; &lt;/colgroup&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Column Name&lt;/th&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Data Type&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;ID&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt; The unique identifier of the signal such as a UUID.&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;TYPE&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt; The unique command to be performed.&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;DATA&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt; The payload for the command.&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Lastly, the signal table must be explicitly found as part of your connector&amp;#8217;s include/exclude-list specifications. In other words, if you&amp;#8217;re specifying a list of tables to monitor, this list will need to be adjusted to include the name of the signal table as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This new feature has quite a number of use cases that we intend to explore in future releases. Lets discuss what signals are currently supported in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;log_signal&quot;&gt;Log Signal&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The log signal is detected when the &lt;code&gt;TYPE&lt;/code&gt; column in the signal table is &lt;code&gt;log&lt;/code&gt;. This signal requests that Debezium write the contents of the &lt;code&gt;DATA&lt;/code&gt; column (payload) to the connector logs as-is. This can be useful for a variety of purposes from debugging to tracking progress of database script operations and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; DEBEZIUM_SIGNALS (ID, TYPE, DATA) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Hello World&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once that insert is committed and written to the database&amp;#8217;s transaction logs, Debezium will recognize the signal and will then write &lt;code&gt;Hello World&lt;/code&gt; to the connector logs using the &lt;code&gt;INFO&lt;/code&gt; log level.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;schema_changes_signal&quot;&gt;Schema Changes Signal&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The schema changes signal is detected when the &lt;code&gt;TYPE&lt;/code&gt; column in the signal table is &lt;code&gt;schema-changes&lt;/code&gt;. This signal tells Debezium to emit a &lt;code&gt;SchemaChangeEvent&lt;/code&gt; to the schema changes topic that is based on the changes supplied in the row&amp;#8217;s &lt;code&gt;DATA&lt;/code&gt; column (payload). The format of the &lt;code&gt;DATA&lt;/code&gt; column must be given in JSON and an example of the format is below. Additionally, this signal will also have Debezium update it&amp;#8217;s in-memory representation of the table&amp;#8217;s schema structure.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As an example, we have a PostgreSQL table &lt;code&gt;s1.a&lt;/code&gt; where we want to add a new column &lt;code&gt;aa&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;changes&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ALTER&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s1.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;defaultCharsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;primaryKeyColumnNames&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pk&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; ], &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pk&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;jdbcType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;nativeType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;23&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;serial&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeExpression&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;serial&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;charsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;autoIncremented&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;generated&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt; }, { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;jdbcType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;nativeType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;23&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;int4&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeExpression&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;int4&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;charsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;autoIncremented&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;generated&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt; }] } }] }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With this JSON payload, the signal would be inserted as:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; DEBEZIUM_SIGNALS (ID, TYPE, DATA) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema-changes&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &amp;lt;json-payload-string&amp;gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess_set_support&quot;&gt;Vitess SET support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess team improved the &lt;code&gt;SET&lt;/code&gt; data type support in the VStream API as part of Vitess 9.0. This improvement has lead to the &lt;code&gt;SET&lt;/code&gt; data type now being supported by the Debezium Vitess connector. This data type will be emitted as an &lt;code&gt;EnumSet&lt;/code&gt; that will now contain all the permissible values of the column&amp;#8217;s &lt;code&gt;SET&lt;/code&gt; definition.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_features_and_fixes&quot;&gt;Other Features and Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides the Signal Table and Vitess SET support, a few other improvements and fixes found their way into this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Oracle now uses the LogMiner-based capturing implementation by default. In order to use the XStream-based implementation, the &lt;code&gt;database.connection.adapter&lt;/code&gt; option must be explicitly set to &lt;code&gt;xstream&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3241&quot;&gt;DBZ-3241&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;In an earlier release of Debezium 1.5, the Oracle connector began to emit &lt;code&gt;NUMBER(1)&lt;/code&gt; data types as &lt;code&gt;BOOLEAN&lt;/code&gt;. Rather than this conversion be implicitly done by the connector, this behavior has been moved to an OOTB converter, &lt;code&gt;NumberOneToBooleanConverter&lt;/code&gt;, that can be used as needed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3208&quot;&gt;DBZ-3208&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;System generated index-organized tables (tables that begin with &lt;code&gt;SYS_IOT_OVER&lt;/code&gt;) are ignored by the Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3036&quot;&gt;DBZ-3036&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Server&amp;#8217;s sink for AWS Kinesis can be configured with an endpoint by specifying &lt;code&gt;debezium.sink.kinesis.endpoint&lt;/code&gt; (&lt;a href=&quot;https://www.redhat.com/browse/DBZ-3246&quot;&gt;DBZ-3246&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, you can find the complete list of all the addressed issues and upgrade procedures in the &lt;a href=&quot;/release/1.5/release-notes/#release-1.5.0-beta2&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to all the community members contributing to this release: &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/ddseapy&quot;&gt;David Seapy&lt;/a&gt;, &lt;a href=&quot;https://github.com/denisprog&quot;&gt;Victar Malinouski&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;, &lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;, &lt;a href=&quot;https://github.com/vaosinbi&quot;&gt;Vladimir Osin&lt;/a&gt;, &lt;a href=&quot;https://github.com/martper2&quot;&gt;Martín Pérez&lt;/a&gt;, and &lt;a href=&quot;https://github.com/mengqiu&quot;&gt;Meng Qiu&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Slowly wrapping up the work on the Debezium 1.5 release train, we&amp;#8217;ve also taken the opportunity and integrated the Debezium Oracle into the main &lt;a href=&quot;https://github.com/debezium/debezium&quot;&gt;debezium&lt;/a&gt; source code repository. With that, all connectors of the former &lt;a href=&quot;https://github.com/debezium/debezium-incubator&quot;&gt;debezium-incubator&lt;/a&gt; respository have either been moved into their own, dedicated repository, or integrated into the main one. The incubator repository has been set to &quot;Archived&quot; mode, allowing to examine its history if needed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the remaining time until 1.5 Final, we&amp;#8217;re planning to focus on bug fixes, performance improvements, documentation adjustments and other stabilization efforts; barring any unforeseen issues, the LogMiner-based capture implementation will be promoted from &lt;em&gt;Incubating&lt;/em&gt; to &lt;em&gt;Stable&lt;/em&gt; state for the Final release, too. If things go as planned, there&amp;#8217;ll be a CR (candidate release) mid next week, followed by the final release around the end of the month.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">We are very happy to announce the release of Debezium 1.5.0.Beta2! The main features of this release is the new Debezium Signaling Table support, Vitess SET type support, and a continued focus to minor improvements, bugfixes, and polish as we sprint to the finish line for the 1.5 release. Overall, the community fixed 54 issues since the Beta1 release, some of which we&amp;#8217;ll explore more in-depth below.</summary></entry><entry><title type="html">Debezium 1.5.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Beta1 Released"/><published>2021-02-24T00:00:00+00:00</published><updated>2021-02-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.5.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release adds a brand-new component&amp;#8201;&amp;#8212;&amp;#8201;the web-based Debezium UI --, transaction metadata support for the MySQL connector, a large number of improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, support for Vitess 9.0, and much more. Let&amp;#8217;s explore some of the new features in the following.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_ui&quot;&gt;Debezium UI&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The different Debezium connectors provide great power and flexibility for setting up and running change data capture sources for a range of databases. But this flexibility also comes at a cost: getting started with the connectors can take some time for understanding all the different options and their semantics. Another critical aspect is operating the connectors, i.e. gaining insight into their current status and metrics, being able to react to connector failures, and more etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Based on this feedback from the community, we &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;have explored&lt;/a&gt; over the last few months how a graphical user interface could help with these matters. The initial proof-of-concept looked very promising, so we decided to move forward and make the &lt;a href=&quot;https://github.com/debezium/debezium-ui/&quot;&gt;UI&lt;/a&gt; an official component of the Debezium project. Still under active development, you already can try out the UI today (available as a &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui&quot;&gt;container image on Docker Hub&lt;/a&gt;) and use it to set up Debezium connectors in your Kafka Connect clusters.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ll follow up with more details on the Debezium UI in a separate blog post within the next few days, discussing its current status, the roadmap for this component, and more.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improved_logminer_based_cdc_implementation&quot;&gt;Improved LogMiner-based CDC Implementation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Continuing our current focus on the LogMiner-based CDC implementation for Oracle, we&amp;#8217;ve fixed a substantial number of issues for this connector. Amongst them are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Drastically improved DML parsing performance (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3078&quot;&gt;DBZ-3078&lt;/a&gt;); a new hand-written parser for the LogMiner DML statements allows for better throughput of this connector, the existing external parser implementation will be removed very soon&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for capturing changes from multiple schemas (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3009&quot;&gt;DBZ-3009&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for column filtering (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3167&quot;&gt;DBZ-3167&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Correct transaction metadata (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3090&quot;&gt;DBZ-3090&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several bug fixes related to log file switching and similar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2754&quot;&gt;DBZ-2754&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3001&quot;&gt;DBZ-3001&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3153&quot;&gt;DBZ-3153&lt;/a&gt;, etc.)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess_connector&quot;&gt;Vitess Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Led by community member Kewei Shang, the Debezium connector for Vitess now supports Vitess 9.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3100&quot;&gt;DBZ-3100&lt;/a&gt;). The connector also can capture changes from JSON and ENUM columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3115&quot;&gt;DBZ-3115&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3124&quot;&gt;DBZ-3124&lt;/a&gt;), and it implements the configuration validation API of Kafka Connect (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3117&quot;&gt;DBZ-3117&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in this release including the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The Debezium MySQL connector can expose metadata about transaction boundaries (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3114&quot;&gt;DBZ-3114&lt;/a&gt;); this is one of the first benefits we obtain by rebasing this connector onto the common Debezium connector framework, as discussed in the &lt;a href=&quot;/blog/2021/02/08/debezium-1-5-alpha1-released/&quot;&gt;1.5.0.Alpha1&lt;/a&gt; release announcement&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Postgres is tested and validated against PG 13 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3022&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DBZ-3022&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Ability to customize offsets when using the Debezium embedded API (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2897&quot;&gt;DBZ-2897&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for &lt;code&gt;CREATE OR REPLACE INDEX&lt;/code&gt; DDL when using the MySQL connector with MariaDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3067&quot;&gt;DBZ-3067&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinite timestamp values supported with Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2614&quot;&gt;DBZ-2614&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a grand total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;78 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thanks you to all the community members who contributed: &lt;a href=&quot;https://github.com/adhaamehab&quot;&gt;Adhaam Ehab&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/fahimfarookme&quot;&gt;Fahim Farook&lt;/a&gt;, &lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/michaelcizmar&quot;&gt;Michael Cizmar&lt;/a&gt;, &lt;a href=&quot;https://github.com/nitin456&quot;&gt;Nitin Agarwal&lt;/a&gt;, &lt;a href=&quot;https://github.com/r-ballard&quot;&gt;Russell Ballard&lt;/a&gt;, &lt;a href=&quot;https://github.com/mrshanepaul&quot;&gt;Shane Paul&lt;/a&gt;, &lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;, &lt;a href=&quot;https://github.com/twthorn&quot;&gt;Thomas Thornton&lt;/a&gt;, and &lt;a href=&quot;https://github.com/Cyril-Engels&quot;&gt;Yilong Chang&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.5.0.Beta1! This release adds a brand-new component&amp;#8201;&amp;#8212;&amp;#8201;the web-based Debezium UI --, transaction metadata support for the MySQL connector, a large number of improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, support for Vitess 9.0, and much more. Let&amp;#8217;s explore some of the new features in the following.</summary></entry><entry><title type="html">Debezium 1.5.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Alpha1 Released"/><published>2021-02-08T00:00:00+00:00</published><updated>2021-02-08T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.5 series, &lt;strong&gt;1.5.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release brings many improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, a large overhaul of the MySQL connector, as well as a wide range of bug fixes and other small feature additions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improved_logminer_based_capture_implementation&quot;&gt;Improved LogMiner-based Capture Implementation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since we&amp;#8217;ve announced the LogMiner-based implementation for the Debezium Oracle connector in &lt;a href=&quot;/blog/2020/10/01/debezium-1-3-final-released/&quot;&gt;Debezium 1.3&lt;/a&gt;, we&amp;#8217;ve seen a constantly growing interest in this connector by folks from our lively community, who tested it out, provided feedback, logged bug reports and feature requests, submitted pull requests with fixes, and more. Based on all this input, the connector is rapidly maturing, and we aim to move the LogMiner-based implementation from &quot;Incubating&quot; to &quot;Stable&quot; state in Debezium 1.5, or 1.6 the latest. This first Alpha release of Debezium 1.5 contains a number of related improvements:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;java.sql.SQLException: ORA-01333: failed to establish Logminer Dictionary (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2939&quot;&gt;DBZ-2939&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Capture and report LogMiner state when mining session fails to start (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3055&quot;&gt;DBZ-3055&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Oracle Connector will appear stuck on large SCN jumps (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2982&quot;&gt;DBZ-2982&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improve logging for Logminer adapter (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2999&quot;&gt;DBZ-2999&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks Martín Pérez, Milo van der Zee, Anton Kondratev, and all the others for their intensive testing, feedback, and contributions while working on this! One of the next steps in this area will be several performance-related improvements; stay tuned for the details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;reworked_mysql_connector&quot;&gt;Reworked MySQL Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to reduce the maintenance effort for all the different Debezium connectors, we&amp;#8217;ve started work towards a common connector framework long time ago. This framework allows us to implement many features (and bug fixes) just once, and all the connectors based on this framework will be able to benefit from it. By now, almost all of the Debezium connectors have been ported to this framework, with the exception of the Cassandra and MySQL connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As of this release, also the MySQL connector provides an implementation based on this framework. Since the MySQL connector has been the first one amongst the Debezium connectors, and it has quite a few specific characteristics and features, we have decided to not simply replace the existing implementation with a new one, but rather keep both, existing and new, side by side for some time.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This allows the new implementation to mature, also giving users the choice of which implementation to use. While the new connector implementation is the default one as of this release, you can go back to the earlier one by setting the &lt;code&gt;internal.implementation&lt;/code&gt; option to &lt;code&gt;legacy&lt;/code&gt;. We don&amp;#8217;t have any immediate plans for removing the existing implementation, but focus for feature work and bug fixes will shift to the new implementation going forward. Please give the new connector implementation a try and let us know if you encounter any issues with it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While the new implementation is largely on par feature-wise with with the earlier one, there&amp;#8217;s one exception: the previous, experimental support for changing the filter configuration of a connector instance isn&amp;#8217;t part of the new implementation. We&amp;#8217;re planning to roll out a comparable feature for all the framework-based connectors in the near future. Now that there also is a framework-based implementation for the MySQL connector, we&amp;#8217;re planning to provide a range of improvements to snapshotting for all the (relational) connectors: for instance the aforementioned capability to change filter configurations, means of parallelizing snapshot operations, and more.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides these key features, there&amp;#8217;s a range of other improvements, smaller new features, and bug fixes coming with this release, including the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Correct handling of lists of user types in the Cassandra connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2974&quot;&gt;DBZ-2974&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Multiple DDL parser fixes for MySQL and MariaDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3018&quot;&gt;DBZ-3018&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3020&quot;&gt;DBZ-3020&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3023&quot;&gt;DBZ-3023&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3039&quot;&gt;DBZ-3039&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Better snapshotting performance for large Postgres schemas with many tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2575&quot;&gt;DBZ-2575&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Ability to emit &lt;code&gt;TRUNCATE&lt;/code&gt; events via the Postgres connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2382&quot;&gt;DBZ-2382&lt;/a&gt;); note that, when enabled, this adds a new &lt;code&gt;op&lt;/code&gt; type &lt;code&gt;t&lt;/code&gt; for this connector&amp;#8217;s change events, so please ensure your consumers can handle such events gracefully&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Thanks to the work of &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, there is now instructions for following the Debezium tutorial example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/tutorial#using-vitess&quot;&gt;using the incubating connector for Vitess&lt;/a&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2678&quot;&gt;DBZ-2678&lt;/a&gt;), which was added in Debezium 1.4:&lt;/p&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/vitess-sharding-setup.png&quot; class=&quot;responsive-image&quot; alt=&quot;Vitess Tutorial Example Overview&quot; style=&quot;max-width:90%;&quot;&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;32 issues&lt;/a&gt; were fixed for this release. A big thank you goes out to all the community members who contributed: &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/davecramer&quot;&gt;Dave Cramer&lt;/a&gt; &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;, &lt;a href=&quot;https://github.com/msillence&quot;&gt;Martin Sillence&lt;/a&gt;, &lt;a href=&quot;https://github.com/pkpfr&quot;&gt;Nick Murray&lt;/a&gt;, and &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the upcoming 1.5 preview releases, we&amp;#8217;re planning to focus on further improving and stabilizing the LogMiner-based connector implementation for Oracle, wrap up some loose ends around the MySQL connector migration, and begin to explore the aforementioned snapshotting improvements.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ve also made the decision to continue our efforts for creating a &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;graphical Debezium user interface&lt;/a&gt;; this component is currently under active development, with support for more connectors, functionality for (re-)starting and stopping connectors, examining logs, and much more in the workings. If things go as planned, the UI will officially be part of the next Debezium 1.5 preview release!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.5 series, 1.5.0.Alpha1! This release brings many improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, a large overhaul of the MySQL connector, as well as a wide range of bug fixes and other small feature additions.</summary></entry><entry><title type="html">Debezium 1.4.1.Final Released</title><link href="https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.4.1.Final Released"/><published>2021-01-28T00:00:00+00:00</published><updated>2021-01-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.1.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We highly recommend upgrading from 1.4.0.Final and earlier versions as this release includes bug fixes and enhancements to several Debezium connectors which includes some of the following: &lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[MySQL] - Use collation to get charset when charset is not set (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2922&quot;&gt;DBZ-2922&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] - Debezium Connectors are failing while reading binlog: Unknown event type 100 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2499&quot;&gt;DBZ-2499&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] - Some column default values are not extracted correctly while reading table structure (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2698&quot;&gt;DBZ-2698&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] - Default database charset is not recorded (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2921&quot;&gt;DBZ-2921&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] - Labeled create procedure&amp;#8217;s body is not parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2972&quot;&gt;DBZ-2972&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Supplemental logging is required for entire database rather than per monitored table (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2711&quot;&gt;DBZ-2711&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Missing log file error when current SCN differs from snapshotted in Oracle connector and Logminer (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2855&quot;&gt;DBZ-2855&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - DML statements longer than 4000 characters are incorrectly combined from V$LOGMNR_CONTENTS (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2920&quot;&gt;DBZ-2920&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Snapshot causes ORA-08181 exception (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2949&quot;&gt;DBZ-2949&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Deadlock in the XStream handler and offset commiter call concurrently (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2891&quot;&gt;DBZ-2891&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Debezium swallows DML exception in certain cases (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2981&quot;&gt;DBZ-2981&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] - Implement Scn as a domain type (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2518&quot;&gt;DBZ-2518&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[PostgreSQL] - Instable test: PostgresConnectorIT#testCustomSnapshotterSnapshotCompleteLifecycleHook() (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2938&quot;&gt;DBZ-2938&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[PostgreSQL] - Postgres connector config validation fails because current connector is occupying replication slot (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2952&quot;&gt;DBZ-2952&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[SQL Server] - Add support for binary.handling.mode to the SQL Server connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2912&quot;&gt;DBZ-2912&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[SQL Server] - Retry on &quot;The server failed to resume the transaction&quot; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2959&quot;&gt;DBZ-2959&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] - Sanitise DECIMAL string from VStream (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2906&quot;&gt;DBZ-2906&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] - Vitess Connector download link missing on website (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2907&quot;&gt;DBZ-2907&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Dependencies] - Upgrade to Apache Kafka Connect 2.6.1 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2630&quot;&gt;DBZ-2630&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.1.Final&quot;&gt;35 issues&lt;/a&gt; were resolved in this release. Please refer to the &lt;a href=&quot;/releases/1.4/release-notes/#release-1.4.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to everyone who helped test and identify these bugs and contributed to this release: &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt;, &lt;a href=&quot;https://github.com/isopropylcyanide&quot;&gt;Aman Garg&lt;/a&gt;, &lt;a href=&quot;https://github.com/ant0nk&quot;&gt;Anton Kondratev&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxxz&quot;&gt;Giovanni De Stefano&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martin Perez&lt;/a&gt;, &lt;a href=&quot;https://github.com/NishantSinghChandel&quot;&gt;Nishant Singh&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Shuguang Xiang&lt;/a&gt;, &lt;a href=&quot;https://github.com/siufay325&quot;&gt;siufay325&lt;/a&gt;, and &lt;a href=&quot;https://github.com/tjg184&quot;&gt;Troy Gaines&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongodb"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="debezium-server"/><category term="outbox"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.1.Final! We highly recommend upgrading from 1.4.0.Final and earlier versions as this release includes bug fixes and enhancements to several Debezium connectors which includes some of the following:</summary></entry><entry><title type="html">Debezium 1.4.0.Final Released</title><link href="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Final Released"/><published>2021-01-07T00:00:00+00:00</published><updated>2021-01-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/07/debezium-1-4-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release concludes the major work put into Debezium over the last three months. Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.4.0.Final%2C%201.4.0.Alpha1%2C%201.4.0.Beta1%2C%201.4.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;117 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;New &lt;a href=&quot;/documentation/reference/connectors/vitess.html&quot;&gt;Vitess&lt;/a&gt; connector, featured in an in-depth &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;blog post&lt;/a&gt; by Kewei Shang&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Fine-grained selection of snapshotted tables&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; completion hook&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Distributed &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;Tracing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL support for &lt;em&gt;create&lt;/em&gt; or &lt;em&gt;read&lt;/em&gt; records emitted during snapshot&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Many Oracle &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;Logminer adapter&lt;/a&gt; improvements&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Full support for Oracle JDBC connection strings&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improved reporting of DDL errors&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to previous release announcements (&lt;a href=&quot;/blog/2020/10/23/debezium-1-4-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/11/17/debezium-1-4-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/09/debezium-1-4-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/17/debezium-1-4-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details. Since the CR1 release just before the holidays, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;focused&lt;/a&gt; on addressing some remaining bugs and improvements.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thank you to everyone involved in testing the previous releases, this is invaluable by spotting and addressing any problems with new features as well as regressions. And of course we&amp;#8217;d like to thank all the community members contributing to this release: &lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;, &lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;, &lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;, &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;, &lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;, &lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;, &lt;a href=&quot;https://github.com/martper2&quot;&gt;Martin Perez&lt;/a&gt;, &lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;, &lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt; &lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;, &lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;, &lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;, &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;, &lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;, &lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;, &lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;, &lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;, &lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;, &lt;a href=&quot;https://github.com/yrodiere&quot;&gt;Yoann Rodière&lt;/a&gt;, and &lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, more than 245 individuals have contributed to the Debezium project and the number of Debezium &lt;a href=&quot;/community/users/&quot;&gt;users&lt;/a&gt; continues to grow. As we usher in 2021, check out our &lt;a href=&quot;/blog/2021/01/06/debezium-2020-recap/&quot;&gt;recap of Debezium in 2020&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With 1.4 Final released, planning for the 1.5 version (due by the end of March) is currently underway. The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; is still being discussed, so be sure to let us know about your requirements and feature requests. Some of the things we&amp;#8217;re considering for this next release are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Continued stability and improvements to the new LogMiner-based implementation for Oracle&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until then remain safe, it&amp;#8217;s onwards and upwards from here!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am pleased to announce the release of Debezium 1.4.0.Final! This release concludes the major work put into Debezium over the last three months. Overall, the community fixed 117 issues during that time, including the following key features and changes: New Vitess connector, featured in an in-depth blog post by Kewei Shang Fine-grained selection of snapshotted tables PostgreSQL Snapshotter completion hook Distributed Tracing MySQL support for create or read records emitted during snapshot Many Oracle Logminer adapter improvements Full support for Oracle JDBC connection strings Improved reporting of DDL errors</summary></entry><entry><title type="html">Debezium in 2020 – The Recap!</title><link href="https://debezium.io/blog/2021/01/06/debezium-2020-recap/" rel="alternate" type="text/html" title="Debezium in 2020 – The Recap!"/><published>2021-01-06T00:00:00+00:00</published><updated>2021-01-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/06/debezium-2020-recap</id><content type="html" xml:base="https://debezium.io/blog/2021/01/06/debezium-2020-recap/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A Happy New Year to the Debezium Community!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy. With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, some facts and numbers for you stats lovers out there:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;After the release of &lt;a href=&quot;/blog/2019/12/18/debezium-1-0-0-final-released/&quot;&gt;Debezium 1.0&lt;/a&gt; in December 2019, we successfully released a stable Debezium version at the end of each quarter, with preview releases roughly every three weeks&lt;sup class=&quot;footnote&quot;&gt;[&lt;a id=&quot;_footnoteref_1&quot; class=&quot;footnote&quot; href=&quot;#_footnotedef_1&quot; title=&quot;View footnote.&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;About 1,400 commits in the core repo (plus many more in the other ones), 36 blog posts and release announcements, 166 threads on the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; (if the query in my Google inbox is to be trusted)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;About 100 new contributors, bringing the &lt;a href=&quot;https://github.com/debezium/debezium/blob/master/COPYRIGHT.txt&quot;&gt;overall number&lt;/a&gt; of people contributing to the Debezium core repo to 245, plus additional people contributing to the other repositories of the Debezium GitHub organization&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The first &lt;a href=&quot;https://developers.redhat.com/blog/2020/04/14/capture-database-changes-with-debezium-apache-kafka-connectors/&quot;&gt;GA release&lt;/a&gt; of the commercially supported Debezium offering by Red Hat, as part of &lt;a href=&quot;https://www.redhat.com/en/products/integration&quot;&gt;Red Hat Integration&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;/blog/2020/07/28/hello-debezium/&quot;&gt;Two&lt;/a&gt; &lt;a href=&quot;/blog/2020/10/27/hello-debezium/&quot;&gt;new&lt;/a&gt; members on the core engineering team&amp;#8201;&amp;#8212;&amp;#8201;the more, the merrier!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;About 1,600 additional GitHub ⭐s for the Debezium core repo, bringing the total number of star gazers to more than 4,100&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/github_stars_2020.png&quot; style=&quot;max-width:75%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While those figures give a nice impression of the overall activity of Debezium, they don&amp;#8217;t really tell &lt;em&gt;what&lt;/em&gt; has been happening exactly. What&amp;#8217;s behind the numbers? Here are some of my personal Debezium highlights from the last year:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Two new, community-led Debezium connectors for &lt;a href=&quot;https://github.com/debezium/debezium-connector-db2/&quot;&gt;Db2&lt;/a&gt; and &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess&lt;/a&gt;; a big shout-out to the engineers of &lt;a href=&quot;/blog/2020/03/05/db2-cdc-approaches/&quot;&gt;IBM&lt;/a&gt; and &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;Bolt&lt;/a&gt;, respectively, for stepping up and taking the lead of these connectors!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Besides these new connectors, each of the releases brought a wide range of new features; some of the things I&amp;#8217;m most excited about are &lt;a href=&quot;/documentation/reference/1.2/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; for integrating Debezium with message infrastructure like Apache Pulsar, AWS Kinesis, Google Cloud Pub/Sub, and Azure Event Hubs, the &lt;a href=&quot;/documentation/reference/1.1/integrations/outbox.html&quot;&gt;Quarkus extension&lt;/a&gt; for implementing the outbox pattern, the new &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based connector implementation&lt;/a&gt; for ingesting change events from Oracle, transaction markers, support for CloudEvents, and so much more!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Integration of Debezium by multiple open-source projects, e.g. &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/formats/debezium.html&quot;&gt;Apache Flink&lt;/a&gt;, &lt;a href=&quot;https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time&quot;&gt;Spring Cloud Stream&lt;/a&gt;, &lt;a href=&quot;https://jet-start.sh/docs/tutorials/cdc&quot;&gt;Hazecast Jet&lt;/a&gt;, and &lt;a href=&quot;https://camel.apache.org/blog/2020/05/CdcWithCamelAndDebezium/&quot;&gt;Apache Camel&lt;/a&gt;. Further integrators of Debezium include &lt;a href=&quot;https://materialize.io/docs/third-party/debezium/&quot;&gt;Materialize&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/how-to-move-data-from-mysql-to-bigquery&quot;&gt;Google Cloud DataFlow&lt;/a&gt; and &lt;a href=&quot;https://devcenter.heroku.com/articles/heroku-data-connectors&quot;&gt;Heroku’s streaming data connectors&lt;/a&gt;. Here on this blog, we also discussed how to integrate and use Debezium with technologies such as &lt;a href=&quot;/blog/2020/03/19/integration-testing-for-change-data-capture-with-testcontainers/&quot;&gt;Testcontainers&lt;/a&gt;, the &lt;a href=&quot;/blog/2020/04/09/using-debezium-with-apicurio-api-schema-registry/&quot;&gt;Apicurio API and schema registry&lt;/a&gt;, and &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;OpenTracing&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium being &lt;a href=&quot;https://www.thoughtworks.com/radar/platforms/debezium&quot;&gt;listed at &quot;Trial&quot; level&lt;/a&gt; on the ThoughtWorks Tech Radar&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A proof-of-concept for a &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;graphical user interface for configuring and operating Debezium&lt;/a&gt;; stay tuned for more details here, as this is currently in the process of being built out for other connectors&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The year also brought a large number of blog posts and presentations from the community about their experiences with Debezium. You can find our full list of Debezium-related resources &lt;a href=&quot;debezium.io/documentation/online-resources/&quot;&gt;here&lt;/a&gt; (please send a PR for adding anything you think should be listed there). Some contents I particularly enjoyed include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://static.sched.com/hosted_files/ossna2020/c6/Managing Data Consistency with Debezium.pdf&quot;&gt;&quot;Managing Data Consistency Among Microservices with Debezium&quot;&lt;/a&gt; by Justin Chao&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;&quot;Change Data Capture with Flink SQL and Debezium&quot;&lt;/a&gt; by Marta Paes&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=6nU9i022yeY&quot;&gt;&quot;Microservices &amp;amp; Data: Implementing the Outbox Pattern with Debezium&quot;&lt;/a&gt; by Thorben Janssen&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.systemcraftsman.com/2020/11/30/asap-the-storified-demo-of-introduction-to-debezium-and-kafka-on-kubernetes/&quot;&gt;&quot;ASAP! – The Storified Demo of Introduction to Debezium and Kafka on Kubernetes&quot;&lt;/a&gt; by Aykut Bulgu&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://elephanttamer.net/?p=50&quot;&gt;&quot;Setting up PostgreSQL for Debezium&quot;&lt;/a&gt; by Michał Mackiewicz&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@midhunsukumaran.mec/a-year-and-a-half-with-debezium-f4f323b4909d&quot;&gt;&quot;A year and a half with Debezium: CDC With MySQL&quot;&lt;/a&gt; by Midhun Sukumaran&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;&quot;Debezium on OpenShift Cheat Sheet&quot;&lt;/a&gt; by Abdellatif Bouchama&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;&quot;Implementing the Transactional Outbox pattern with Debezium in Quarkus&quot;&lt;/a&gt; by Iain Porter&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.confluent.io/blog/cdc-and-streaming-analytics-using-debezium-kafka/&quot;&gt;&quot;Analysing Changes with Debezium and Kafka Streams&quot;&lt;/a&gt; by Mike Fowler&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@bogdan.dina03/de-coupling-yourself-507a15fa100d&quot;&gt;&quot;(De)coupling yourself&quot;&lt;/a&gt; by Dina Bogdan&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@limadelrey/kafka-connect-how-to-create-a-real-time-data-pipeline-using-change-data-capture-cdc-c60e06e5306a&quot;&gt;&quot;Kafka Connect: How to create a real time data pipeline using Change Data Capture (CDC)&quot;&lt;/a&gt; by Francisco Lima&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://dev.to/abhirockzz/tutorial-set-up-a-change-data-capture-architecture-on-azure-using-debezium-postgres-and-kafka-49h6&quot;&gt;&quot;Tutorial: Set up a Change Data Capture architecture on Azure using Debezium, Postgres and Kafka &quot;&lt;/a&gt; by Abhishek Gupta&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It is just so amazing to see how engaged and helpful this community is; A big thank you to everyone for writing and talking about your experiences with Debezium and change data capture!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I think 2020 has been a great year for the Debezium community, and I couldn&amp;#8217;t be happier about all the things we&amp;#8217;ve achieved together. Again, a huge thank you to each and everyone in the community contributing to the project, be it via by implementing features and bug fixes, reporting issues, engaging in discussions, answering questions on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/debezium&quot;&gt;Stack Overflow&lt;/a&gt;, helping to spread the word in blog posts and conference talks, or otherwise!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;What&amp;#8217;s on the roadmap for this year? It&amp;#8217;s fair to say: &quot;A lot&quot; :) E.g. we&amp;#8217;d like to rework the way snapshots are done: they should be parallelizeable, updates to the include/exclude filters should be possible, and more. The Debezium UI will see substantial expansion and improvements. We&amp;#8217;re planning to conduct a systematic performance profiling and improvements of identified bottlenecks. There may be official support for MariaDB, as well as an operator for running Debezium Server on Kubernetes. Plus some super-cool things I cannot talk about at this point yet :)&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Onwards and Upwards!&lt;/p&gt; &lt;/div&gt; &lt;div id=&quot;footnotes&quot;&gt; &lt;hr&gt; &lt;div class=&quot;footnote&quot; id=&quot;_footnotedef_1&quot;&gt; &lt;a href=&quot;#_footnoteref_1&quot;&gt;1&lt;/a&gt;. Where is Debezium 1.4, you ask? The agile bunch we are, we adhered to the &quot;Individuals over processes&quot; principle and decided to move this release to later this week, due to the holiday break :) &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="discussion"/><summary type="html">A Happy New Year to the Debezium Community! May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy. With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year. First, some facts and numbers for you stats lovers out there:</summary></entry><entry><title type="html">Debezium 1.4.0.CR1 Released</title><link href="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.CR1 Released"/><published>2020-12-17T00:00:00+00:00</published><updated>2020-12-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release focuses primarily on polishing the 1.4 release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.CR1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;15 issues&lt;/a&gt; for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A number of bugs were fixed, e.g.:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Document &quot;database.oracle.version&quot; option &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2603&quot;&gt;DBZ-2603&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Move Cassandra connector to separate repository &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2636&quot;&gt;DBZ-2636&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Remove link in MySQL docs section that points to the same section &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2710&quot;&gt;DBZ-2710&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Invalid column name should fail connector with meaningful message &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2836&quot;&gt;DBZ-2836&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Fix typos in downstream ModuleID declarations in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2838&quot;&gt;DBZ-2838&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Duplicate anchor ID in partials/ref-connector-monitoring-snapshot-metrics.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2839&quot;&gt;DBZ-2839&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle schema history events fail on partitioned table &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2841&quot;&gt;DBZ-2841&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Fix additional typo in ModuleID declaration in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2843&quot;&gt;DBZ-2843&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Edit modularization annotations in logging.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2846&quot;&gt;DBZ-2846&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;outbox extension emits UPDATE events when delete is disabled &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2847&quot;&gt;DBZ-2847&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Update Groovy version to 3.0.7 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2850&quot;&gt;DBZ-2850&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.4 Final should be out the first week of January. Until then, we wish everyone a safe and happy holiday season!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongodb"/><category term="sqlserver"/><category term="cassandra"/><category term="db2"/><category term="oracle"/><category term="vitess"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.CR1! This release focuses primarily on polishing the 1.4 release.</summary></entry><entry><title type="html">Distributed Tracing with Debezium</title><link href="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/" rel="alternate" type="text/html" title="Distributed Tracing with Debezium"/><published>2020-12-16T11:00:00+00:00</published><updated>2020-12-16T11:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/">&lt;div id=&quot;preamble&quot;&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The current pattern in application development gravitates toward microservices and microservices architecture. While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state. This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path. This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context. &lt;a href=&quot;https://microservices.io/patterns/observability/distributed-tracing.html&quot;&gt;Distributed Tracing&lt;/a&gt; comes here to the rescue.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;distributed_tracing&quot;&gt;Distributed Tracing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;. SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And this is where Debezium becomes part of the picture. Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into. How long does it take for change events to flow from source database to sink systems? Where is the most time spent in the pipeline? Are there any anomalies like spikes in end-to-end lags? The integration of distributed tracing with Debezium can help to answer these questions.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;opentracing&quot;&gt;OpenTracing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the &lt;a href=&quot;https://opentracing.io/&quot;&gt;OpenTracing&lt;/a&gt; specification. OpenTracing is an incubating project of &lt;a href=&quot;https://www.cncf.io/&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; which guarantees that the user will be free of any vendor lock-in by adhering to an open standard.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The OpenTracing project is in the process of being merged with OpenCensus to the improved &lt;a href=&quot;https://opentelemetry.io/&quot;&gt;OpenTelemetry&lt;/a&gt; standard. Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus), but it will use and support OpenTelemetry in the future, too.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A distributed trace in OpenTracing consists of a set of spans. Each span represents a logical unit of work executed. The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;OpenTracing is only the specification and the instrumentation API. To use it you need to have an implementation, too. While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the &lt;a href=&quot;https://www.jaegertracing.io/&quot;&gt;Jaeger&lt;/a&gt; distributed tracing platform.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application. The Jaeger &lt;a href=&quot;https://www.jaegertracing.io/docs/1.21/getting-started/#all-in-one&quot;&gt;All-In-One&lt;/a&gt; container image will be used to simplify the deployment.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_and_opentracing&quot;&gt;Debezium and OpenTracing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium integration with OpenTracing consists of three distinct components:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;EventDispatcher&lt;/code&gt; in the &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Debezium outbox extension&lt;/a&gt; for Quarkus applications&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;EventRouter&lt;/code&gt; &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;SMT&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The first one is intended for general use. The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;outbox_distributed_tracing&quot;&gt;Outbox Distributed Tracing&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing. The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;When an event arrives at &lt;code&gt;EventDispatcher&lt;/code&gt; a new span &lt;code&gt;outbox-write&lt;/code&gt; is created. It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The span metadata is exported into a distinct field of the outbox event.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The outbox event is written to the outbox table.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Event Router SMT receives the event and imports the span metadata from the field&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Two new spans are created&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;db-log-write&lt;/code&gt; with its start timestamp set to database write timestamp. The fields from the &lt;code&gt;source&lt;/code&gt; block are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;debezium-read&lt;/code&gt; with its start time set to the processing timestamp. Fields from the envelope are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;demo&quot;&gt;Demo&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/outbox&quot;&gt;outbox example&lt;/a&gt; was extended with distributed tracing support to demonstrate the functionality. This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This demo uses the &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt; container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To try it yourself you need to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;check out the repository and switch to the &lt;code&gt;outbox&lt;/code&gt; directory&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;build the services&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;$ mvn clean install&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;deploy the application&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;export DEBEZIUM_VERSION=1.4 docker-compose up --build&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;register a Debezium connector to listen on the outbox table&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;$ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json HTTP/1.1 201 Created&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;execute multiple business requests&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;$ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json $ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;check the &lt;a href=&quot;http://localhost:16686/&quot;&gt;Jaeger UI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After all the steps above were completed you should see an introduction screen of the Jaeger UI:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-main.png&quot; class=&quot;responsive-image&quot; alt=&quot;Jaeger intro&quot;&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Filter on &lt;code&gt;order-service&lt;/code&gt; as a service and click on &lt;code&gt;Find Traces&lt;/code&gt;. Two traces should be available:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-service.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Click on the &lt;code&gt;addOrder&lt;/code&gt; service. A tree will open that displays how the initial request incoming via REST API was&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;written to the database by the outbox extension&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;read by Debezium and processed by outbox SMT&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;written to a Kafka topic&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;read from a Kafka topic by &lt;code&gt;shipment-service&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;processed in the different &lt;code&gt;shipment-service&lt;/code&gt; business methods&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-trace.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Click on the &lt;code&gt;db-log-write&lt;/code&gt; and &lt;code&gt;debezium-read&lt;/code&gt; spans. The &lt;strong&gt;tags&lt;/strong&gt; of each of them contain extracted Debezium-related metadata like &lt;code&gt;operation&lt;/code&gt; or &lt;code&gt;source&lt;/code&gt; fields:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;imageblock centered-image&quot;&gt; &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-debezium-details.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it. We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While this example was focused on the specific use case of microservices data exchange via the outbox pattern, Debezium integrates with distributed tracing also independently of this particular pattern. By means of the &lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT, Debezium can produce spans representing the time of the change in the source database itself, as well as the time of processing the event by the Debezium connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases. Your feedback on this new functionality is highly welcomed!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="tracing"/><category term="jaeger"/><summary type="html">The current pattern in application development gravitates toward microservices and microservices architecture. While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production. Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state. This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes. You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path. This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context. Distributed Tracing comes here to the rescue. Distributed Tracing Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;. SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs. And this is where Debezium becomes part of the picture. Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into. How long does it take for change events to flow from source database to sink systems? Where is the most time spent in the pipeline? Are there any anomalies like spikes in end-to-end lags? The integration of distributed tracing with Debezium can help to answer these questions. OpenTracing There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the OpenTracing specification. OpenTracing is an incubating project of Cloud Native Computing Foundation which guarantees that the user will be free of any vendor lock-in by adhering to an open standard. The OpenTracing project is in the process of being merged with OpenCensus to the improved OpenTelemetry standard. Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus), but it will use and support OpenTelemetry in the future, too. A distributed trace in OpenTracing consists of a set of spans. Each span represents a logical unit of work executed. The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span. OpenTracing is only the specification and the instrumentation API. To use it you need to have an implementation, too. While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the Jaeger distributed tracing platform. Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application. The Jaeger All-In-One container image will be used to simplify the deployment. Debezium and OpenTracing The Debezium integration with OpenTracing consists of three distinct components: ActivateTracingSpan SMT EventDispatcher in the Debezium outbox extension for Quarkus applications EventRouter SMT The first one is intended for general use. The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced. Outbox Distributed Tracing The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing. The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes. In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created: When an event arrives at EventDispatcher a new span outbox-write is created. It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available. The span metadata is exported into a distinct field of the outbox event. The outbox event is written to the outbox table. The Event Router SMT receives the event and imports the span metadata from the field Two new spans are created db-log-write with its start timestamp set to database write timestamp. The fields from the source block are added to the span as tags. debezium-read with its start time set to the processing timestamp. Fields from the envelope are added to the span as tags. Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata. Demo The outbox example was extended with distributed tracing support to demonstrate the functionality. This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern. This demo uses the Strimzi container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level. To try it yourself you need to: check out the repository and switch to the outbox directory build the services $ mvn clean install deploy the application export DEBEZIUM_VERSION=1.4 docker-compose up --build register a Debezium connector to listen on the outbox table $ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json HTTP/1.1 201 Created execute multiple business requests $ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json $ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json check the Jaeger UI After all the steps above were completed you should see an introduction screen of the Jaeger UI: Filter on order-service as a service and click on Find Traces. Two traces should be available: Click on the addOrder service. A tree will open that displays how the initial request incoming via REST API was written to the database by the outbox extension read by Debezium and processed by outbox SMT written to a Kafka topic read from a Kafka topic by shipment-service processed in the different shipment-service business methods Click on the db-log-write and debezium-read spans. The tags of each of them contain extracted Debezium-related metadata like operation or source fields: Conclusion In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it. We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration. While this example was focused on the specific use case of microservices data exchange via the outbox pattern, Debezium integrates with distributed tracing also independently of this particular pattern. By means of the ActivateTracingSpan SMT, Debezium can produce spans representing the time of the change in the source database itself, as well as the time of processing the event by the Debezium connector. Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases. Your feedback on this new functionality is highly welcomed!</summary></entry><entry><title type="html">Debezium 1.4.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Beta1 Released"/><published>2020-12-09T00:00:00+00:00</published><updated>2020-12-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release includes support for distributed tracing, lowercase table and schema naming for Db2, specifying MySQL snapshot records as create or read operations, and enhancements to Vitess for nullable and primary key columns.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Beta1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;39 issues&lt;/a&gt; for this release. Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;distributed_tracing&quot;&gt;Distributed Tracing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In a nutshell, distributed tracing is a pattern used to profile and monitor applications to allow quick identification of failures or performance concerns. Tracing works by having each component in a distributed process contribute a block of metadata called a &quot;span&quot;. Each span contains unique details about that component&amp;#8217;s unit of work. Typically a full distributed trace consists of a sequence of multiple spans.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Distributed tracing in Debezium is enabled by using the &lt;strong&gt;ActivateTracingSpan&lt;/strong&gt; SMT:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;&quot;transforms&quot;: &quot;tracing&quot; &quot;transforms.tracing.type&quot;: &quot;io.debezium.transforms.tracing.ActivateTracingSpan&quot;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The above configuration will lead to the emitted message header containing the tracing key/value pairs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A blog post discussing the distributed tracing support in depth, including end-to-end tracing for microservices data exchange via the outbox pattern, will follow up shortly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;DDL parser: Allow stored procedure variables in LIMIT clause &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2692&quot;&gt;DBZ-2692&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Wrong mysql command in openshift dpeloyment docs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2746&quot;&gt;DBZ-2746&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;long running transaction will be abandoned and ignored &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2759&quot;&gt;DBZ-2759&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MS SQL Decimal with default value not matching the scale of the column definition cause exception &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2767&quot;&gt;DBZ-2767&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cassandra Connector doesn&amp;#8217;t shut down completely &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2768&quot;&gt;DBZ-2768&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL Parser fails for BINARY collation shortcut &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2771&quot;&gt;DBZ-2771&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;PostgresConnectorIT.shouldResumeStreamingFromSlotPositionForCustomSnapshot is failing for wal2json on CI &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2772&quot;&gt;DBZ-2772&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connector configuration property &quot;database.out.server.name&quot; is not relevant for Logminer implementation but cannot be omitted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2801&quot;&gt;DBZ-2801&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CHARACTER VARYING mysql identifier for varchar is not supported in debezium &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2821&quot;&gt;DBZ-2821&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;try-with-resources should not be used when OkHttp Response object is returned &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2827&quot;&gt;DBZ-2827&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;EmbeddedEngine does not shutdown when commitOffsets is interrupted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2830&quot;&gt;DBZ-2830&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Rename user command parsing fails &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2743&quot;&gt;DBZ-2743&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;, &lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;, &lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;, and &lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongodb"/><category term="sqlserver"/><category term="cassandra"/><category term="db2"/><category term="oracle"/><category term="vitess"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.Beta1! This release includes support for distributed tracing, lowercase table and schema naming for Db2, specifying MySQL snapshot records as create or read operations, and enhancements to Vitess for nullable and primary key columns.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha2 Released</title><link href="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha2 Released"/><published>2020-11-17T00:00:00+00:00</published><updated>2020-11-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This second pass of the 1.4 release line provides a few useful new features:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;New API hook for the PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; interface&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Field renaming using &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT&amp;#8217;s &lt;code&gt;add.fields&lt;/code&gt; and &lt;code&gt;add.headers&lt;/code&gt; configurations&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;37 issues&lt;/a&gt; for this release. Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;postgresql_snapshotter_completion_hook&quot;&gt;PostgreSQL Snapshotter completion hook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; API is a contract that allows for the customization of the snapshot process. This API was introduced in 0.9.3.Final and has continued to evolve in the releases since.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A new backward compatible completion hook has been added:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;void snapshotCompleted()&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This new hook is called by the snapshot process when the snapshot has concluded, allowing implementations to clean-up any resources it may have allocated prior streaming changes.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;extractnewrecordstate_smt_field_renaming_support&quot;&gt;ExtractNewRecordState SMT field renaming support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the features of the &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT is that the transformation can retain parts of the original message in the transformed message&amp;#8217;s header or payload. This release extends this feature to allow specifying a new name to be used for the field when added to the message header or payload.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, to add the source database&amp;#8217;s event timestamp to the message header using the new renaming feature, the SMT configuration would be:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;transforms=unwrap transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState transforms.unwrap.add.headers=source.ts_ms:timestamp&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The format of the &lt;code&gt;add.headers&lt;/code&gt; and &lt;code&gt;add.fields&lt;/code&gt; configuration options have been improved to support a comma-separated list of fields with the syntax &lt;code&gt;&amp;lt;OLD_FIELD&amp;gt;[:NEW_FIELD]&lt;/code&gt;. The above emitted message&amp;#8217;s headers would now contain &lt;code&gt;__timestamp&lt;/code&gt; rather than the default &lt;code&gt;__source.ts_ms&lt;/code&gt; field.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This syntax improvement remains backward compatible.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Oracle throw &quot;no snapshot found based on specified time&quot; when running flashback query &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exception when PK definition precedes column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2580&quot;&gt;DBZ-2580&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Patroni can&amp;#8217;t stop PostgreSQL when Debezium is streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2617&quot;&gt;DBZ-2617&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ChangeRecord informations don&amp;#8217;t connect with the TableSchema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2679&quot;&gt;DBZ-2679&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL connector fails on a zero date &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2682&quot;&gt;DBZ-2682&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle LogMiner doesn&amp;#8217;t support partition tables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2683&quot;&gt;DBZ-2683&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DB2 doesn&amp;#8217;t start reliably in OCP &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2693&quot;&gt;DBZ-2693&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Dropped columns cause NPE in SqlServerConnector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2716&quot;&gt;DBZ-2716&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Timestamp default value in 'yyyy-mm-dd' format fails MySQL connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2726&quot;&gt;DBZ-2726&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connection timeout on write should retry &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2727&quot;&gt;DBZ-2727&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;No viable alternative at input error on &quot;min&quot; column &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SQLServer CI error in SqlServerConnectorIT.whenCaptureInstanceExcludesColumnsAndColumnsRenamedExpectNoErrors:1473 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2747&quot;&gt;DBZ-2747&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;debezium-connector-db2: DB2 SQL Error: SQLCODE=-206 on DB2 for z/OS &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2755&quot;&gt;DBZ-2755&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;no viable alternative at input 'alter table &lt;code&gt;order&lt;/code&gt; drop CONSTRAINT' &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2760&quot;&gt;DBZ-2760&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Tests are failing on macos &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2762&quot;&gt;DBZ-2762&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;, &lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;, &lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;, &lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;, &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;, &lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;, &lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;, &lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;, &lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;, &lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongodb"/><category term="sqlserver"/><category term="cassandra"/><category term="db2"/><category term="oracle"/><category term="vitess"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.4.0.Alpha2! This second pass of the 1.4 release line provides a few useful new features: New API hook for the PostgreSQL Snapshotter interface Field renaming using ExtractNewRecordState SMT&amp;#8217;s add.fields and add.headers configurations</summary></entry><entry><title type="html">Debezium 1.3.1.Final Released</title><link href="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.1.Final Released"/><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.1.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugs that were reported after the 1.3 release. Most importantly, the following bugs were fixed related to the &lt;a href=&quot;/docs/connectors/oracle&quot;&gt;Debezium connector for Oracle&lt;/a&gt; LogMiner adapter thanks to the continued feedback by the Debezium community.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;SQLExceptions thrown when using Oracle LogMiner (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;LogMiner mining session stopped due to WorkerTask killed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;) &lt;!-- more --&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, there were other bugs identified and fixed in this release, including:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[MongoDB] Sanitization of field names not applied to nested struct fields (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] MariaDB nextval function is not supported by grammar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MSSQL] Hide stack-trace when default value cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2642&quot;&gt;DBZ-2642&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] Upgrade JDBC driver to 8.0.19 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2626&quot;&gt;DBZ-2626&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] ANTLR parser fails to interpret &lt;code&gt;BLOB(size)&lt;/code&gt; types (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] Should allow non-ascii character in SQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] Connector fails if non-existing view with same name as table is dropped (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[MySQL] No viable alternative at input error when column uses aggregate function names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] No snapshot found based on specified time (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[PostgreSQL] WAL logs are not properly flushed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Server] Event Hubs plugin support (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.1.Final&quot;&gt;14 issues&lt;/a&gt; were resolved in this release. Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to everyone who helped test and identify these bugs. The team appreciates the invaluable feedback the community continually provides!&lt;/p&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.1.Final! This release primarily focuses on bugs that were reported after the 1.3 release. Most importantly, the following bugs were fixed related to the Debezium connector for Oracle LogMiner adapter thanks to the continued feedback by the Debezium community. SQLExceptions thrown when using Oracle LogMiner (DBZ-2624) LogMiner mining session stopped due to WorkerTask killed (DBZ-2629)</summary></entry><entry><title type="html">Streaming Vitess at Bolt</title><link href="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/" rel="alternate" type="text/html" title="Streaming Vitess at Bolt"/><published>2020-11-04T16:19:59+00:00</published><updated>2020-11-04T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt</id><content type="html" xml:base="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&quot;https://medium.com/bolt-labs/streaming-vitess-at-bolt-f8ea93211c3f&quot;&gt;Bolt Labs Engineering blog&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Traditionally, MySQL has been used to power most of the backend services at &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt;. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once data is persisted to the database, we use the &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL Connector&lt;/a&gt; to &lt;a href=&quot;https://www.confluent.io/blog/how-bolt-adopted-cdc-with-confluent-for-real-time-data-and-analytics/&quot;&gt;capture data change events&lt;/a&gt; and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices. &lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess_at_bolt&quot;&gt;Vitess at Bolt&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Bolt has grown considerably over the past few years, and so did the volume of data written to MySQL. Manual database sharding has become quite an expensive and long-lasting process prone to errors. So we started to evaluate more scalable databases, one of which is &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;. Vitess is an open-source database clustering system that is based on MySQL and provides horizontal scalability for it. Originated and battle-tested at YouTube, it was later open-sourced and is used by companies like Slack, Github, JD.com to power their backend storage. It combines important MySQL features with the scalability of a NoSQL database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the most important features that Vitess provides is its built-in sharding. It allows the database to grow horizontally by adding new shards in a way that is transparent to back-end application logic. To your application, Vitess appears like a giant single database, but in fact data is partitioned into multiple physical shards behind the scenes. For any table, an arbitrary column can be chosen as the sharding key, and all inserts and updates will be seamlessly directed to a proper shard by Vitess itself.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; below illustrates how back-end services interact with Vitess. At a high level, services connect to the stateless VTGate instances through a load balancer. Each VTGate has the Vitess cluster’s topology cached in its memory and redirects queries to the correct shards and the correct VTTablet (and its underlying MySQL instance) within the shards. More on VTTablet is written below.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/vitess/vitess_architecture.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. Vitess architecture. Reference: &lt;a href=&quot;https://www.planetscale.com/vitess&quot; class=&quot;bare&quot;&gt;https://www.planetscale.com/vitess&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other useful features provided by Vitess are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Failover (a.k.a. Reparenting) is easy and transparent for clients. Clients only talk to a VTGate who takes care of failover and service discovery of the new primary transparently.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It automatically rewrites “problematic” queries that could potentially cause database performance degradation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It has a caching mechanism that prevents duplicate queries to reach the underlying MySQL database simultaneously. Only one query will reach the database and its result will be cached and returned to answer duplicate queries.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It has its connection pool and eliminates the high-memory overhead of MySQL connections. As a result, it can easily handle thousands of connections at the same time.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connection timeout and transaction timeout can be configured.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It has minimal downtime when doing &lt;a href=&quot;https://vitess.io/docs/user-guides/configuration-advanced/resharding/&quot;&gt;resharding&lt;/a&gt; operations.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Its VStream feature can be used by downstream CDC applications to read change events from Vitess.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;streaming_vitess_options&quot;&gt;Streaming Vitess Options&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The ability to capture data changes and publish them to Apache Kafka was one of the requirements for adopting Vitess at Bolt. There were several different options we’ve considered.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;option_1_using_debezium_mysql_connector&quot;&gt;Option 1: Using Debezium MySQL Connector&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Applications connect to Vitess VTGate to send queries. VTGate supports the MySQL protocol and has a SQL parser. You can use any MySQL client (e.g. JDBC) to connect to VTGate, which redirects your query to the correct shard and returns the result to your client.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, VTGate is not equal to a MySQL instance, it is rather a stateless proxy to various MySQL instances. For the MySQL connector to receive change events, the Debezium MySQL connector needs to connect to a real MySQL instance. To make it more obvious, VTGate also has some known &lt;a href=&quot;https://vitess.io/docs/reference/compatibility/mysql-compatibility/&quot;&gt;compatibility&lt;/a&gt; issues, which makes connecting to VTGate different from MySQL.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Another option is to use the Debezium MySQL Connector to connect directly to the underlying MySQL instances of different shards. It has its advantages and disadvantages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One advantage is that for an unsharded keyspace (Vitess&amp;#8217;s terminology for a database), the MySQL Connector can continue to work correctly and we don&amp;#8217;t need to include additional logic or specific implementation. It should just work fine.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the biggest disadvantages is that resharding operations would become more complex. For example, the GTID of the original MySQL instance would change when resharded, and the MySQL connector depends on the GTID to work correctly. We also believe that having the MySQL connector connected directly to each underlying MySQL instance defies the purpose of Vitess&amp;#8217;s operational simplicity as a new connector has to be added (or removed) each time resharding is done. Not to mention that such operation would lead to data duplication inside Kafka brokers.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;option_2_using_jdbc_source_connector&quot;&gt;Option 2: Using JDBC Source Connector&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ve also considered using the &lt;a href=&quot;https://docs.confluent.io/current/connect/kafka-connect-jdbc/source-connector/index.html&quot;&gt;JDBC Source Connector&lt;/a&gt;. It allows sourcing data from any relational databases that support the JDBC driver into Kafka. Therefore, it is compatible with Vitess VTGate. It has its advantages and disadvantages as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Advantages:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;It is compatible with VTGate.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It handles Vitess resharding operation better. During resharding operation, reads are simply automatically redirected (by VTGate) to the target shards. It won&amp;#8217;t generate any duplicates or lose any data.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Disadvantages:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;It is poll-based, meaning that the connector polls the database for new change events on a defined interval (typically every few seconds). This means that we would have a much higher latency, compared to the Debezium MySQL Connector.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Its offsets are managed by either the table&amp;#8217;s incremental primary key or one of the table&amp;#8217;s timestamp columns. If we use the timestamp column for offset, we&amp;#8217;d have to create a secondary-index of the timestamp column for each table. This adds more constraints on our backend services. If we use the incremental primary key, we would miss the change events for row-updates because the primary key is simply not updated.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The topic name created by the JDBC connector doesn&amp;#8217;t include the table&amp;#8217;s schema name. Using the &lt;code&gt;topic.prefix&lt;/code&gt; connector configuration would mean that we&amp;#8217;ll have one connector per schema. At Bolt, we have a large number of schemas, which means we would need to create a large number of JDBC Source Connectors.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;At Bolt, our downstream applications are already set up to use Debezium&amp;#8217;s data formats and topic naming conventions, e.g. we&amp;#8217;d need to change our downstream application&amp;#8217;s decoding logic to the new data formats.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Row deletes are not captured.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;option_3_using_vstream_grpc&quot;&gt;Option 3: Using VStream gRPC&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;VTGate exposes a gRPC service called VStream. It is a server-side streaming service. Any gRPC client can subscribe to the &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;VStream&lt;/a&gt; service to get a continuous stream of change events from the underlying MySQL instances. The change events that VStream emits have similar information to the MySQL binary logs of the underlying MySQL instances. A single VStream can even subscribe to multiple shards for a given keyspace, making it quite a convenient API to build CDC tools.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Behind the scene, as shown in &lt;em&gt;Figure 2&lt;/em&gt;, VStream reads change events from multiple &lt;a href=&quot;https://vitess.io/docs/reference/programs/vttablet/&quot;&gt;VTTablets&lt;/a&gt;, one VTTablet per shard. Therefore, it doesn’t send duplicates from multiple VTTablets for a given shard. Each VTTablet is a proxy to its MySQL instance. A typical topology would include one master VTTablet and its corresponding MySQL instance, and multiple replica VTTablets, each of which is the proxy of its own replica MySQL instance. A VTTablet gets change events from its underlying MySQL instance and sends the change events back to VTGate, which in turn sends the change events back to VStream’s gRPC client.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When subscribing to the VStream service, the client can specify a VGTID and &lt;a href=&quot;https://vitess.io/docs/concepts/tablet/#tablet-types&quot;&gt;Tablet Type&lt;/a&gt; (e.g. &lt;code&gt;MASTER&lt;/code&gt;, &lt;code&gt;REPLICA&lt;/code&gt;). The VGTID tells the position from which VStream starts to send change events. Essentially, VGTID includes a list of (keyspace, shard, shard GTID) tuples. The Tablet Type tells which MySQL instance (primary or replica) in each shard do we read change events from.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/vitess/vstream.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. VStream architecture. Reference: &lt;a href=&quot;https://vitess.io/docs/concepts/vstream&quot; class=&quot;bare&quot;&gt;https://vitess.io/docs/concepts/vstream&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some advantages of using VStream gRPC are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;It is a simple way to receive change events from Vitess. It is also recommended in Vitess’s &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;documentation&lt;/a&gt; to use VStream to build CDC processes downstream.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;VTGate hides the complexity of connecting to various source MySQL instances.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It has low latency since change events are streamed to the client as soon as they happen.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The change events include not only inserts and updates, but also deletes.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Probably one of the biggest advantages is that the change events contain the schema of each table. So you don’t have to worry about fetching each table’s schema in advance (by, for example, parsing DDLs or querying the table’s definition).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The change events have VGTID included, which the CDC process can store and use as the offset from where to restart the CDC process next time.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Also importantly, VStream is designed to work well with Vitess operations such as &lt;a href=&quot;https://vitess.io/docs/user-guides/resharding/&quot;&gt;Resharding&lt;/a&gt; and &lt;a href=&quot;https://vitess.io/docs/user-guides/move-tables/&quot;&gt;Moving Tables&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are also some disadvantages:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Although it includes table schemas, some important information is still missing. For example, the &lt;code&gt;Enum&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt; column types don’t provide all the allowed values yet. This should be fixed in the next major release (Vitess 9) though.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Since VStream is a gRPC service, we cannot use the Debezium MySQL Connector out-of-the-box. However, it is quite straightforward to implement the gRPC client in other languages.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;All things considered, we’ve decided to use VStream gRPC to capture change events from Vitess and implement our Vitess Connector based on all the best practices of Debezium.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess_connector_deep_dive_and_open_source&quot;&gt;Vitess Connector Deep Dive and Open Source&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After we’ve decided to implement our Vitess Connector, we started looking into the implementation details of various Debezium source connectors (MySQL, Postgres, SQLServer), to borrow some ideas. Almost all of them are implemented using a common Connector development framework. So it was clear we should develop the Vitess connector on top of it. Given we are very active users of the MySql Connector and we benefit from it being open-sourced, as it allows us to contribute to it things we were missing ourselves. So we decided we want to give back to community and open-source the Vitess source connector code-base under the Debezium umbrella. Please feel free to learn more at &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Debezium Connector Vitess&lt;/a&gt;. We welcome and value any contributions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At a high level, as you can see below, connector instances are created in Kafka Connect workers. At the time of writing, you have two options to configure the connector to read from Vitess:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Option 1 (recommended):&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As shown in &lt;em&gt;Figure 3&lt;/em&gt;, each connector captures change events from all shards in a specific keyspace. If the keyspace is not sharded, the connector can still capture change events from the only shard in the keyspace. When it’s the first time that the connector starts, it reads from the current VGTID position of all shards in the keyspace. Because it subscribes to all shards, it continuously captures change events from all shards and sends them to Kafka. It automatically supports the Vitess Reshard operation, there is no data loss, nor duplication.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/vitess/vitess_connector_multi_shards.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 3. Each connector subscribes to all shards of a specific keyspace&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As shown in &lt;em&gt;Figure 4&lt;/em&gt;, each connector instance captures change events from a specific keyspace/shard pair. The connector instance gets the initial (the current) VGTID position of the keyspace/shard pair from VTCtld gRPC, which is another Vitess component. Each connector instance, independently, uses the VGTID it gets to subscribe to VStream gRPC and continuously capture change events from VStream and sends them to Kafka. To support the Vitess Reshard operation, you would need more manual operations.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/vitess/vitess_connector_single_shard.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 4. Each connector subscribes to one shard of a specific keyspace&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Internally, each connector task uses a gRPC thread to constantly receive change events from VStream and puts the events into an internal blocking queue. The connector task thread polls events out of the queue and sends them to Kafka, as can be seen in &lt;em&gt;Figure 5&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/vitess/vitess_connector_internal.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 5. How each connector task works internally&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;replication_challenges&quot;&gt;Replication Challenges&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While we were implementing the Vitess Connector and digging deeper into Vitess, we’ve also realized a few challenges.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;vitess_reshard&quot;&gt;Vitess Reshard&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Vitess connector supports the Vitess Reshard operation when the connector is configured to subscribe to all shards of a given keyspace. VStream sends a VGTID that contains the shard GTID for all shards. Vitess Resharding is transparent to users. Once it’s completed, Vitess will send the VGTID of the new shards. Therefore, the connector will use the new VGTID after reshard. However, you need to make sure that the connector is up and running when the reshard operation takes place. Especially please check that the offset topic of the connector has the new VGTID before deleting the old shards. This is because in case the old shards are deleted, VStream will not be able to recognize the VGTID from the old shards.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you decide to subscribe to one shard per connector, the connector does not provide out-of-the-box support for Vitess resharding. One manual workaround to support resharding is creating one new connector per target shard. For example, one new connector for the &lt;code&gt;commerce/-80&lt;/code&gt; shard, and another new connector for the &lt;code&gt;commerce/80-&lt;/code&gt; shard. Bear in mind that because they’re new connectors, by default, new topics will be created, however, you could use the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/topic-routing.html&quot;&gt;Debezium logical topic router&lt;/a&gt; to route the records to the same Kafka topics.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;offset_management&quot;&gt;Offset Management&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;VStream includes a VGTID event in its response. We save the VGTID as the offset in the Kafka offset topic, so when the connector restarts, we can start from the saved VGTID. However, in rare cases when a transaction includes a huge amount of rows, VStream batches the change events into multiple responses, and only the last response has the VGTID. In such cases, we don’t have the VGTID for every change event we receive. We have a few options to solve this particular issue:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;We can buffer all the change events in memory and wait for the last response that contains the VGTID to arrive. So all events will have the correct VGTID associated with them. A few disadvantages are that we’ll have higher latency before events are sent to Kafka. Also, memory usage could potentially increase quite a lot due to buffering. Buffering also adds complexity to the logic. We also have no control over the number of events VStream sends to us.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;We can use the latest VGTID we have, which is the VGTID from the previous VStream response. If the connector fails and restarts when processing such a big transaction, it’ll restart from the VGTID of the previous VStream response, thus reprocessing some events. Therefore, it has at-least-once event delivery semantics and it expects the downstream to be idempotent. Since most transactions are not big enough, most VStream responses will have VGTID in the response, so the chance of having duplicates is low. In the end, we chose this approach for its at-least-once delivery guarantee and its design simplicity.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;schema_management&quot;&gt;Schema Management&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;VStream’s response also includes a &lt;code&gt;FIELD&lt;/code&gt; event. It’s a special event that contains the schemas of the tables of which the rows are affected. For example, let&amp;#8217;s assume we have 2 tables, &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. If we insert a few rows into table &lt;code&gt;A&lt;/code&gt;, the &lt;code&gt;FIELD&lt;/code&gt; event will only contain table &lt;code&gt;A&lt;/code&gt;’s schema. The VStream is smart enough to only include the &lt;code&gt;FIELD&lt;/code&gt; event whenever necessary. For example, when a VStream client reconnects, or when a table’s schema is changed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The older version of VStream includes only the column type (e.g. &lt;code&gt;Integer&lt;/code&gt;, &lt;code&gt;Varchar&lt;/code&gt;), no additional information such as whether the column is the primary key, whether the column has a default value, &lt;code&gt;Decimal&lt;/code&gt; type’s scale and precision, &lt;code&gt;Enum&lt;/code&gt; type’s allowed values, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The newer version (Vitess 8) of VStream starts to include more information on each column. This will help the connector to deserialize more accurately certain types and have a more precise schema in the change events sent to Kafka.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;future_development_work&quot;&gt;Future Development Work&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;We can use VStream&amp;#8217;s API to start streaming from the latest VGTID position, instead of getting the initial VGTID position from VTCtld gRPC. Doing so would eliminate the dependency from VTCtld.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;We don’t support automatically extracting the primary keys from the change events yet. Currently, by default, all change events sent to Kafka have &lt;code&gt;null&lt;/code&gt; as the key, unless the &lt;code&gt;message.key.columns&lt;/code&gt; connector configuration is specified. Vitess recently added flags of each column in the VStream FIELD event, which allows us to implement this feature soon.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add support for initial snapshots to capture all existing data before streaming changes.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MySQL has been used to power most of our backend services at Bolt. Due to the considerable growth of the volume of data and operational complexity, Bolt started to evaluate Vitess for its scalability and its built-in features such as resharding.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To capture data changes from Vitess, as what we’ve been doing with Debezium MySQL Connector, we’ve considered a few options. In the end, we have implemented our own Vitess Connector based on the common Debezium connector framework. While implementing the Vitess connector, we’ve encountered a few challenges. For example, support for the Vitess reshard operation, offset management, and schema management. We reasoned about ways to address the challenges and what we worked out as solutions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We’ve also received quite some interest from multiple communities in this project and we’ve decided to open-source &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess Connector&lt;/a&gt; under the Debezium umbrella. Please feel free to learn more, and we welcome and value any contributions.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>keweishang, rgibaiev</name></author><category term="vitess"/><summary type="html">This post originally appeared on the Bolt Labs Engineering blog. Traditionally, MySQL has been used to power most of the backend services at Bolt. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes. Once data is persisted to the database, we use the Debezium MySQL Connector to capture data change events and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.</summary></entry><entry><title type="html">Hello Debezium!</title><link href="https://debezium.io/blog/2020/10/27/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium!"/><published>2020-10-27T16:19:59+00:00</published><updated>2020-10-27T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/27/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/10/27/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;My work started under the Data Virtualization team with Teiid and then under the &lt;a href=&quot;https://graphqlcrud.org/&quot;&gt;GRAPHQLCRUD&lt;/a&gt; project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Can&amp;#8217;t wait to learn and explore awesome things. Happy to get started here!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;--Anisha&lt;/p&gt; &lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="community"/><category term="news"/><summary type="html">Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team. I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat. My work started under the Data Virtualization team with Teiid and then under the GRAPHQLCRUD project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications. Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha1 Released"/><published>2020-10-23T16:19:59+00:00</published><updated>2020-10-23T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This first pass of the 1.4 release line provides a few useful new features:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;New Vitess connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Allow fine-grained selection of snapshotted tables&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;41 issues&lt;/a&gt; for this release. Let&amp;#8217;s take a closer look at some of the highlights. &lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;vitess_connector&quot;&gt;Vitess Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://www.vitess.io&quot;&gt;Vitess&lt;/a&gt; is a database solution for deploying, scaling, and managing large clusters of MySQL. We are very happy that the development team around Ruslan Gibaiev and Kewei Shang of &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt Technology OÜ&lt;/a&gt; decided to build a CDC solution based on Debezium and to &lt;a href=&quot;https://www.github.com/debezium/debezium-connector-vitess&quot;&gt;open-source it&lt;/a&gt; under the Debezium umbrella. This connector is released in &lt;strong&gt;incubating&lt;/strong&gt; state in Debezium 1.4.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Ruslan and Kewei will follow up with a blog post with more details around this connector very soon; in the mean time please refer to the connector &lt;a href=&quot;https://debezium.io/documentation/reference/1.4/connectors/vitess.html&quot;&gt;reference documentation&lt;/a&gt; to learn more.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;fine_grained_selection_of_snapshotted_tables&quot;&gt;Fine-grained Selection of Snapshotted Tables&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the major focus points for Debezium 1.4 is to explore more flexible snapshot options, e.g. to re-snapshot chosen tables or parallelizing long-running snapshot operations.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A first improvement related to snapshotting is the new connector configuration &lt;code&gt;snapshot.include.collection.list&lt;/code&gt;, which allows to snapshot only a subset of all the tables which the connector will capture later on during log reading. This comes in handy if for instance you&amp;#8217;re interested in capturing changes to all your tables, but only need an initial snasphot of the data for some of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the Postgres connector, by creating a custom implementation of the &lt;code&gt;Snapshotter&lt;/code&gt; SPI contract, this also allows for a selective re-snapshot of specific tables. After restarting the connector, such &lt;code&gt;Snapshotter&lt;/code&gt; would continue to read the log from the point where it left off previously until &quot;now&quot;, then it would take a snapshot of the given tables, and finally continue to read the log for &lt;em&gt;all&lt;/em&gt; captured tables.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For more information on this option, please see the connector-specific &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/index.html&quot;&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides these key features, there&amp;#8217;s a few other features coming with the 1.4.0.Alpha1 release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Implement snapshot select override behavior for MongoDB &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2496&quot;&gt;DBZ-2496&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SqlServer - Skip processing of LSNs not associated with change table entries &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2582&quot;&gt;DBZ-2582&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Cant override environment variables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2559&quot;&gt;DBZ-2559&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;ConcurrentModificationException during exporting data for a mongodb collection in a sharded cluster &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2597&quot;&gt;DBZ-2597&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mysql connector didn&amp;#8217;t pass the default db charset to the column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2604&quot;&gt;DBZ-2604&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Doc] &quot;registry.redhat.io/amq7/amq-streams-kafka-25: unknown: Not Found&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2609&quot;&gt;DBZ-2609&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Doc] &quot;Error: no context directory and no Containerfile specified&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2610&quot;&gt;DBZ-2610&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SqlExceptions using dbz with Oracle on RDS online logs and LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mining session stopped - task killed/SQL operation cancelled - Oracle LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Unparseable DDL: Using 'trigger' as table alias in view creation &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2639&quot;&gt;DBZ-2639&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Antlr DDL parser fails to interpret BLOB([size]) &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MySQL Connector keeps stale offset metadata after snapshot.new.tables is changed &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2643&quot;&gt;DBZ-2643&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;WAL logs are not flushed in Postgres Connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium Server Event Hubs plugin support in v1.3 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cassandra Connector doesn&amp;#8217;t use log4j for logging correctly &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2661&quot;&gt;DBZ-2661&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Should Allow NonAsciiCharacter in SQL &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MariaDB nextval function is not supported in grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Sanitize field name do not sanitize sub struct field &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium fails if a non-existing view with the same name as existing table is dropped &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, &lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;, &lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;, &lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;, &lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;, &lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;, &lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;, &lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;, &lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;, and &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongodb"/><category term="sqlserver"/><category term="cassandra"/><category term="db2"/><category term="oracle"/><category term="vitess"/><summary type="html">I am excited to announce the release of Debezium 1.4.0.Alpha1! This first pass of the 1.4 release line provides a few useful new features: New Vitess connector Allow fine-grained selection of snapshotted tables Overall, the community fixed 41 issues for this release. Let&amp;#8217;s take a closer look at some of the highlights.</summary></entry><entry><title type="html">Towards a Graphical Debezium User Interface</title><link href="https://debezium.io/blog/2020/10/22/towards-debezium-ui/" rel="alternate" type="text/html" title="Towards a Graphical Debezium User Interface"/><published>2020-10-22T16:19:59+00:00</published><updated>2020-10-22T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/22/towards-debezium-ui</id><content type="html" xml:base="https://debezium.io/blog/2020/10/22/towards-debezium-ui/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases. Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors, allowing to safely operate CDC pipelines also in huge installations with thousands of connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production. We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily. &lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today it&amp;#8217;s my great pleasure to introduce you to a proof-of-concept for a potential future &lt;strong&gt;Debezium graphical user interface&lt;/strong&gt;. The goal for this PoC is to explore how a graphical UI could facilitate the getting started and operational experience of Debezium users.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The scope of the PoC is the set-up flow for configuring and instantiating a Debezium Postgres connector. The user is guided through the required configuration steps in a wizard interface, starting from mandatory information (e.g. database credentials), over selecting the tables to be captured, up to optional settings like different data mapping options. After reviewing the final configuration, the UI will instantiate the connector in Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can see a short demo of how this looks like in this video:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/RZ_3DF7Ndnk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We focused on some core interaction patterns, e.g. the preview functionality for the selecting the captured tables. Instead of solely taking key/value pairs of configuration parameters, the UI should guide the user through the process, provide context and help, e.g. by showing the allowed options for settings in drop-downs, validating the provided settings after each step, and more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now this is just the beginning, there&amp;#8217;s many more things that could be done in such Debezium UI, e.g. in the connection configuration step, we could validate whether the given user has all the required database permissions, whether the right WAL level is set in the database, etc. There could be views for monitoring and trouble-shooting connectors. When running on Kubernetes, the UI could produce resource definitions processed by a Kafka (Connector) operator like Strimzi (instead of calling the Kafka Connect REST API), and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But before further progressing with this, we&amp;#8217;d like to gather your feedback and opinions: Do you consider a graphical UI for Debezium useful in general, and is it something you would use in your projects? What is your feedback on the functionality currently implemented in the PoC? Which other functionality besides connector configuration would you like to see in a Debezium UI? We&amp;#8217;ve provided a short survey with these and a few other questions:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph text-center&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSfEEqslTWSLX89gzIDmSE_4v8hH0mYg0YBRaXhfDrrBbCUJgQ/viewform?usp=sf_link&quot;&gt;Go to survey&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Before taking the questionnaire, please watch the video or run the PoC yourself (see below). Answering these questions should take just a few minutes; your participation would be very helpful for us in order to decide whether and how we should move forward with this effort.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;trying_it_out_yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As everything in Debezium, the UI PoC is fully open source (Apache License Version 2.0); you can find its &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;source code&lt;/a&gt; under the Debezium organization on Git Hub. The PoC is implemented as a &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;-based web application, using &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; as the frontend technology.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Quarkus backend is configured with the URL(s) of one more Kafka Connect clusters. Note that there&amp;#8217;s currently no means of authentication or authorization implemented in the PoC, so don&amp;#8217;t use it with your production Connect clusters just yet. After starting the application, you can choose the cluster to work with from the drop-down to the top right. Different from what&amp;#8217;s shown in the video recording, the &quot;Delete&quot; button is working in the PoC now, too ;) There&amp;#8217;s an example &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/blob/master/docker-compose.yml&quot;&gt;Docker Compose file&lt;/a&gt;, which starts up all required components for getting started quickly. Alternatively, you can obtain a &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui-poc&quot;&gt;pre-built container image&lt;/a&gt; with the Debezium UI PoC from Docker Hub. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/#debezium-ui-poc&quot;&gt;README file&lt;/a&gt; for more details on building and running the Debezium UI PoC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re looking forward very much to learning about your feedback on the Debezium UI PoC. Try it out yourself and let us know about your thoughts in the comments below and by participating in the quick survey linked above.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team working on this PoC: Ashique Ansari, Indra Shukla, June Zhang, Mark Drilling, Na Ding, and René Kerner!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community"/><category term="discussion"/><summary type="html">Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases. Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more. When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors, allowing to safely operate CDC pipelines also in huge installations with thousands of connectors. All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production. We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily.</summary></entry><entry><title type="html">Debezium Community Stories With… Renato Mefi</title><link href="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/" rel="alternate" type="text/html" title="Debezium Community Stories With… Renato Mefi"/><published>2020-10-08T16:19:59+00:00</published><updated>2020-10-08T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi</id><content type="html" xml:base="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know. In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;Renato Mefi&lt;/a&gt;, a long-time Debezium user and contributor. &lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/renatomefi.jpg&quot; style=&quot;max-width:50%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Renato, could you introduce yourself? What is your job, if you&amp;#8217;re not contributing to Debezium?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Hello all, I&amp;#8217;m Renato and my first Debezium commit was on Nov 12, 2018, it&amp;#8217;s been a long and fun ride so far, and I&amp;#8217;m glad to have the opportunity to share my story here with you all!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m a Staff Software Engineer at &lt;a href=&quot;https://www.surveymonkey.com/&quot;&gt;SurveyMonkey&lt;/a&gt; in Amsterdam, The Netherlands, within the Platform team for our CX (customer experience) suite, if you&amp;#8217;re curious about what that is, you can &lt;a href=&quot;https://usabilla.com/blog/introducing-the-getfeedback-suite/&quot;&gt;check it out here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On the internet you&amp;#8217;re going to find me talking about Docker, Debezium, Kafka, Microservices and other things that I enjoy. Although those amazing engineering pieces really excite me, at this moment I&amp;#8217;m also really passionate about Platform Engineering teams and how they can operate in an organization, the stories I&amp;#8217;m going to tell below represent my view of it, of how critical the role of a platform team can be when adopting new technologies and solving difficult problems for the whole, in this case powered by Debezium!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;What are your use cases for Debezium and CDC in your current project?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s a long and enjoyable story (long in terms of the internet), we&amp;#8217;ve been using Debezium since Q4 2018, it&amp;#8217;s been 2 years at the moment I&amp;#8217;m writing those answers here.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When I classify Debezium within our product, I say it is an architectural component, the idea behind this is to position it as a platform/infrastructure concern, in a way that it can reach multiple parts of the stack and services. I consider this abstraction of Debezium one of the key success factors it had in its adoption and growth within our platform, let me explain this better!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our first use case is likely to be one of the most common ones for CDC, the &lt;a href=&quot;https://martinfowler.com/bliki/StranglerFigApplication.html&quot;&gt;strangler pattern&lt;/a&gt;, which for us came before Debezium; so let me tell this part of the story first: when I joined Usabilla (later acquired by SurveyMoney), there was already an effort to move our platform to a new architecture and the strangler pattern was already there. When the first couple of services started to grow, their primary way to bring data out of legacy was to poll the database, and needless to say, this could go very wrong! Our legacy database is a MongoDB cluster, and since I was pre-occupied with the polling approach, I started to dig into possibilities. I was hoping to find something like a streaming API for it, but what I ended up encountering was the database changelog (&lt;a href=&quot;https://en.wikipedia.org/wiki/Write-ahead_logging&quot;&gt;Write-ahead logging&lt;/a&gt;, &quot;oplog&quot; as it&amp;#8217;s called in Mongo!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It came to my mind right away: &quot;Oh, I could write something that queries the data from the oplog and sends it to Kafka&quot;. So I checked with our in-house Senior SRE and MongoDB expert &lt;a href=&quot;https://twitter.com/gwkunze&quot;&gt;Gijs Kunze&lt;/a&gt; who thought it could be a good idea; as a next step I went to talk to my colleague &lt;a href=&quot;https://twitter.com/rdohms&quot;&gt;Rafael Dohms&lt;/a&gt;, and we decided to do some extra Googling, and like that, we found Debezium! It was the perfect match to our needs and better than what we could have written by ourselves!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now back to our use case, what makes it an architecture component for us, is basically the approach, we abstracted and wrapped Debezium in a project called Legacy Data Syncer (LDS for us, because acronyms never get old). Although it might look simple to spin up a Kafka Connect with Debezium, running it production-ready, monitoring multiple collections within the database, exposing metrics, doing transformations and more, is not such an easy task. So how does it work? Every time an engineering team needs to capture data from our legacy system, to start strangling a feature, they only have to do two things, open a pull request which literally adds one line to LDS, and create their Kafka consumer!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_lds.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. The configuration file in LDS; a developer will open a PR adding a new line, the rest will be taken care of.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Upon merging the PR, our project will provision the whole configuration to Kafka Connect, it ensures the snapshot is executed, metrics are present and etc; We&amp;#8217;ve done the same thing for the outbox pattern and I talk a little bit more about it in this &lt;a href=&quot;https://twitter.com/renatomefi/status/1185098904745992197&quot;&gt;tweet thread&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Self-servicing the teams was a great way to remove resistance for adoption, no Jira tickets were necessary, no advanced ops knowledge or anything else to get it running. The other factors I consider to have contributed to Debezium&amp;#8217;s success in our platform is its reliability and straight forward value perception, in those two years we never had major outages or critical problems of any kind!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;You mention the outbox pattern; Could you tell more about why and how you&amp;#8217;re using this?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Absolutely! One more time, it&amp;#8217;s crazy how CDC and Debezium can simplify some of the most critical architectural parts of big platforms! One year after using Debezium in the core of our architecture migration, we had another problem at our hands: how to reliably write data to our new source of truth databases and propagate messages to Kafka at the same time. Although it seems to be simple to answer and find a solution, each of them comes with a major drawback.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Which solutions do we have?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Embrace eventual consistency to its peak by adopting &lt;em&gt;event sourcing&lt;/em&gt;, by writing first to Kafka and reading our own writes; the drawbacks here are extra complexity and intensified eventual consistency&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Dual writes&lt;/em&gt;, well, actually this is not an option, because as you know, &lt;a href=&quot;https://thorben-janssen.com/dual-writes/&quot;&gt;&quot;Friends Don&amp;#8217;t Let Friends Do Dual Writes&quot;&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Different approaches of &lt;em&gt;distributed transactions&lt;/em&gt; like 2PC and sagas; the costs here are performance and engineering effort, now every service we have has to either become a transaction coordinator or have rollback capabilities, also the cascade effect scared us quite a bit!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Well, what&amp;#8217;s left? We found that outbox was the right answer for us, but before we get there, let me get into the cost x benefit equation of our decision making!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Although some of the options were quite attractive technically, for instance event sourcing, the engineering effort and growth is immense. Also, it&amp;#8217;s not the kind of thing which comes ready to use, and there&amp;#8217;s a lot of discovery to be made along the way, so what were the constraints and desires:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Reliability&lt;/em&gt;; we want at least once semantics, exactly once isn&amp;#8217;t necessary as we can uniquely identify each message/event;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Eventual consistency only between services&lt;/em&gt;, but not within the services themselves. Being able to interact with a service which is the source of truth of a certain model, and get an immediate answer is not just handy, but incredibly powerful (and that&amp;#8217;s why monoliths are also so attractive);&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Avoiding distributed transactions&lt;/em&gt; as much as we can, it&amp;#8217;s scary and we should be scared about it too!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;em&gt;Manageable effort&lt;/em&gt;; how can we &quot;easily&quot; get 30+ engineers to adopt a solution for this problem? At the same time, how can you ensure the implementation guarantees among every service and team?&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We realized that the &lt;a href=&quot;https://microservices.io/patterns/data/transactional-outbox.html&quot;&gt;outbox pattern&lt;/a&gt; would help us meet those requirements: applications would publish events via an outbox table, which gets written to as part of business transactions in the database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As with the strangler pattern, we wanted to resort to an architecture component, something the teams could self-service. At first, we were exploring a home-grown solution which would look for the outbox tables among every service and publish the messages. The problem with this approach would be the polling databases problem, although in this case this is less harmful as we don&amp;#8217;t need to look for updates or deletes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Luckily, by that time I was closely following the work being done in Debezium and I read the blogpost about &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;reliable data exchange between microservices using the outbox pattern&lt;/a&gt;, and there was my answer! Well, I mean, parts of the answer, we still needed to implement it, and that&amp;#8217;s a story for the next question!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Fast forward a couple of months and we got a reliable way to exchange messages between services, with all the guarantees we wanted to have, and by applying some platform DevOps flavor to it, we also made it self-service and easy to plug in every service!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The user can specify which database their service is at, what&amp;#8217;s the table name, and which column to use as event router, you can find more details about it in the official &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html#outbox-event-router-property-route-by-field&quot;&gt;Debezium outbox event router docs&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_outbox.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. The configuration file for configuring outbox connectors&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;You&amp;#8217;re not only using Debezium but you&amp;#8217;ve also contributed to the project. How was your experience doing so? Are you doing other open-source work, too?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As I spoiled at the beginning, my usage and contributions to Debezium walked hand-to-hand. In both the use cases we have for Debezium in SurveyMonkey, I had great opportunities to contribute to both Debezium and Kafka (just a bug fix, but I&amp;#8217;m happy about it!).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At first, I was fixing bugs in the Debezium MongoDB connector; as we really scaled it up to all the teams, a lot of edge cases started to show up, mostly in the transformation which takes the raw database transaction log and transforms it into a nicely readable Kafka Connect struct. Also due to our architecture choice, we split the raw log and transformed data into two different steps, which go in separate topics and are configured as separate Kafka Connect connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Quick sidestep: the rationale behind this decision was to be able to survive transformation errors; MongoDB has a replication window which, if you lose it, means that you are going to have to make a new full snapshot of the collection and you might lose deletion events in this process. Because of this we opted for a safer approach, which was to split the logic of transformation from the raw logs like this: The step we call &lt;code&gt;op&lt;/code&gt; (stands for operation), is the Debezium MongoDB source connector and outputs the raw data into the topic without any change or transformation, minimizing the chances of errors in the process. The second step called &lt;code&gt;cdc&lt;/code&gt;, is a &lt;a href=&quot;https://github.com/salesforce/mirus&quot;&gt;Salesforce Mirus&lt;/a&gt; source connector, which reads from the &lt;code&gt;op&lt;/code&gt; output topic, transforms the message using the &lt;a href=&quot;https://debezium.io/documentation/reference/1.3/configuration/mongodb-event-flattening.html&quot;&gt;Debezium document flattening SMT&lt;/a&gt; and outputs to the final topic, which the services can consume from. With this approach, we now have two main abilities: Resist to errors and crashes on the native/custom transformation process like mentioned above, and we have the chance to change the transformation to our desires without having to read from the database again, giving us more flexibility. That also created some extra features and challenges to be incorporated in Debezium itself! As I kept contributing I noticed a few things that could be improved and started fixing them, including an almost full refactor of the build process of Debezium&amp;#8217;s container images, its scripts, and other smaller things!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s circle back to outbox; when the post about this appeared on the Debezium blog, it was mostly an idea and a proof-of-concept. But we really wanted it to run in production, in this case, why not partnership on it?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I want to take the opportunity here to mention how helpful the Debezium community was for getting me started with contributing. As I showed the intent to work on this, they were super welcoming and we had a call about it, so I quickly felt productive working on the code base.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Almost immediately after the conversation I started a technical draft (which you can see &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1169&quot;&gt;here&lt;/a&gt;) and soon thereafter, the first implementation was done. I can almost certainly say we were the first ones to run the transactional outbox pattern powered by Debezium. I was running a custom build on our platform, which then finally became the official &lt;a href=&quot;https://debezium.io/documentation/reference/1.2/configuration/outbox-event-router.html&quot;&gt;outbox event router&lt;/a&gt; you see in the Debezium docs today. I was lucky to be there at the right time and with the right people, so thanks again to the Debezium team for helping me throughout the whole process of drafting and making it happen!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Will I do more open source? Yes, but I must say most of my open source activity is &quot;selfish&quot;, I&amp;#8217;m developing solutions to problems I face at work but I&amp;#8217;m happy to take the extra step and make them to the OSS world, but it also makes it seasonal. One of the advantages to that is if I&amp;#8217;m doing something for a project, be sure I&amp;#8217;ll make it to production and likely be able to find more corner cases!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Is there anything you&amp;#8217;re missing in Debezium or you&amp;#8217;d like to see improved in the future?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When I think of the Kafka and Debezium ecosystem, the next steps I consider important are the ones which will make it more accessible. Although there&amp;#8217;s a lot of content and examples online, there&amp;#8217;s still a big gap between reading those and getting to a production ready implementation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;What I mean by that is abstracting the individual pieces away and giving them more meaning. The outbox pattern is a good example, it was not natural for people to think of CDC and know that it was such a good match to it, there are plenty of more use cases to be explored in this ecosystem.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;What if you could have everything out-of-the-box? An outbox implementation in your favorite framework, which knows how to integrate with the ORM, handle the transaction part, then, how to shape the messages and events? How to adopt the schema for it and how an evolution of it looks like. After that, getting closer to the consumer implementation, how can I handle the messages idempotently, respect the semantics, do retries, and project them to a database if need be? There are already initiatives like those, for instance, the &lt;a href=&quot;https://debezium.io/documentation/reference/integrations/outbox.html&quot;&gt;Quarkus Outbox extension&lt;/a&gt;, which takes care of framework and database integration. The future for me has those things, for multiple frameworks and tech stacks, going even broader and helping you design good events (maybe even powered by &lt;a href=&quot;https://www.asyncapi.com/&quot;&gt;AsyncAPI&lt;/a&gt;), giving everyone a kickstart!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Those are very complex things to do in a growing architecture, the patterns will keep repeating and hopefully the community will be able to come to consensus of design and implementations, and that&amp;#8217;s what I think the next step is, a place where the complexity of a good architecture doesn&amp;#8217;t live in the wires and plugs anymore, making it more accessible!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Bonus question: What&amp;#8217;s the next big thing in software engineering?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I think I handled clues for this one in many parts of my previous answers!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For me the next big thing is a methodology; I often say the evolution of DevOps is self-service, and it can go in many layers of the stack. The examples I gave about our Debezium implementation is what I call self-service between Platform/Ops and product development teams, but it can be applied in many, many places!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The idea is to facilitate the implementation of complex structures, something more end-to-end, taking care of the good practices in metrics, alerts, and diverse other guaranteed semantics for the use case! We can see there&amp;#8217;s a convergence towards that path, for instance Kubernetes operators are a great example where you can abstract one use case which will be translated to many, if not dozens of internal resources in the infrastructure.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I believe we already have the base technology to do so, all the Infrastructure as Code, containers, frameworks, observability systems are there, we just have to give meaning to them!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Where&amp;#8217;s the framework where I can: Handle a user request, validate, write to the source-of-truth, produce a message to my broker, consume at another end where my only concern is the payload itself? All the semantics should be taken care of, idempotency, retries, SerDes issues, dead letter queues, eventual consistency mitigations, metrics, alerts, SLOs, SLAs, etc!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And that&amp;#8217;s where I put my energy in everyday at work, giving all the engineering teams a more fun and safe way to develop their software, which also sums up my passion for Platform Engineering!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Renato, thanks a lot for taking your time, it was a pleasure to have you here!&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;If you&amp;#8217;d like to stay in touch with Renato Mefi and discuss with him, please drop a comment below or follow and reach out to him &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;on Twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community"/><category term="outbox"/><summary type="html">Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know. In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to Renato Mefi, a long-time Debezium user and contributor.</summary></entry><entry><title type="html">Debezium 1.3.0.Final Released</title><link href="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Final Released"/><published>2020-10-01T16:19:59+00:00</published><updated>2020-10-01T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/01/debezium-1-3-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium &lt;strong&gt;1.3.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months. Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.3.0.Final%2C%201.3.0.Alpha1%2C%201.3.0.Beta1%2C%201.3.0.Beta2%2C%201.3.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;138 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A new incubating &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based implementation&lt;/a&gt; for ingesting change events from Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for Azure Event Hubs in &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Apache Kafka 2.6&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Revised &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;filter option names&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A new SQL Server connector snapshot mode, &lt;code&gt;initial_only&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for database-filtered columns for SQL Server&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Additional connection options for the MongoDB connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improvements to &lt;code&gt;ByteBufferConverter&lt;/code&gt; for implementing the &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;outbox pattern&lt;/a&gt; with Avro as the payload format&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the announcements of the preview releases (&lt;a href=&quot;https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/&quot;&gt;Beta2&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details. Since last week&amp;#8217;s CR1 release, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;been focusing&lt;/a&gt; on ironing out some remaining bugs and improvements to the documentation. To learn more about procedures for upgrading from earlier Debezium versions, please take a look the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-final1&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thank you to everyone testing the preview releases, this is of invaluable help for spotting and fixing short-comings in new features as well as regressions. And of course I&amp;#8217;d also like to thank all the community members contributing to this release: &lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;, &lt;a href=&quot;https://github.com/abhirockzz&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;, &lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/bjoernhaeuser&quot;&gt;Björn Häuser&lt;/a&gt;, &lt;a href=&quot;https://github.com/coryharperbind&quot;&gt;Cory Harper&lt;/a&gt;, &lt;a href=&quot;https://github.com/denisprog&quot;&gt;Denis Liseichykau&lt;/a&gt;, &lt;a href=&quot;https://github.com/eric-weaver&quot;&gt;Eric Weaver&lt;/a&gt;, &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;, &lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;, &lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt;, &lt;a href=&quot;https://github.com/GuyIEX&quot;&gt;Guy Pascarella&lt;/a&gt;, &lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;, &lt;a href=&quot;https://github.com/jfinzel&quot;&gt;Jeremy Finzel&lt;/a&gt;, &lt;a href=&quot;https://github.com/jonaslins&quot;&gt;Jonas Lins&lt;/a&gt;, &lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;, &lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;, &lt;a href=&quot;https://github.com/korzenek&quot;&gt;Lukasz Korzeniowski&lt;/a&gt;, &lt;a href=&quot;https://github.com/lga-zurich&quot;&gt;Luis Garcés-Erice&lt;/a&gt;, &lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;, &lt;a href=&quot;https://github.com/misaert&quot;&gt;Mickaël Isaert&lt;/a&gt;, &lt;a href=&quot;https://github.com/mtagle&quot;&gt;Moira Tagle&lt;/a&gt;, &lt;a href=&quot;https://github.com/rivernate&quot;&gt;Nathan Mills&lt;/a&gt;, &lt;a href=&quot;https://github.com/petoju&quot;&gt;Peter Junos&lt;/a&gt;, &lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt;, &lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;, and &lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Victor Xiang&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, more than 220 individuals have contributed to the Debezium project at this point.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But not only that, also the number of Debezium users is constantly growing, as e.g. documented on our &lt;a href=&quot;/community/users/&quot;&gt;reference list of Debezium users&lt;/a&gt; (let us know if you want to be added). There&amp;#8217;s also several new entries in our compilation of &lt;a href=&quot;/documentation/online-resources/&quot;&gt;public talks and blog posts&lt;/a&gt; touching on Debezium, e.g. a highly recommendable talk by Marta Paes about &lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;change data capture with Flink SQL and Debezium&lt;/a&gt;, a blog post by Cemal Turkoglu about &lt;a href=&quot;https://turkogluc.com/postgresql-capture-data-change-with-debezium/&quot;&gt;[making sense of change data capture pipelines for Postgres with the Debezium Kafka Connector&lt;/a&gt;, and a nice piece on &lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;implementing the outbox pattern with Debezium in Quarkus&lt;/a&gt; by Iain Porter. Abdellatif Bouchama did an amazing job by creating a &lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;cheat sheet&lt;/a&gt; for running Debezium on OpenShift.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the 1.3 Final release out, planning for the 1.4 version (due by the end of the year) is happening right now. The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; still is in flux, so make sure to chime in and let us know about your requirements and feature requests. Some of the things we&amp;#8217;re likely going to work on include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;community-led connector&lt;/a&gt; for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;; the initial contribution has already been merged and we plan to ship the first release of this as part of Debezium 1.4 Alpha1 later this month&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improving the new LogMiner-based implementation for Oracle&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And lastly, there&amp;#8217;s one other area of activity which I&amp;#8217;m particularly excited to share here today for the first time: a proof-of-concept of how a potential future Debezium user interface might look like. In that PoC we&amp;#8217;re exploring how a graphical UI could help with the set-up and operation of Debezium connectors. We&amp;#8217;ve got quite a few ideas in that field and will share more details in a blog post very soon. If you feel adventureous in the meantime, you could grab the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;current PoC code&lt;/a&gt; and take it for spin!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Until then, happy change data streaming, onwards and upwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium 1.3.0.Final! As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months. Overall, the community has fixed 138 issues during that time, including the following key features and changes: A new incubating LogMiner-based implementation for ingesting change events from Oracle Support for Azure Event Hubs in Debezium Server Upgrade to Apache Kafka 2.6 Revised filter option names A new SQL Server connector snapshot mode, initial_only Support for database-filtered columns for SQL Server Additional connection options for the MongoDB connector Improvements to ByteBufferConverter for implementing the outbox pattern with Avro as the payload format</summary></entry><entry><title type="html">Debezium 1.3.0.CR1 Released</title><link href="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.CR1 Released"/><published>2020-09-24T16:19:59+00:00</published><updated>2020-09-24T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.3.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we approach the final stretch of Debezium 1.3 Final, we took this opportunity to add delegate converter support for the &lt;code&gt;ByteBufferConverter&lt;/code&gt; and introduce a &lt;code&gt;debezium-scripting&lt;/code&gt; module. In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish; overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.CR1%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;15 issues&lt;/a&gt; have been resolved for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;bytebufferconverter_improvements&quot;&gt;ByteBufferConverter improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;ByteBufferConverter&lt;/code&gt; is a converter that is used with the Outbox event router SMT to serialize an existing Avro payload column. In a recent report (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2396&quot;&gt;DBZ-2396&lt;/a&gt;), the &lt;code&gt;ByteBufferConverter&lt;/code&gt; was unable to serialize events emitted from a connector that was configured to emit heartbeat, transaction metadata, or schema change events. In order to improve the converter&amp;#8217;s compatibility when these events are emitted, the &lt;code&gt;ByteBufferConverter&lt;/code&gt; can now be configured to delegate event serialization to an additional converter. This delegation is necessary so that heartbeat, transaction metadata, and schema change events (if applicable) can be serialized.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use the Outbox event router SMT and the &lt;code&gt;ByteBufferConverter&lt;/code&gt; with these event types, the connector configuration must be changed to reflect the delegate converter and its configurable options.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As an example to use the Apache Kafka &lt;code&gt;JsonConverter&lt;/code&gt; as a delegate with schemas disabled, the following configuration would need to be included in the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;value.converter=io.debezium.converters.ByteBufferConverter value.converter.delegate.converter.type=org.apache.kafka.connect.json.JsonConverter value.converter.delegate.converter.type.schemas.enable=false&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For more information about using the &lt;code&gt;ByteBufferConverter&lt;/code&gt;, please see the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/outbox-event-router.html#avro-as-payload-format&quot;&gt;Using Avro as the payload format&lt;/a&gt; section in the Outbox event router documentation.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;scripting_module&quot;&gt;Scripting module&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, the SMTs for content-based routing and filtering that both use JSR 223 scripting engines have been moved out of &lt;code&gt;debezium-core&lt;/code&gt; and into a separate artifact &lt;code&gt;debezium-scripting&lt;/code&gt; (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2549&quot;&gt;DBZ-2549&lt;/a&gt;). Any connector that previous used these SMTs requires that the new artifact be added to the plug-in directories for those connector(s).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the Debezium container image for Kafka Connect, set the environment variable &lt;code&gt;ENABLE_DEBEZIUM_SCRIPTING&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; to enable this feature. This change is done to allow the scripting functionality to be available only in environments with an apppropriately secured Kafka Connect configuration interface.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;misc_features_and_bug_fixes&quot;&gt;Misc. Features and Bug Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, the community has completed the work on some other features and fixes, too:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Catch up streaming before snapshot may duplicate messages upon resuming streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2550&quot;&gt;DBZ-2550&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Fix Quarkus datasource configuration for Quarkus 1.9 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2558&quot;&gt;DBZ-2558&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Implement connection retry support for Oracle &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2531&quot;&gt;DBZ-2531&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-cr1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thank you so much to &lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt; and &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt; for their contributions to this release.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.3 Final should be out next week. Until then, we&amp;#8217;ll focus on some more polishing. The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;community-lead work&lt;/a&gt; towards a Debezium connector for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt; is also making good progress, with an initial release of this new connector planned with Debezium 1.4 Alpha1 in late October.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="outbox"/><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.3.0.CR1! As we approach the final stretch of Debezium 1.3 Final, we took this opportunity to add delegate converter support for the ByteBufferConverter and introduce a debezium-scripting module. In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish; overall, not less than 15 issues have been resolved for this release.</summary></entry></feed>