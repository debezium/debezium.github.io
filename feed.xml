<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2021-11-11T17:33:42+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 1.8.0.Alpha2 Released</title><link href="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha2 Released"/><published>2021-11-11T00:00:00+00:00</published><updated>2021-11-11T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;MySQL support for heartbeat action queries&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Configurable transaction topic name&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, the latest &lt;code&gt;1.2&lt;/code&gt; tag of the &lt;a href=&quot;https://hub.docker.com/repository/docker/debezium/tooling&quot;&gt;debezium/tooling&lt;/a&gt; image is available. The newest version includes all the latest tools, including &lt;a href=&quot;https://github.com/kcctl/kcctl&quot;&gt;kcctl&lt;/a&gt;, a super simple, cuddly CLI for Apache Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release does include several breaking changes. Please see the &lt;a href=&quot;https://debezium.io/releases/1.8/release-notes#release-1.8.0-alpha2&quot;&gt;release notes&lt;/a&gt; for details on what changed and how to upgrade.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mysql_heartbeat_action_query_support&quot;&gt;MySQL heartbeat action query support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat action query can be enabled by supplying a &lt;code&gt;heartbeat.action.query&lt;/code&gt; configuration option in the connector&amp;#8217;s configuration. This property is meant to supply a SQL statement that the connector will execute periodically.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The initial implementation of the heartbeat action query was specifically for PostgreSQL to handle dealing with WAL growth under specific conditions. But a heartbeat action query has many uses and is entirely connector or even user driven.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, you may want to notify downstream consumers that your MySQL topology has changed by supplying consumers with an event with the GTID. The following configuration shows how to capture changes from the heartbeat action query table that can then be consumed easily by your CDC pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;gtid_history&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;heartbeat.action.query&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;INSERT INTO gtid_history( select * from mysql.gtid_executed )&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configurable_transaction_topic_names&quot;&gt;Configurable transaction topic names&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium transaction metadata topic had previously used a relatively non-configurable naming convention of &lt;code&gt;&amp;lt;database.server.name&amp;gt;.transaction&lt;/code&gt;. While it was possible to manipulate the topic name using a single message transform (SMT) as a workaround, we felt that allowing this to be a bit more flexible in Debezium proper made sense.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A new configuration option, &lt;code&gt;transaction.topic.prefix&lt;/code&gt;, has been introduced that allows the connector configuration to adjust the naming of the transaction metadata topic. The configuration option value specifies what will be used as a direct replacement for the `&amp;lt;database.server.name&amp;gt;~ portion of the topic name. If this configuration option is not supplied, the prior topic naming behavior will continue to be used; requiring no changes for existing connector deployments.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Invalid default value error on captured table DDL with default value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3710&quot;&gt;DBZ-3710&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental snapshot doesn&amp;#8217;t work without primary key &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4107&quot;&gt;DBZ-4107&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Signal based incremental snapshot is failing if database name contains dash &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4244&quot;&gt;DBZ-4244&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha2%20ORDER%20BY%20component%20ASC&quot;&gt;45 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/abhishekkh&quot;&gt;Abhishek Hodavdekar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, and &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_1_7&quot;&gt;Debezium 1.7&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition to this release, we also released Debezium 1.7.1.Final, a bugfix update for the 1.7 series. The 1.7.1.Final release includes many of the bugfixes in the 1.8 series that have been done since 1.7.0.Final. For more information on what changed in 1.7.1.Final, please see the &lt;a href=&quot;https://debezium.io/releases/1.7/release-notes#release-1.7.1-final&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The holiday season is upon us, but we intend to stick to our release cadence as closely as possible. If you haven&amp;#8217;t already taken an opportunity, we&amp;#8217;d love your feedback on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. In the meantime, you can expect the first beta release of 1.8 in a couple of weeks.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, 1.8.0.Alpha2! With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes: MySQL support for heartbeat action queries Configurable transaction topic name In addition, the latest 1.2 tag of the debezium/tooling image is available. The newest version includes all the latest tools, including kcctl, a super simple, cuddly CLI for Apache Kafka Connect.</summary></entry><entry><title type="html">Debezium 1.8.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha1 Released"/><published>2021-10-27T00:00:00+00:00</published><updated>2021-10-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_change_streams_support&quot;&gt;MongoDB Change Streams Support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MonogoDB &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/&quot;&gt;change streams&lt;/a&gt; allow an application or client access to real-time change data capture events without the complexity of tailing the oplog. This functionality was first introduced by the MongoDB engine in version 3.6; however the functionality was limited. Starting with MongoDB 4.0, change streams now captures changes across a database, replica set, or even a sharded cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium added change streams support to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Enable compatibility with MongoDB 5 (not yet tested, see future work below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide full document output in update events (see below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Abstract from internal (and potentially changing) specifics of the oplog format, making this new implementation a potential replacement for oplog reading in the future.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use change stream support with Debezium, you must use MongoDB 4.0 or later.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;enablement&quot;&gt;Enablement&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium for MongoDB exposes a new configuration property called &lt;code&gt;capture.mode&lt;/code&gt;. The capture mode specifies how the connector should obtain change events from the MongoDB database. The valid options are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;oplog&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by tailing the oplog; this is the legacy behavior.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will not contain the full message; only changed fields are part of the event.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_update_full&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will contain a full snapshot of the current record in the event. This is the new default for the connector.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The new &lt;code&gt;change_streams&lt;/code&gt; and &lt;code&gt;change_streams_update_full&lt;/code&gt; capture modes are incubating and the format and details surrounding how these work may change in future releases.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;event_changes&quot;&gt;Event changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using our tutorial from our &lt;a href=&quot;https://www.github.com/debezium-examples&quot;&gt;examples repository&lt;/a&gt;, lets take a look at the differences in these capture modes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, lets add a new record to our &lt;code&gt;customers&lt;/code&gt; collection. Using the MongoDB shell, this can be done by running the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.insert([ { _id : NumberLong(&amp;quot;1005&amp;quot;), first_name : 'Bob', last_name : 'Hopper', email : 'thebob@example.com', unique_id : UUID() } ]);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This will generate a change event but as you&amp;#8217;ll see if you inspect the topic, the contents of the event are not all that different in this release. Since the event is an insert, all field values provided in the emitted event.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During updates, this is where we can see the capture mode differences in action. Now modify the customer&amp;#8217;s first and last name using the MongoDB shell with this command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.update( { _id:NumberLong(&amp;quot;1005&amp;quot;) }, { $set: { first_name: &amp;quot;Bobby&amp;quot;, last_name: &amp;quot;Copper&amp;quot; } });&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This modifies the first and last name of the customer with id &lt;code&gt;1005&lt;/code&gt;. The following sections show what each event will look like for the given capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;oplog&quot;&gt;Oplog&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;oplog&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$v&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: 1, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$set&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: { &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;3510217852938498600&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250803&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event&amp;#8217;s after field has no value. Instead, the event provides values for patch and filter that describe limited details about what changed in the source document. Since the event only provides details about what fields have changed and not the values for unchanged fields, this may not be ideal for certain consumers that require knowledge of the full document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams&quot;&gt;Change Streams&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448736&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event has a slightly different set of values than the legacy oplog output. As shown above, the event does not have a value in the after, patch, or filter fields. Instead, the event relies on describing the changes to the document&amp;#8217;s fields in the &lt;code&gt;updateDescription&lt;/code&gt; structure. While this provides a bit more detail about values that may have been set and even unset due to an update, this may still not be ideal for some consumers that need values for all fields of the source document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams_full_document&quot;&gt;Change Streams Full Document&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams_update_full&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;thebob@example.com&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;unique_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$binary&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;KRywzYp5RneNu8DUmhQHAQ==&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$type&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;04&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878244&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This capture mode is nearly identical to the &lt;code&gt;change_streams&lt;/code&gt; mode except with one critical difference, the &lt;code&gt;after&lt;/code&gt; field is populated with a complete snapshot of document. This mode is great for consumers that rely on having all fields in the source document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please see the &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/#lookup-full-document-for-update-operations&quot;&gt;MongoDB documentation&lt;/a&gt; for more details on full document mode semantics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The full document mode is based on a re-selection of the source document when MongoDB provides the change event over the change stream to the connector. In cases where multiple changes to the same document happen within close proximity of one another, each event may have the same full document representation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;future_work&quot;&gt;Future work&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In conjunction to the work already done with MongoDB change streams, we recognize there is much work that remains which includes testing the new change streams implementations against MongoDB 5 and updating the connector documentation to reflect these new changes. You can expect this and much more as a part of the next preview release. As per the updated Debezium 1.8 &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt;, we&amp;#8217;re also planning to add support for incremental snapshots to the Debezium connector for MongoDB, as well as a variant of the outbox event router which supports the event format of this connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Row hashing in LogMiner Query not able to differentiate between rows of a statement (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3834&quot;&gt;DBZ-3834&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk select statement is incorrect for combined primary key in incremental snapshot (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3860&quot;&gt;DBZ-3860&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;column.the mask.hash.hashAlgorithm.with&amp;#8230;&amp;#8203;. data corruption occurs when using this feature (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4033&quot;&gt;DBZ-4033&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan SPI throws NPE with more than one connector configured to the same Oracle database (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4064&quot;&gt;DBZ-4064&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;82 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/cburch824&quot;&gt;Christopher Burch&lt;/a&gt;, &lt;a href=&quot;https://github.com/kometen&quot;&gt;Claus Guttesen&lt;/a&gt;, &lt;a href=&quot;https://github.com/famartinrh&quot;&gt;Fabian Martinez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gkorland&quot;&gt;Guy Korland&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/lbroudoux&quot;&gt;Laurent Broudoux&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/unalsurmeli&quot;&gt;nal Srmeli&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashulin&quot;&gt;Zongwen Li&lt;/a&gt;, and &lt;a href=&quot;https://github.com/lujiefsi&quot;&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the end of the year is just around the corner, we intend to press forward with the same vigor. We have started an &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. Your feedback is invaluable so let us know what you&amp;#8217;d like to see added, changed, or improved! In the meantime, you can also expect a minor bugfix release to the Debezium 1.7 series next week, as well as another preview release of the Debezium 1.8 series in a couple more weeks. Happy Streaming!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, 1.8.0.Alpha1! With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!</summary></entry><entry><title type="html">Using Debezium to Create a Data Lake with Apache Iceberg</title><link href="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/" rel="alternate" type="text/html" title="Using Debezium to Create a Data Lake with Apache Iceberg"/><published>2021-10-20T00:00:00+00:00</published><updated>2021-10-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg</id><content type="html" xml:base="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s start with a short description of the data lake concept: A &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_lake&quot;&gt;data lake&lt;/a&gt; is &quot;usually a central store of data including raw copies of source system data, sensor data, social data etc&quot;. You can store your data as-is, without having to first process the data and then run different types of analytics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_server_iceberg&quot;&gt;Debezium Server Iceberg&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As operational data typically resides in a relational database or a NoSQL data store, the question is how the data can be propagated into the data lake. This is where the &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; project comes in: Based on Debezium and Apache Iceberg, it lets you process realtime data change events from a source database and upload them to any object storage supported by Iceberg. So let&amp;#8217;s take a closer look at these two projects.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;/&quot;&gt;Debezium&lt;/a&gt; is an open source distributed platform for change data capture. Debezium extracts change events from a database&amp;#8217;s transaction log and delivers them to consumers via event streaming platforms, using different formats such as JSON, Apache Avro, Google Protocol Buffers and others. Most of the time, Debezium is used with Apache Kafka and Kafka Connect. But via Debezium Server, also users of other messaging infrastructure like Kinesis, Google Pub/Sub, Pulsar can benefit from Debezium&amp;#8217;s change data capture capabilities. Here you can see the currently &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_sink_configuration&quot;&gt;supported destinations&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Apache Iceberg&lt;/a&gt; is an &quot;open table format for huge analytic datasets. Iceberg adds tables to compute engines including Spark, Trino, PrestoDB, Flink and Hive, using a high-performance table format which works just like a SQL table.&quot; It supports ACID inserts as well as row-level deletes and updates. It provides a Java API to manage table metadata, like schemas and partition specs, as well as data files that store table data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apache Iceberg has a notion of &lt;a href=&quot;https://iceberg.apache.org/spec/#version-2-row-level-deletes&quot;&gt;data and delete files&lt;/a&gt;. Data files are the files Iceberg uses behind the scene to keep actual data. Delete files are the immutable files to encode rows that are deleted in existing data files. This is how Iceberg deletes/replaces individual rows in immutable data files without rewriting the files. In the case of Debezium Server Iceberg, these are immutable &lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Apache Parquet&lt;/a&gt; files, a format which is designed as an &quot;efficient as well as performant flat columnar storage format of data compared to row based files like CSV or TSV files&quot;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;the_apache_iceberg_consumer&quot;&gt;The Apache Iceberg Consumer&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium Server provides an SPI to &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_implementation_of_a_new_sink&quot;&gt;implement new sink adapters&lt;/a&gt;, and this is the extension point used for creating the Apache Iceberg consumer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium-iceberg.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. Architecture Overview: Debezium Server and Apache Iceberg&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Iceberg consumer converts CDC change events to Iceberg data files and commits them to a destination table using the Iceberg Java API. It maps each Debezium source topic to a destination Iceberg table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a given Iceberg destination table is not found, the consumer creates it using the change event schema. Additionally, the event schema is used to map the change event itself to an equivalent Iceberg record. Because of this, the &lt;code&gt;debezium.format.value.schemas.enable&lt;/code&gt; configuration option must be set. Once the Debezium change event has been recorded into an Iceberg record, the schema is removed from the data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On a high level, change events processed as follows. For each received batch of events:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The events are grouped per destination Iceberg table; each group contains list of a change events coming from a single source table, sharing the same data schema&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;For each destination, events are converted to Iceberg records&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Iceberg records are saved as Iceberg data and delete files (delete files are created only if the consumer is running with upsert mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The files are committed to the destination Iceberg table (i.e. uploaded to the destination storage)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The processed change events marked as processed with Debezium&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here is a complete example configuration for using Debezium Server with the Iceberg adaptor:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.type=iceberg # run with append mode debezium.sink.iceberg.upsert=false debezium.sink.iceberg.upsert-keep-deletes=true debezium.sink.iceberg.table-prefix=debeziumcdc_ debezium.sink.iceberg.table-namespace=debeziumevents debezium.sink.iceberg.fs.defaultFS=s3a://S3_BUCKET); debezium.sink.iceberg.warehouse=s3a://S3_BUCKET/iceberg_warehouse debezium.sink.iceberg.type=hadoop debezium.sink.iceberg.catalog-name=mycatalog debezium.sink.iceberg.catalog-impl=org.apache.iceberg.hadoop.HadoopCatalog # enable event schemas debezium.format.value.schemas.enable=true debezium.format.value=json # complex nested data types are not supported, do event flattening. unwrap message! debezium.transforms=unwrap debezium.transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState debezium.transforms.unwrap.add.fields=op,table,source.ts_ms,db debezium.transforms.unwrap.delete.handling.mode=rewrite debezium.transforms.unwrap.drop.tombstones=true&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;upsert_and_append_modes&quot;&gt;Upsert and Append Modes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, the Iceberg consumer is running in upsert mode (&lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;). This means that when a row is updated in the source table, the destination is row replaced with the new updated version. And when a row is deleted from the source, it also is deleted from the destination. When using upsert mode, data at the destination is kept identical to the source data. The upsert mode uses the Iceberg equality delete feature and creates delete files using the key of the Debezium change data events (derived from the primary key of the source table). To avoid duplicate data, deduplication is done on each batch and only the last version of the record kept. For example in a single batch of events, the same record could appear twice: once when it is inserted, and another time when it gets updated. With upsert mode, always the last extracted version of the record is stored in Iceberg.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note that when a source table doesn&amp;#8217;t define a primary key and there is also no key information available by other means (e.g. a unique key or a custom message key defined in Debezium), the consumer uses the &lt;code&gt;append&lt;/code&gt; mode for this table (see below).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;keeping_deleted_records_with_upsert_mode&quot;&gt;Keeping Deleted Records With Upsert Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For some use cases it is useful to keep deleted records as a soft delete. This is possible by setting the &lt;code&gt;debezium.sink.iceberg.upsert-keep-deletes&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt;. This setting will keep the latest version of deleted records in the destination Iceberg table. Setting it to false will remove deleted records from the destination table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;append_mode&quot;&gt;Append Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This is the most straightforward operation mode, enabled by setting &lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. When using Debezium Server Iceberg with append mode, all received records are appended to the destination table. No data deduplication or deletion of records is done. With append mode it is possible to analyze entire change history of a record.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It also is possible to consume realtime events and do &lt;a href=&quot;https://iceberg.apache.org/maintenance/&quot;&gt;data compaction&lt;/a&gt; afterwards with a separate compaction job. Iceberg supports compacting data and metadata files to increase performance.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;optimizing_batch_sizes&quot;&gt;Optimizing Batch Sizes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium extracts and delivers database events in real time, and this could cause too frequent commits to the tables in Iceberg, generating too many small files. This is not optimal for batch processing, especially when a near-realtime data feed is sufficient. To avoid this problem, it is possible to increase the batch size per commit.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When enabling the &lt;code&gt;MaxBatchSizeWait&lt;/code&gt; mode, the Iceberg consumer uses Debezium metrics to optimize the batch size. It periodically retrieves the current size of Debezium&amp;#8217;s internal event queue and waits until it has reached &lt;code&gt;max.batch.size&lt;/code&gt;. During the wait time, Debezium events are collected in memory (in Debezium&amp;#8217;s internal queue). That way, each commit (set of events processed) processes more records and consistent batch size. The maximum wait and check interval are controlled via the &lt;code&gt;debezium.sink.batch.batch-size-wait.max-wait-ms&lt;/code&gt; and &lt;code&gt;debezium.sink.batch.batch-size-wait.wait-interval-ms&lt;/code&gt; properties. These settings should be configured together with Debezium&amp;#8217;s &lt;code&gt;debezium.source.max.queue.size&lt;/code&gt; and &lt;code&gt;debezium.source.max.batch.size&lt;/code&gt; properties.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here&amp;#8217;s an example for all the related settings:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.batch.batch-size-wait=MaxBatchSizeWait debezium.sink.batch.batch-size-wait.max-wait-ms=60000 debezium.sink.batch.batch-size-wait.wait-interval-ms=10000 debezium.sink.batch.metrics.snapshot-mbean=debezium.postgres:type=connector-metrics,context=snapshot,server=testc debezium.sink.batch.metrics.streaming-mbean=debezium.postgres:type=connector-metrics,context=streaming,server=testc # increase max.batch.size to receive large number of events per batch debezium.source.max.batch.size=50000 debezium.source.max.queue.size=400000&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;creating_additional_data_lake_layers&quot;&gt;Creating Additional Data Lake Layers&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At this point, the raw layer of the data lake has been loaded, including data deduplication and near realtime pipeline features. Building curated layers on top (sometimes called analytics layer or data warehouse layer) becomes very straightforward and simple. At the analytics layer, raw data is prepared to meet the analytics requirement; usually raw data is reorganized, cleaned, versioned (see example below), aggregated, and business logic may be applied. Using SQL through scalable processing engines is the most common way of doing this kind of data transformation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, someone could easily use &lt;a href=&quot;https://Iceberg.apache.org/spark-writes/&quot;&gt;Spark SQL&lt;/a&gt;(or PrestoDB, Trino, Flink, etc) to load a &lt;a href=&quot;https://en.wikipedia.org/wiki/Slowly_changing_dimension&quot;&gt;slowly changing dimension&lt;/a&gt;, the most commonly used data warehouse table type:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;MERGE &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;USING&lt;/span&gt; ( &lt;span class=&quot;comment&quot;&gt;-- new data to insert&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; customer_id, name, effective_date, to_date(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;9999-12-31&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;yyyy-MM-dd&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers &lt;span class=&quot;keyword&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;-- update exiting records. close end_date&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; t.customer_id, t.name, t.effective_date, s.effective_date &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers s &lt;span class=&quot;keyword&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; ) s &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; s.effective_date = t.effective_date &lt;span class=&quot;comment&quot;&gt;-- close last records/versions.&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;, t.end_date = s.end_date &lt;span class=&quot;comment&quot;&gt;-- insert new versions and new data&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;NOT&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt;(customer_id, name, current, effective_date, end_date) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt;(s.customer_id, s.name, &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;, s.effective_date, s.end_date);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Additional data lake layers may need to be updated periodically with new data. The easiest way of doing this is using SQL update or delete statements. These SQL operations are also &lt;a href=&quot;https://iceberg.apache.org/spark-writes/&quot;&gt;supported by Iceberg&lt;/a&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; prod.db.table &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; ...; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.table &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; ts &amp;gt;= &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-05-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; ts &amp;lt; &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-06-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.orders &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; t1 &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXISTS&lt;/span&gt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; order_id &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.returned_orders &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; t1.order_id = order_id; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; prod.db.all_events &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; session_time = &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, ignored = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; session_time &amp;lt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;predefined&quot;&gt;min&lt;/span&gt;(session_time) &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.good_events));&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;wrap_up_and_contributions&quot;&gt;Wrap-Up and Contributions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Based on Debezium and Apache Iceberg, &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; makes it very simple to set up a low-latency data ingestion pipeline for your data lake. The project completely open-source, using the Apache 2.0 license. Debezium Server Iceberg still is a young project and there are things to improve. Please feel free to test it, give feedback, open feature requests or send pull requests. You can see more examples and start experimenting with Iceberg and Spark using &lt;a href=&quot;https://github.com/ismailsimsek/iceberg-examples&quot;&gt;this project&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Ismail Simsek</name></author><category term="debezium"/><category term="iceberg"/><category term="datalake"/><category term="lakehouse"/><summary type="html">Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs. In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.</summary></entry><entry><title type="html">Incremental Snapshots in Debezium</title><link href="https://debezium.io/blog/2021/10/07/incremental-snapshots/" rel="alternate" type="text/html" title="Incremental Snapshots in Debezium"/><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/07/incremental-snapshots</id><content type="html" xml:base="https://debezium.io/blog/2021/10/07/incremental-snapshots/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the major improvements in Debezium starting in version 1.6 is support for &lt;a href=&quot;/documentation/reference/connectors/mysql.html#_ad_hoc_snapshot&quot;&gt;incremental snapshots&lt;/a&gt;. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;why_incremental_snapshots&quot;&gt;Why Incremental Snapshots?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the biggest pain points in Debezium since its inception was the sup-optimal support for changes to the captured tables list. As a user, you create a new connector with a list of tables to be captured (&lt;code&gt;table.include.list&lt;/code&gt; and related options); at a later point in time, it may become necessary to adjust this configuration, so to capture further tables which where not part to CDC initially. If it suffices to only &lt;em&gt;stream&lt;/em&gt; changes from these tables, then the problem is pretty simple to solve. But what if you also need to capture the existing contents of the tables?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Capturing existing data in tables is traditionally done by Debezium in the &lt;em&gt;snapshot&lt;/em&gt; phase. This phase is executed once upon the first connector start-up, and its objective is capturing consistent data at a point of time (transforming data at rest into data in motion). This can be a fairly long operation, and by definition, it must be executed completely or not at all - a bit like transaction semantics. This means that if the snapshot is not completed due to a connector restart for instance, it must be re-executed from scratch, and everything already done is thrown away. Also, while the snapshot is taken, any data modifications that are executed in parallel in the database are not streamed until the snapshot has been completed. This could lead to problems with database resources for very large snapshots, as transaction logs must be kept available until the streaming is started.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are thus ended up with three issues to be solved:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The near-impossibility of adding of additional tables to the captured tables list, if existing data must be streamed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A long-running process for consistent snapshotting that cannot be terminated or resumed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Change data streaming being blocked till the snapshot is completed&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;legacy_solutions&quot;&gt;Legacy Solutions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The problem was well known, and over time we developed workarounds and also ideated possible improvements and new solutions. As a workaround, the general recommendation was to use a multiple connector approach. The user was asked to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Stop the connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create a new one to take the snapshot of new tables (using the &lt;code&gt;initial_only&lt;/code&gt; snapshotting mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;When completed, stop the new connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Reconfigure and start the old connector with newly captured tables added to the list&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This method somewhat did the trick, but is very clumsy, and all the questions around snapshot consistency mentioned above still apply.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next step was a community contribution into the Debezium connector for MySQL via &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-175&quot;&gt;DBZ-175&lt;/a&gt;. It was based on the notion of having multiple binary log readers in place. One reader would capture the originally configured tables, while the other one will snapshot the new tables and then capture changes from the new tables. The latter reader would catch up with the original one, and then they would be reconciled and merged into a single one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The code was working well, but it never left the incubating stage, as the process itself was quite complex and liable to errors in corner cases. Last but not least, it was an ingenious approach, but unfortunately not portable to other connectors.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;watermark_based_snapshots&quot;&gt;Watermark-based Snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In late 2019, the Netflix engineering team announced that they had developed an in-house change data capture framework. They also came up with an innovative solution of executing concurrent snapshots using &lt;em&gt;watermarking&lt;/em&gt;, described in the paper &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt; DBLog: A Watermark Based Change-Data-Capture Framework&lt;/a&gt; by Andreas Andreakis and Ioannis Papapanagiotou.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The main idea behind this approach is that change data streaming is executed continuously together with snapshotting. The framework inserts low and high watermarks into the transaction log (by writing to the source database) and between those two points, a part of the snapshotted table is read. The framework keeps a record of database changes in between the watermarks and reconciles them with the snapshotted values, if the same records are snapshotted and modified during the window.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This means that the data is snapshotted in chunks - no lengthy process at the connector start, and also in case of crashes or a controlled termination of the connector, the snapshotting can be resumed since the last completed chunk.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As per Netflix, the implementation is provided for MySQL and PostgreSQL databases.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;signalling_table&quot;&gt;Signalling Table&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Before moving to Debezium&amp;#8217;s implementation of the watermark-based snapshotting approach, a small detour is needed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Sometimes it can be useful to control Debezium from the outside, so to force it to execute some requested action. Let&amp;#8217;s suppose it is necessary to re-snapshot an already snapshotted table - a so-called &lt;em&gt;ad-hoc&lt;/em&gt; snapshot. The user would need to send a command to Debezium to pause the current operation and do the snapshot. For that purpose, Debezium defines the concept &lt;em&gt;signals&lt;/em&gt;, issued via a &lt;a href=&quot;/documentation/reference/configuration/signalling.html&quot;&gt;signalling table&lt;/a&gt;. This is a special table, designated for communication between the user and Debezium. Debezium captures the table and when the user requires a certain operation to be executed, they simply write a record to the signalling table (sending a signal). Debezium will receive the captured change and then execute the required action.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_in_debezium&quot;&gt;Incremental Snapshotting in Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we became aware of DBLog&amp;#8217;s snapshotting approach, we decided that the method is a universal one and that we could try to adopt it in Debezium, too. Also as we share a lot of codebase among the different connectors (using the Debezium connector framework) our objective was to implement it in the Debezium core component, so that all connectors would benefit from the feature at once. The design and implementation were driven by the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;DDD-3&lt;/a&gt; Debezium design document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting in Debezium is available in form of ad-hoc snapshots. The user does not configure the connector to execute the snapshot, but instead they use the signalling mechanism to send a snapshot signal and thus trigger a snapshot of a set of tables. The signal in question is called &lt;code&gt;execute-snapshot&lt;/code&gt; and the signal message follows the format of:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-1&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-2&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-3&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;]}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a table snapshot is requested, then Debezium will do the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Obtain the largest primary key in the table; this is the snapshot endpoint, and its value is stored in the connector offsets&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Split the table into chunks based on the primary key&amp;#8217;s total order and of a size as prescribed by the &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; configuration option&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a chunk is queried, a dynamic SQL statement is built, selecting the next &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; records, whose primary keys are larger than the last one from the previous chunk (or the first primary key for the first chunk) and which are smaller or equal to the recorded maximum primary key.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The default chunk size is 1,024. You may increase the value for efficiency purposes (a smaller total number of snapshot queries will be executed), but this should be balanced with the increased memory consumption needed for the buffer. It is recommended to do some experimentation in your own environment to identify the setting working best for your situation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The reading of a chunk is a slightly complicated procedure:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk query is executed and the chunk content is read into memory&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Why is this needed? Why it is not enough to just query the database? The answers lie in the following picture:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/transactions.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. The transaction isolation&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is not the only process accessing the database. We can expect a multitude of processes accessing the database concurrently, potentially accessing the same records which currently are snapshotted. As shown in the picture, any changes to data are written to the transaction log based on the commit order. As it is not possible to precisely time the chunk read transaction to identify potential conflicts, the open and close window events are added to demarcate the time in which the conflicts can happen. Debezium&amp;#8217;s task is the deduplication of those conflicts.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For that purpose, Debezium records all events generated by the chunk into a buffer. When the &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is received, then all events coming from the transaction log are checked whether they belong to the snapshotted table(s). If yes, then the buffer is checked whether it contains the primary key. If yes, then the snapshot event is dropped from the buffer, as this is a potential conflict. And as it is not possible to correctly order the snapshot and transaction log events, only the transaction log event is kept. When the &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is received, the remaining snapshot events in the buffer are sent downstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following image shows an example of how such a buffer works and how are the transaction log events are filtered before being sent downstream:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/windowprocessing.png&quot; style=&quot;max-width:70%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. The buffer in action&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Records K2, K3, and K4 exist already in the database. Before the snapshot window opens, records K1 gets inserted, K2 updated, and K3 deleted. These events are sent downstream as they are read from the log. The snapshot windows opens, and its query selects K1, K2, and K4 into the buffer. While the window is open, the deletion of K4 is retrieved from the transaction log; the snapshot event for K4 is dropped from the buffer and the deletion event is sent downstream. K5 and K6 are inserted, which is retrieved from the log, corresponding events will be emitted. Depending on the specific timing, there may be read events for them in the buffer too (in the image that&amp;#8217;s the case for K5), which would be dropped. When the snapshot window closes, the remaining snapshot events for K1 and K2 will be emitted from the buffer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;connector_restarts&quot;&gt;Connector Restarts&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By now we have demonstrated that, using the notion of incremental snapshots, the same table(s) can be snapshotted repeatedly, if and when needed, while the connector is running. We have shown that its execution does not stop streaming from the transaction log. The last item is pausing and continuation of the process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When an incremental snapshot is running, then incremental snapshot context is added to each of the message offsets. The context is represented by three pieces of information:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The list of tables to be snapshotted where the first one is the one currently snapshotted&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The maximum primary key of the table&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The primary key of the last event from incremental snapshot sent downstream&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These three items are enough to resume the snapshot after a connector restart, be it intentionally or after a crash. Upon connector start, the component responsible for the snapshotting reads the data from the offsets. It initializes its internal state and resumes snapshotting after the last processed event. Note that any records which were inserted or updated while the connector wasn&amp;#8217;t running, will be processed via the regular stream reading, i.e. they are not subject to the ongoing snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This approach ensures the robustness of the process, resilience to restarts and crashes, and minimizes the number of redelivered events (at-least-once delivery semantics still apply).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;limitations&quot;&gt;Limitations&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The incremental snapshotting has few drawbacks in comparison to the initial consistent snapshot:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The snapshotted table must contain primary keys&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is deleted from the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and a &lt;code&gt;delete&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only a &lt;code&gt;delete&lt;/code&gt; event is be received&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is updated in the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and an &lt;code&gt;update&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;An &lt;code&gt;update&lt;/code&gt; event and &lt;code&gt;read&lt;/code&gt; event are received (note the opposite order)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only an &lt;code&gt;update&lt;/code&gt; event is received (in case the update happened within the chunk that would have emitted the &lt;code&gt;read&lt;/code&gt; event, causing that &lt;code&gt;read&lt;/code&gt; event to be discarded during de-duplication)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In general, &lt;code&gt;read&lt;/code&gt; events should not be understood as the initial state of the record in a table, but as the state of the record at an arbitrary point of time. Semantics for consumers are slightly changed in comparison to traditional initial snapshots in Debezium, while it will be guaranteed that a consumer has received the complete data set after an incremental snapshot has been completed, there won&amp;#8217;t be &lt;code&gt;read&lt;/code&gt; (snapshot) events for all records, but it could be &lt;code&gt;update&lt;/code&gt; events instead. The same goes for &lt;code&gt;delete&lt;/code&gt; events: consumers must be prepared to receive such events for records they had not seen before.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Having discussed the general concepts, let&amp;#8217;s explore things a bit more in an example. We will use our standard &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial&quot;&gt;tutorial deployment&lt;/a&gt; to demonstrate ad-hoc incremental snapshotting. We are using &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#using-postgres&quot;&gt;PostgreSQL&lt;/a&gt; as the source database. For this demo, you will need multiple terminal windows.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the beginning we will start the deployment, create the signalling table, and start the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 1 - start the deployment # Start the deployment export DEBEZIUM_VERSION=1.7 docker-compose -f docker-compose-postgres.yaml up # Terminal 2 # Create a signalling table echo &amp;quot;CREATE TABLE inventory.dbz_signal (id varchar(64), type varchar(32), data varchar(2048))&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Start Postgres connector, capture only customers table and enable signalling curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; -H &amp;quot;Content-Type:application/json&amp;quot; http://localhost:8083/connectors/ -d @- &amp;lt;&amp;lt;EOF { &amp;quot;name&amp;quot;: &amp;quot;inventory-connector&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.debezium.connector.postgresql.PostgresConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;database.hostname&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.port&amp;quot;: &amp;quot;5432&amp;quot;, &amp;quot;database.user&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.password&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.dbname&amp;quot; : &amp;quot;postgres&amp;quot;, &amp;quot;database.server.name&amp;quot;: &amp;quot;dbserver1&amp;quot;, &amp;quot;schema.include&amp;quot;: &amp;quot;inventory&amp;quot;, &amp;quot;table.include.list&amp;quot;: &amp;quot;inventory.customers,inventory.dbz_signal&amp;quot;, &amp;quot;signal.data.collection&amp;quot;: &amp;quot;inventory.dbz_signal&amp;quot; } } EOF&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the log we see that as per the &lt;code&gt;table.include.list&lt;/code&gt; setting only one table is snapshotted, &lt;code&gt;customers&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;connect_1 | 2021-09-24 13:38:21,781 INFO Postgres|dbserver1|snapshot Snapshotting contents of 1 tables while still in transaction [io.debezium.relational.RelationalSnapshotChangeEventSource]&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next step we will simulate continuous activity in the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 3 # Continuously consume messages from Debezium topic for customers table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.customers # Terminal 4 # Modify records in the database via Postgres client docker-compose -f docker-compose-postgres.yaml exec postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;i=0; while true; do psql -U $POSTGRES_USER postgres -c \&amp;quot;INSERT INTO customers VALUES(default,'name\$i','surname\$i','email\$i')\&amp;quot;; ((i++)); done&amp;quot;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic &lt;code&gt;dbserver1.inventory.customers&lt;/code&gt; receives a continuous stream of messages. Now the connector will be reconfigured to also capture the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;# Terminal 5 # Add orders table among the captured curl -i -X PUT -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/inventory-connector/config -d @- &amp;lt;&amp;lt;EOF { &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;, &quot;tasks.max&quot;: &quot;1&quot;, &quot;database.hostname&quot;: &quot;postgres&quot;, &quot;database.port&quot;: &quot;5432&quot;, &quot;database.user&quot;: &quot;postgres&quot;, &quot;database.password&quot;: &quot;postgres&quot;, &quot;database.dbname&quot; : &quot;postgres&quot;, &quot;database.server.name&quot;: &quot;dbserver1&quot;, &quot;schema.include&quot;: &quot;inventory&quot;, &quot;table.include.list&quot;: &quot;inventory.customers,inventory.dbz_signal,inventory.orders&quot;, &quot;signal.data.collection&quot;: &quot;inventory.dbz_signal&quot; } EOF&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As expected, there are no messages for the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now let&amp;#8217;s start an incremental ad-hoc snapshot by sending a signal. The snapshot messages for the &lt;code&gt;orders&lt;/code&gt; table are delivered to the &lt;code&gt;dbserver1.inventory.orders&lt;/code&gt; topic. Messages for the &lt;code&gt;customers&lt;/code&gt; table are delivered without interruption.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 # Send the signal echo &amp;quot;INSERT INTO inventory.dbz_signal VALUES ('signal-1', 'execute-snapshot', '{\&amp;quot;data-collections\&amp;quot;: [\&amp;quot;inventory.orders\&amp;quot;]}')&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Check messages for orders table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you were to modify any record in the &lt;code&gt;orders&lt;/code&gt; table while the snapshot is running, this would be either emitted as a &lt;code&gt;read&lt;/code&gt; event or as an &lt;code&gt;update&lt;/code&gt; event, depending on the exact timing and sequence of things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the last step, let&amp;#8217;s terminate the deployed systems and close all terminals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Shut down the cluster docker-compose -f docker-compose-postgres.yaml down&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post, we have discussed the motivation for the notion of incremental snapshotting, as introduced by the DBLog paper. We have reviewed the methods used in the past to achieve the described functionality. Then we dived into the deep waters of the implementation of this novel snapshotting approach in Debezium, and in the end we tried to use it live.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We hope you will find incremental snapshotting useful and we look forward to your feedback, experiences, and use cases. In a future blog post, we&amp;#8217;ll talk about the support for incremental snaphots of read-only databases (supported by the Debezium MySQL connector as of version 1.7) and how to trigger ad-hoc snapshots using a Kafka topic as the means of signalling instead of a database table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="db2"/><category term="snapshots"/><summary type="html">One of the major improvements in Debezium starting in version 1.6 is support for incremental snapshots. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.</summary></entry><entry><title type="html">Debezium 1.7.0.Final Released</title><link href="https://debezium.io/blog/2021/10/04/debezium-1-7-final-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.Final Released"/><published>2021-10-04T00:00:00+00:00</published><updated>2021-10-04T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/04/debezium-1-7-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/10/04/debezium-1-7-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s with great pleasure that I am announcing the release of Debezium &lt;strong&gt;1.7.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Key features of this release include substantial improvements to the notion of incremental snapshotting (as introduced in Debezium 1.6), a web-based user Debezium user interface, NATS support in Debezium Server, and support for running Apache Kafka without ZooKeeper via the Debezium Kafka container image.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also in the wider Debezium community some exciting things happened over the last few months; For instance, we saw a CDC connector for ScyllaDB &lt;a href=&quot;/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/&quot;&gt;based on the Debezium connector framework&lt;/a&gt;, and there&amp;#8217;s work happening towards a &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server connector for Apache Iceberg&lt;/a&gt; (details about this coming soon in a guest post on this blog).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_improvements&quot;&gt;Incremental Snapshotting Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Introduced in Debezium 1.6 and based on a &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;paper published by Netflix Engineering&lt;/a&gt;, incremental snapshotting addresses many long-standing feature requests around initial snapshots, such as the ability to re-snapshot specific tables, support for modifications to the include/exclude filter configuration, and resumeability of snapshots after a connector restart.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For Debezium 1.7, incremental snapshotting has been further improved and stabilized. The &lt;a href=&quot;/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL connector&lt;/a&gt; now allows incremental snapshotting for databases without write access by the connector, which is very useful when pointing Debezium to read-only replicas. Ad-hoc snapshots can now not only be triggered via the signal table as before, but also by sending a message to a specific Kafka topic, again strengthening the support for read-only scenarios. A big thank you to &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Kate Galieva&lt;/a&gt; of &lt;a href=&quot;https://shopify.engineering/capturing-every-change-shopify-sharded-monolith&quot;&gt;Shopify Engineering&lt;/a&gt; for these contributions!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting is now also supported by the &lt;a href=&quot;/documentation/reference/connectors/oracle.html&quot;&gt;Debezium connector for Oracle&lt;/a&gt;. Another snapshotting improvement relates to non-incremental snapshots: filtered columns are now excluded from snapshot select statements right away, which improves performance of the connector when excluding large BLOB columns for instance.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ll follow up with a more detailed blog post around incremental snapshotting shortly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_ui&quot;&gt;Debezium UI&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium UI is part of our efforts to further simplify the experience of getting started with and operating Debezium. &lt;a href=&quot;/documentation/reference/operations/debezium-ui.html&quot;&gt;The UI&lt;/a&gt; lets you configure and start new connectors, examine the state of running connectors, and more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/CreateConnectorStep2.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team has been working tirelessly to build out this web app, with support for setting up transformations (SMTs) and topic auto creation settings coming up shortly. In the meantime please take a look at the &lt;a href=&quot;/blog/2021/08/12/introducing-debezium-ui/&quot;&gt;blog post&lt;/a&gt; initially announcing the UI to learn more about it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements&quot;&gt;Further Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other improvements in Debezium 1.7 include &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_nats_streaming&quot;&gt;support for NATS Streaming in Debezium Server&lt;/a&gt;, as well as support for Apache Kafka 2.8 in the Debezium container images. You even can use the Debezium container image for Apache Kafka to &lt;a href=&quot;https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/&quot;&gt;get your feet wet&lt;/a&gt; with running Apache Kafka without ZooKeeper!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There&amp;#8217;s support for MySQL &lt;code&gt;INVISIBLE&lt;/code&gt; columns, an off-heap implementation of the transaction buffer of the Debezium connector for Oracle, allowing to process large long-running transactions, and much more. There also have been made several very nice performance improvements; a shout-out to Naveen Kumar for his continued help here, including the creation of several JMH benchmarks for measuring the impact of improvements to specific performance-sensitive areas of the code base.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4067?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.7.0.Alpha1%2C%201.7.0.Beta1%2C%201.7.0.CR1%2C%201.7.0.CR2%2C%201.7.0.Final&quot;&gt;206 issues&lt;/a&gt; have been fixed for the 1.7 final and preview releases. You can find out more in the original announcement posts for Debezium &lt;a href=&quot;/blog/2021/08/02/debezium-1-7-alpha1-released/&quot;&gt;1.7.0.Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/08/25/debezium-1-7-beta1-released/&quot;&gt;1.7.0.Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/09/16/debezium-1-7-cr1-released/&quot;&gt;1.7.0.CR1&lt;/a&gt;, and &lt;a href=&quot;/blog/2021/09/23/debezium-1-7-cr2-released/&quot;&gt;1.7.0.CR2&lt;/a&gt;. Please refer to the &lt;a href=&quot;/releases/1.7/release-notes#release-1.7.0-final&quot;&gt;release notes&lt;/a&gt; of Debezium 1.7.0.Final for the list of issues resolved since CR2 as well as procedures for upgrading from earlier versions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium project couldn&amp;#8217;t exist without its amazing community of contributors from different countries all around the world! A big thank you to everyone contributing to this release in one way or another! Kudos to the following individuals from the community which contributed to the Debezium core repository in 1.7:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashmeet13&quot;&gt;Ashmeet Lamba&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/diff-by-default&quot;&gt;Blake Peno&lt;/a&gt;, &lt;a href=&quot;https://github.com/umanwizard&quot;&gt;Brennan Vincent&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/d3vel0per&quot;&gt;Dhrubajyoti G&lt;/a&gt;, &lt;a href=&quot;https://github.com/sirscratchalot&quot;&gt;Erik Malm&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/indraraj&quot;&gt;Indra Shukla&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/jornargelo&quot;&gt;Jorn Argelo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/kyleyj&quot;&gt;Kyley Jex&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martn Prez&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt;, &lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;, &lt;a href=&quot;https://github.com/xaka&quot;&gt;Pavel Strashkin&lt;/a&gt;, &lt;a href=&quot;https://github.com/raphaelauv&quot;&gt;Raphael Auv&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;Ren Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/tavancini&quot;&gt;Thiago Avancini&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/tinntsea&quot;&gt;Tin Nguyen&lt;/a&gt;, &lt;a href=&quot;https://github.com/tommyk-gears&quot;&gt;Tommy Karlsson&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/elgca&quot;&gt;WenChao Ke&lt;/a&gt;, &lt;a href=&quot;https://github.com/jjiey&quot;&gt;yangsanity&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhangyuan&quot;&gt;Yuan Zhang&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;https://github.com/zregvart&quot;&gt;Zoran Regvart&lt;/a&gt;, &lt;a href=&quot;https://github.com/ili-zh&quot;&gt;&lt;/a&gt;, and &lt;a href=&quot;https://github.com/pkgonan&quot;&gt; &lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next Debezium release, 1.8, is planned for the end of the year. The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; is still in flux, but some of the features we plan to address are support for MongoDB change streams (so to support MongoDB 5.0), improved support for MariaDB, and the ability to compact large database history topics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re also planning to further build out the Debezium UI, continue the work on the Debezium connector for Oracle and making the SQL Server connector capable of dealing with multiple databases at once, and much more. Please let us know about your feature requests via the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s with great pleasure that I am announcing the release of Debezium 1.7.0.Final! Key features of this release include substantial improvements to the notion of incremental snapshotting (as introduced in Debezium 1.6), a web-based user Debezium user interface, NATS support in Debezium Server, and support for running Apache Kafka without ZooKeeper via the Debezium Kafka container image. Also in the wider Debezium community some exciting things happened over the last few months; For instance, we saw a CDC connector for ScyllaDB based on the Debezium connector framework, and there&amp;#8217;s work happening towards a Debezium Server connector for Apache Iceberg (details about this coming soon in a guest post on this blog).</summary></entry><entry><title type="html">Debezium 1.7.0.CR2 Released</title><link href="https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.CR2 Released"/><published>2021-09-23T00:00:00+00:00</published><updated>2021-09-23T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are very happy to announce the release of Debezium &lt;strong&gt;1.7.0.CR2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we are moving ahead towards the final release we include mostly bugfixes. Yet this release contains important performance improvements and a new feature for read-only MySQL incremental snapshots.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_based_signalling&quot;&gt;Kafka based signalling&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Recent releases provided a new feature for MySQL - incremental snapshotting from a read-only database. The snapshot process is based on GTIDs and does not need writing to signalling table. The problem is that triggering the process still required the existence and write access to the signalling table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now it is possible to send the signal via Kafka topic. This feature is available when the MySQL connector is configured with &lt;code&gt;read-only = true&lt;/code&gt;. Please refer to the documentation for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;performance_improvements&quot;&gt;Performance improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt; identified multiple performance issues in the Debezium&amp;#8217;s core critical path. He benchmarked them and provided pull requests solving them. If you are interested in details, please check &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4015&quot;&gt;DBZ-4015&lt;/a&gt; and &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3887&quot;&gt;DBZ-3887&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we&amp;#8217;re approaching the 1.7 Final release, most changes have been centered around bug fixing and maturing the codebase. Some of the resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Connection failure after snapshot wasn&amp;#8217;t executed for a while (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3951&quot;&gt;DBZ-3951&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incorrect incremental snapshot DDL triggers snapshot that generates unending inserts against signalling table (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-4013&quot;&gt;DBZ-4013&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3917&quot;&gt;DBZ-3917&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4017&quot;&gt;DBZ-4017&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.7.0.CR2&quot;&gt;14 issues&lt;/a&gt; have been fixed for this release. A big thank you to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, and &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are on a good path towards &lt;code&gt;1.7.0.Final&lt;/code&gt; by the end of the next week.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="outbox"/><summary type="html">We are very happy to announce the release of Debezium 1.7.0.CR2! As we are moving ahead towards the final release we include mostly bugfixes. Yet this release contains important performance improvements and a new feature for read-only MySQL incremental snapshots.</summary></entry><entry><title type="html">Deep Dive Into a Debezium Community Connector: The Scylla CDC Source Connector</title><link href="https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/" rel="alternate" type="text/html" title="Deep Dive Into a Debezium Community Connector: The Scylla CDC Source Connector"/><published>2021-09-22T17:10:00+00:00</published><updated>2021-09-22T17:10:00+00:00</updated><id>https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector</id><content type="html" xml:base="https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At ScyllaDB, we develop a high-performance NoSQL database &lt;a href=&quot;https://www.scylladb.com/&quot;&gt;Scylla&lt;/a&gt;, API-compatible with Apache Cassandra, Amazon DynamoDB and Redis. Earlier this year, we introduced support for &lt;a href=&quot;https://docs.scylladb.com/using-scylla/cdc/cdc-intro/&quot;&gt;Change Data Capture&lt;/a&gt; in Scylla 4.3. This new feature seemed like a perfect match for integration with the Apache Kafka ecosystem, so we developed the &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector&quot;&gt;Scylla CDC Source Connector&lt;/a&gt; using the Debezium framework. In this blogpost we will cover the basic structure of Scyllas CDC, reasons we chose the Debezium framework and design decisions we made.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cdc_support_in_scylla&quot;&gt;CDC support in Scylla&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Change Data Capture (CDC) allows users to track data modifications in their Scylla database. It can be easily enabled/disabled on any Scylla table. Upon turning it on, a log of all modifications (INSERTs, UPDATEs, DELETEs) will be created and automatically updated.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we designed our implementation of CDC in Scylla, we wanted to make it easy to consume the CDC log. Therefore, the CDC log is stored as a regular Scylla table, accessible by any existing CQL driver. When a modification is made to a table with CDC enabled, information about that operation is saved to the CDC log table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Heres a quick demo of it: First, we will create a table with CDC enabled:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; ks.orders( user &lt;span class=&quot;predefined-type&quot;&gt;text&lt;/span&gt;, order_id &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, order_name &lt;span class=&quot;predefined-type&quot;&gt;text&lt;/span&gt;, &lt;span class=&quot;directive&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;KEY&lt;/span&gt;(user, order_id) ) WITH cdc = {&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;};&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Next, lets perform some operations:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.orders(user, order_id, order_name) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Tim&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;apple&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.orders(user, order_id, order_name) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Alice&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;blueberries&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; ks.orders &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; order_name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pineapple&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; user = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Tim&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; order_id = &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Finally, lets see the contents of the modified table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.orders; user | order_id | order_name &lt;span class=&quot;comment&quot;&gt;------+----------+-------------&lt;/span&gt; Tim | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | pineapple Alice | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | blueberries&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Looking only at this table, you cannot reconstruct all modifications that took place, e.g. Tims order name before the UPDATE. Lets look at the CDC log, easily accessible as a table (some columns truncated for clarity):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.orders_scylla_cdc_log; cdc$stream_id | cdc$time | | cdc$operation | order_id | order_name | user &lt;span class=&quot;comment&quot;&gt;---------------+----------+-...-+---------------+----------+-------------+----------&lt;/span&gt; &lt;span class=&quot;hex&quot;&gt;0x2e46a&lt;/span&gt;... | &lt;span class=&quot;error&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;4&lt;/span&gt;... | ... | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | apple | Tim &lt;span class=&quot;hex&quot;&gt;0x2e46a&lt;/span&gt;... | &lt;span class=&quot;float&quot;&gt;8f&lt;/span&gt;dc... | ... | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | pineapple | Tim &lt;span class=&quot;hex&quot;&gt;0x41400&lt;/span&gt;... | &lt;span class=&quot;error&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;8&lt;/span&gt;e... | ... | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | blueberries | Alice&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;All three operations are visible in the CDC log. There are two INSERTs (&lt;code&gt;cdc$operation = 2&lt;/code&gt;) and one UPDATE (&lt;code&gt;cdc$operation = 1&lt;/code&gt;). For each operation, its timestamp is also preserved in &lt;code&gt;cdc$time&lt;/code&gt; column. The timestamp is encoded as a time-based UUID value as specified by the &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc4122&quot;&gt;RFC 4122&lt;/a&gt; specification, which can be decoded using helper methods in Scylla drivers.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;choosing_debezium&quot;&gt;Choosing Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As shown in the previous section, Scylla CDC can be easily queried as a regular table. To get the latest operations in real-time, you poll the table with appropriate time ranges. To make this easier, we developed client libraries for &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-java&quot;&gt;Java&lt;/a&gt; and &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-go&quot;&gt;Go&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we thought about how our customers could access the CDC log, using it with Kafka seemed like the most accessible method. Therefore, we decided to develop a source connector for Scylla CDC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For our first proof-of-concept, we implemented the source connector using the &lt;a href=&quot;https://kafka.apache.org/documentation.html#connect_development&quot;&gt;Kafka Connect API&lt;/a&gt;. This prototype was crucial for us to determine if the connector could scale horizontally (described later in this blogpost).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, we quickly realized that by using only the Kafka Connect API, we would have to reimplement a lot of functionality already present in other connectors. We also wanted our connector to be a good citizen in the Kafka community, sticking to the best practices and conventions. Thats exactly why we choose Debezium!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to this, when you start the Scylla CDC Source Connector, the configuration parameters will be immediately familiar, as many of them are common with other Debezium connectors. The generated data change events have the same &lt;a href=&quot;https://javadoc.io/static/io.debezium/debezium-core/1.6.2.Final/io/debezium/data/Envelope.html&quot;&gt;Envelope&lt;/a&gt; structure as generated by other Debezium connectors. This similarity allows for the use of many standard Debezium features, such as &lt;a href=&quot;/documentation/reference/1.6/transformations/event-flattening.html&quot;&gt;New Record State Extraction&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;event_representation&quot;&gt;Event representation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After we decided to use the Debezium framework, we looked at how Scylla CDC operations should be represented in Debeziums Envelope format.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Envelope format consists of the following fields:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;op&lt;/code&gt; - type of operation: &lt;code&gt;c&lt;/code&gt; for create, &lt;code&gt;u&lt;/code&gt; for update, &lt;code&gt;d&lt;/code&gt; for delete and &lt;code&gt;r&lt;/code&gt; for read&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;before&lt;/code&gt; - state of row before an event occured&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;after&lt;/code&gt; - state of row after an event occurred&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;source&lt;/code&gt; - metadata of the event&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;ts_ms&lt;/code&gt; - time the connector processed the event&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Mapping Scylla operations to the &lt;code&gt;op&lt;/code&gt; field was fairly easy: &lt;code&gt;c&lt;/code&gt; for INSERT, &lt;code&gt;u&lt;/code&gt; for UPDATE, &lt;code&gt;d&lt;/code&gt; for DELETE.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We decided to skip DELETE events that span multiple rows, such as range DELETEs:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.table &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; pk = &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; ck &amp;gt; &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; ck &amp;lt; &lt;span class=&quot;integer&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Representing such operations would unnecessarily complicate the format in order to accommodate additional range information. Moreover, it would break the expectation that an Envelope represents a modification to a single row.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Scylla CDC, range DELETEs are represented as two rows in the CDC table: the first row encodes the information about the start of the deleted range (in the example above: &lt;code&gt;pk = 1, ck &amp;gt; 0&lt;/code&gt;) and the second row encodes the end of the deleted range (in the example above: &lt;code&gt;pk = 1, ck &amp;lt; 5&lt;/code&gt;). An information about each of the rows present in that range is not persisted. This corresponds to a fact that DELETEs in Scylla generate a tombstone in the database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, Scyllas CDC stores the primary key and only the modified columns of an operation. For example, suppose I created a table and inserted a row:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; ks.example( pk &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v1 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v2 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v3 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;directive&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;KEY&lt;/span&gt;(pk)) WITH cdc = {&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;}; &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.example(pk, v1, v2, v3) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Scylla you can issue another INSERT statement, which will override some of the columns:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.example(pk, v1, v3) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;predefined-constant&quot;&gt;null&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;v2&lt;/code&gt; column is left unchanged after this query and we dont have any information about its previous value.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We must be able to represent three possibilities: a column was not modified, a column was assigned a &lt;code&gt;NULL&lt;/code&gt; value or a column was assigned a non-null value. The representation we chose was inspired by &lt;a href=&quot;/documentation/reference/1.6/connectors/cassandra.html&quot;&gt;Debezium Connector for Cassandra&lt;/a&gt;, which works by wrapping the value for a column in a structure:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;}, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A &lt;code&gt;null&lt;/code&gt; structure value represents that a column was not modified (&lt;code&gt;v2&lt;/code&gt; field). If the column was assigned a &lt;code&gt;NULL&lt;/code&gt; value (&lt;code&gt;v3&lt;/code&gt; field), there will be a structure with a &lt;code&gt;NULL&lt;/code&gt; &lt;code&gt;value&lt;/code&gt; field. A non-null column assignment (&lt;code&gt;v1&lt;/code&gt; field) fills the contents of the &lt;code&gt;value&lt;/code&gt; field. Such a format allows us to correctly represent all the possibilities and differentiate between assigning &lt;code&gt;NULL&lt;/code&gt; and non-modification.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, most sink connectors wont be able to correctly parse such a structure. Therefore, we decided to develop our own SMT, based on Debeziums &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/transformations/event-flattening.html&quot;&gt;New Record State Extraction SMT&lt;/a&gt;. Our &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector#scyllaextractnewstate-transformer&quot;&gt;ScyllaExtractNewState&lt;/a&gt; SMT works by applying Debezium&amp;#8217;s New Record State Extraction and flattening the &lt;code&gt;{&quot;value&quot;: &amp;#8230;&amp;#8203;}&lt;/code&gt; structures (at the expense of not being able to distinguish &lt;code&gt;NULL&lt;/code&gt; value and missing column value):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Scyllas CDC also supports recording pre-images and post-images with every operation (at an additional cost). We plan to add support for them in the future versions of the Scylla CDC Source Connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;horizontal_scaling&quot;&gt;Horizontal scaling&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Even at a stage of proof-of-concept, great performance was a paramount requirement. Scylla databases can scale to hundreds of nodes and PBs of data, so it became clear that a single Kafka Connect worker node (even multithreaded) could not handle the load of a big Scylla cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thankfully, we took that into consideration while implementing CDC functionality in Scylla. Generally, you can think of Change Data Capture as a time-ordered queue of changes. To allow for horizontal scaling, Scylla maintains a set of multiple time-ordered queues of changes, called streams. When there is only a single consumer of the CDC log, it has to query all streams to properly read all changes. A benefit of this design is that you can introduce additional consumers, assigning a disjunct set of streams to each one of them. As a result, you can greatly increase the parallelism of processing the CDC log.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thats the approach we implemented in the Scylla CDC Source Connector. When starting, the connector first reads the identifiers of all available streams. Next, it distributes them among many Kafka Connect tasks (configurable by &lt;code&gt;tasks.max&lt;/code&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Each created Kafka Connect task (that can run on a separate Kafka Connect node) reads CDC changes from its assigned set of streams. If you double the number of tasks, each task will have to read only a half of the number of streams - half of data throughput, making it possible to handle a higher load.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;solving_large_stream_count_problem&quot;&gt;Solving large stream count problem&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While designing CDC functionality in Scylla, we had to carefully pick the number of streams that would be created. If we chose too few streams, a consumer could possibly not keep up with the data throughput of a single stream. That could also slow down INSERT, UPDATE, DELETE operations, because many concurrent operations would fight for access to a single stream. However, if Scylla created too many streams, the consumers would have to issue a large number of queries to Scylla (to cover each stream), causing unnecessary load.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The current implementation of CDC in Scylla creates &lt;code&gt;number_of_nodes * number_of_vnodes_per_node * number_of_shards&lt;/code&gt; streams per cluster. The number of VNodes refers to the fact that Scylla uses a &lt;a href=&quot;https://docs.scylladb.com/architecture/ringarchitecture/&quot;&gt;Ring architecture&lt;/a&gt;, which has 256 VNodes per node by default. Each Scylla node consists of several independent shards, which contain their share of the nodes total data. Typically, there is one shard per each hyperthread or physical core.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, if you create a 4-node i3.metal (72 vCPU per node) Scylla cluster, which is capable of roughly 600k operations per second (half INSERTs, half SELECTs), that would be: &lt;code&gt;4 * 256 * 72 = 73728&lt;/code&gt; streams.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We quickly realised that this many streams could be a problem in bigger clusters:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;Too many queries to Scylla - one query per each stream&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Too many Kafka Connect offsets - one offset per each stream. Storing offsets means the connector can resume from the last saved position after a crash.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To mitigate those problems, we made a decision to group streams on the client side. We chose to group the streams by VNode. This reduced the count from &lt;code&gt;number_of_nodes * number_of_vnodes_per_node * number_of_shards&lt;/code&gt; to &lt;code&gt;number_of_nodes * number_of_vnodes_per_node&lt;/code&gt;. In the case of 4-node i3.metal that means a reduction from 73728 to 1024: only 1024 queries to Scylla and 1024 offsets stored on Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, we were still uneasy about the number of offsets to be stored on Kafka. When we looked into other connectors, most of them stored only a single offset or at most tens of offsets per replicated table (and as an effect having a limited scalability).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To understand why storing thousands of streams on Kafka Connect could be a problem, lets look at how it works under the hood. Each Kafka Connect record created by a source connector contains a key/value offset, for example: key - &lt;code&gt;my_table&lt;/code&gt;; offset - &lt;code&gt;25&lt;/code&gt;, which could represent that the connector finished reading 25 rows in &lt;code&gt;my_table&lt;/code&gt;. Periodically (configured by &lt;code&gt;offset.flush.interval.ms&lt;/code&gt;), those offsets are flushed to a Kafka topic called &lt;code&gt;connect-offsets&lt;/code&gt;, as regular Kafka messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Unfortunately, Kafka is not a key/value store. When a connector starts up, it must scan all messages on the &lt;code&gt;connect-offsets&lt;/code&gt; topic to find the one it needs. When it updates a previously saved offset, it just appends the new value to this topic without deleting the previous entry. Its not a problem with connectors that have only a single offset - when updated every minute, this topic would hold roughly 10,000 messages after a week. However, in the case of the Scylla CDC Source Connector this number could be several orders of magnitude larger!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Fortunately, this issue can be easily mitigated by setting a more aggressive compaction configuration on the &lt;code&gt;connect-offsets&lt;/code&gt; topic. With the default configuration of &lt;code&gt;retention.ms&lt;/code&gt; of 7 days and &lt;code&gt;segment.bytes&lt;/code&gt; of 1GB, this topic could grow up to several hundred megabytes after just a few hours (with a Scylla cluster with tens of nodes and very small &lt;code&gt;offset.flush.interval.ms&lt;/code&gt;). This made the connector startup time slower, as it had to scan the entire offset topic after a start/restart. By tuning the &lt;code&gt;segment.bytes&lt;/code&gt;, &lt;code&gt;segment.ms&lt;/code&gt; or &lt;code&gt;cleanup.policy&lt;/code&gt;, &lt;code&gt;retention.ms&lt;/code&gt; we were able to mitigate the problem and significantly reduce the &lt;code&gt;connect-offsets&lt;/code&gt; topic size. The first two options specify the frequency of the log compaction process. When a segment is compacted, all messages with the same key are reduced to the latest one (the latest offset). Alternatively, setting a shorter retention time (but one that is larger than Scyllas CDC retention time) proved to be a good option to reduce the offset topic size.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;benchmarks_near_linear_scaling&quot;&gt;Benchmarks: near linear scaling&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To verify that our connector can actually scale horizontally, we performed a benchmark to measure the maximum throughput of Scylla CDC Source Connector on increasingly larger Kafka Connect clusters.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, we started a single-node i3.4xlarge Scylla cluster (based on the official Scylla AMI). Next, we inserted 50 million rows (total size 5.33GB) to a CDC-enabled table. Later, we started an Apache Kafka 2.6.0 cluster and Kafka Connect cluster on either 1, 3 or 5 nodes (r5n.2xlarge). We started the Scylla CDC Source Connector to consume data from the previously populated CDC-enabled table and measured the time it took to produce all 50 million Kafka messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our connector was able to scale the throughput near linearly:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-09-08-deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/horizontal_scalability.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt; &lt;colgroup&gt; &lt;col style=&quot;width: 50%;&quot;&gt; &lt;col style=&quot;width: 33.3333%;&quot;&gt; &lt;col style=&quot;width: 16.6667%;&quot;&gt; &lt;/colgroup&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Kafka cluster size&lt;/th&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Throughput&lt;/th&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Speedup&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1 node&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;46k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;3 nodes&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;129k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;2.8x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;5 nodes&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;215k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;4.7x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post, we took a deep dive into the development of Scylla CDC Source Connector. We started with an overview of CDC implementation in Scylla. We have discussed the reasons we chose Debezium rather than just Kafka Connect API to build our connector, in turn making it familiar to users and Kafka-idiomatic. Next, we looked at two problems we encountered: how to represent Scylla changes and make the connector scalable.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are very excited to continue improving our connector even further with additional features and making it even more performant. We are eagerly looking forward to watching the Debezium ecosystem grow and integrating functionalities introduced in the latest versions of Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you want to check out the connector yourself, the GitHub repository with its source code is available here: &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector&quot;&gt;github.com/scylladb/scylla-cdc-source-connector&lt;/a&gt;. You can learn more about Scylla here: &lt;a href=&quot;https://scylladb.com&quot;&gt;scylladb.com&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Piotr Grabowski</name></author><category term="community"/><category term="kafka"/><category term="scylla"/><summary type="html">At ScyllaDB, we develop a high-performance NoSQL database Scylla, API-compatible with Apache Cassandra, Amazon DynamoDB and Redis. Earlier this year, we introduced support for Change Data Capture in Scylla 4.3. This new feature seemed like a perfect match for integration with the Apache Kafka ecosystem, so we developed the Scylla CDC Source Connector using the Debezium framework. In this blogpost we will cover the basic structure of Scyllas CDC, reasons we chose the Debezium framework and design decisions we made.</summary></entry><entry><title type="html">Debezium 1.7.0.CR1 Released</title><link href="https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.CR1 Released"/><published>2021-09-16T00:00:00+00:00</published><updated>2021-09-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am very happy to announce the release of Debezium &lt;strong&gt;1.7.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For this release, we&amp;#8217;ve reworked how column filters are handled during snapshotting, the Debezium container images have been updated to use Fedora 34 as their base, there&amp;#8217;s support for MySQL &lt;code&gt;INVISIBLE&lt;/code&gt; columns, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;column_filtering_during_snapshotting&quot;&gt;Column Filtering During Snapshotting&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While the different Debezium connectors already had the capability to exclude specific columns of the captured tables from change events, these filters were only applied when processing the data within the connectors. For initial snapshots, a more efficient approach has been implemented now: tailored SQL SELECT statements will be executed for fetching only the actually included columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2525&quot;&gt;DBZ-2525&lt;/a&gt;). This allows for significant performance gains when for instance excluding large &lt;code&gt;BLOB&lt;/code&gt; columns from change events.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;updated_container_image_base&quot;&gt;Updated Container Image Base&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;a href=&quot;https://hub.docker.com/u/debezium&quot;&gt;Debezium container images&lt;/a&gt; for Apache Kafka, Kafka Connect, and Apache ZooKeeper are based on the Fedora 34 minimal container base image (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3939&quot;&gt;DBZ-3939&lt;/a&gt;). This change became necessary as the previously used base image (derived from CentOS 7) was not maintained any longer. While this change will be transparent for most users of Debezium, some adjustments may be required for those users who derive their own custom images from the Debezium ones, e.g. when installing further packages using the operating system&amp;#8217;s package manager. Please refer to the &lt;a href=&quot;https://debezium.io/releases/1.7/release-notes#breaking_changes&quot;&gt;release notes&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we&amp;#8217;re approaching the 1.7 Final release, most changes have been centered around bug fixing and maturing the code base. Some of the resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for &lt;code&gt;INVISIBLE&lt;/code&gt; columns as available since MySQL 8.0.23 (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3623&quot;&gt;DBZ-3623&lt;/a&gt;); we&amp;#8217;ve used that occassion to also update the Debezium example image for MySQL to version 8.0 (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3936&quot;&gt;DBZ-3936&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The SQL Server allows for the usage of custom connection factories (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-4001&quot;&gt;DBZ-4001&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3969&quot;&gt;DBZ-3969&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3984&quot;&gt;DBZ-3984&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3892&quot;&gt;DBZ-3892&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3962&quot;&gt;DBZ-3962&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.7.0.CR1&quot;&gt;47 issues&lt;/a&gt; have been fixed for this release. A big thank you to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashmeet13&quot;&gt;Ashmeet Lamba&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/d3vel0per&quot;&gt;Dhrubajyoti G&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/indraraj&quot;&gt;Indra Shukla&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;Ren Kerner&lt;/a&gt;, and &lt;a href=&quot;https://github.com/zhangyuan&quot;&gt;Yuan Zhang&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, we&amp;#8217;re planning to do another CR (candidate release) in a few days, followed by Debezium 1.7.0.Final at the end of the month. We&amp;#8217;ll primarily focus on bug fixing and some asorted performance optimizations. There&amp;#8217;ll also be some exciting improvements to the &lt;a href=&quot;/documentation/reference/1.7/operations/debezium-ui.html&quot;&gt;Debezium UI&lt;/a&gt;, which should be wrapped up for the 1.7 Final release: support for the configuration of single message transforms (SMTs), as well as the ability to configure topic creation settings.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In parallel, we&amp;#8217;re working on the roadmap for Debezium 1.8, planned to be released by the end of the year. Please reach out in the comments below or on the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt; if you&amp;#8217;d like to raise specific feature requests for this release.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="outbox"/><summary type="html">I am very happy to announce the release of Debezium 1.7.0.CR1! For this release, we&amp;#8217;ve reworked how column filters are handled during snapshotting, the Debezium container images have been updated to use Fedora 34 as their base, there&amp;#8217;s support for MySQL INVISIBLE columns, and much more.</summary></entry><entry><title type="html">Going ZooKeeper-less With the Debezium Container Image for Apache Kafka</title><link href="https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/" rel="alternate" type="text/html" title="Going ZooKeeper-less With the Debezium Container Image for Apache Kafka"/><published>2021-08-31T00:00:00+00:00</published><updated>2021-08-31T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka</id><content type="html" xml:base="https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://blogs.apache.org/kafka/entry/what-s-new-in-apache5&quot;&gt;Apache Kafka 2.8&lt;/a&gt; allows for a first glimpse into the ZooKeeper-less future of the widely used event streaming platform: shipping with a preview of &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt; (&quot;Replace ZooKeeper with a Self-Managed Metadata Quorum&quot;), you can now run Kafka clusters without the need for setting up and operating Apache ZooKeeper. This does not only simplify running Kafka from an operational perspective, the new metadata quorum implementation (named &quot;KRaft&quot;, Kafka Raft metadata mode) also should provide much better scaling characteristics, for instance when it comes to large numbers of topics and partitions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;I have blogged&lt;/a&gt; about my first experiences with KRaft and ZooKeeper-less Kafka a while ago over on my personal blog. Since then, the Debezium community has upgraded its &lt;a href=&quot;https://hub.docker.com/r/debezium/kafka&quot;&gt;container image&lt;/a&gt; for Apache Kafka to version 2.8, which makes it really simple to start your own explorations around running Kafka without ZooKeeper. Note that KRaft mode is an early access feature of Apache Kafka at this point in time and should not be used for production purposes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;enabling_kraft_mode&quot;&gt;Enabling KRaft Mode&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As of Debezium version 1.7, the container image for Kafka supports three new environment variables, to be specified when running the image:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;CLUSTER_ID&lt;/code&gt;: A unique id, such as &quot;5Yr1SIgYQz-b-dgRabWx4g&quot;; if this variable is present, KRaft mode is enabled. Otherwise, the image behaves as before, and must be configured with a reference to ZooKeeper. When using KRaft mode, all nodes of the Kafka cluster must use the same cluster id. Values can be generated using the &lt;em&gt;kafka-storage.sh&lt;/em&gt; script coming with Apache Kafka.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;NODE_ROLE&lt;/code&gt;: Specifies the role of the Kafka node; must be one of &quot;controller&quot;, &quot;broker&quot;, or &quot;combined&quot;. In KRaft mode, Kafka nodes can either be part of the metadata quorum (controller nodes), they can be exclusively used for propagating messages (broker nodes), or they can do both (combined nodes). Depending on your use case and requirements, you might for instance go for a smaller Kafka cluster of three combined nodes, or for a larger one with three controllers and seven brokers. If no value is given, the image will start the broker in combined mode.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;NODE_ID&lt;/code&gt;; Specifies a unique id (1, 2, 3, &amp;#8230;&amp;#8203;) for each node in the cluster; the previously used variable &lt;code&gt;BROKER_ID&lt;/code&gt; has been deprecated in favour of &lt;code&gt;NODE_ID&lt;/code&gt;; for the time being, it still is supported as an alias for the new name, but using it will trigger a warning in the logs, and it is planned to be phased out eventually.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, one more environment variable must be given when starting a Kafka cluster in KRaft mode using the Debezium container image: &lt;code&gt;KAFKA_CONTROLLER_QUORUM_VOTERS&lt;/code&gt;. This one is used to pass the &lt;code&gt;controller.quorum.voters&lt;/code&gt; configuration option to Kafka, referencing all controller nodes in the cluster in the format &quot;id-1@controller-node-1:controller-port-1,&amp;#8230;&amp;#8203;&quot;, for instance &lt;code&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;giving_it_a_try&quot;&gt;Giving it a Try&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And really that&amp;#8217;s all there is to it. So let&amp;#8217;s take a look at a Docker Compose file for starting up a three node Kafka cluster, formed of combined nodes solely:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;'2'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;services&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;kafka-1&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=1&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-2&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=2&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-3&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=3&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One quick &lt;code&gt;docker compose up&lt;/code&gt; later, and you&amp;#8217;ll have your ZooKeeper-less Kafka cluster running, ready to be used with Debezium, Kafka Connect, or any other Kafka workload you may have. Just remember: don&amp;#8217;t roll it out to production just yet ;) Note that whether ZooKeeper is or isn&amp;#8217;t used by a given cluster, solely is an implementation detail of Kafka, i.e. it&amp;#8217;s fully transparent to Debezium, its history producers/consumers, and any other Kafka clients.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Setting up a cluster with dedicated controller and broker nodes isn&amp;#8217;t much more complex either. Here&amp;#8217;s the configuration for a cluster with one controller and three brokers (of course you&amp;#8217;d want to run with at least three controllers in reality, so to avoid the single point of failure of only one controller node):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;'2'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;services&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;kafka-1&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=1&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=controller&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-2&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=2&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-3&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=3&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-4&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;49092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;49093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=4&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can find extended versions of the two Compose files (&lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/main/tutorial/docker-compose-zookeeperless-kafka-combined.yaml&quot;&gt;combined&lt;/a&gt;, &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/main/tutorial/docker-compose-zookeeperless-kafka.yaml&quot;&gt;controller/broker&lt;/a&gt;) in the Debezium examples repository, also containing services for Kafka Connect and a Postgres database, and accompanied by &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#running-without-zookeeper&quot;&gt;instructions&lt;/a&gt; for running the &lt;a href=&quot;https://debezium.io/documentation/reference/tutorial.html&quot;&gt;Debezium tutorial&lt;/a&gt; with ZooKeeper-less Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As KRaft mode matures in Kafka 3.0 and later versions, we may do some adjustments to the container image, so to support the new mode of running Kafka in the best way possible. Eventually, the option to run with ZooKeeper will be removed, but it&amp;#8217;ll be quite some more time until then.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about KRaft, refer to &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt; and related KIPs, which describe the feature and its design in great detail, the &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/config/kraft/README.md&quot;&gt;KRaft README file&lt;/a&gt;, &lt;a href=&quot;https://github.com/debezium/docker-images/tree/main/kafka/1.7&quot;&gt;the README&lt;/a&gt; of the Debezium 1.7 container image for Apache Kafka, and aforementioned blog post &lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;&quot;Exploring ZooKeeper-less Kafka&quot;&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Many thanks to &lt;a href=&quot;https://twitter.com/rk3rn3r/&quot;&gt;Ren Kerner&lt;/a&gt; for providing feedback while writing this post.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="docker"/><category term="apache kafka"/><category term="examples"/><summary type="html">Apache Kafka 2.8 allows for a first glimpse into the ZooKeeper-less future of the widely used event streaming platform: shipping with a preview of KIP-500 (&quot;Replace ZooKeeper with a Self-Managed Metadata Quorum&quot;), you can now run Kafka clusters without the need for setting up and operating Apache ZooKeeper. This does not only simplify running Kafka from an operational perspective, the new metadata quorum implementation (named &quot;KRaft&quot;, Kafka Raft metadata mode) also should provide much better scaling characteristics, for instance when it comes to large numbers of topics and partitions.</summary></entry><entry><title type="html">Debezium 1.7.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.Beta1 Released"/><published>2021-08-25T00:00:00+00:00</published><updated>2021-08-25T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.7 series, &lt;strong&gt;1.7.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release brings &lt;a href=&quot;https://docs.nats.io/developing-with-nats-streaming/streaming#nats-streaming-overview&quot;&gt;NATS Streaming&lt;/a&gt; support for Debezium Server along with many other fixes and enhancements. Also this release is the first one tested with Apache Kafka 2.8.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium container images for &lt;a href=&quot;https://hub.docker.com/r/debezium/kafka&quot;&gt;Apache Kafka&lt;/a&gt; and &lt;a href=&quot;https://hub.docker.com/r/debezium/connect&quot;&gt;Kafka Connect&lt;/a&gt; have been updated to version 2.8, too. This means that you can test Debezium with the new ZooKeeper-less mode for running Kafka (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt;). We&amp;#8217;ll share more details on that in a separate post shortly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A large number of bug fixes and quality improvements have been made for this release; one focus area was the Debezium connector for Oracle, which received several fixes including the ability to configure multiple Oracle RAC nodes with different ports (DBZ-3813), multiple DDL parser corrections (DBZ-3877, DBZ-3893), and improved updating of SCN offsets (DBZ-3876).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other changes include performance improvement for the Debezium connectors for Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3870&quot;&gt;DBZ-3870&lt;/a&gt;) and MongoDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3788&quot;&gt;DBZ-3788&lt;/a&gt;), proper timezone conversions for change event timestamps in the connector for SQL Server (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3479&quot;&gt;DBZ-3479&lt;/a&gt;), and more resilient handling of errors during connector start-up (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3823&quot;&gt;DBZ-3823&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Furthermore, this release has a breaking change for the MySQL Connector. The MySQL driver was updated to the latest version 8.0.26 with &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3833&quot;&gt;DBZ-3833&lt;/a&gt;. This update comes with a new timezone handling and configuration options. Detailed information can be found in the &lt;a href=&quot;https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-connp-props-datetime-types-processing.html&quot;&gt;MySQL docs&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Earlier this month, we added the &lt;a href=&quot;https://debezium.io/documentation/reference/operations/debezium-ui.html&quot;&gt;Debezium UI&lt;/a&gt; to our regular release process. If you want to learn more about the Debezium UI have a look at our recent &lt;a href=&quot;/blog/2021/08/12/introducing-debezium-ui/&quot;&gt;release announcement&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&amp;amp;version=12359667&quot;&gt;81 issues&lt;/a&gt; were fixed for this release. Thanks a lot to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/umanwizard&quot;&gt;Brennan Vincent&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/sirscratchalot&quot;&gt;Erik Malm&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;Ren Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/tavancini&quot;&gt;Thiago Avancini&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;https://github.com/zregvart&quot;&gt;Zoran Regvart&lt;/a&gt;, &lt;a href=&quot;https://github.com/ili-zh&quot;&gt;&lt;/a&gt;, &lt;a href=&quot;https://github.com/pkgonan&quot;&gt; &lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;</content><author><name>Ren Kerner</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="kafka"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.7 series, 1.7.0.Beta1! This release brings NATS Streaming support for Debezium Server along with many other fixes and enhancements. Also this release is the first one tested with Apache Kafka 2.8.</summary></entry><entry><title type="html">Debezium Community Stories With Sergei Morozov</title><link href="https://debezium.io/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/" rel="alternate" type="text/html" title="Debezium Community Stories With Sergei Morozov"/><published>2021-08-23T13:50:00+00:00</published><updated>2021-08-23T13:50:00+00:00</updated><id>https://debezium.io/blog/2021/08/23/debezium-community-stories-with-sergei-morozov</id><content type="html" xml:base="https://debezium.io/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Welcome to the latest edition of &lt;a href=&quot;/tag/community-stories/&quot;&gt;&quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;&lt;/a&gt;, a series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. Today it&amp;#8217;s my pleasure to talk to &lt;a href=&quot;https://twitter.com/srgmrzv&quot;&gt;Sergei Morozov&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/sergeimorozov.jpg&quot; style=&quot;max-width:40%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Sergei, could you introduce yourself? What is your job, if youre not contributing to Debezium?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Hi, my name is Sergei, I&amp;#8217;m a Software Architect at &lt;a href=&quot;http://sugarcrm.com/&quot;&gt;SugarCRM&lt;/a&gt;. Most of my career, I&amp;#8217;ve been building software based on the LAMP stack. A few years ago, my team and I started building a data streaming platform meant to integrate the existing SugarCRM products and the new services we wanted to build on top of them. We started prototyping the platform with Maxwell&amp;#8217;s Daemon, AWS Kinesis and DynamoDB and later switched to Kafka, Kafka Connect and Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Interestingly, Debezium was the reason why we started experimenting with the Kafka ecosystem. The solution we had built before the pivot was only capable of streaming CDC changes but not snapshotting the initial state. During the work on snapshotting, we stumbled upon Debezium and discovered Kafka. After some experimentation and learning more about the ecosystem, we decided to switch the technology stack.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;What are your use cases for Debezium and change data capture in your current project?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We capture data changes from the products based on MySQL and SQL Server and use them to enable AI and data analytics use cases. Apart from processing recent changes, we store as much historical data as possible. The data comes from thousands of customer databases hosted in the cloud environment.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We use it for AI, analytics, and enabling future use cases. For instance, SugarPredict provides scoring of opportunities and helps sales representatives to focus on those that are more likely to close. The historical data from the CRM and other sources is used to train the AI models. The data change events are used to run the scoring process and update the prediction.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the data flow perspective, it looks very simple but there are quite some engineering challenges caused by the flexibility of the products and the cloud scale.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;This sounds really interesting; can you tell us more about the challenges you encountered and how you solved them?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Absolutely. Let me dive into the details a bit. I hope our ideas and solutions will be helpful to the community.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Flexibility and Data Serialization&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The products that provide data changes are extremely customizable. Customers can create new modules, fields, install extensions, etc. which from the CDC standpoint means that the customers have full control over the database schema. Combined with the scale of thousands of customers, it makes it challenging to use Apache Avro which implies that the schema is managed by the developers.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A couple of years ago, we tested the then de-facto standard Schema Registry and concluded that it wouldn&amp;#8217;t perform well at the scale of roughly a million message schemas we&amp;#8217;d have in the cloud, not even counting schema versions the number of which is unbounded. For comparison, the accompanying managed offering for that schema registry allows to store up to a thousand schemas. So we resorted to using JSON to serialize data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Onboarding Challenges&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;SugarCloud is a multi-tenant hosting environment for SugarCRM products. It consists of a few dozens of large MySQL-compatible AWS Aurora clusters that usually host a hundred to a thousand customer databases each. The cluster storage size varies from a few hundred gigabytes to 5 terabytes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a Debezium connector for MySQL first starts, it performs the initial consistent snapshot, and to guarantee the consistency, it usually obtains a short-lived global read lock for capturing the schema of all relevant tables. Since AWS Aurora doesn&amp;#8217;t allow to perform a global lock, Debezium has to lock all tables individually for the entire duration of the snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The snapshot of a database cluster would take from a few hours to a couple of days which we cannot afford because it would require downtime of all the customer instances hosted on a given cluster. Fortunately, we stumbled upon the great article &lt;a href=&quot;https://thedataguy.in/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot/&quot;&gt;Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot&lt;/a&gt; by The Data Guy that describes a workaround that allowed us to snapshot all the data without causing any application downtime. We implemented a shell script that clones the database cluster, records the position in the binlog from which the clone was made, takes a snapshot of the clone and then reconfigures the connector to stream from the position of the snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Instance Lifecycle Management&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;SugarCloud is a very dynamic environment. Once a customer database has been deployed to one of the clusters, there&amp;#8217;s no guarantee that it will remain there during its entire lifetime. A database can be backed up and restored. It can be moved between clusters in the same AWS region for load-balancing purposes. It can be moved from one AWS region to another if requested by the customer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our source connectors are configured to capture all data changes from all databases on a given cluster but not all of them make sense from the data consumers' standpoint. For instance, when a database is restored from a backup on a different cluster, the INSERT statements generated by mysqldump don&amp;#8217;t represent new rows. They represent the state of the database during the backup and should be ignored.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to enable post-processing of the raw data, there is a system database on each of the clusters where the cluster management system logs all events relevant to the instance lifecycle (see the &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;outbox pattern&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to post-process the raw data according to the lifecycle events, we built a Kafka Streams application that is deployed between Debezium and the actual data consumers. Internally, it uses a state store which is effectively a projection of each customer database status (active/maintenance). Prior to restoring a database from a SQL dump, the database is marked as &quot;in maintenance&quot; (an event is emitted to outbox), so all corresponding INSERTs are ignored until the maintenance is over (another event emitted).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Storage&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The need to store all historical data brings the challenge of having enough storage. Since the end of last year, we&amp;#8217;ve collected more than 120TB of compressed CDC events. Currently we store historical data in S3 but plan to move it back to Kafka once S3-backed tiered storage (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&quot;&gt;KIP-405&lt;/a&gt;) is available in AWS MSK.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Infrastructure&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We run our software primarily in Kubernetes and manage all of our Kafka-related infrastructure other than brokers themselves with &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt;. Strimzi not only allows to manage applications and Kafka resources using the same tools, it also provides a great foundation for automation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we started designing the data streaming platform, one of the requirements was that it should automatically adjust to certain changes in SugarCloud. For instance, when a new Aurora cluster is deployed, the data streaming pipeline should be deployed for this cluster. Another requirement was that the pipeline should be deployed in multiple AWS regions and be managed via Sugar&amp;#8217;s single control plane, codenamed Mothership. We went one level deeper and built the Mothership Operator that serves as the API for managing the pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a new Aurora cluster is created, Mothership creates a secret in Vault with the database credentials and a StackIngestor. The StackIngestor contains the information about the Aurora cluster: its AWS region, MySQL endpoint, the name of the Vault secret and other technical information. Mothership Operator subscribes to the changes in StackIngestors and manages the Kafka resources that implement the pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With some exceptions, each pipeline is deployed to the same AWS region where the Aurora cluster is located. There are Strimzi Topic and Cluster operators deployed in each region. The pipeline consists of a few Kafka topics, a source connector (Debezium), a sink connector (S3) and runs on a shared or a dedicated Kafka Connect cluster. For each StackIngestor created in the primary region, Mothership Operator creates the needed Strimzi resources in the regional Kubernetes cluster. The Strimzi operators subscribe to the updates in their resources and manages the corresponding resources in Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium_community_stories_with_sergei_morozov_architecture.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. System Overview&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We also use Strimzi to export JMX metrics from Debezium to Prometheus. The Prometheus metrics are visualized in Grafana. We started with a community &lt;a href=&quot;https://grafana.com/grafana/dashboards/11523&quot;&gt;dashboard&lt;/a&gt; (also by The Data Guy) and improved it o better fit the multi-tenant use case.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium_community_stories_with_sergei_morozov_dashboard.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. Multi-Tenant Debezium Dashboard&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Youre not only using Debezium but youve also contributed to the project. How was your experience doing so?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In my experience, whatever open-source software I touch  be it at work or for fun  I always end up finding something about that software that needs to be improved to enable my use case.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I contributed one of my first patches to Debezium (or, more precisely, to its dependency &lt;a href=&quot;https://github.com/osheroff/mysql-binlog-connector-java&quot;&gt;mysql-binlog-connector-java&lt;/a&gt;) back in October 2020. We had just rolled out one of our first connectors to production and had experienced an issue where the connector was consuming all available memory and crashing at a specific position in the binlog. The issue was quite pressing since we had a very limited time before the binlog compaction would kick in and we might start losing data. At the same time, we had just a basic understanding of the Debezium and Kafka Connect architecture and no experience with the Debezium internals.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The whole team had swarmed in and figured out that the connector was misinterpreting a non-standard binlog event that AWS Aurora produced instead of ignoring it. Troubleshooting and finding the root cause was the hardest part. Getting the issue fixed and unit-tested was relatively easy. Although the change wasn&amp;#8217;t that obvious, I&amp;#8217;m glad it was accepted promptly with constructive feedback from the team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Are you doing other open-source work, too?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m one of the maintainers of the most popular library for relational databases in PHP, &lt;a href=&quot;https://github.com/doctrine/dbal&quot;&gt;Doctrine DBAL&lt;/a&gt;. I made my first contributions there while I was working on integrating the library into the core SugarCRM product and fixed some issues that blocked the integration. It took a few releases to get everything fixed, and at the end I got invited to the core team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apart from that, I&amp;#8217;ve been an occasional contributor to some open-source projects in the PHP ecosystem: primarily those that I would use daily like PHPBrew, PHPUnit, PHP_CodeSniffer, Vimeo Psalm and PHP itself.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Is there anything which youre missing in Debezium or which youd like to see improved in the future?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While Debezium is a great tool that covers most of the industry-standard database platforms, one the greatest challenges for our team was and still is scaling Debezium to the size of our customer base. The SQL Server connector is currently capable of handling only one logical database per connector. We have hundreds of customer databases hosted on SQL Server, but running a dedicated connector for each of them would require expensive infrastructure and would be hard to manage.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Earlier this year, we started working with the Debezium team on improving the connector and making it capable of capturing changes from multiple databases and running multiple tasks. This way, instead of running hundreds of connectors, we could run a dozen or so. The original design is outlined in &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/pull/1&quot;&gt;DDD-1&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With these changes implemented, one of our production connectors captures changes from over a hundred databases. At the same time, we&amp;#8217;re working on contributing the changes back upstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Bonus question: Whats the next big thing in data engineering?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Nowadays, especially in multi-tenant environments, it&amp;#8217;s really hard to predict how much time it will take from &quot;it works on my machine&quot; to &quot;it works at the cloud scale&quot;. I&amp;#8217;m looking forward to the time when container orchestration and data streaming platforms become as simple to operate as they look on PowerPoint diagrams.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Sergei, thanks a lot for taking your time, it was a pleasure to have you here!&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;If youd like to stay in touch with Sergei Morozov and discuss with him, please drop a comment below or follow and reach out to him &lt;a href=&quot;https://twitter.com/srgmrzv&quot;&gt;on Twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community"/><category term="community-stories"/><summary type="html">Welcome to the latest edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. Today it&amp;#8217;s my pleasure to talk to Sergei Morozov.</summary></entry><entry><title type="html">Introducing the Debezium UI</title><link href="https://debezium.io/blog/2021/08/12/introducing-debezium-ui/" rel="alternate" type="text/html" title="Introducing the Debezium UI"/><published>2021-08-12T00:00:00+00:00</published><updated>2021-08-12T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/12/introducing-debezium-ui</id><content type="html" xml:base="https://debezium.io/blog/2021/08/12/introducing-debezium-ui/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are pleased to announce the first official release of the &lt;strong&gt;Debezium graphical user interface&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As announced &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;a few months back&lt;/a&gt;, our team has been working on a Debezium UI proof-of-concept. The goal of the PoC was to explore ways in which a graphical UI could facilitate the getting started and operational experience of Debezium users.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is very flexible - each connector can be configured and fine-tuned in a variety of ways. It provides metrics which give the user insight into the state of the running Debezium connectors, allowing the customer to safely operate CDC pipelines in huge installations with thousands of connectors. This flexibility, however, comes with a learning curve for the user to understand all of the different settings and options.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To that end, we have produced a UI which will allow users to set up and operate connectors more easily. The UI is now available as part of the Debezium releases for our community!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at some features of the UI in the following.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;ui_connector_list&quot;&gt;UI Connector List&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The main page of the UI displays all the registered connectors. Some of the highlights of the main page are as follows:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kafka connect cluster&lt;/strong&gt; can be selected via the dropdown in the header.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Connector table shows each connector with it&amp;#8217;s type (MySQL, PostgreSQL, MongoDB), connector status and connector tasks.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A connector row can be expanded to show more details, as shown below with the 'testPostgres' connector. Metrics are shown in the expansion area (&lt;strong&gt;Note:&lt;/strong&gt; this feature is still under development and not functional yet). Connector tasks are shown, with ability to &lt;strong&gt;Restart&lt;/strong&gt; the task if desired.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The kebab menu at the right of each connector row provides actions which allow the user to &lt;strong&gt;Pause, Resume, Restart or Delete&lt;/strong&gt; the connector.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/ConnectorsList.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;ui_create_connector_wizard&quot;&gt;UI Create Connector Wizard&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The user can create a connector by clicking on the &lt;strong&gt;Create a connector&lt;/strong&gt; button on the main page. The first two steps of the wizard are required, but the remaining steps are optional. Each step will validate the user entries and provide feedback if there are problems. After completing steps 1 and 2 successfully, the user can proceed to the final page to review and create the connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;create_connector_connector_type_required&quot;&gt;Create Connector - Connector type (required)&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Choose the type of connector in step 1. Currently the &lt;strong&gt;MongoDB, MySQL and PostgreSQL&lt;/strong&gt; connector types are supported. Addition of more connector types is currently in progress.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/CreateConnectorStep1.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;create_connector_properties_required&quot;&gt;Create Connector - Properties (required)&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The basic connection properties for the selected connector are entered in step 2, and the properties must be validated before proceeding. Advanced connection properties are also provided in a separate section of this step. Upon successful validation, the user may proceed to the next steps (Additional properties) - or they can elect to bypass the additional properties and proceed directly to Review.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/CreateConnectorStep2.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;create_connector_additional_properties_optional&quot;&gt;Create Connector - Additional properties (optional)&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Additional properties are optional and can be summarized as follows:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter definition&lt;/strong&gt; - entry of &lt;strong&gt;regular expressions&lt;/strong&gt; which define the filters for inclusion/exclusion of the items that will be included for CDC. The included items are displayed as the filters are entered and applied.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data options&lt;/strong&gt; - &lt;strong&gt;Snapshot&lt;/strong&gt; and &lt;strong&gt;Mapping&lt;/strong&gt; properties (optional). The defaults can be viewed and changed if desired.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Runtime options&lt;/strong&gt; - &lt;strong&gt;Engine&lt;/strong&gt; and &lt;strong&gt;Heartbeat&lt;/strong&gt; properties (optional). The defaults can be viewed and changed if desired.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;create_connector_review&quot;&gt;Create Connector - Review&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;strong&gt;Review&lt;/strong&gt; step provides a summary of the configuration that will be used to create the connector. If happy with the selections, click 'Finish' to create the connector. If the properties need adjustment, navigate back to the earlier steps.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/CreateConnectorReview.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;design_considerations&quot;&gt;Design Considerations&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The UI is implemented as a &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;-based web application. The backend is configured with the URL(s) of one or more Kafka Connect clusters and provides a REST interface for the frontend. The frontend user interface uses &lt;a href=&quot;https://reactjs.org/&quot;&gt;ReactJS&lt;/a&gt; as the primary technology, utilizing &lt;a href=&quot;https://www.patternfly.org/v4/&quot;&gt;Patternfly&lt;/a&gt; react components and design patterns.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As with everything in Debezium, the UI is fully open source (Apache License Version 2.0). You can find the &lt;a href=&quot;https://github.com/debezium/debezium-ui/&quot;&gt;UI Source Code&lt;/a&gt; under the Debezium organization on Github.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;trying_it_out_yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;debezium_ui_container_image&quot;&gt;Debezium UI Container Image&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui&quot;&gt;container image&lt;/a&gt; is available for running the UI. E.g. run the following comand to start the UI and connect it to an existing Kafka Connect instance via Docker (where KAFKA_CONNECT_URI supplies a comma-separated list of the available Kafka Connect URI(s)):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;$ docker run -it --rm --name debezium-ui -p 8080:8080 -e KAFKA_CONNECT_URI=http://connect:8083 debezium/debezium-ui:1.7&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The UI connects to Kafka Connect via REST, so you need to make sure that the latter is reachable, e.g. by running both components on the same Docker network.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Currently, the UI connects to un-authenticated Kafka Connect instances. Also, there&amp;#8217;s no authorization or authentication implemented in the UI itself yet. Until that is the case, you should secure the components e.g. with your own proxy for authorization, if needed.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;self_contained_example&quot;&gt;Self-contained example&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have also created a self-contained example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;UI demo&lt;/a&gt;, which is included under &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;debezium-examples&lt;/a&gt; on Github. The UI demo includes a Docker Compose file which brings up several sources with data as well as the UI. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;README file&lt;/a&gt; for more details on running the Debezium UI demo.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the Debezium UI, please refer to the &lt;a href=&quot;/documentation/reference/operations/debezium-ui.html&quot;&gt;reference documentation&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;next_steps&quot;&gt;Next Steps&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We plan to continue with improvements and new features for the UI in the coming releases. Some items under consideration:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Incorporation of more Debezium connector types, such as the ones for SQL Server and Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add capability to configure topic creation settings and single message transformations&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Addition and improvement of connector metrics and monitoring&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add capability for viewing and editing connector properties after creation&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&amp;#8230;&amp;#8203;And more!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;d also be very happy to learn about your requirements and feedback on the Debezium UI. Please let us know in the comments below, or send a message to our &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team who have contributed in many ways: Ashique Ansari, Indra Shukla, June Zhang, Na Ding, Ren Kerner and Gunnar Morling!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Mark Drilling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongo"/><category term="debezium-ui"/><summary type="html">We are pleased to announce the first official release of the Debezium graphical user interface! As announced a few months back, our team has been working on a Debezium UI proof-of-concept. The goal of the PoC was to explore ways in which a graphical UI could facilitate the getting started and operational experience of Debezium users. Debezium is very flexible - each connector can be configured and fine-tuned in a variety of ways. It provides metrics which give the user insight into the state of the running Debezium connectors, allowing the customer to safely operate CDC pipelines in huge installations with thousands of connectors. This flexibility, however, comes with a learning curve for the user to understand all of the different settings and options. To that end, we have produced a UI which will allow users to set up and operate connectors more easily. The UI is now available as part of the Debezium releases for our community!</summary></entry><entry><title type="html">Debezium 1.7.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/08/02/debezium-1-7-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.Alpha1 Released"/><published>2021-08-02T00:00:00+00:00</published><updated>2021-08-02T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/02/debezium-1-7-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/08/02/debezium-1-7-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.7 series, &lt;strong&gt;1.7.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the summer in a full-swing, this release brings additional improvements to the Debezium Oracle connector but also to the others as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;alternative_oracle_connector_logminer_processors&quot;&gt;Alternative Oracle Connector LogMiner processors&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium connector for Oracle uses an in-memory buffer to cache in-progress transaction changes until the transaction is either committed or rolled back. This cache can require a significant memory footprint depending on the number of events in the transaction, how many concurrent transactions are in-progress, as well as the data itself that represents each event such as large character or binary objects. This can be tough to manage for some environments that have ongoing long-running transactions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release introduces a significant refactoring to the connector processing code that allows for varied modes of processing LogMiner change events. Out-of-the-box the memory-based implementation remains the default, but we&amp;#8217;ve included a new implementation based on the &lt;a href=&quot;https://infinispan.org/&quot;&gt;Infinispan&lt;/a&gt; distributed data store. This implementation makes it possible to track any number of in-progress transactions regardless of their size or duration.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To take advantage of the new Infinispan implementation, the following configuration options must be provided:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As this is early work, the new Infinispan buffer mode currently has a few limitations:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The Infinispan configuration is not exposed outside to the user for tuning&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only file-based cache store is supported; if you work with multi-node Kafka Connect clusters, a networked filesystem must be used for the cache store in order to support rebalancing of connector tasks in the Connect cluster&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This should not stop you from giving it a test drive and send as much feedback as possible to us for further improvements. We expect to remove the above restrictions in the next release.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting&quot;&gt;Incremental Snapshotting&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The major feature of the 1.6 release has got also new improvements. The Debezium connector for Oracle now supports incremental snapshots in the same way as the other connectors, so Oracle users now can easily add new tables to the capture list and get them snapshotted on the fly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the MySQL connector, there is a new incremental snapshot mode that could be used for databases that do not allow writing to the signal table. &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Kate Galieva&lt;/a&gt; invented a method based on GTID lists that could be used to provide watermarking without writing to the database. Thank you for the nice contribution!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.7.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;49 issues&lt;/a&gt; were fixed for this release. A big thank you goes out to all the community members who contributed: Blake Peno, &lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/kyleyj&quot;&gt;Kyley Jex&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martn Prez&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;, &lt;a href=&quot;https://github.com/xaka&quot;&gt;Pavel Strashkin&lt;/a&gt;, &lt;a href=&quot;https://github.com/raphaelauv&quot;&gt;Raphael Auv&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/tinntsea&quot;&gt;Tin Nguyen&lt;/a&gt;, &lt;a href=&quot;https://github.com/tommyk-gears&quot;&gt;Tommy Karlsson&lt;/a&gt;, &lt;a href=&quot;https://github.com/elgca&quot;&gt;WenChao Ke&lt;/a&gt;, and &lt;a href=&quot;https://github.com/jjiey&quot;&gt;yangsanity&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the upcoming 1.7 preview releases, we&amp;#8217;re planning to focus on completing the follow-up task for the Oracle LogMiner processor and provide the support for JDBC based process too. We will explore incremental snapshotting support for MongoDB and do research on MariaDB support.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;release_of_1_6_1_final&quot;&gt;Release of 1.6.1.Final&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While the team&amp;#8217;s focus is primarily on 1.7, we have recently fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.6.1.Final%20ORDER%20BY%20component%20ASC&quot;&gt;9 issues&lt;/a&gt; to the 1.6 stream and released &lt;strong&gt;1.6.1.Final&lt;/strong&gt;. You can check out the &lt;a href=&quot;https://debezium.io/releases/1.6/release-notes#release-1.6.1.final&quot;&gt;release notes&lt;/a&gt; for details. We recommend if you&amp;#8217;re using a release prior to 1.6, take this opportunity to upgrade and get access to the latest new features!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.7 series, 1.7.0.Alpha1! With the summer in a full-swing, this release brings additional improvements to the Debezium Oracle connector but also to the others as well.</summary></entry><entry><title type="html">Debezium Community Newsletter 01/2021</title><link href="https://debezium.io/blog/2021/07/07/debezium-newsletter-01-2021/" rel="alternate" type="text/html" title="Debezium Community Newsletter 01/2021"/><published>2021-07-07T00:00:00+00:00</published><updated>2021-07-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/07/07/debezium-newsletter-01-2021</id><content type="html" xml:base="https://debezium.io/blog/2021/07/07/debezium-newsletter-01-2021/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Welcome to the newest edition of the Debezium community newsletter, in which we share all things CDC related including blog posts, group discussions, as well as StackOverflow questions that are relevant to our user community.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s been a long time since our last edition. But we are back again! In case you missed our last edition, you can check it out &lt;a href=&quot;/blog/2020/03/31/debezium-newsletter-01-2020/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;upcoming_events&quot;&gt;Upcoming Events&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Due to the ongoing global pandemic, all the conferences, and meet-ups have gone virtual. On the bright side, this means you get to attend some nice events from the comfort of your couch:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.meetup.com/apache-pinot/events/279202435/&quot;&gt;Apache Pinot meet-up&amp;#8201;&amp;#8212;&amp;#8201;&quot;Analyzing Real-time Order Deliveries using CDC with Debezium and Pinot&quot;&lt;/a&gt; by Kenny Bastani and Gunnar Morling&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.mongodb.com/live/agenda&quot;&gt;MongoDB.Live&amp;#8201;&amp;#8212;&amp;#8201;&quot;Dissecting our Legacy: The Strangler Fig Pattern with Apache Kafka, Debezium and MongoDB&quot;&lt;/a&gt; by Hans-Peter Grahsl and Gunnar Morling&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you&amp;#8217;d like to have a session on Debezium at your virtual meetup or conference, please get in touch!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;articles&quot;&gt;Articles&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There have been several blog posts about Debezium lately; here are some of the latest ones that you should not miss:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://shopify.engineering/capturing-every-change-shopify-sharded-monolith&quot;&gt;Capturing Every Change From Shopifys Sharded Monolith&lt;/a&gt; by John Martin and Adam Bellemare&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;Streaming Vitess at Bolt&lt;/a&gt; by Kewei Shang, and Ruslan Gibaiev&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.infoq.com/articles/saga-orchestration-outbox/&quot;&gt;Saga Orchestration for Microservices Using the Outbox Pattern&lt;/a&gt; by Gunnar Morling&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://developers.redhat.com/articles/2021/06/14/application-modernization-patterns-apache-kafka-debezium-and-kubernetes/&quot;&gt;Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/a&gt; by Bilgin Ibryam&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://inside.getyourguide.com/blog/2021/5/4/enhancing-the-outbox-pattern-with-kafka-streams/&quot;&gt;Enhancing the outbox pattern with Kafka Streams&lt;/a&gt; by Hinrik rn Sigursson&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://thenewstack.io/kubernetes-run-analytics-at-the-edge-postgres-kafka-debezium/&quot;&gt;Kubernetes-Run Analytics at the Edge: Postgres, Kafka, Debezium&lt;/a&gt; by Jonathan Katz&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams/&quot;&gt;Understanding Non-Key Joins With the Quarkus Extension for Kafka Streams&lt;/a&gt; by Anisha Mohanty&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/vimeo-engineering-blog/debezium-event-flattening-with-sql-in-snowflake-b0e8397cfac2/&quot;&gt;Debezium event flattening with SQL in Snowflake&lt;/a&gt; by Obed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A series of really insightful blog posts about Debezium and change data capture in general by Dunith Dhanushka:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/event-driven-utopia/a-gentle-introduction-to-event-driven-change-data-capture-683297625f9b/&quot;&gt;A Gentle Introduction to Event-driven Change Data Capture&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/event-driven-utopia/a-visual-introduction-to-debezium-32563e23c6b8/&quot;&gt;A Visual Introduction to Debezium&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/event-driven-utopia/8-practical-use-cases-of-change-data-capture-8f059da4c3b7/&quot;&gt;8 Practical Use Cases of Change Data Capture&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/apache-pinot-developer-blog/change-data-analysis-with-debezium-and-apache-pinot-b4093dc178a7/&quot;&gt;Change Data Analysis with Debezium and Apache Pinot&lt;/a&gt; by Kenny Bastani&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;Change Data Capture with Flink SQL and Debezium&lt;/a&gt; by Marta Paes&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.wix.engineering/post/change-data-capture-at-deviantart/&quot;&gt;Change Data Capture at DeviantArt&lt;/a&gt; by Ruslan Danilin&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And if watching a talk is more your kind of thing, here&amp;#8217;s the recording of the session &lt;a href=&quot;https://2021.berlinbuzzwords.de/session/change-data-streaming-patterns-distributed-systems/&quot;&gt;Change Data Streaming Patterns in Distributed Systems&lt;/a&gt; from this year&amp;#8217;s Berlin Buzzwords, by Gunnar Morling and Hans-Peter Grahsl:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/CLv2EcYnr2g&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please also check out our compiled list of &lt;a href=&quot;/documentation/online-resources/&quot;&gt;resources around Debezium&lt;/a&gt; for even more related posts, articles, podcasts and presentations.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;integrations&quot;&gt;Integrations&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A few cool integrations and usages of Debezium appeared over the last few weeks and months. Here are several ones which we found especially fascinating:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A Debezium Server &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;outbound adaptor for Apache Iceberg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The &lt;a href=&quot;https://docs.scylladb.com/using-scylla/integrations/scylla-cdc-source-connector/&quot;&gt;ScyllaDB CDC Source Connector&lt;/a&gt;, based on Debezium&amp;#8217;s CDC connector framework&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/connectors/table/formats/debezium/&quot;&gt;Bespoke support&lt;/a&gt; for the Debezium change event format in Apache Flink&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://materialize.com/docs/sql/create-source/avro-kafka/#kafka-topic-requirements&quot;&gt;Support&lt;/a&gt; for Debezium change events in Materialize&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are getting started with Debezium, you can get hands-on learning and better understanding of how things work from the examples and demos in our &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;examples repository&lt;/a&gt;. We have introduced several new examples and updated the existing ones. Out of which we&amp;#8217;d like to highlight some new additions:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/debezium-server-mongo-pubsub/&quot;&gt;Integration of Debezium Server with MongoDB and Pub/Sub (GCP)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/distributed-caching/&quot;&gt;Integration of Debezium with Infinispan&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/kstreams-fk-join/&quot;&gt;Demonstrates non-key joins with the Quarkus Kafka Streams extension&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/monitoring/&quot;&gt;Demonstrates how to monitor a Debezium instance&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/saga&quot;&gt;Demonstrates the implementation of Saga pattern for realizing distributed transactions across multiple microservices&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are interested in showcasing a new demo or an example, please send us a GitHub pull request or reach out to us directly through our community channels found &lt;a href=&quot;/community&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;time_to_upgrade&quot;&gt;Time to Upgrade&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium version &lt;a href=&quot;/blog/2021/06/30/debezium-1-6-final-released/&quot;&gt;1.6.0.Final&lt;/a&gt; was released last week. Apart from Debezium Server sinks for Apache Kafka and Pravega, the 1.6 release brought a brand-new feature for incremental and ad-hoc snapshots, providing long-awaited capabilities like resuming long-running snapshots after a connector restart, Re-snapshotting selected tables during streaming, and snapshotting tables newly added to the list of captured tables after changing the filter configuration. A big shout-out to Netflix engineers Andreas Andreakis and Ioannis Papapanagiotou for their paper &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;DBLog: A Watermark Based Change-Data-Capture Framework&lt;/a&gt;, upon which incremental snapshotting is based.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Given the long time since the last community newsletter, it&amp;#8217;s also worth mentioning some of the new features added in Debezium 1.5, &lt;a href=&quot;/blog/2021/04/08/debezium-1-5-final-released/&quot;&gt;released in April&lt;/a&gt; this year: the MySQL connector saw a substantial rewrite, now also supporting transaction marker events, Debezium&amp;#8217;s LogMiner-based CDC implementation for Oracle was declared stable, and we&amp;#8217;ve added support for Redis Streams to Debezium Server.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are using an older version, we urge you to check out the latest major release. For details on all the bug fixes, enhancements, and improvements, check out the &lt;a href=&quot;/releases/1.6/release-notes/&quot;&gt;release-notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium team has also begun active development on the next version, 1.7. The major focus in 1.7 is implementing incremental snapshotting for more connectors (MongoDB, Oracle), reworking the transaction buffer for the Oracle connector, and expanding the Debezium UI. For details on the further upcoming release check out the &lt;a href=&quot;/docs/roadmap/&quot;&gt;Debezium roadmap&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can keep track of bug fixes, enhancements, and changes that will be coming up in the 1.7 release by visiting our &lt;a href=&quot;/releases/&quot;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;questions_and_answers&quot;&gt;Questions and Answers&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/68073799/mongodb-as-sink-connector-not-capturing-data-as-expected-kafka&quot;&gt;MongoDB as sink connector not capturing data as expected - kafka?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/67823515/additional-unique-index-referencing-columns-not-exposed-by-cdc-causes-exception&quot;&gt;Additional unique index referencing columns not exposed by CDC causes exception&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/66384583/unable-to-deserialise-dynamic-json-with-jackson-using-generics&quot;&gt;Unable to deserialise dynamic json with Jackson using generics&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/66150335/the-connector-does-not-work-after-stopping-the-debezium-connector-with-ctrlc-an&quot;&gt;The connector does not work after stopping the Debezium Connector with Ctrl+C and restart the connector again&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/66123544/debezium-heartbeat-action-not-firing&quot;&gt;Debezium Heartbeat Action not firing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/66816670/flink-interrupted-while-waiting-for-data-to-be-acknowledged-by-pipeline&quot;&gt;Flink: Interrupted while waiting for data to be acknowledged by pipeline&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/67330280/cdc-with-debezium-in-docker&quot;&gt;CDC with debezium in docker&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/67368304/is-debezium-sqlserver-connector-task-multi-threading&quot;&gt;Is debezium sqlServer connector task multi-threading?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/68148783/how-to-create-subject-for-ksqldb-from-kafka-tapic&quot;&gt;How to create subject for ksqldb from kafka topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/65682694/debezium-kafka-connect-is-there-a-way-to-send-only-payload-and-not-schema&quot;&gt;Debezium, Kafka connect: is there a way to send only payload and not schema?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;getting_involved&quot;&gt;Getting Involved&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Getting started with a huge, and an existing code base can be intimidating, but we want to make sure that the process of getting started is extremely easy and smooth for you here. We are now a vibrant community with &lt;a href=&quot;https://github.com/debezium/debezium/graphs/contributors&quot;&gt;270+ contributors&lt;/a&gt; overall, and we welcome all kinds of community contributions, discussions, and enhancements. As a beginner you can grab some of the issues labeled with &lt;code&gt;easy-starter&lt;/code&gt; if you want to dive in quickly. Below is a list of issues that are open to grab:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Document &quot;schema.include.list&quot;/&quot;schema.exclude.list&quot; for SQL Server connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2793&quot;&gt;DBZ-2793&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Limit log output for &quot;Streaming requested from LSN&quot; warnings (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3007&quot;&gt;DBZ-3007&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create smoke test to make sure Debezium Server container image works (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3226&quot;&gt;DBZ-3226&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add signal table automatically to include list (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3293&quot;&gt;DBZ-3293&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Implement support for JSON_TABLE in MySQL parser (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3575&quot;&gt;DBZ-3575&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Implement window function in MySQL parser (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3576&quot;&gt;DBZ-3576&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Standardize &quot;snapshot.fetch.size default&quot; values across connectors (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3694&quot;&gt;DBZ-3694&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are new to open source, please check out our &lt;a href=&quot;https://github.com/debezium/debezium.github.io/blob/develop/CONTRIBUTING.md&quot;&gt;contributing guidelines&lt;/a&gt; to get started!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;call_to_action&quot;&gt;Call to Action&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our &lt;a href=&quot;https://www.debezium.io/community/users&quot;&gt;community users&lt;/a&gt; page includes a variety of organizations that are currently using Debezium. If you are a user of Debezium, and would like to be included, please send us a GitHub pull request or reach out to us directly through our community channels found &lt;a href=&quot;/community&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And if you haven&amp;#8217;t yet done so, please consider &lt;a href=&quot;https://github.com/debezium/debezium/stargazers&quot;&gt;adding a &lt;/a&gt; for the GitHub repo; keep them coming, we&amp;#8217;re almost at 5,000 stars!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also, we&amp;#8217;d like to learn about your requirements for future Debezium versions. In particular, we&amp;#8217;d be very curious about your feedback on the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/saga&quot;&gt;CDC-based Sagas approach&lt;/a&gt; mentioned above. Is it something you&amp;#8217;d like to see supported in our &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Quarkus extension&lt;/a&gt; for instance? Please let us know about this, as well as any other feedback you may have, via the Debezium &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Lastly, we&amp;#8217;re planning to continue our interview series &lt;a href=&quot;/blog/2020/10/08/debezium-community-stories-with-renato-mefi/&quot;&gt;Debezium Community Stories With&amp;#8230;&amp;#8203;&lt;/a&gt;; so if you got exciting stories to tell about your usage of Debezium, please reach out!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And as always, stay safe, and healthy. Wish you and your loved ones good health and strength.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="community"/><category term="news"/><category term="newsletter"/><summary type="html">Welcome to the newest edition of the Debezium community newsletter, in which we share all things CDC related including blog posts, group discussions, as well as StackOverflow questions that are relevant to our user community. It&amp;#8217;s been a long time since our last edition. But we are back again! In case you missed our last edition, you can check it out here.</summary></entry><entry><title type="html">Debezium 1.6.0.Final Released</title><link href="https://debezium.io/blog/2021/06/30/debezium-1-6-final-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Final Released"/><published>2021-06-30T00:00:00+00:00</published><updated>2021-06-30T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/06/30/debezium-1-6-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/06/30/debezium-1-6-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.6.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is packed full with tons of new features, including support for incremental snapshotting that can be toggled using the new the &lt;a href=&quot;/documentation/reference/1.6/configuration/signalling.html&quot;&gt;Signal API&lt;/a&gt;. Based on the excellent paper &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;DBLog: A Watermark Based Change-Data-Capture Framework&lt;/a&gt; by Netflix engineers Andreas Andreakis and Ioannis Papapanagiotou, the notion of incremental snapshotting addresses several requirements around snapshotting that came up repeatedly in the Debezium community:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Ability to resume an on-going snapshot after a connector restart&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Re-snapshot selected tables during streaming, e.g. to re-bootstrap Kafka topics with change events for specific tables&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Snapshot tables newly added to the list of captured tables after changing the filter configuration&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Begin to stream changes while an initial snapshot is running&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting is an incubating feature as of Debezium 1.6, and we&amp;#8217;re looking forward to your feedback on this feature. To learn more about this functionality, please refer to the individual connector docs, e.g. for the Debezium &lt;a href=&quot;/documentation/reference/1./connectors/mysql#_incremental_snapshot&quot;&gt;MySQL connector&lt;/a&gt;. There are already some follow-up improvements in this area in the workings, for instance the &lt;a href=&quot;https://github.com/debezium/debezium/pull/2430&quot;&gt;usage of MySQL GTIDs&lt;/a&gt; for setting the high/low watermarks required for this snapshotting approach, which will avoid the need for write access to the database by the connector. You can expect these improvements to be rolled out in one of the upcoming 1.7 preview releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides incremental snapshotting, other new features in Debezium 1.6 include two brand new &lt;a href=&quot;/documentation/reference/1.6/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; sinks, one for Apache Kafka and another for &lt;a href=&quot;https://pravega.io/&quot;&gt;Pravega&lt;/a&gt;, as well as several notable enhancements to the &lt;a href=&quot;/documentation/reference/1.6/connectors/oracle.html&quot;&gt;Debezium connector for Oracle&lt;/a&gt; which include reacting to DDL schema changes and an opt-in, incubating feature to emit &lt;code&gt;BLOB&lt;/code&gt; and &lt;code&gt;CLOB&lt;/code&gt; column data types. There&amp;#8217;s also improvements to the community-led connectors for &lt;a href=&quot;/documentation/reference/1.6/connectors/vitess.html&quot;&gt;Vitess&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/1.6/connectors/cassandra.html&quot;&gt;Apache Cassandra&lt;/a&gt;, as well as wide range of bug fixes and other smaller improvements. We&amp;#8217;ve also upgraded the &lt;a href=&quot;/documentation/reference/1.6/integrations/outbox.html&quot;&gt;Debezium Quarkus extension&lt;/a&gt; for implementing the outbox pattern to Quarkus 2.0.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Across all the 1.6 preview and the final releases, a grand total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.6.0.Alpha1%2C%201.6.0.Beta1%2C%201.6.0.Beta2%2C%201.6.0.CR1%2C%201.6.0.Final)&quot;&gt;188 issues&lt;/a&gt; has been addressed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For more details, please see the earlier announcements for the &lt;a href=&quot;/blog/2021/05/06/debezium-1-6-alpha1-released/&quot;&gt;1.6.0 Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/05/20/debezium-1-6-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/06/10/debezium-1-6-beta2-released/&quot;&gt;Beta2&lt;/a&gt;, and &lt;a href=&quot;/blog/2021/06/24/debezium-1-6-cr1-released/&quot;&gt;CR1&lt;/a&gt; releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since the CR1 release, we&amp;#8217;ve primarily focused on documentation improvements and some bug fixes. But there was one last-minute feature addition, too, which allows you to specify archive log locations (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3661&quot;&gt;DBZ-3661&lt;/a&gt;) for the Oracle connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.6/release-notes#release-1.6.0-final&quot;&gt;release notes&lt;/a&gt; of Debezium 1.6.0.Final for the complete list of resolved issues as well as procedures for upgrading from earlier versions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to all the members from the community who helped with this release, be it via code contributions, bug report, testing, providing insight and expertise, etc. Kudos to the following individuals from the community which contributed to Debezium 1.6, bringing the &lt;a href=&quot;https://github.com/debezium/debezium/graphs/contributors&quot;&gt;overall number&lt;/a&gt; of contributors to the Debezium core repository to 277:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/CaoManhDat&quot;&gt;Cao Manh Dat&lt;/a&gt;, &lt;a href=&quot;https://github.com/ccollingwood&quot;&gt;Chris Collingwood&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/eslep&quot;&gt;Eric Slep&lt;/a&gt;, &lt;a href=&quot;https://github.com/gvaquez-ubi&quot;&gt;Gilles Vaquez&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/piee9818&quot;&gt;Hyunjin Oh&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;, &lt;a href=&quot;https://github.com/truman303&quot;&gt;Mike&lt;/a&gt;, &lt;a href=&quot;https://github.com/ojacquemart&quot;&gt;Olivier Jacquemart&lt;/a&gt;, &lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarafonseca-123&quot;&gt;Sara Fonseca&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/siufay325&quot;&gt;SiuFay&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/zifeo&quot;&gt;Teo Stocco&lt;/a&gt;, &lt;a href=&quot;https://github.com/TAregger&quot;&gt;Thomas Aregger&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, Debezium will be following its normal quarterly release cadence with Debezium 1.7 planned by the end of September. There are a couple of key issues we intend to work on over the course of this version including support for incremental snapshots with the MongoDB and Oracle connectors. Additionally, we plan to explore some new buffering options for the Oracle connector&amp;#8217;s LogMiner-based implementation, work on a tool for compacting large schema history topics, expand the feature set of &lt;a href=&quot;https://github.com/debezium/debezium-ui/&quot;&gt;Debezium UI&lt;/a&gt;, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the coming week(s), keep an eye out on our &lt;a href=&quot;https://debezium.io/roadmap/&quot;&gt;roadmap&lt;/a&gt; as we&amp;#8217;ll be refining this in preparations for Debezium 1.7. If you have any specific feature requests or other input for the roadmap and future releases, please let us know via the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.6.0.Final! This release is packed full with tons of new features, including support for incremental snapshotting that can be toggled using the new the Signal API. Based on the excellent paper DBLog: A Watermark Based Change-Data-Capture Framework by Netflix engineers Andreas Andreakis and Ioannis Papapanagiotou, the notion of incremental snapshotting addresses several requirements around snapshotting that came up repeatedly in the Debezium community:</summary></entry><entry><title type="html">Debezium 1.6.0.CR1 Released</title><link href="https://debezium.io/blog/2021/06/24/debezium-1-6-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.CR1 Released"/><published>2021-06-24T00:00:00+00:00</published><updated>2021-06-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/06/24/debezium-1-6-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/06/24/debezium-1-6-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.6.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release adds skipped operations optimizations for SQL Server, introduces Heartbeat support to the Oracle connector, Oracle BLOB/CLOB support is now opt-in only, and provides a range of bug fixes and other improvements across different Debezium connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;skipped_operations_optimizations_sql_server&quot;&gt;Skipped operations optimizations - SQL Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium introduced the notion of &lt;code&gt;skipped.operations&lt;/code&gt; some time ago. This feature allows connectors to control what change events are emitted during the streaming phase, optionally omitting certain change types such as updates or deletes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;skipped.operations&lt;/code&gt; feature was originally implemented to act more like an SMT where it was a filter that was applied toward the end of the CDC pipeline just before an event was emitted. While this worked well, there was an optimization that could be achieved here because SQL Server records the change type in the capture table along side the change data. Using this knowledge, the query to fetch changes from the capture table was adjusted so that the changes returned from SQL Server are pre-filtered based on these &quot;skipped operations&quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, this optimization should improve both the time spent during iterations of capturing changes when the connector is configured to use &lt;code&gt;skipped.operations&lt;/code&gt; as well as reduce the overall garbage collection that the connector may do over its lifetime due to generating fewer objects that are later discarded.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt; for identifying this optimization and contributing it!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;heartbeat_support_for_the_oracle_connector&quot;&gt;Heartbeat Support for the Oracle Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium supports heartbeats across its other connectors, this feature is now available to Oracle!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat is a critical part of insuring that a connector&amp;#8217;s offsets remain synchronized with Kafka. Normally, the offsets are automatically maintained by Kafka Connect when we emit an event to a topic. But there are circumstances where event emission can be infrequent enough that stale offsets become a concern.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Regardless which adapter the Debezium Oracle connector is deployed to use, there are situations where events may be seen by the connector and in-memory offset state is updated but because we don&amp;#8217;t emit an event to Kafka, the offsets aren&amp;#8217;t synchronized to Kafka Connect. A great example is when the connector could be capturing changes for a table that changes very infrequently compared to other tables in the data source.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to guarantee that offsets remain synchronized with Kafka Connect, specifically during periods of low capture activity, the &lt;code&gt;heartbeat.interval.ms&lt;/code&gt; configuration option can be set to periodically keep offsets in sync.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_blobclob_support_now_opt_in&quot;&gt;Oracle BLOB/CLOB Support now Opt-In&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While we added support for &lt;code&gt;BLOB&lt;/code&gt; and &lt;code&gt;CLOB&lt;/code&gt; data types to the Debezium connector for Oracle in an earlier 1.6 pre-release, we believe that the work towards fully supporting these types is still an ongoing one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There is a certain amount of overhead the connector has when handling BLOB and CLOB fields. Transactions which contain these data types require a reconciliation step at commit-time to merge certain events into a single logical emitted event. Additionally, LOB data types require a certain amount of memory footprint for their values to be kept in memory while the event to be emitted is constructed. Furthermore, users may not want to have LOB data emitted at all due to the size of the data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So with that, the Oracle connector&amp;#8217;s support for LOB data types is now an opt-in only feature. This means that OOTB the connector won&amp;#8217;t attempt to capture LOB column data. If LOB columns need to be captured by the connector, the connector option, &lt;code&gt;lob.enabled&lt;/code&gt;, must be set to &lt;code&gt;true&lt;/code&gt; so that the connector will pickup and process those column types.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Lastly, we also felt that since there is still some ongoing effort for BLOB and CLOB support, it made sense to denote LOB support as &lt;em&gt;incubating&lt;/em&gt; for the short-term until we believe the solution has matured. We strongly encourage users who want to capture LOB-based columns to enable LOB support and give it test drive and provide any and all feedback, both good or bad, so that we can continue to improve support for LOB columns.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements_and_bugfixes&quot;&gt;Further Improvements and Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium connector for Oracle also saw quite a number of small improvements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3612&quot;&gt;DBZ-3612&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3616&quot;&gt;DBZ-3616&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3619&quot;&gt;DBZ-3619&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3631&quot;&gt;DBZ-3631&lt;/a&gt;). These improvements focused on improving the DDL parser as well as logging.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the recent release of Quarkus 2.0.0.Final, the Quarkus Outbox extension is now based on Quarkus 2.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3602&quot;&gt;DBZ-3602&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20=%2012317320%20AND%20fixVersion%20=%2012358695%20ORDER%20BY%20priority%20DESC,%20key%20ASC&quot;&gt;27 issues&lt;/a&gt; have been addressed in Debezium 1.6.0.CR1. We&amp;#8217;re deeply grateful to all the community members contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/piee9818&quot;&gt;Hyunjin Oh&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, and &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With CR1 out, we&amp;#8217;re nearing the end of the stablization phase for the 1.6 release cycle. You can expect possibly one more CR (candidate release), before the final release, which is planned for the end of the month, barring any unforeseen complications of cause. Besides some more bug fixes and documentation improvements we&amp;#8217;re also intending to upgrade to Apache Kafka 2.8, which will allow you to take a sneak peak at using Debezium with &lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;ZooKeeper-less Kafka&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In parallel, we&amp;#8217;re going to work on the roadmap for Debezium 1.7 (due by the end of September). Please get in touch via the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; if you have specific feature requests for this release!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.6.0.CR1! This release adds skipped operations optimizations for SQL Server, introduces Heartbeat support to the Oracle connector, Oracle BLOB/CLOB support is now opt-in only, and provides a range of bug fixes and other improvements across different Debezium connectors.</summary></entry><entry><title type="html">Debezium 1.6.0.Beta2 Released</title><link href="https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Beta2 Released"/><published>2021-06-10T00:00:00+00:00</published><updated>2021-06-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.6.0.Beta2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release adds support for Pravega to Debezium Server, expands the snapshotting options of the Debezium Oracle connector, and provides a range of bug fixes and other improvements across different Debezium connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;pravega_support_for_debezium_server&quot;&gt;Pravega Support for Debezium Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;, we&amp;#8217;re on a mission to bring open-source change data capture to all the users, no matter which data streaming platform or commit log they are using. So we are very happy to receive a contribution which adds support for &lt;a href=&quot;https://pravega.io/&quot;&gt;Pravega&lt;/a&gt; to Debezium Server. A Cloud Native Computing Foundation (CNCF) sandbox and Apache 2.0 licensed open-source project, Pravega describes itself as a &quot;storage abstraction for continuously generated and unbounded data&quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium Server Pravega sink adapter offers two modes: non-transactional and transactional. The non-transactional mode individually writes each event in a Debezium batch to Pravega. The transactional mode writes the Debezium batch to a Pravega transaction that commits when the batch is completed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about using Debezium with Pravega, please refer to the &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_pravega&quot;&gt;documentation&lt;/a&gt;. Many thanks to &lt;a href=&quot;https://twitter.com/derekm00r3&quot;&gt;Derek Moore&lt;/a&gt; for this fantastic contribution!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_snapshotting_improvements&quot;&gt;Oracle Snapshotting Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium connector for Oracle received two improvements related to snapshotting:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for the &lt;code&gt;snapshot.include.collection.list&lt;/code&gt; option (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3062&quot;&gt;DBZ-3062&lt;/a&gt;); this allows to create an initial snapshot only for a subset of all those tables captured by the connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;New option &lt;code&gt;snapshot.locking.mode&lt;/code&gt; which provides control over the locking behavior when the connector captures the schema of the tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3557&quot;&gt;DBZ-3557&lt;/a&gt;); in particular, this allows to disable locking completely, which is very useful if you can guarantee that no DDL changes are happening while the connector is taking the (schema) snapshot&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, there&amp;#8217;s several bug fixes for this connector, including a few ones related to DDL and DML parsing (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3545&quot;&gt;DBZ-3545&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3549&quot;&gt;DBZ-3549&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3554&quot;&gt;DBZ-3554&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3606&quot;&gt;DBZ-3606&lt;/a&gt;), handling of RAC installations (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3563&quot;&gt;DBZ-3563&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3599&quot;&gt;DBZ-3599&lt;/a&gt;), and more efficient handling of LOB columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3556&quot;&gt;DBZ-3556&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements_and_bugfixes&quot;&gt;Further Improvements and Bugfixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium connector for SQL Server saw two performance-related improvments (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3486&quot;&gt;3486&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3515&quot;&gt;DBZ-3515&lt;/a&gt;). The schemas of change events from the Postgres connector contain default values now, based on the source column definition (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2790&quot;&gt;DBZ-2790&lt;/a&gt;). This comes in handy for instance when deriving downstream table schemas from a change event stream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other fixes include correct identification of primary members in MongoDB replica sets (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3522&quot;&gt;DBZ-3522&lt;/a&gt;), support for the &lt;code&gt;JSON&lt;/code&gt; function in the MySQL connector&amp;#8217;s DDL parser (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3559&quot;&gt;DBZ-3559&lt;/a&gt;), and the upgrade of the &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Debezium Quarkus extension&lt;/a&gt; for implementing the outbox pattern to Quarkus 2.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3550&quot;&gt;DBZ-3550&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-400?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.6.0.Beta2%20ORDER%20BY%20key%20ASC%2C%20component%20ASC&quot;&gt;48 issues&lt;/a&gt; have been addressed in Debezium 1.6.0.Beta2. We&amp;#8217;re deeply grateful to all the community members contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/ccollingwood&quot;&gt;Chris Collingwood&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/eslep&quot;&gt;Eric Slep&lt;/a&gt;, &lt;a href=&quot;https://github.com/gvaquez-ubi&quot;&gt;Gilles Vaquez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, Jackey Zhang, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;, &lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarafonseca-123&quot;&gt;Sara Fonseca&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With Beta2 through the door, we&amp;#8217;re entering the stabilization phase for the 1.6 release cycle. You can expect one or two CRs (candidate releases), before the final release, which is planned for the end of the month, barring any unforeseen complications of cause. Besides some more bug fixes and documentation improvements we&amp;#8217;re also intending to upgrade to Apache Kafka 2.8, which will allow you to take a sneak peak at using Debezium with &lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;ZooKeeper-less Kafka&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In parallel, we&amp;#8217;re going to work on the roadmap for Debezium 1.7 (due by the end of September). Please get in touch via the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; if you have specific feature requests for this release!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.6.0.Beta2! This release adds support for Pravega to Debezium Server, expands the snapshotting options of the Debezium Oracle connector, and provides a range of bug fixes and other improvements across different Debezium connectors.</summary></entry><entry><title type="html">Debezium 1.5.2.Final Released</title><link href="https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released/" rel="alternate" type="text/html" title="Debezium 1.5.2.Final Released"/><published>2021-05-28T00:00:00+00:00</published><updated>2021-05-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let me announce the bugfix release of Debezium 1.5, &lt;strong&gt;1.5.2.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is a rebuild of 1.5.1.Final using Java 8.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium 1.5.1.Final was incorrectly built using Java 11. That would prevent it running in environments still using Java 8. This version is rebuilt using Java 8.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20and%20fixVersion%20%3D%201.5.2.Final&quot;&gt;2 issues&lt;/a&gt; were fixed for this release. Thanks a lot to all contributors!&lt;/p&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">Let me announce the bugfix release of Debezium 1.5, 1.5.2.Final! This release is a rebuild of 1.5.1.Final using Java 8.</summary></entry><entry><title type="html">Debezium 1.5.1.Final Released</title><link href="https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.5.1.Final Released"/><published>2021-05-27T00:00:00+00:00</published><updated>2021-05-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let me announce the bugfix release of Debezium 1.5, &lt;strong&gt;1.5.1.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release fixes a small set of issues discovered since the original release and few improvements into the documentation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The two most important fixes in this release are related to the MySQL database history that can get potentially corrupted under an unfavorable set of conditions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;If you execute a &lt;code&gt;DROP TABLE&lt;/code&gt; command and the affected table&amp;#8217;s name contains dashes, then the resulting statement cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3485&quot;&gt;DBZ-3485&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;RENAME TABLE&lt;/code&gt; statements that contains more than one table can be stored incompletely (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3399&quot;&gt;DBZ-3399&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Both issues were introduced during the rewrite of MySQL connector and were not covered by integration tests.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We strongly recommend upgrading to 1.5.1.Final before you hit these issues. If you are already affected, then the easiest way to recover from the error situation is using a new topic (or dropping the old one) for the database history and execute a &lt;code&gt;schema_only_recovery&lt;/code&gt; snapshot. We apologize for the potential inconvenience.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3549?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.1.Final&quot;&gt;31 issues&lt;/a&gt; were fixed for this release. Thanks a lot to all contributors!&lt;/p&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">Let me announce the bugfix release of Debezium 1.5, 1.5.1.Final! This release fixes a small set of issues discovered since the original release and few improvements into the documentation.</summary></entry><entry><title type="html">Debezium 1.6.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Beta1 Released"/><published>2021-05-20T00:00:00+00:00</published><updated>2021-05-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.6.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release introduces incremental snapshot support for SQL Server and Db2, performance improvements for SQL Server, support for BLOB/CLOB for Oracle, and much more. Lets take a few moments and explore some of these new features in the following.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_sql_server_db2&quot;&gt;Incremental Snapshotting - SQL Server / Db2&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium first introduced incremental snapshotting in 1.6.0.Alpha1. As discussed in this &lt;a href=&quot;https://debezium.io/blog/2021/05/06/debezium-1-6-alpha1-released/&quot;&gt;blog post&lt;/a&gt;, there are several pain points that exist when running Debezium:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;the necessity to execute consistent snapshots before streaming has begun upon connector restarts&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;inability to trigger full or even partial snapshots after having the connector running for extended periods of time&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With this release, this feature has been extended to both the SQL Server and Db2 connectors. We intend to continue to roll this feature out to additional connectors in future releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you would like to try the feature yourself then you need to&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;provide a &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/configuration/signalling.html#_overview&quot;&gt;signalling table&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;trigger an ad-hoc incremental snapshot by using a SQL command like&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;INSERT INTO myschema.debezium_signal VALUES('ad-hoc-1', 'execute-snapshot', '{&quot;data-collections&quot;: [&quot;schema1.table1&quot;, &quot;schema1.table2&quot;]}')&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;sql_server_performance_improvement&quot;&gt;SQL Server Performance Improvement&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The SQL Server connector option, &lt;code&gt;source.timestamp.mode&lt;/code&gt;, controls how the timestamp for an emitted event is resolved. The default &lt;code&gt;commit&lt;/code&gt; setting is designed to resolve the timestamp based on when the change record was committed in the database. It was identified that this method used separate JDBC calls to resolve the timestamp for an event, which caused a loss in both performance and throughput.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release fixes the &lt;code&gt;commit&lt;/code&gt; mode performance problem by moving where the timestamp is resolved. This substantially increases the connector&amp;#8217;s performance and throughput while maintaining existing functionality.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We would like to thank &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt; for identifying and contributing a solution to this problem.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_large_object_data_types&quot;&gt;Oracle Large Object Data Types&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the era of &quot;Big Data&quot;, its not all that uncommon to use data types such as &lt;code&gt;BLOB&lt;/code&gt; and &lt;code&gt;CLOB&lt;/code&gt; to store large object data. The Debezium Oracle connector has supported a wide range of data types and we&amp;#8217;re happy to report that we&amp;#8217;ve now extended that support to cover large both BLOB and CLOB for both the XStream and LogMiner based implementations.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When emitting events that contain &lt;code&gt;BLOB&lt;/code&gt; or &lt;code&gt;CLOB&lt;/code&gt; data, the memory footprint of the connector as well as the emitted event&amp;#8217;s message size will be directly impacted by the size of the large object data. As a result, the connector&amp;#8217;s JVM process may require additional memory as well as adjusting some Kafka configurations, such as &lt;code&gt;message.max.bytes&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We encourage the community to test drive the support for these new data types and report any and all feedback.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in this release include the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Oracle now supports &lt;code&gt;ALTER TABLE&lt;/code&gt; and &lt;code&gt;DROP TABLE&lt;/code&gt; automatically (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2916&quot;&gt;DBZ-2916&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Oracle is tested and validated using ojdbc.jar version 21.1.0.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3460&quot;&gt;DBZ-3460&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for MonogDB could lead to lost change events where a long running snapshot was greater than the configured oplog window (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3331&quot;&gt;DBZ-3331&lt;/a&gt;); the connector now validates the oplog position&amp;#8217;s existance when streaming starts&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Cassandra was not responding to schema changes correctly (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3417&quot;&gt;DBZ-3417&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.6.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;52 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to all the community members who contributed: &lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/CaoManhDat&quot;&gt;Cao Manh Dat&lt;/a&gt;, &lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;, &lt;a href=&quot;https://github.com/shiawu&quot;&gt;John Wu&lt;/a&gt;, &lt;a href=&quot;https://github.com/truman303&quot;&gt;Mike&lt;/a&gt;, &lt;a href=&quot;https://github.com/ojacquemart&quot;&gt;Olivier Jacquemart&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/siufay325&quot;&gt;SiuFay&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/TAregger&quot;&gt;Thomas Aregger&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.6.0.Beta1! This release introduces incremental snapshot support for SQL Server and Db2, performance improvements for SQL Server, support for BLOB/CLOB for Oracle, and much more. Lets take a few moments and explore some of these new features in the following.</summary></entry></feed>