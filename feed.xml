<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://debezium.io/" rel="alternate" type="text/html" /><updated>2021-01-19T19:34:02+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 1.4.0.Final Released</title><link href="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Final Released" /><published>2021-01-07T00:00:00+00:00</published><updated>2021-01-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/07/debezium-1-4-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release concludes the major work put into Debezium over the last three months.
Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.4.0.Final%2C%201.4.0.Alpha1%2C%201.4.0.Beta1%2C%201.4.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;117 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New &lt;a href=&quot;/documentation/reference/connectors/vitess.html&quot;&gt;Vitess&lt;/a&gt; connector, featured in an in-depth &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;blog post&lt;/a&gt; by Kewei Shang&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fine-grained selection of snapshotted tables&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; completion hook&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Distributed &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;Tracing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL support for &lt;em&gt;create&lt;/em&gt; or &lt;em&gt;read&lt;/em&gt; records emitted during snapshot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many Oracle &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;Logminer adapter&lt;/a&gt; improvements&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Full support for Oracle JDBC connection strings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved reporting of DDL errors&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to previous release announcements (&lt;a href=&quot;/blog/2020/10/23/debezium-1-4-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/11/17/debezium-1-4-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/09/debezium-1-4-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/17/debezium-1-4-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details.
Since the CR1 release just before the holidays, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;focused&lt;/a&gt; on addressing some remaining bugs and improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you to everyone involved in testing the previous releases, this is invaluable by spotting and addressing any problems with new features as well as regressions.
And of course we&amp;#8217;d like to thank all the community members contributing to this release:
&lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/martper2&quot;&gt;Martin Perez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;,
&lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yrodiere&quot;&gt;Yoann Rodière&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, more than 245 individuals have contributed to the Debezium project and the number of Debezium &lt;a href=&quot;/community/users/&quot;&gt;users&lt;/a&gt; continues to grow.
As we usher in 2021, check out our &lt;a href=&quot;/blog/2021/01/06/debezium-2020-recap/&quot;&gt;recap of Debezium in 2020&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With 1.4 Final released, planning for the 1.5 version (due by the end of March) is currently underway.
The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; is still being discussed, so be sure to let us know about your requirements and feature requests.
Some of the things we&amp;#8217;re considering for this next release are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Continued stability and improvements to the new LogMiner-based implementation for Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Until then remain safe, it&amp;#8217;s onwards and upwards from here!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I am pleased to announce the release of Debezium 1.4.0.Final! This release concludes the major work put into Debezium over the last three months. Overall, the community fixed 117 issues during that time, including the following key features and changes: New Vitess connector, featured in an in-depth blog post by Kewei Shang Fine-grained selection of snapshotted tables PostgreSQL Snapshotter completion hook Distributed Tracing MySQL support for create or read records emitted during snapshot Many Oracle Logminer adapter improvements Full support for Oracle JDBC connection strings Improved reporting of DDL errors</summary></entry><entry><title type="html">Debezium in 2020 – The Recap!</title><link href="https://debezium.io/blog/2021/01/06/debezium-2020-recap/" rel="alternate" type="text/html" title="Debezium in 2020 – The Recap!" /><published>2021-01-06T00:00:00+00:00</published><updated>2021-01-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/06/debezium-2020-recap</id><content type="html" xml:base="https://debezium.io/blog/2021/01/06/debezium-2020-recap/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A Happy New Year to the Debezium Community!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy.
With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First, some facts and numbers for you stats lovers out there:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;After the release of &lt;a href=&quot;/blog/2019/12/18/debezium-1-0-0-final-released/&quot;&gt;Debezium 1.0&lt;/a&gt; in December 2019, we successfully released a stable Debezium version at the end of each quarter, with preview releases roughly every three weeks&lt;sup class=&quot;footnote&quot;&gt;[&lt;a id=&quot;_footnoteref_1&quot; class=&quot;footnote&quot; href=&quot;#_footnotedef_1&quot; title=&quot;View footnote.&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 1,400 commits in the core repo (plus many more in the other ones), 36 blog posts and release announcements, 166 threads on the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; (if the query in my Google inbox is to be trusted)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 100 new contributors, bringing the &lt;a href=&quot;https://github.com/debezium/debezium/blob/master/COPYRIGHT.txt&quot;&gt;overall number&lt;/a&gt; of people contributing to the Debezium core repo to 245, plus additional people contributing to the other repositories of the Debezium GitHub organization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The first &lt;a href=&quot;https://developers.redhat.com/blog/2020/04/14/capture-database-changes-with-debezium-apache-kafka-connectors/&quot;&gt;GA release&lt;/a&gt; of the commercially supported Debezium offering by Red Hat, as part of &lt;a href=&quot;https://www.redhat.com/en/products/integration&quot;&gt;Red Hat Integration&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;/blog/2020/07/28/hello-debezium/&quot;&gt;Two&lt;/a&gt; &lt;a href=&quot;/blog/2020/10/27/hello-debezium/&quot;&gt;new&lt;/a&gt; members on the core engineering team&amp;#8201;&amp;#8212;&amp;#8201;the more, the merrier!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 1,600 additional GitHub ⭐s for the Debezium core repo, bringing the total number of star gazers to more than 4,100&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/github_stars_2020.png&quot; style=&quot;max-width:75%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While those figures give a nice impression of the overall activity of Debezium, they don&amp;#8217;t really tell &lt;em&gt;what&lt;/em&gt; has been happening exactly.
What&amp;#8217;s behind the numbers?
Here are some of my personal Debezium highlights from the last year:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two new, community-led Debezium connectors for &lt;a href=&quot;https://github.com/debezium/debezium-connector-db2/&quot;&gt;Db2&lt;/a&gt; and &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess&lt;/a&gt;;
a big shout-out to the engineers of &lt;a href=&quot;/blog/2020/03/05/db2-cdc-approaches/&quot;&gt;IBM&lt;/a&gt; and &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;Bolt&lt;/a&gt;, respectively, for stepping up and taking the lead of these connectors!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Besides these new connectors, each of the releases brought a wide range of new features; some of the things I&amp;#8217;m most excited about are &lt;a href=&quot;/documentation/reference/1.2/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; for integrating Debezium with message infrastructure like Apache Pulsar, AWS Kinesis, Google Cloud Pub/Sub, and Azure Event Hubs, the &lt;a href=&quot;/documentation/reference/1.1/integrations/outbox.html&quot;&gt;Quarkus extension&lt;/a&gt; for implementing the outbox pattern,
the new &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based connector implementation&lt;/a&gt; for ingesting change events from Oracle,
transaction markers, support for CloudEvents, and so much more!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integration of Debezium by multiple open-source projects,
e.g. &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/formats/debezium.html&quot;&gt;Apache Flink&lt;/a&gt;,
&lt;a href=&quot;https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time&quot;&gt;Spring Cloud Stream&lt;/a&gt;,
&lt;a href=&quot;https://jet-start.sh/docs/tutorials/cdc&quot;&gt;Hazecast Jet&lt;/a&gt;, and
&lt;a href=&quot;https://camel.apache.org/blog/2020/05/CdcWithCamelAndDebezium/&quot;&gt;Apache Camel&lt;/a&gt;.
Further integrators of Debezium include &lt;a href=&quot;https://materialize.io/docs/third-party/debezium/&quot;&gt;Materialize&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/how-to-move-data-from-mysql-to-bigquery&quot;&gt;Google Cloud DataFlow&lt;/a&gt; and &lt;a href=&quot;https://devcenter.heroku.com/articles/heroku-data-connectors&quot;&gt;Heroku’s streaming data connectors&lt;/a&gt;.
Here on this blog, we also discussed how to integrate and use Debezium with technologies such as &lt;a href=&quot;/blog/2020/03/19/integration-testing-for-change-data-capture-with-testcontainers/&quot;&gt;Testcontainers&lt;/a&gt;,
the &lt;a href=&quot;/blog/2020/04/09/using-debezium-with-apicurio-api-schema-registry/&quot;&gt;Apicurio API and schema registry&lt;/a&gt;,
and &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;OpenTracing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium being &lt;a href=&quot;https://www.thoughtworks.com/radar/platforms/debezium&quot;&gt;listed at &quot;Trial&quot; level&lt;/a&gt; on the ThoughtWorks Tech Radar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A proof-of-concept for a &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;graphical user interface for configuring and operating Debezium&lt;/a&gt;;
stay tuned for more details here, as this is currently in the process of being built out for other connectors&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The year also brought a large number of blog posts and presentations from the community about their experiences with Debezium.
You can find our full list of Debezium-related resources &lt;a href=&quot;debezium.io/documentation/online-resources/&quot;&gt;here&lt;/a&gt;
(please send a PR for adding anything you think should be listed there).
Some contents I particularly enjoyed include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://static.sched.com/hosted_files/ossna2020/c6/Managing Data Consistency with Debezium.pdf&quot;&gt;&quot;Managing Data Consistency Among Microservices with Debezium&quot;&lt;/a&gt; by Justin Chao&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;&quot;Change Data Capture with Flink SQL and Debezium&quot;&lt;/a&gt; by Marta Paes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=6nU9i022yeY&quot;&gt;&quot;Microservices &amp;amp; Data: Implementing the Outbox Pattern with Debezium&quot;&lt;/a&gt; by Thorben Janssen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.systemcraftsman.com/2020/11/30/asap-the-storified-demo-of-introduction-to-debezium-and-kafka-on-kubernetes/&quot;&gt;&quot;ASAP! – The Storified Demo of Introduction to Debezium and Kafka on Kubernetes&quot;&lt;/a&gt; by Aykut Bulgu&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://elephanttamer.net/?p=50&quot;&gt;&quot;Setting up PostgreSQL for Debezium&quot;&lt;/a&gt; by Michał Mackiewicz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@midhunsukumaran.mec/a-year-and-a-half-with-debezium-f4f323b4909d&quot;&gt;&quot;A year and a half with Debezium: CDC With MySQL&quot;&lt;/a&gt; by Midhun Sukumaran&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;&quot;Debezium on OpenShift Cheat Sheet&quot;&lt;/a&gt; by Abdellatif Bouchama&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;&quot;Implementing the Transactional Outbox pattern with Debezium in Quarkus&quot;&lt;/a&gt; by Iain Porter&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.confluent.io/blog/cdc-and-streaming-analytics-using-debezium-kafka/&quot;&gt;&quot;Analysing Changes with Debezium and Kafka Streams&quot;&lt;/a&gt; by Mike Fowler&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@bogdan.dina03/de-coupling-yourself-507a15fa100d&quot;&gt;&quot;(De)coupling yourself&quot;&lt;/a&gt; by Dina Bogdan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@limadelrey/kafka-connect-how-to-create-a-real-time-data-pipeline-using-change-data-capture-cdc-c60e06e5306a&quot;&gt;&quot;Kafka Connect: How to create a real time data pipeline using Change Data Capture (CDC)&quot;&lt;/a&gt; by Francisco Lima&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.to/abhirockzz/tutorial-set-up-a-change-data-capture-architecture-on-azure-using-debezium-postgres-and-kafka-49h6&quot;&gt;&quot;Tutorial: Set up a Change Data Capture architecture on Azure using Debezium, Postgres and Kafka &quot;&lt;/a&gt; by Abhishek Gupta&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is just so amazing to see how engaged and helpful this community is; A big thank you to everyone for writing and talking about your experiences with Debezium and change data capture!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I think 2020 has been a great year for the Debezium community,
and I couldn&amp;#8217;t be happier about all the things we&amp;#8217;ve achieved together.
Again, a huge thank you to each and everyone in the community contributing to the project,
be it via by implementing features and bug fixes, reporting issues, engaging in discussions, answering questions on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/debezium&quot;&gt;Stack Overflow&lt;/a&gt;, helping to spread the word in blog posts and conference talks, or otherwise!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What&amp;#8217;s on the roadmap for this year?
It&amp;#8217;s fair to say: &quot;A lot&quot; :) E.g. we&amp;#8217;d like to rework the way snapshots are done: they should be parallelizeable, updates to the include/exclude filters should be possible, and more.
The Debezium UI will see substantial expansion and improvements. We&amp;#8217;re planning to conduct a systematic performance profiling and improvements of identified bottlenecks. There may be official support for MariaDB, as well as an operator for running Debezium Server on Kubernetes.
Plus some super-cool things I cannot talk about at this point yet :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Onwards and Upwards!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;footnotes&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;footnote&quot; id=&quot;_footnotedef_1&quot;&gt;
&lt;a href=&quot;#_footnoteref_1&quot;&gt;1&lt;/a&gt;. Where is Debezium 1.4, you ask? The agile bunch we are, we adhered to the &quot;Individuals over processes&quot; principle and decided to move this release to later this week, due to the holiday break :)
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="discussion" /><summary type="html">A Happy New Year to the Debezium Community! May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy. With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year. First, some facts and numbers for you stats lovers out there:</summary></entry><entry><title type="html">Debezium 1.4.0.CR1 Released</title><link href="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.CR1 Released" /><published>2020-12-17T00:00:00+00:00</published><updated>2020-12-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release focuses primarily on polishing the 1.4 release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.CR1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;15 issues&lt;/a&gt; for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Document &quot;database.oracle.version&quot; option &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2603&quot;&gt;DBZ-2603&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move Cassandra connector to separate repository &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2636&quot;&gt;DBZ-2636&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove link in MySQL docs section that points to the same section &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2710&quot;&gt;DBZ-2710&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Invalid column name should fail connector with meaningful message &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2836&quot;&gt;DBZ-2836&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix typos in downstream ModuleID declarations in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2838&quot;&gt;DBZ-2838&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Duplicate anchor ID in partials/ref-connector-monitoring-snapshot-metrics.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2839&quot;&gt;DBZ-2839&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle schema history events fail on partitioned table &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2841&quot;&gt;DBZ-2841&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix additional typo in ModuleID declaration in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2843&quot;&gt;DBZ-2843&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit modularization annotations in logging.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2846&quot;&gt;DBZ-2846&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;outbox extension emits UPDATE events when delete is disabled &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2847&quot;&gt;DBZ-2847&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update Groovy version to 3.0.7 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2850&quot;&gt;DBZ-2850&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.4 Final should be out the first week of January.
Until then, we wish everyone a safe and happy holiday season!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.CR1! This release focuses primarily on polishing the 1.4 release.</summary></entry><entry><title type="html">Distributed Tracing with Debezium</title><link href="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/" rel="alternate" type="text/html" title="Distributed Tracing with Debezium" /><published>2020-12-16T11:00:00+00:00</published><updated>2020-12-16T11:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The current pattern in application development gravitates toward microservices and microservices architecture.
While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state.
This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path.
This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context.
&lt;a href=&quot;https://microservices.io/patterns/observability/distributed-tracing.html&quot;&gt;Distributed Tracing&lt;/a&gt; comes here to the rescue.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;distributed-tracing&quot;&gt;Distributed Tracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;.
SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And this is where Debezium becomes part of the picture.
Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into.
How long does it take for change events to flow from source database to sink systems?
Where is the most time spent in the pipeline?
Are there any anomalies like spikes in end-to-end lags?
The integration of distributed tracing with Debezium can help to answer these questions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;opentracing&quot;&gt;OpenTracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the &lt;a href=&quot;https://opentracing.io/&quot;&gt;OpenTracing&lt;/a&gt; specification.
OpenTracing is an incubating project of &lt;a href=&quot;https://www.cncf.io/&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; which guarantees that the user will be free of any vendor lock-in by adhering to an open standard.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The OpenTracing project is in the process of being merged with OpenCensus to the improved &lt;a href=&quot;https://opentelemetry.io/&quot;&gt;OpenTelemetry&lt;/a&gt; standard.
Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus),
but it will use and support OpenTelemetry in the future, too.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A distributed trace in OpenTracing consists of a set of spans.
Each span represents a logical unit of work executed.
The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;OpenTracing is only the specification and the instrumentation API.
To use it you need to have an implementation, too.
While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the &lt;a href=&quot;https://www.jaegertracing.io/&quot;&gt;Jaeger&lt;/a&gt; distributed tracing platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application.
The Jaeger &lt;a href=&quot;https://www.jaegertracing.io/docs/1.21/getting-started/#all-in-one&quot;&gt;All-In-One&lt;/a&gt; container image will be used to simplify the deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;debezium-and-opentracing&quot;&gt;Debezium and OpenTracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium integration with OpenTracing consists of three distinct components:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;EventDispatcher&lt;/code&gt; in the &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Debezium outbox extension&lt;/a&gt; for Quarkus applications&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;EventRouter&lt;/code&gt; &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;SMT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first one is intended for general use.
The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;outbox-distributed-tracing&quot;&gt;Outbox Distributed Tracing&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing.
The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When an event arrives at &lt;code&gt;EventDispatcher&lt;/code&gt; a new span &lt;code&gt;outbox-write&lt;/code&gt; is created.
It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The span metadata is exported into a distinct field of the outbox event.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The outbox event is written to the outbox table.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Event Router SMT receives the event and imports the span metadata from the field&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two new spans are created&lt;/p&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;db-log-write&lt;/code&gt; with its start timestamp set to database write timestamp.
The fields from the &lt;code&gt;source&lt;/code&gt; block are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;debezium-read&lt;/code&gt; with its start time set to the processing timestamp.
Fields from the envelope are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;demo&quot;&gt;Demo&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/outbox&quot;&gt;outbox example&lt;/a&gt; was extended with distributed tracing support to demonstrate the functionality.
This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This demo uses the &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt; container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To try it yourself you need to:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;check out the repository and switch to the &lt;code&gt;outbox&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;build the services&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ mvn clean install&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;deploy the application&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;export DEBEZIUM_VERSION=1.4
docker-compose up --build&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;register a Debezium connector to listen on the outbox table&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json
HTTP/1.1 201 Created&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;execute multiple business requests&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json
$ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;check the &lt;a href=&quot;http://localhost:16686/&quot;&gt;Jaeger UI&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After all the steps above were completed you should see an introduction screen of the Jaeger UI:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-main.png&quot; class=&quot;responsive-image&quot; alt=&quot;Jaeger intro&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Filter on &lt;code&gt;order-service&lt;/code&gt; as a service and click on &lt;code&gt;Find Traces&lt;/code&gt;.
Two traces should be available:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-service.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Click on the &lt;code&gt;addOrder&lt;/code&gt; service.
A tree will open that displays how the initial request incoming via REST API was&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;written to the database by the outbox extension&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;read by Debezium and processed by outbox SMT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;written to a Kafka topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;read from a Kafka topic by &lt;code&gt;shipment-service&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;processed in the different &lt;code&gt;shipment-service&lt;/code&gt; business methods&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-trace.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Click on the &lt;code&gt;db-log-write&lt;/code&gt; and &lt;code&gt;debezium-read&lt;/code&gt; spans.
The &lt;strong&gt;tags&lt;/strong&gt; of each of them contain extracted Debezium-related metadata like &lt;code&gt;operation&lt;/code&gt; or &lt;code&gt;source&lt;/code&gt; fields:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-debezium-details.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it.
We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While this example was focused on the specific use case of microservices data exchange via the outbox pattern,
Debezium integrates with distributed tracing also independently of this particular pattern.
By means of the &lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT, Debezium can produce spans representing the time of the change in the source database itself,
as well as the time of processing the event by the Debezium connector.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases.
Your feedback on this new functionality is highly welcomed!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="tracing" /><category term="jaeger" /><summary type="html">The current pattern in application development gravitates toward microservices and microservices architecture. While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production. Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state. This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes. You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path. This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context. Distributed Tracing comes here to the rescue. Distributed Tracing Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;. SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs. And this is where Debezium becomes part of the picture. Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into. How long does it take for change events to flow from source database to sink systems? Where is the most time spent in the pipeline? Are there any anomalies like spikes in end-to-end lags? The integration of distributed tracing with Debezium can help to answer these questions. OpenTracing There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the OpenTracing specification. OpenTracing is an incubating project of Cloud Native Computing Foundation which guarantees that the user will be free of any vendor lock-in by adhering to an open standard. Note The OpenTracing project is in the process of being merged with OpenCensus to the improved OpenTelemetry standard. Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus), but it will use and support OpenTelemetry in the future, too. A distributed trace in OpenTracing consists of a set of spans. Each span represents a logical unit of work executed. The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span. OpenTracing is only the specification and the instrumentation API. To use it you need to have an implementation, too. While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the Jaeger distributed tracing platform. Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application. The Jaeger All-In-One container image will be used to simplify the deployment. Debezium and OpenTracing The Debezium integration with OpenTracing consists of three distinct components: ActivateTracingSpan SMT EventDispatcher in the Debezium outbox extension for Quarkus applications EventRouter SMT The first one is intended for general use. The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced. Outbox Distributed Tracing The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing. The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes. In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created: When an event arrives at EventDispatcher a new span outbox-write is created. It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available. The span metadata is exported into a distinct field of the outbox event. The outbox event is written to the outbox table. The Event Router SMT receives the event and imports the span metadata from the field Two new spans are created db-log-write with its start timestamp set to database write timestamp. The fields from the source block are added to the span as tags. debezium-read with its start time set to the processing timestamp. Fields from the envelope are added to the span as tags. Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata. Demo The outbox example was extended with distributed tracing support to demonstrate the functionality. This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern. Note This demo uses the Strimzi container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level. To try it yourself you need to: check out the repository and switch to the outbox directory build the services $ mvn clean install deploy the application export DEBEZIUM_VERSION=1.4 docker-compose up --build register a Debezium connector to listen on the outbox table $ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json HTTP/1.1 201 Created execute multiple business requests $ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json $ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json check the Jaeger UI After all the steps above were completed you should see an introduction screen of the Jaeger UI: Filter on order-service as a service and click on Find Traces. Two traces should be available: Click on the addOrder service. A tree will open that displays how the initial request incoming via REST API was written to the database by the outbox extension read by Debezium and processed by outbox SMT written to a Kafka topic read from a Kafka topic by shipment-service processed in the different shipment-service business methods Click on the db-log-write and debezium-read spans. The tags of each of them contain extracted Debezium-related metadata like operation or source fields: Conclusion In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it. We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration. While this example was focused on the specific use case of microservices data exchange via the outbox pattern, Debezium integrates with distributed tracing also independently of this particular pattern. By means of the ActivateTracingSpan SMT, Debezium can produce spans representing the time of the change in the source database itself, as well as the time of processing the event by the Debezium connector. Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases. Your feedback on this new functionality is highly welcomed!</summary></entry><entry><title type="html">Debezium 1.4.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Beta1 Released" /><published>2020-12-09T00:00:00+00:00</published><updated>2020-12-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release includes support for distributed tracing,
lowercase table and schema naming for Db2,
specifying MySQL snapshot records as create or read operations,
and enhancements to Vitess for nullable and primary key columns.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Beta1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;39 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;distributed-tracing&quot;&gt;Distributed Tracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In a nutshell, distributed tracing is a pattern used to profile and monitor applications to allow quick identification of failures or performance concerns.
Tracing works by having each component in a distributed process contribute a block of metadata called a &quot;span&quot;.
Each span contains unique details about that component&amp;#8217;s unit of work.
Typically a full distributed trace consists of a sequence of multiple spans.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Distributed tracing in Debezium is enabled by using the &lt;strong&gt;ActivateTracingSpan&lt;/strong&gt; SMT:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;transforms&quot;: &quot;tracing&quot;
&quot;transforms.tracing.type&quot;: &quot;io.debezium.transforms.tracing.ActivateTracingSpan&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The above configuration will lead to the emitted message header containing the tracing key/value pairs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A blog post discussing the distributed tracing support in depth, including end-to-end tracing for microservices data exchange via the outbox pattern, will follow up shortly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DDL parser: Allow stored procedure variables in LIMIT clause &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2692&quot;&gt;DBZ-2692&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wrong mysql command in openshift dpeloyment docs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2746&quot;&gt;DBZ-2746&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;long running transaction will be abandoned and ignored &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2759&quot;&gt;DBZ-2759&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MS SQL Decimal with default value not matching the scale of the column definition cause exception &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2767&quot;&gt;DBZ-2767&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra Connector doesn&amp;#8217;t shut down completely &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2768&quot;&gt;DBZ-2768&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL Parser fails for BINARY collation shortcut &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2771&quot;&gt;DBZ-2771&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PostgresConnectorIT.shouldResumeStreamingFromSlotPositionForCustomSnapshot is failing for wal2json on CI &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2772&quot;&gt;DBZ-2772&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector configuration property &quot;database.out.server.name&quot; is not relevant for Logminer implementation but cannot be omitted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2801&quot;&gt;DBZ-2801&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CHARACTER VARYING mysql identifier for varchar is not supported in debezium &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2821&quot;&gt;DBZ-2821&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;try-with-resources should not be used when OkHttp Response object is returned &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2827&quot;&gt;DBZ-2827&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EmbeddedEngine does not shutdown when commitOffsets is interrupted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2830&quot;&gt;DBZ-2830&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rename user command parsing fails &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2743&quot;&gt;DBZ-2743&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.Beta1! This release includes support for distributed tracing, lowercase table and schema naming for Db2, specifying MySQL snapshot records as create or read operations, and enhancements to Vitess for nullable and primary key columns.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha2 Released</title><link href="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha2 Released" /><published>2020-11-17T00:00:00+00:00</published><updated>2020-11-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This second pass of the 1.4 release line provides a few useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New API hook for the PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; interface&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Field renaming using &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT&amp;#8217;s &lt;code&gt;add.fields&lt;/code&gt; and &lt;code&gt;add.headers&lt;/code&gt; configurations&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;37 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;postgresql-snapshotter-completion-hook&quot;&gt;PostgreSQL Snapshotter completion hook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; API is a contract that allows for the customization of the snapshot process.
This API was introduced in 0.9.3.Final and has continued to evolve in the releases since.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A new backward compatible completion hook has been added:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;void snapshotCompleted()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This new hook is called by the snapshot process when the snapshot has concluded,
allowing implementations to clean-up any resources it may have allocated prior streaming changes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;extractnewrecordstate-smt-field-renaming-support&quot;&gt;ExtractNewRecordState SMT field renaming support&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the features of the &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT is that the transformation can retain parts of the original message in the transformed message&amp;#8217;s header or payload.
This release extends this feature to allow specifying a new name to be used for the field when added to the message header or payload.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, to add the source database&amp;#8217;s event timestamp to the message header using the new renaming feature, the SMT configuration would be:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;transforms=unwrap
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
transforms.unwrap.add.headers=source.ts_ms:timestamp&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The format of the &lt;code&gt;add.headers&lt;/code&gt; and &lt;code&gt;add.fields&lt;/code&gt; configuration options have been improved to support a comma-separated list of fields with the syntax &lt;code&gt;&amp;lt;OLD_FIELD&amp;gt;[:NEW_FIELD]&lt;/code&gt;.
The above emitted message&amp;#8217;s headers would now contain &lt;code&gt;__timestamp&lt;/code&gt; rather than the default &lt;code&gt;__source.ts_ms&lt;/code&gt; field.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This syntax improvement remains backward compatible.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Oracle throw &quot;no snapshot found based on specified time&quot; when running flashback query &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exception when PK definition precedes column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2580&quot;&gt;DBZ-2580&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Patroni can&amp;#8217;t stop PostgreSQL when Debezium is streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2617&quot;&gt;DBZ-2617&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChangeRecord informations don&amp;#8217;t connect with the TableSchema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2679&quot;&gt;DBZ-2679&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL connector fails on a zero date &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2682&quot;&gt;DBZ-2682&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle LogMiner doesn&amp;#8217;t support partition tables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2683&quot;&gt;DBZ-2683&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DB2 doesn&amp;#8217;t start reliably in OCP  &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2693&quot;&gt;DBZ-2693&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dropped columns cause NPE in SqlServerConnector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2716&quot;&gt;DBZ-2716&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timestamp default value in 'yyyy-mm-dd' format fails MySQL connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2726&quot;&gt;DBZ-2726&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout on write should retry &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2727&quot;&gt;DBZ-2727&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No viable alternative at input error on &quot;min&quot; column &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQLServer CI error in SqlServerConnectorIT.whenCaptureInstanceExcludesColumnsAndColumnsRenamedExpectNoErrors:1473 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2747&quot;&gt;DBZ-2747&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;debezium-connector-db2: DB2 SQL Error: SQLCODE=-206 on DB2 for z/OS &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2755&quot;&gt;DBZ-2755&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no viable alternative at input 'alter table &lt;code&gt;order&lt;/code&gt; drop CONSTRAINT' &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2760&quot;&gt;DBZ-2760&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tests are failing on macos &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2762&quot;&gt;DBZ-2762&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.4.0.Alpha2! This second pass of the 1.4 release line provides a few useful new features: New API hook for the PostgreSQL Snapshotter interface Field renaming using ExtractNewRecordState SMT&amp;#8217;s add.fields and add.headers configurations</summary></entry><entry><title type="html">Debezium 1.3.1.Final Released</title><link href="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.1.Final Released" /><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release primarily focuses on bugs that were reported after the 1.3 release.
Most importantly, the following bugs were fixed related to the &lt;a href=&quot;/docs/connectors/oracle&quot;&gt;Debezium connector for Oracle&lt;/a&gt; LogMiner adapter thanks to the continued feedback by the Debezium community.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SQLExceptions thrown when using Oracle LogMiner (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LogMiner mining session stopped due to WorkerTask killed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;)
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, there were other bugs identified and fixed in this release, including:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;[MongoDB] Sanitization of field names not applied to nested struct fields (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] MariaDB nextval function is not supported by grammar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MSSQL] Hide stack-trace when default value cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2642&quot;&gt;DBZ-2642&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Upgrade JDBC driver to 8.0.19 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2626&quot;&gt;DBZ-2626&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] ANTLR parser fails to interpret &lt;code&gt;BLOB(size)&lt;/code&gt; types (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Should allow non-ascii character in SQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Connector fails if non-existing view with same name as table is dropped (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] No viable alternative at input error when column uses aggregate function names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] No snapshot found based on specified time (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[PostgreSQL] WAL logs are not properly flushed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Server] Event Hubs plugin support (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.1.Final&quot;&gt;14 issues&lt;/a&gt; were resolved in this release.
Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to everyone who helped test and identify these bugs.
The team appreciates the invaluable feedback the community continually provides!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.1.Final! This release primarily focuses on bugs that were reported after the 1.3 release. Most importantly, the following bugs were fixed related to the Debezium connector for Oracle LogMiner adapter thanks to the continued feedback by the Debezium community. SQLExceptions thrown when using Oracle LogMiner (DBZ-2624) LogMiner mining session stopped due to WorkerTask killed (DBZ-2629)</summary></entry><entry><title type="html">Streaming Vitess at Bolt</title><link href="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/" rel="alternate" type="text/html" title="Streaming Vitess at Bolt" /><published>2020-11-04T16:19:59+00:00</published><updated>2020-11-04T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt</id><content type="html" xml:base="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&quot;https://medium.com/bolt-labs/streaming-vitess-at-bolt-f8ea93211c3f&quot;&gt;Bolt Labs Engineering blog&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Traditionally, MySQL has been used to power most of the backend services at &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt;. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once data is persisted to the database, we use the &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL Connector&lt;/a&gt; to &lt;a href=&quot;https://www.confluent.io/blog/how-bolt-adopted-cdc-with-confluent-for-real-time-data-and-analytics/&quot;&gt;capture data change events&lt;/a&gt; and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-at-bolt&quot;&gt;Vitess at Bolt&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bolt has grown considerably over the past few years, and so did the volume of data written to MySQL. Manual database sharding has become quite an expensive and long-lasting process prone to errors. So we started to evaluate more scalable databases, one of which is &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;. Vitess is an open-source database clustering system that is based on MySQL and provides horizontal scalability for it. Originated and battle-tested at YouTube, it was later open-sourced and is used by companies like Slack, Github, JD.com to power their backend storage. It combines important MySQL features with the scalability of a NoSQL database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the most important features that Vitess provides is its built-in sharding. It allows the database to grow horizontally by adding new shards in a way that is transparent to back-end application logic. To your application, Vitess appears like a giant single database, but in fact data is partitioned into multiple physical shards behind the scenes. For any table, an arbitrary column can be chosen as the sharding key, and all inserts and updates will be seamlessly directed to a proper shard by Vitess itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; below illustrates how back-end services interact with Vitess. At a high level, services connect to the stateless VTGate instances through a load balancer. Each VTGate has the Vitess cluster’s topology cached in its memory and redirects queries to the correct shards and the correct VTTablet (and its underlying MySQL instance) within the shards. More on VTTablet is written below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_architecture.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 1. Vitess architecture. Reference: &lt;a href=&quot;https://www.planetscale.com/vitess&quot; class=&quot;bare&quot;&gt;https://www.planetscale.com/vitess&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Other useful features provided by Vitess are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Failover (a.k.a. Reparenting) is easy and transparent for clients. Clients only talk to a VTGate who takes care of failover and service discovery of the new primary transparently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It automatically rewrites “problematic” queries that could potentially cause database performance degradation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has a caching mechanism that prevents duplicate queries to reach the underlying MySQL database simultaneously. Only one query will reach the database and its result will be cached and returned to answer duplicate queries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has its connection pool and eliminates the high-memory overhead of MySQL connections. As a result, it can easily handle thousands of connections at the same time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout and transaction timeout can be configured.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has minimal downtime when doing &lt;a href=&quot;https://vitess.io/docs/user-guides/configuration-advanced/resharding/&quot;&gt;resharding&lt;/a&gt; operations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its VStream feature can be used by downstream CDC applications to read change events from Vitess.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;streaming-vitess-options&quot;&gt;Streaming Vitess Options&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The ability to capture data changes and publish them to Apache Kafka was one of the requirements for adopting Vitess at Bolt. There were several different options we’ve considered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-1-using-debezium-mysql-connector&quot;&gt;Option 1: Using Debezium MySQL Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Applications connect to Vitess VTGate to send queries. VTGate supports the MySQL protocol and has a SQL parser. You can use any MySQL client (e.g. JDBC) to connect to VTGate, which redirects your query to the correct shard and returns the result to your client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, VTGate is not equal to a MySQL instance, it is rather a stateless proxy to various MySQL instances. For the MySQL connector to receive change events, the Debezium MySQL connector needs to connect to a real MySQL instance. To make it more obvious, VTGate also has some known &lt;a href=&quot;https://vitess.io/docs/reference/compatibility/mysql-compatibility/&quot;&gt;compatibility&lt;/a&gt; issues, which makes connecting to VTGate different from MySQL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another option is to use the Debezium MySQL Connector to connect directly to the underlying MySQL instances of different shards. It has its advantages and disadvantages.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One advantage is that for an unsharded keyspace (Vitess&amp;#8217;s terminology for a database), the MySQL Connector can continue to work correctly and we don&amp;#8217;t need to include additional logic or specific implementation. It should just work fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the biggest disadvantages is that resharding operations would become more complex. For example, the GTID of the original MySQL instance would change when resharded, and the MySQL connector depends on the GTID to work correctly. We also believe that having the MySQL connector connected directly to each underlying MySQL instance defies the purpose of Vitess&amp;#8217;s operational simplicity as a new connector has to be added (or removed) each time resharding is done. Not to mention that such operation would lead to data duplication inside Kafka brokers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-2-using-jdbc-source-connector&quot;&gt;Option 2: Using JDBC Source Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ve also considered using the &lt;a href=&quot;https://docs.confluent.io/current/connect/kafka-connect-jdbc/source-connector/index.html&quot;&gt;JDBC Source Connector&lt;/a&gt;. It allows sourcing data from any relational databases that support the JDBC driver into Kafka. Therefore, it is compatible with Vitess VTGate. It has its advantages and disadvantages as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is compatible with VTGate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It handles Vitess resharding operation better. During resharding operation, reads are simply automatically redirected (by VTGate) to the target shards. It won&amp;#8217;t generate any duplicates or lose any data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is poll-based, meaning that the connector polls the database for new change events on a defined interval (typically every few seconds). This means that we would have a much higher latency, compared to the Debezium MySQL Connector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its offsets are managed by either the table&amp;#8217;s incremental primary key or one of the table&amp;#8217;s timestamp columns. If we use the timestamp column for offset, we&amp;#8217;d have to create a secondary-index of the timestamp column for each table. This adds more constraints on our backend services. If we use the incremental primary key, we would miss the change events for row-updates because the primary key is simply not updated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The topic name created by the JDBC connector doesn&amp;#8217;t include the table&amp;#8217;s schema name. Using the &lt;code&gt;topic.prefix&lt;/code&gt; connector configuration would mean that we&amp;#8217;ll have one connector per schema. At Bolt, we have a large number of schemas, which means we would need to create a large number of JDBC Source Connectors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At Bolt, our downstream applications are already set up to use Debezium&amp;#8217;s data formats and topic naming conventions, e.g. we&amp;#8217;d need to change our downstream application&amp;#8217;s decoding logic to the new data formats.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Row deletes are not captured.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option-3-using-vstream-grpc&quot;&gt;Option 3: Using VStream gRPC&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VTGate exposes a gRPC service called VStream. It is a server-side streaming service. Any gRPC client can subscribe to the &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;VStream&lt;/a&gt; service to get a continuous stream of change events from the underlying MySQL instances. The change events that VStream emits have similar information to the MySQL binary logs of the underlying MySQL instances. A single VStream can even subscribe to multiple shards for a given keyspace, making it quite a convenient API to build CDC tools.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Behind the scene, as shown in &lt;em&gt;Figure 2&lt;/em&gt;, VStream reads change events from multiple &lt;a href=&quot;https://vitess.io/docs/reference/programs/vttablet/&quot;&gt;VTTablets&lt;/a&gt;, one VTTablet per shard. Therefore, it doesn’t send duplicates from multiple VTTablets for a given shard. Each VTTablet is a proxy to its MySQL instance. A typical topology would include one master VTTablet and its corresponding MySQL instance, and multiple replica VTTablets, each of which is the proxy of its own replica MySQL instance. A VTTablet gets change events from its underlying MySQL instance and sends the change events back to VTGate, which in turn sends the change events back to VStream’s gRPC client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When subscribing to the VStream service, the client can specify a VGTID and &lt;a href=&quot;https://vitess.io/docs/concepts/tablet/#tablet-types&quot;&gt;Tablet Type&lt;/a&gt; (e.g. &lt;code&gt;MASTER&lt;/code&gt;, &lt;code&gt;REPLICA&lt;/code&gt;). The VGTID tells the position from which VStream starts to send change events. Essentially, VGTID includes a list of (keyspace, shard, shard GTID) tuples. The Tablet Type tells which MySQL instance (primary or replica) in each shard do we read change events from.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vstream.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 2. VStream architecture. Reference: &lt;a href=&quot;https://vitess.io/docs/concepts/vstream&quot; class=&quot;bare&quot;&gt;https://vitess.io/docs/concepts/vstream&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Some advantages of using VStream gRPC are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is a simple way to receive change events from Vitess. It is also recommended in Vitess’s &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;documentation&lt;/a&gt; to use VStream to build CDC processes downstream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VTGate hides the complexity of connecting to various source MySQL instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has low latency since change events are streamed to the client as soon as they happen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events include not only inserts and updates, but also deletes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probably one of the biggest advantages is that the change events contain the schema of each table. So you don’t have to worry about fetching each table’s schema in advance (by,  for example, parsing DDLs or querying the table’s definition).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events have VGTID included, which the CDC process can store and use as the offset from where to restart the CDC process next time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also importantly, VStream is designed to work well with Vitess operations such as &lt;a href=&quot;https://vitess.io/docs/user-guides/resharding/&quot;&gt;Resharding&lt;/a&gt; and &lt;a href=&quot;https://vitess.io/docs/user-guides/move-tables/&quot;&gt;Moving Tables&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are also some disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Although it includes table schemas, some important information is still missing. For example, the &lt;code&gt;Enum&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt; column types don’t provide all the allowed values yet. This should be fixed in the next major release (Vitess 9) though.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since VStream is a gRPC service, we cannot use the Debezium MySQL Connector out-of-the-box. However, it is quite straightforward to implement the gRPC client in other languages.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All things considered, we’ve decided to use VStream gRPC to capture change events from Vitess and implement our Vitess Connector based on all the best practices of Debezium.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-connector-deep-dive-and-open-source&quot;&gt;Vitess Connector Deep Dive and Open Source&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After we’ve decided to implement our Vitess Connector, we started looking into the implementation details of various Debezium source connectors (MySQL, Postgres, SQLServer), to borrow some ideas. Almost all of them are implemented using a common Connector development framework. So it was clear we should develop the Vitess connector on top of it. Given we are very active users of the MySql Connector and we benefit from it being open-sourced, as it allows us to contribute to it things we were missing ourselves. So we decided we want to give back to community and open-source the Vitess source connector code-base under the Debezium umbrella. Please feel free to learn more at &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Debezium Connector Vitess&lt;/a&gt;. We welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At a high level, as you can see below, connector instances are created in Kafka Connect workers. At the time of writing, you have two options to configure the connector to read from Vitess:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 1 (recommended):&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 3&lt;/em&gt;, each connector captures change events from all shards in a specific keyspace. If the keyspace is not sharded, the connector can still capture change events from the only shard in the keyspace. When it’s the first time that the connector starts, it reads from the current VGTID position of all shards in the keyspace. Because it subscribes to all shards, it continuously captures change events from all shards and sends them to Kafka. It automatically supports the Vitess Reshard operation, there is no data loss, nor duplication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_multi_shards.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 3. Each connector subscribes to all shards of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 4&lt;/em&gt;, each connector instance captures change events from a specific keyspace/shard pair. The connector instance gets the initial (the current) VGTID  position of the keyspace/shard pair from VTCtld gRPC, which is another Vitess component. Each connector instance, independently, uses the VGTID it gets to subscribe to VStream gRPC and continuously capture change events from VStream and sends them to Kafka. To support the Vitess Reshard operation, you would need more manual operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_single_shard.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 4. Each connector subscribes to one shard of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Internally, each connector task uses a gRPC thread to constantly receive change events from VStream and puts the events into an internal blocking queue. The connector task thread polls events out of the queue and sends them to Kafka, as can be seen in &lt;em&gt;Figure 5&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_internal.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 5. How each connector task works internally&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;replication-challenges&quot;&gt;Replication Challenges&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While we were implementing the Vitess Connector and digging deeper into Vitess, we’ve also realized a few challenges.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;vitess-reshard&quot;&gt;Vitess Reshard&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Vitess connector supports the Vitess Reshard operation when the connector is configured to subscribe to all shards of a given keyspace. VStream sends a VGTID that contains the shard GTID for all shards. Vitess Resharding is transparent to users. Once it’s completed, Vitess will send the VGTID of the new shards. Therefore, the connector will use the new VGTID after reshard. However, you need to make sure that the connector is up and running when the reshard operation takes place. Especially please check that the offset topic of the connector has the new VGTID before deleting the old shards. This is because in case the old shards are deleted, VStream will not be able to recognize the VGTID from the old shards.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you decide to subscribe to one shard per connector, the connector does not provide out-of-the-box support for Vitess resharding. One manual workaround to support resharding is creating one new connector per target shard. For example, one new connector for the &lt;code&gt;commerce/-80&lt;/code&gt; shard, and another new connector for the &lt;code&gt;commerce/80-&lt;/code&gt; shard. Bear in mind that because they’re new connectors, by default, new topics will be created, however, you could use the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/topic-routing.html&quot;&gt;Debezium logical topic router&lt;/a&gt; to route the records to the same Kafka topics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;offset-management&quot;&gt;Offset Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream includes a VGTID event in its response. We save the VGTID as the offset in the Kafka offset topic, so when the connector restarts, we can start from the saved VGTID. However, in rare cases when a transaction includes a huge amount of rows, VStream batches the change events into multiple responses, and only the last response has the VGTID. In such cases, we don’t have the VGTID for every change event we receive. We have a few options to solve this particular issue:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can buffer all the change events in memory and wait for the last response that contains the VGTID to arrive. So all events will have the correct VGTID associated with them. A few disadvantages are that we’ll have higher latency before events are sent to Kafka. Also, memory usage could potentially increase quite a lot due to buffering. Buffering also adds complexity to the logic. We also have no control over the number of events VStream sends to us.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can use the latest VGTID we have, which is the VGTID from the previous VStream response. If the connector fails and restarts when processing such a big transaction, it’ll restart from the VGTID of the previous VStream response, thus reprocessing some events. Therefore, it has at-least-once event delivery semantics and it expects the downstream to be idempotent. Since most transactions are not big enough, most VStream responses will have VGTID in the response, so the chance of having duplicates is low. In the end, we chose this approach for its at-least-once delivery guarantee and its design simplicity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;schema-management&quot;&gt;Schema Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream’s response also includes a &lt;code&gt;FIELD&lt;/code&gt; event. It’s a special event that contains the schemas of the tables of which the rows are affected. For example, let&amp;#8217;s assume we have 2 tables, &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. If we insert a few rows into table &lt;code&gt;A&lt;/code&gt;, the &lt;code&gt;FIELD&lt;/code&gt; event will only contain table &lt;code&gt;A&lt;/code&gt;’s schema. The VStream is smart enough to only include the &lt;code&gt;FIELD&lt;/code&gt; event whenever necessary. For example, when a VStream client reconnects, or when a table’s schema is changed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The older version of VStream includes only the column type (e.g. &lt;code&gt;Integer&lt;/code&gt;, &lt;code&gt;Varchar&lt;/code&gt;), no additional information such as whether the column is the primary key, whether the column has a default value, &lt;code&gt;Decimal&lt;/code&gt; type’s scale and precision, &lt;code&gt;Enum&lt;/code&gt; type’s allowed values, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The newer version (Vitess 8) of VStream starts to include more information on each column. This will help the connector to deserialize more accurately certain types and have a more precise schema in the change events sent to Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;future-development-work&quot;&gt;Future Development Work&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can use VStream&amp;#8217;s API to start streaming from the latest VGTID position, instead of getting the initial VGTID position from VTCtld gRPC. Doing so would eliminate the dependency from VTCtld.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We don’t support automatically extracting the primary keys from the change events yet. Currently, by default, all change events sent to Kafka have &lt;code&gt;null&lt;/code&gt; as the key, unless the &lt;code&gt;message.key.columns&lt;/code&gt; connector configuration is specified. Vitess recently added flags of each column in the VStream FIELD event, which allows us to implement this feature soon.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add support for initial snapshots to capture all existing data before streaming changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;MySQL has been used to power most of our backend services at Bolt. Due to the considerable growth of the volume of data and operational complexity, Bolt started to evaluate Vitess for its scalability and its built-in features such as resharding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To capture data changes from Vitess, as what we’ve been doing with Debezium MySQL Connector, we’ve considered a few options. In the end, we have implemented our own Vitess Connector based on the common Debezium connector framework. While implementing the Vitess connector, we’ve encountered a few challenges. For example, support for the Vitess reshard operation, offset management, and schema management. We reasoned about ways to address the challenges and what we worked out as solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We’ve also received quite some interest from multiple communities in this project and we’ve decided to open-source &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess Connector&lt;/a&gt; under the Debezium umbrella. Please feel free to learn more, and we welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>keweishang, rgibaiev</name></author><category term="vitess" /><summary type="html">This post originally appeared on the Bolt Labs Engineering blog. Traditionally, MySQL has been used to power most of the backend services at Bolt. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes. Once data is persisted to the database, we use the Debezium MySQL Connector to capture data change events and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.</summary></entry><entry><title type="html">Hello Debezium!</title><link href="https://debezium.io/blog/2020/10/27/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium!" /><published>2020-10-27T16:19:59+00:00</published><updated>2020-10-27T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/27/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/10/27/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;My work started under the Data Virtualization team with Teiid and then under the &lt;a href=&quot;https://graphqlcrud.org/&quot;&gt;GRAPHQLCRUD&lt;/a&gt; project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Can&amp;#8217;t wait to learn and explore awesome things. Happy to get started here!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;--Anisha&lt;/p&gt;
&lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="community" /><category term="news" /><summary type="html">Hello everyone, my name is Anisha Mohanty and I recently joined Red Hat and the Debezium team. I started my journey with Red Hat in April 2020 after completing my graduation. I was introduced to open source in my early college days, but I wasn&amp;#8217;t aware of how organizations work and wanted to get the essence of open source ethics and values. That is something that I am fascinated to learn as I joined Red Hat. My work started under the Data Virtualization team with Teiid and then under the GRAPHQLCRUD project which is a standard for a generic query interface on top of GraphQL. The project has started well and is in great shape right now. We have successfully added CRUD capabilities, paging, and filtering specifications. Coming to Debezium, I first heard about it as some DV members started contributing here, well back then it was a completely new thing for me. I started exploring more, and it was not long when I had my first interaction with Gunnar and Jiri. With a warm welcome and great team here, I am really excited to work with the Debezium Community.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha1 Released" /><published>2020-10-23T16:19:59+00:00</published><updated>2020-10-23T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/23/debezium-1-4-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This first pass of the 1.4 release line provides a few useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New Vitess connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Allow fine-grained selection of snapshotted tables&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;41 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess-connector&quot;&gt;Vitess Connector&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.vitess.io&quot;&gt;Vitess&lt;/a&gt; is a database solution for deploying, scaling, and managing large clusters of MySQL.
We are very happy that the development team around Ruslan Gibaiev and Kewei Shang of &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt Technology OÜ&lt;/a&gt; decided to build a CDC solution based on Debezium and to &lt;a href=&quot;https://www.github.com/debezium/debezium-connector-vitess&quot;&gt;open-source it&lt;/a&gt; under the Debezium umbrella.
This connector is released in &lt;strong&gt;incubating&lt;/strong&gt; state in Debezium 1.4.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ruslan and Kewei will follow up with a blog post with more details around this connector very soon;
in the mean time please refer to the connector &lt;a href=&quot;https://debezium.io/documentation/reference/1.4/connectors/vitess.html&quot;&gt;reference documentation&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;fine-grained-selection-of-snapshotted-tables&quot;&gt;Fine-grained Selection of Snapshotted Tables&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the major focus points for Debezium 1.4 is to explore more flexible snapshot options,
e.g. to re-snapshot chosen tables or parallelizing long-running snapshot operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A first improvement related to snapshotting is the new connector configuration &lt;code&gt;snapshot.include.collection.list&lt;/code&gt;,
which allows to snapshot only a subset of all the tables which the connector will capture later on during log reading.
This comes in handy if for instance you&amp;#8217;re interested in capturing changes to all your tables, but only need an initial snasphot of the data for some of them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For the Postgres connector, by creating a custom implementation of the &lt;code&gt;Snapshotter&lt;/code&gt; SPI contract, this also allows for a selective re-snapshot of specific tables.
After restarting the connector, such &lt;code&gt;Snapshotter&lt;/code&gt; would continue to read the log from the point where it left off previously until &quot;now&quot;,
then it would take a snapshot of the given tables, and finally continue to read the log for &lt;em&gt;all&lt;/em&gt; captured tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For more information on this option, please see the connector-specific &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/index.html&quot;&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a few other features coming with the 1.4.0.Alpha1 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Implement snapshot select override behavior for MongoDB &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2496&quot;&gt;DBZ-2496&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SqlServer - Skip processing of LSNs not associated with change table entries &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2582&quot;&gt;DBZ-2582&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cant override environment variables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2559&quot;&gt;DBZ-2559&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ConcurrentModificationException during exporting data for a mongodb collection in a sharded cluster &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2597&quot;&gt;DBZ-2597&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mysql connector didn&amp;#8217;t pass the default db charset to the column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2604&quot;&gt;DBZ-2604&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Doc] &quot;registry.redhat.io/amq7/amq-streams-kafka-25: unknown: Not Found&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2609&quot;&gt;DBZ-2609&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Doc] &quot;Error: no context directory and no Containerfile specified&quot; error occurs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2610&quot;&gt;DBZ-2610&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SqlExceptions using dbz with Oracle on RDS online logs and LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mining session stopped - task killed/SQL operation cancelled - Oracle LogMiner &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unparseable DDL: Using 'trigger' as table alias in view creation &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2639&quot;&gt;DBZ-2639&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Antlr DDL parser fails to interpret BLOB([size]) &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL Connector keeps stale offset metadata after snapshot.new.tables is changed &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2643&quot;&gt;DBZ-2643&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WAL logs are not flushed in Postgres Connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Server Event Hubs plugin support in v1.3 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra Connector doesn&amp;#8217;t use log4j for logging correctly &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2661&quot;&gt;DBZ-2661&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Should Allow NonAsciiCharacter in SQL &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MariaDB nextval function is not supported in grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sanitize field name do not sanitize sub struct field &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium fails if a non-existing view with the same name as existing table is dropped &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I am excited to announce the release of Debezium 1.4.0.Alpha1! This first pass of the 1.4 release line provides a few useful new features: New Vitess connector Allow fine-grained selection of snapshotted tables Overall, the community fixed 41 issues for this release. Let&amp;#8217;s take a closer look at some of the highlights.</summary></entry><entry><title type="html">Towards a Graphical Debezium User Interface</title><link href="https://debezium.io/blog/2020/10/22/towards-debezium-ui/" rel="alternate" type="text/html" title="Towards a Graphical Debezium User Interface" /><published>2020-10-22T16:19:59+00:00</published><updated>2020-10-22T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/22/towards-debezium-ui</id><content type="html" xml:base="https://debezium.io/blog/2020/10/22/towards-debezium-ui/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases.
Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors,
allowing to safely operate CDC pipelines also in huge installations with thousands of connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production.
We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today it&amp;#8217;s my great pleasure to introduce you to a proof-of-concept for a potential future &lt;strong&gt;Debezium graphical user interface&lt;/strong&gt;.
The goal for this PoC is to explore how a graphical UI could facilitate the getting started and operational experience of Debezium users.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The scope of the PoC is the set-up flow for configuring and instantiating a Debezium Postgres connector.
The user is guided through the required configuration steps in a wizard interface,
starting from mandatory information (e.g. database credentials), over selecting the tables to be captured, up to optional settings like different data mapping options.
After reviewing the final configuration, the UI will instantiate the connector in Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can see a short demo of how this looks like in this video:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;responsive-video&quot;&gt;
&lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/RZ_3DF7Ndnk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We focused on some core interaction patterns, e.g. the preview functionality for the selecting the captured tables.
Instead of solely taking key/value pairs of configuration parameters,
the UI should guide the user through the process, provide context and help, e.g. by showing the allowed options for settings in drop-downs, validating the provided settings after each step, and more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now this is just the beginning, there&amp;#8217;s many more things that could be done in such Debezium UI,
e.g. in the connection configuration step, we could validate whether the given user has all the required database permissions, whether the right WAL level is set in the database, etc.
There could be views for monitoring and trouble-shooting connectors.
When running on Kubernetes, the UI could produce resource definitions processed by a Kafka (Connector) operator like Strimzi (instead of calling the Kafka Connect REST API), and much more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But before further progressing with this, we&amp;#8217;d like to gather your feedback and opinions:
Do you consider a graphical UI for Debezium useful in general, and is it something you would use in your projects?
What is your feedback on the functionality currently implemented in the PoC?
Which other functionality besides connector configuration would you like to see in a Debezium UI?
We&amp;#8217;ve provided a short survey with these and a few other questions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph text-center&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSfEEqslTWSLX89gzIDmSE_4v8hH0mYg0YBRaXhfDrrBbCUJgQ/viewform?usp=sf_link&quot;&gt;Go to survey&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Before taking the questionnaire, please watch the video or run the PoC yourself (see below).
Answering these questions should take just a few minutes; your participation would be very helpful for us in order to decide whether and how we should move forward with this effort.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;trying-it-out-yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As everything in Debezium, the UI PoC is fully open source (Apache License Version 2.0);
you can find its &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;source code&lt;/a&gt; under the Debezium organization on Git Hub.
The PoC is implemented as a &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;-based web application,
using &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; as the frontend technology.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Quarkus backend is configured with the URL(s) of one more Kafka Connect clusters.
Note that there&amp;#8217;s currently no means of authentication or authorization implemented in the PoC,
so don&amp;#8217;t use it with your production Connect clusters just yet.
After starting the application, you can choose the cluster to work with from the drop-down to the top right.
Different from what&amp;#8217;s shown in the video recording, the &quot;Delete&quot; button is working in the PoC now, too ;)
There&amp;#8217;s an example &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/blob/master/docker-compose.yml&quot;&gt;Docker Compose file&lt;/a&gt;, which starts up all required components for getting started quickly.
Alternatively, you can obtain a &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui-poc&quot;&gt;pre-built container image&lt;/a&gt; with the Debezium UI PoC from Docker Hub.
Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/#debezium-ui-poc&quot;&gt;README file&lt;/a&gt; for more details on building and running the Debezium UI PoC.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;re looking forward very much to learning about your feedback on the Debezium UI PoC.
Try it out yourself and let us know about your thoughts in the comments below and by participating in the quick survey linked above.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;A big thank you to the team working on this PoC: Ashique Ansari, Indra Shukla, June Zhang, Mark Drilling, Na Ding, and René Kerner!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community" /><category term="discussion" /><summary type="html">Over the last five years, Debezium has become a leading open-source solution for change data capture for a variety of databases. Users from all kinds of industries work with Debezium for use cases like replication of data from operational databases into data warehouses, updating caches and search indexes, driving streaming queries via Kafka Streams or Apache Flink, synchronizing data between microservices, and many more. When talking to Debezium users, we generally receive very good feedback on the range of applications enabled by Debezium and its flexibility: e.g. each connector can be configured and fine-tuned in many ways, depending on your specific requirements. A large number of metrics provide deep insight into the state of running Debezium connectors, allowing to safely operate CDC pipelines also in huge installations with thousands of connectors. All this comes at the cost of a learning curve, though: users new to Debezium need to understand the different options and settings as well as learn about best practices for running Debezium in production. We&amp;#8217;re therefore constantly exploring how the user experience of Debezium can be further improved, allowing people to set up and operate its connectors more easily.</summary></entry><entry><title type="html">Debezium Community Stories With… Renato Mefi</title><link href="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/" rel="alternate" type="text/html" title="Debezium Community Stories With… Renato Mefi" /><published>2020-10-08T16:19:59+00:00</published><updated>2020-10-08T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi</id><content type="html" xml:base="https://debezium.io/blog/2020/10/08/debezium-community-stories-with-renato-mefi/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know.
In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;Renato Mefi&lt;/a&gt;, a long-time Debezium user and contributor.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/renatomefi.jpg&quot; style=&quot;max-width:50%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Renato, could you introduce yourself? What is your job, if you&amp;#8217;re not contributing to Debezium?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello all, I&amp;#8217;m Renato and my first Debezium commit was on Nov 12, 2018, it&amp;#8217;s been a long and fun ride so far, and I&amp;#8217;m glad to have the opportunity to share my story here with you all!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m a Staff Software Engineer at &lt;a href=&quot;https://www.surveymonkey.com/&quot;&gt;SurveyMonkey&lt;/a&gt; in Amsterdam, The Netherlands, within the Platform team for our CX (customer experience) suite, if you&amp;#8217;re curious about what that is, you can &lt;a href=&quot;https://usabilla.com/blog/introducing-the-getfeedback-suite/&quot;&gt;check it out here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;On the internet you&amp;#8217;re going to find me talking about Docker, Debezium, Kafka, Microservices and other things that I enjoy.
Although those amazing engineering pieces really excite me, at this moment I&amp;#8217;m also really passionate about Platform Engineering teams and how they can operate in an organization, the stories I&amp;#8217;m going to tell below represent my view of it, of how critical the role of a platform team can be when adopting new technologies and solving difficult problems for the whole, in this case powered by Debezium!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;What are your use cases for Debezium and CDC in your current project?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s a long and enjoyable story (long in terms of the internet), we&amp;#8217;ve been using Debezium since Q4 2018, it&amp;#8217;s been 2 years at the moment I&amp;#8217;m writing those answers here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I classify Debezium within our product, I say it is an architectural component, the idea behind this is to position it as a platform/infrastructure concern, in a way that it can reach multiple parts of the stack and services. I consider this abstraction of Debezium one of the key success factors it had in its adoption and growth within our platform, let me explain this better!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Our first use case is likely to be one of the most common ones for CDC, the &lt;a href=&quot;https://martinfowler.com/bliki/StranglerFigApplication.html&quot;&gt;strangler pattern&lt;/a&gt;, which for us came before Debezium; so let me tell this part of the story first: when I joined Usabilla (later acquired by SurveyMoney), there was already an effort to move our platform to a new architecture and the strangler pattern was already there. When the first couple of services started to grow, their primary way to bring data out of legacy was to poll the database, and needless to say, this could go very wrong! Our legacy database is a MongoDB cluster, and since I was pre-occupied with the polling approach, I started to dig into possibilities. I was hoping to find something like a streaming API for it, but what I ended up encountering was the database changelog (&lt;a href=&quot;https://en.wikipedia.org/wiki/Write-ahead_logging&quot;&gt;Write-ahead logging&lt;/a&gt;, &quot;oplog&quot; as it&amp;#8217;s called in Mongo!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It came to my mind right away: &quot;Oh, I could write something that queries the data from the oplog and sends it to Kafka&quot;. So I checked with our in-house Senior SRE and MongoDB expert &lt;a href=&quot;https://twitter.com/gwkunze&quot;&gt;Gijs Kunze&lt;/a&gt; who thought it could be a good idea; as a next step I went to talk to my colleague &lt;a href=&quot;https://twitter.com/rdohms&quot;&gt;Rafael Dohms&lt;/a&gt;, and we decided to do some extra Googling, and like that, we found Debezium! It was the perfect match to our needs and better than what we could have written by ourselves!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now back to our use case, what makes it an architecture component for us, is basically the approach, we abstracted and wrapped Debezium in a project called Legacy Data Syncer (LDS for us, because acronyms never get old). Although it might look simple to spin up a Kafka Connect with Debezium, running it production-ready, monitoring multiple collections within the database, exposing metrics, doing transformations and more, is not such an easy task. So how does it work? Every time an engineering team needs to capture data from our legacy system, to start strangling a feature, they only have to do two things, open a pull request which literally adds one line to LDS, and create their Kafka consumer!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_lds.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 1. The configuration file in LDS; a developer will open a PR adding a new line, the rest will be taken care of.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Upon merging the PR, our project will provision the whole configuration to Kafka Connect, it ensures the snapshot is executed, metrics are present and etc; We&amp;#8217;ve done the same thing for the outbox pattern and I talk a little bit more about it in this &lt;a href=&quot;https://twitter.com/renatomefi/status/1185098904745992197&quot;&gt;tweet thread&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Self-servicing the teams was a great way to remove resistance for adoption, no Jira tickets were necessary, no advanced ops knowledge or anything else to get it running. The other factors I consider to have contributed to Debezium&amp;#8217;s success in our platform is its reliability and straight forward value perception, in those two years we never had major outages or critical problems of any kind!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;You mention the outbox pattern; Could you tell more about why and how you&amp;#8217;re using this?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Absolutely! One more time, it&amp;#8217;s crazy how CDC and Debezium can simplify some of the most critical architectural parts of big platforms!
One year after using Debezium in the core of our architecture migration, we had another problem at our hands: how to reliably write data to our new source of truth databases and propagate messages to Kafka at the same time. Although it seems to be simple to answer and find a solution, each of them comes with a major drawback.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Which solutions do we have?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Embrace eventual consistency to its peak by adopting &lt;em&gt;event sourcing&lt;/em&gt;, by writing first to Kafka and reading our own writes; the drawbacks here are extra complexity and intensified eventual consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Dual writes&lt;/em&gt;, well, actually this is not an option, because as you know, &lt;a href=&quot;https://thorben-janssen.com/dual-writes/&quot;&gt;&quot;Friends Don&amp;#8217;t Let Friends Do Dual Writes&quot;&lt;/a&gt;!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Different approaches of &lt;em&gt;distributed transactions&lt;/em&gt; like 2PC and sagas; the costs here are performance and engineering effort, now every service we have has to either become a transaction coordinator or have rollback capabilities, also the cascade effect scared us quite a bit!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Well, what&amp;#8217;s left? We found that outbox was the right answer for us, but before we get there, let me get into the cost x benefit equation of our decision making!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Although some of the options were quite attractive technically, for instance event sourcing, the engineering effort and growth is immense. Also, it&amp;#8217;s not the kind of thing which comes ready to use, and there&amp;#8217;s a lot of discovery to be made along the way, so what were the constraints and desires:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Reliability&lt;/em&gt;; we want at least once semantics, exactly once isn&amp;#8217;t necessary as we can uniquely identify each message/event;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Eventual consistency only between services&lt;/em&gt;, but not within the services themselves. Being able to interact with a service which is the source of truth of a certain model, and get an immediate answer is not just handy, but incredibly powerful (and that&amp;#8217;s why monoliths are also so attractive);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Avoiding distributed transactions&lt;/em&gt; as much as we can, it&amp;#8217;s scary and we should be scared about it too!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Manageable effort&lt;/em&gt;; how can we &quot;easily&quot; get 30+ engineers to adopt a solution for this problem? At the same time, how can you ensure the implementation guarantees among every service and team?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We realized that the &lt;a href=&quot;https://microservices.io/patterns/data/transactional-outbox.html&quot;&gt;outbox pattern&lt;/a&gt; would help us meet those requirements: applications would publish events via an outbox table, which gets written to as part of business transactions in the database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As with the strangler pattern, we wanted to resort to an architecture component, something the teams could self-service. At first, we were exploring a home-grown solution which would look for the outbox tables among every service and publish the messages. The problem with this approach would be the polling databases problem, although in this case this is less harmful as we don&amp;#8217;t need to look for updates or deletes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Luckily, by that time I was closely following the work being done in Debezium and I read the blogpost about &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;reliable data exchange between microservices using the outbox pattern&lt;/a&gt;, and there was my answer! Well, I mean, parts of the answer, we still needed to implement it, and that&amp;#8217;s a story for the next question!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Fast forward a couple of months and we got a reliable way to exchange messages between services, with all the guarantees we wanted to have, and by applying some platform DevOps flavor to it, we also made it self-service and easy to plug in every service!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The user can specify which database their service is at, what&amp;#8217;s the table name, and which column to use as event router, you can find more details about it in the official &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html#outbox-event-router-property-route-by-field&quot;&gt;Debezium outbox event router docs&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/debezium_community_stories_with_renato_mefi_outbox.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 2. The configuration file for configuring outbox connectors&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;You&amp;#8217;re not only using Debezium but you&amp;#8217;ve also contributed to the project. How was your experience doing so? Are you doing other open-source work, too?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As I spoiled at the beginning, my usage and contributions to Debezium walked hand-to-hand. In both the use cases we have for Debezium in SurveyMonkey, I had great opportunities to contribute to both Debezium and Kafka (just a bug fix, but I&amp;#8217;m happy about it!).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At first, I was fixing bugs in the Debezium MongoDB connector; as we really scaled it up to all the teams, a lot of edge cases started to show up, mostly in the transformation which takes the raw database transaction log and transforms it into a nicely readable Kafka Connect struct. Also due to our architecture choice, we split the raw log and transformed data into two different steps, which go in separate topics and are configured as separate Kafka Connect connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Quick sidestep: the rationale behind this decision was to be able to survive transformation errors; MongoDB has a replication window which, if you lose it, means that you are going to have to make a new full snapshot of the collection and you might lose deletion events in this process. Because of this we opted for a safer approach, which was to split the logic of transformation from the raw logs like this:
The step we call &lt;code&gt;op&lt;/code&gt; (stands for operation), is the Debezium MongoDB source connector and outputs the raw data into the topic without any change or transformation, minimizing the chances of errors in the process. The second step called &lt;code&gt;cdc&lt;/code&gt;, is a &lt;a href=&quot;https://github.com/salesforce/mirus&quot;&gt;Salesforce Mirus&lt;/a&gt; source connector, which reads from the &lt;code&gt;op&lt;/code&gt; output topic, transforms the message using the &lt;a href=&quot;https://debezium.io/documentation/reference/1.3/configuration/mongodb-event-flattening.html&quot;&gt;Debezium document flattening SMT&lt;/a&gt; and outputs to the final topic, which the services can consume from. With this approach, we now have two main abilities: Resist to errors and crashes on the native/custom transformation process like mentioned above, and we have the chance to change the transformation to our desires without having to read from the database again, giving us more flexibility. That also created some extra features and challenges to be incorporated in Debezium itself!
As I kept contributing I noticed a few things that could be improved and started fixing them, including an almost full refactor of the build process of Debezium&amp;#8217;s container images, its scripts, and other smaller things!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s circle back to outbox; when the post about this appeared on the Debezium blog, it was mostly an idea and a proof-of-concept. But we really wanted it to run in production, in this case, why not partnership on it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I want to take the opportunity here to mention how helpful the Debezium community was for getting me started with contributing. As I showed the intent to work on this, they were super welcoming and we had a call about it, so I quickly felt productive working on the code base.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Almost immediately after the conversation I started a technical draft (which you can see &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1169&quot;&gt;here&lt;/a&gt;) and soon thereafter, the first implementation was done. I can almost certainly say we were the first ones to run the transactional outbox pattern powered by Debezium. I was running a custom build on our platform, which then finally became the official &lt;a href=&quot;https://debezium.io/documentation/reference/1.2/configuration/outbox-event-router.html&quot;&gt;outbox event router&lt;/a&gt; you see in the Debezium docs today.
I was lucky to be there at the right time and with the right people, so thanks again to the Debezium team for helping me throughout the whole process of drafting and making it happen!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Will I do more open source? Yes, but I must say most of my open source activity is &quot;selfish&quot;, I&amp;#8217;m developing solutions to problems I face at work but I&amp;#8217;m happy to take the extra step and make them to the OSS world, but it also makes it seasonal. One of the advantages to that is if I&amp;#8217;m doing something for a project, be sure I&amp;#8217;ll make it to production and likely be able to find more corner cases!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Is there anything you&amp;#8217;re missing in Debezium or you&amp;#8217;d like to see improved in the future?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I think of the Kafka and Debezium ecosystem, the next steps I consider important are the ones which will make it more accessible. Although there&amp;#8217;s a lot of content and examples online, there&amp;#8217;s still a big gap between reading those and getting to a production ready implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What I mean by that is abstracting the individual pieces away and giving them more meaning. The outbox pattern is a good example, it was not natural for people to think of CDC and know that it was such a good match to it, there are plenty of more use cases to be explored in this ecosystem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What if you could have everything out-of-the-box? An outbox implementation in your favorite framework, which knows how to integrate with the ORM, handle the transaction part, then, how to shape the messages and events? How to adopt the schema for it and how an evolution of it looks like. After that, getting closer to the consumer implementation, how can I handle the messages idempotently, respect the semantics, do retries, and project them to a database if need be? There are already initiatives like those, for instance, the &lt;a href=&quot;https://debezium.io/documentation/reference/integrations/outbox.html&quot;&gt;Quarkus Outbox extension&lt;/a&gt;, which takes care of framework and database integration. The future for me has those things, for multiple frameworks and tech stacks, going even broader and helping you design good events (maybe even powered by &lt;a href=&quot;https://www.asyncapi.com/&quot;&gt;AsyncAPI&lt;/a&gt;), giving everyone a kickstart!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Those are very complex things to do in a growing architecture, the patterns will keep repeating and hopefully the community will be able to come to consensus of design and implementations, and that&amp;#8217;s what I think the next step is, a place where the complexity of a good architecture doesn&amp;#8217;t live in the wires and plugs anymore, making it more accessible!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Bonus question: What&amp;#8217;s the next big thing in software engineering?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I think I handled clues for this one in many parts of my previous answers!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For me the next big thing is a methodology; I often say the evolution of DevOps is self-service, and it can go in many layers of the stack. The examples I gave about our Debezium implementation is what I call self-service between Platform/Ops and product development teams, but it can be applied in many, many places!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The idea is to facilitate the implementation of complex structures, something more end-to-end, taking care of the good practices in metrics, alerts, and diverse other guaranteed semantics for the use case!
We can see there&amp;#8217;s a convergence towards that path, for instance Kubernetes operators are a great example where you can abstract one use case which will be translated to many, if not dozens of internal resources in the infrastructure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I believe we already have the base technology to do so, all the Infrastructure as Code, containers, frameworks, observability systems are there, we just have to give meaning to them!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Where&amp;#8217;s the framework where I can: Handle a user request, validate, write to the source-of-truth, produce a message to my broker, consume at another end where my only concern is the payload itself? All the semantics should be taken care of, idempotency, retries, SerDes issues, dead letter queues, eventual consistency mitigations, metrics, alerts, SLOs, SLAs, etc!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And that&amp;#8217;s where I put my energy in everyday at work, giving all the engineering teams a more fun and safe way to develop their software, which also sums up my passion for Platform Engineering!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Renato, thanks a lot for taking your time, it was a pleasure to have you here!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;If you&amp;#8217;d like to stay in touch with Renato Mefi and discuss with him, please drop a comment below or follow and reach out to him &lt;a href=&quot;https://twitter.com/renatomefi&quot;&gt;on Twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="community" /><category term="outbox" /><summary type="html">Welcome to the first edition of &quot;Debezium Community Stories With&amp;#8230;&amp;#8203;&quot;, a new series of interviews with members of the Debezium and change data capture community, such as users, contributors or integrators. We&amp;#8217;re planning to publish more parts of this series in a loose rhythm, so if you&amp;#8217;d like to be part of it, please let us know. In today&amp;#8217;s edition it&amp;#8217;s my pleasure to talk to Renato Mefi, a long-time Debezium user and contributor.</summary></entry><entry><title type="html">Debezium 1.3.0.Final Released</title><link href="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Final Released" /><published>2020-10-01T16:19:59+00:00</published><updated>2020-10-01T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/10/01/debezium-1-3-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/10/01/debezium-1-3-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium &lt;strong&gt;1.3.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months.
Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.3.0.Final%2C%201.3.0.Alpha1%2C%201.3.0.Beta1%2C%201.3.0.Beta2%2C%201.3.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;138 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A new incubating &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based implementation&lt;/a&gt; for ingesting change events from Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for Azure Event Hubs in &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upgrade to Apache Kafka 2.6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revised &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;filter option names&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new SQL Server connector snapshot mode, &lt;code&gt;initial_only&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for database-filtered columns for SQL Server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional connection options for the MongoDB connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improvements to &lt;code&gt;ByteBufferConverter&lt;/code&gt; for implementing the &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;outbox pattern&lt;/a&gt; with Avro as the payload format&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the announcements of the preview releases (&lt;a href=&quot;https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/&quot;&gt;Beta2&lt;/a&gt;, &lt;a href=&quot;https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details.
Since last week&amp;#8217;s CR1 release, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;been focusing&lt;/a&gt; on ironing out some remaining bugs and improvements to the documentation.
To learn more about procedures for upgrading from earlier Debezium versions, please take a look the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-final1&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you to everyone testing the preview releases, this is of invaluable help for spotting and fixing short-comings in new features as well as regressions.
And of course I&amp;#8217;d also like to thank all the community members contributing to this release:
&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/abhirockzz&quot;&gt;Abhishek Gupta&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bjoernhaeuser&quot;&gt;Björn Häuser&lt;/a&gt;,
&lt;a href=&quot;https://github.com/coryharperbind&quot;&gt;Cory Harper&lt;/a&gt;,
&lt;a href=&quot;https://github.com/denisprog&quot;&gt;Denis Liseichykau&lt;/a&gt;,
&lt;a href=&quot;https://github.com/eric-weaver&quot;&gt;Eric Weaver&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt;,
&lt;a href=&quot;https://github.com/GuyIEX&quot;&gt;Guy Pascarella&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jfinzel&quot;&gt;Jeremy Finzel&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jonaslins&quot;&gt;Jonas Lins&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/korzenek&quot;&gt;Lukasz Korzeniowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/lga-zurich&quot;&gt;Luis Garcés-Erice&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/misaert&quot;&gt;Mickaël Isaert&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mtagle&quot;&gt;Moira Tagle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rivernate&quot;&gt;Nathan Mills&lt;/a&gt;,
&lt;a href=&quot;https://github.com/petoju&quot;&gt;Peter Junos&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Victor Xiang&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, more than 220 individuals have contributed to the Debezium project at this point.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But not only that, also the number of Debezium users is constantly growing,
as e.g. documented on our &lt;a href=&quot;/community/users/&quot;&gt;reference list of Debezium users&lt;/a&gt;
(let us know if you want to be added).
There&amp;#8217;s also several new entries in our compilation of &lt;a href=&quot;/documentation/online-resources/&quot;&gt;public talks and blog posts&lt;/a&gt; touching on Debezium,
e.g. a highly recommendable talk by Marta Paes about &lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;change data capture with Flink SQL and Debezium&lt;/a&gt;,
a blog post by Cemal Turkoglu about &lt;a href=&quot;https://turkogluc.com/postgresql-capture-data-change-with-debezium/&quot;&gt;[making sense of change data capture pipelines for Postgres with the Debezium Kafka Connector&lt;/a&gt;,
and a nice piece on &lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;implementing the outbox pattern with Debezium in Quarkus&lt;/a&gt; by Iain Porter.
Abdellatif Bouchama did an amazing job by creating a &lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;cheat sheet&lt;/a&gt; for running Debezium on OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With the 1.3 Final release out, planning for the 1.4 version (due by the end of the year) is happening right now.
The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; still is in flux, so make sure to chime in and let us know about your requirements and feature requests.
Some of the things we&amp;#8217;re likely going to work on include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;community-led connector&lt;/a&gt; for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;; the initial contribution has already been merged and we plan to ship the first release of this as part of Debezium 1.4 Alpha1 later this month&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improving the new LogMiner-based implementation for Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And lastly, there&amp;#8217;s one other area of activity which I&amp;#8217;m particularly excited to share here today for the first time:
a proof-of-concept of how a potential future Debezium user interface might look like.
In that PoC we&amp;#8217;re exploring how a graphical UI could help with the set-up and operation of Debezium connectors.
We&amp;#8217;ve got quite a few ideas in that field and will share more details in a blog post very soon.
If you feel adventureous in the meantime, you could grab the &lt;a href=&quot;https://github.com/debezium/debezium-ui-poc/&quot;&gt;current PoC code&lt;/a&gt; and take it for spin!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Until then, happy change data streaming, onwards and upwards!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">It&amp;#8217;s with great please that I&amp;#8217;m announcing the release of Debezium 1.3.0.Final! As per Debezium&amp;#8217;s quarterly release cadence, this wraps up the work of the last three months. Overall, the community has fixed 138 issues during that time, including the following key features and changes: A new incubating LogMiner-based implementation for ingesting change events from Oracle Support for Azure Event Hubs in Debezium Server Upgrade to Apache Kafka 2.6 Revised filter option names A new SQL Server connector snapshot mode, initial_only Support for database-filtered columns for SQL Server Additional connection options for the MongoDB connector Improvements to ByteBufferConverter for implementing the outbox pattern with Avro as the payload format</summary></entry><entry><title type="html">Debezium 1.3.0.CR1 Released</title><link href="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.CR1 Released" /><published>2020-09-24T16:19:59+00:00</published><updated>2020-09-24T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/24/debezium-1-3-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.3.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we approach the final stretch of Debezium 1.3 Final,
we took this opportunity to add delegate converter support for the &lt;code&gt;ByteBufferConverter&lt;/code&gt; and introduce a &lt;code&gt;debezium-scripting&lt;/code&gt; module.
In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish;
overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.CR1%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;15 issues&lt;/a&gt; have been resolved for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bytebufferconverter-improvements&quot;&gt;ByteBufferConverter improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;ByteBufferConverter&lt;/code&gt; is a converter that is used with the Outbox event router SMT to serialize an existing Avro payload column.
In a recent report (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2396&quot;&gt;DBZ-2396&lt;/a&gt;),
the &lt;code&gt;ByteBufferConverter&lt;/code&gt; was unable to serialize events emitted from a connector that was configured to emit heartbeat, transaction metadata, or schema change events.
In order to improve the converter&amp;#8217;s compatibility when these events are emitted,
the &lt;code&gt;ByteBufferConverter&lt;/code&gt; can now be configured to delegate event serialization to an additional converter.
This delegation is necessary so that heartbeat, transaction metadata, and schema change events (if applicable) can be serialized.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to use the Outbox event router SMT and the &lt;code&gt;ByteBufferConverter&lt;/code&gt; with these event types,
the connector configuration must be changed to reflect the delegate converter and its configurable options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As an example to use the Apache Kafka &lt;code&gt;JsonConverter&lt;/code&gt; as a delegate with schemas disabled,
the following configuration would need to be included in the connector:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;value.converter=io.debezium.converters.ByteBufferConverter
value.converter.delegate.converter.type=org.apache.kafka.connect.json.JsonConverter
value.converter.delegate.converter.type.schemas.enable=false&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For more information about using the &lt;code&gt;ByteBufferConverter&lt;/code&gt;,
please see the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/outbox-event-router.html#avro-as-payload-format&quot;&gt;Using Avro as the payload format&lt;/a&gt; section in the Outbox event router documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;scripting-module&quot;&gt;Scripting module&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this release, the SMTs for content-based routing and filtering that both use JSR 223 scripting engines have been moved out of &lt;code&gt;debezium-core&lt;/code&gt; and into a separate artifact &lt;code&gt;debezium-scripting&lt;/code&gt; (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2549&quot;&gt;DBZ-2549&lt;/a&gt;).
Any connector that previous used these SMTs requires that the new artifact be added to the plug-in directories for those connector(s).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When using the Debezium container image for Kafka Connect, set the environment variable &lt;code&gt;ENABLE_DEBEZIUM_SCRIPTING&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; to enable this feature.
This change is done to allow the scripting functionality to be available only in environments with an apppropriately secured Kafka Connect configuration interface.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;misc-features-and-bug-fixes&quot;&gt;Misc. Features and Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, the community has completed the work on some other features and fixes, too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Catch up streaming before snapshot may duplicate messages upon resuming streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2550&quot;&gt;DBZ-2550&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix Quarkus datasource configuration for Quarkus 1.9 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2558&quot;&gt;DBZ-2558&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement connection retry support for Oracle &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2531&quot;&gt;DBZ-2531&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-cr1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you so much to &lt;a href=&quot;https://github.com/gsmet&quot;&gt;Guillaume Smet&lt;/a&gt; and &lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt; for their contributions to this release.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.3 Final should be out next week.
Until then, we&amp;#8217;ll focus on some more polishing.
The &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;community-lead work&lt;/a&gt; towards a Debezium connector for &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt; is also making good progress,
with an initial release of this new connector planned with Debezium 1.4 Alpha1 in late October.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.3.0.CR1! As we approach the final stretch of Debezium 1.3 Final, we took this opportunity to add delegate converter support for the ByteBufferConverter and introduce a debezium-scripting module. In addition, there&amp;#8217;s also a range of bug fixes and quite a bit of documentation polish; overall, not less than 15 issues have been resolved for this release.</summary></entry><entry><title type="html">Debezium 1.3.0.Beta2 Released</title><link href="https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Beta2 Released" /><published>2020-09-16T16:19:59+00:00</published><updated>2020-09-16T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/16/debezium-1-3-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.3.0.Beta2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this release we&amp;#8217;ve improved support for column filtering for the MySQL and SQL Server connectors,
and there&amp;#8217;s a brand-new implementation for ingesting change events from Oracle, using the LogMiner package.
As we&amp;#8217;re on the home stretch towards Debezium 1.3 Final,
there&amp;#8217;s also a wide range of smaller improvements, bug fixes and documentation clarifications;
overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Beta2%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;44 issues&lt;/a&gt; have been resolved for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;column-filtering-improvements&quot;&gt;Column Filtering Improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Addressing a long standing feature request (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1068&quot;&gt;DBZ-1068&lt;/a&gt;),
the Debezium connector for SQL Server supports now server-side column filtering:
capture instances in the database itself can be configured so to only contain a sub-set of the captured table&amp;#8217;s columns.
That way, specific columns can be excluded by the CDC process right away,
instead of only removing them in the Debezium connector,
which is much more efficient for large BLOB for instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The MySQL connector adds support for the &lt;code&gt;column.include.list&lt;/code&gt; option already known from the Debezium Postgres connector
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2508&quot;&gt;DBZ-2508&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Related to the matter of filtering,
following up on the work begun in the &lt;a href=&quot;https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/&quot;&gt;1.3 Beta1 release&lt;/a&gt; around replacing the terms &quot;master/slave&quot;, &quot;blacklist&quot; and &quot;whitelist&quot; with more inclusive alternatives,
also all the incubating connectors (Oracle, Db2, Cassandra) use the new terms like &quot;database.include.list&quot;, &quot;primary/replica&quot;, etc. now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2462&quot;&gt;DBZ-2462&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;logminer-based-ingestion-engine-for-oracle&quot;&gt;LogMiner-based Ingestion Engine for Oracle&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium Oracle connector can now use the LogMiner package to ingest change events.
As this package comes with the Oracle database itself,
it&amp;#8217;s a very attractive alternative to the existing XStream-based implementation.
Discussions and work towards LogMiner support have been happening in the Debezium community for a long time
(as you already might have guessed from the very low issue number &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-137&quot;&gt;DBZ-137&lt;/a&gt;),
so we&amp;#8217;re particularly excited about this work being merged eventually and being part of this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Note that there&amp;#8217;s several follow-up tasks to be resolved related to the LogMiner-based ingestion implementation;
while it is not recommended for production usage at this point,
we&amp;#8217;d love to get your feedback from testing and evaluating!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A massive thank you to everyone involved with this:
Andrey Ignatenko and his team for the main work,
Andrey Pustovetov for his ideas around transaction buffering,
Chris Cranford for picking up the PR and preparing it to get merged,
Milo vd Zee for his extensive review,
as well as everyone else commenting and providing feedback on the PR and Jira issue.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;misc-features-and-bug-fixes&quot;&gt;Misc. Features and Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition to these key features, the community has completed the work on some other features and fixes, too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The MySQL connector supports the &lt;code&gt;LOCK TABLES FOR BACKUP&lt;/code&gt; lock mode when being used with Percona Server for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2466&quot;&gt;DBZ-2466&lt;/a&gt;),
which reduces contention during snapshots&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Postgres connector snapshot SPI got more flexible, allowing for custom implementations now that e.g. can re-snapshot selected tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2094&quot;&gt;DBZ-2094&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The prefix of additional headers and fields produced by the event flattening SMTs is customizeable now (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2504&quot;&gt;DBZ-2504&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for JSON functions in MySQL DDL statements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2453&quot;&gt;DBZ-2453&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved exception logging for the Cassandra connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2498&quot;&gt;DBZ-2498&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-beta2&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you so much to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/insom&quot;&gt;Aaron Brady&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/eric-weaver&quot;&gt;Eric Weaver&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/GuyIEX&quot;&gt;Guy Pascarella&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/misaert&quot;&gt;Mickaël Isaert&lt;/a&gt;,
and &lt;a href=&quot;https://github.com/rivernate&quot;&gt;Nathan Mills&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With the first cut of LogMiner support being merged and released,
we&amp;#8217;re now planning to focus on stabilization and bug fixing,
with the Debezium 1.3 Final release to be expected around the end of the month.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In parallel, work is happening on a &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;new connector&lt;/a&gt; contributed by the community for the Vitess (which will - depending on progress of review - be released as an incubating connector either in Debezium 1.3 or 1.4),
and we&amp;#8217;re going to share some exciting efforts around a proof-of-concept for a potential future Debezium UI with you very soon!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.3.0.Beta2! In this release we&amp;#8217;ve improved support for column filtering for the MySQL and SQL Server connectors, and there&amp;#8217;s a brand-new implementation for ingesting change events from Oracle, using the LogMiner package. As we&amp;#8217;re on the home stretch towards Debezium 1.3 Final, there&amp;#8217;s also a wide range of smaller improvements, bug fixes and documentation clarifications; overall, not less than 44 issues have been resolved for this release.</summary></entry><entry><title type="html">Auto-creating Debezium Change Data Topics</title><link href="https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/" rel="alternate" type="text/html" title="Auto-creating Debezium Change Data Topics" /><published>2020-09-15T16:19:59+00:00</published><updated>2020-09-15T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/15/debezium-auto-create-topics</id><content type="html" xml:base="https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/">&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/new_pipes.jpg&quot; class=&quot;responsive-image&quot; alt=&quot;Create new topics / pipes&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you are working with Kafka Connect Distributed then you might have realized that once you start
Kafka Connect there are already some internal Kafka Connect related topics created for you:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --list

connect_configs
connect_offsets
connect_statuses&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is done automatically for you by Kafka Connect with a sane, customized default topic configuration
that fits the needs of these internal topics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you start a Debezium connector the topics for the captured events are created by the Kafka
broker based on a default, maybe customized, configuration in the broker if
&lt;code&gt;auto.create.topics.enable = true&lt;/code&gt; is enabled in the broker config:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;auto.create.topics.enable = true
default.replication.factor = 1
num.partitions = 1
compression.type = producer
log.cleanup.policy = delete
log.retention.ms = 604800000  ## 7 days&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But often, when you use Debezium and Kafka in a production environment you might choose to disable
Kafka&amp;#8217;s topic auto creation capability with &lt;code&gt;auto.create.topics.enable = false&lt;/code&gt;, or you want the
connector topics to be configured differently from the default. In this case you have to create
topics for Debezium&amp;#8217;s captured data sources upfront.&lt;br&gt;
But there&amp;#8217;s good news! Beginning with Kafka Connect version 2.6.0, this can be automated since
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics&quot;&gt;KIP-158&lt;/a&gt;
is implemented to enable customizable topic creation with Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;kafka-connect&quot;&gt;Kafka Connect&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;topic.creation.enable = true&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you don&amp;#8217;t want to allow automatic topic creation by connectors you can set this value to &lt;code&gt;false&lt;/code&gt;
in the Kafka Connect config (&lt;em&gt;connect-distributed.properties&lt;/em&gt; file or via environment variable
&lt;em&gt;CONNECT_TOPIC_CREATION_ENABLE&lt;/em&gt; when using &lt;a href=&quot;https://hub.docker.com/r/debezium/connect&quot;&gt;Debezium&amp;#8217;s container image for Kafka Connect&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;updating-connector-configuration&quot;&gt;Updating Connector Configuration&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Kafka Connect topic creation works with groups. There&amp;#8217;s always a &lt;code&gt;default&lt;/code&gt; group which is used when
there&amp;#8217;s no other group defined that matches the topic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Every group can specify a collection of topic configuration properties, and a regular expression list
of topic names that config should apply to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can specify all &lt;a href=&quot;https://kafka.apache.org/documentation/#topicconfigs&quot;&gt;&lt;strong&gt;topic level configuration parameters&lt;/strong&gt;&lt;/a&gt;
to customize how the matched topics of the group will be created.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s see how we can extend this Postgres config for the Kafka Connect topic creation:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;default-config&quot;&gt;Default Config&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All topics not matching other &lt;code&gt;topic.creation&lt;/code&gt; groups will apply the &lt;code&gt;default&lt;/code&gt; group
config.&lt;br&gt;
As default we want &lt;code&gt;replication.factor = 3&lt;/code&gt;, &lt;code&gt;partitions = 10&lt;/code&gt;, the topic should be key
compacted with &lt;code&gt;cleanup.policy = &quot;compact&quot;&lt;/code&gt;, and all messages should be LZ4 compressed
on harddisk with &lt;code&gt;compression.type = &quot;lz4&quot;&lt;/code&gt;.&lt;br&gt;
So we configure for the default group:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;,

        &quot;topic.creation.default.replication.factor&quot;: 3,
        &quot;topic.creation.default.partitions&quot;: 10,
        &quot;topic.creation.default.cleanup.policy&quot;: &quot;compact&quot;,
        &quot;topic.creation.default.compression.type&quot;: &quot;lz4&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;productlog-config&quot;&gt;Productlog Config&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the databases &lt;code&gt;inventory&lt;/code&gt; schema there are tables starting with &lt;code&gt;product&lt;/code&gt; as table name.&lt;br&gt;
As default the fully qualified table names are captured to the topic with the same name with Debezium,
for example the table &lt;code&gt;products&lt;/code&gt; in the &lt;code&gt;inventory&lt;/code&gt; schema of &lt;code&gt;dbserver1&lt;/code&gt; is captured to the
topic &lt;code&gt;dbserver1.inventory.products&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We want that all messages that go to a topic for table names starting with &lt;code&gt;product&lt;/code&gt; are stored
in a topic with a retention time of 3 months / 90 days with &lt;code&gt;cleanup.policy&quot;: &quot;delete&quot;&lt;/code&gt; and
&lt;code&gt;retention.ms = 7776000000&lt;/code&gt;, &lt;code&gt;replication.factor = 1&lt;/code&gt;, &lt;code&gt;partitions = 20&lt;/code&gt;, and just use the
compression format that&amp;#8217;s used by the producer &lt;code&gt;compression.type&quot;: &quot;producer&quot;&lt;/code&gt;.&lt;br&gt;
You can leave out properties that match the cluster defaults, but be careful once you
change the default config on your Kafka brokers the resulting topic config might differ!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First we need to register a &lt;code&gt;productlog&lt;/code&gt; group using the &lt;code&gt;topic.creation.groups&lt;/code&gt; property.&lt;br&gt;
Then we can define what topic names should be included in that group and specify the configuration
of our group like we did with the &lt;code&gt;default&lt;/code&gt; group:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;inventory-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: 5432,
        &quot;database.user&quot;: &quot;postgres&quot;,
        &quot;database.password&quot;: &quot;postgres&quot;,
        &quot;database.dbname&quot; : &quot;postgres&quot;,
        &quot;database.server.name&quot;: &quot;dbserver1&quot;,
        &quot;schema.include.list&quot;: &quot;inventory&quot;,
        &quot;topic.creation.default.replication.factor&quot;: 3,
        &quot;topic.creation.default.partitions&quot;: 10,
        &quot;topic.creation.default.cleanup.policy&quot;: &quot;compact&quot;,
        &quot;topic.creation.default.compression.type&quot;: &quot;lz4&quot;,

        &quot;topic.creation.groups&quot;: &quot;productlog&quot;,  //&lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;

        &quot;topic.creation.productlog.include&quot;: &quot;dbserver1\\.inventory\\.product.*&quot;,  //&lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
        &quot;topic.creation.productlog.replication.factor&quot;: 1,
        &quot;topic.creation.productlog.partitions&quot;: 20,
        &quot;topic.creation.productlog.cleanup.policy&quot;: &quot;delete&quot;,
        &quot;topic.creation.productlog.retention.ms&quot;: 7776000000,
        &quot;topic.creation.productlog.compression.type&quot;: &quot;producer&quot;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt;
&lt;caption class=&quot;title&quot;&gt;Table 1. Connector Configuration for customized automatic topic creation&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 10%;&quot;&gt;
&lt;col style=&quot;width: 90%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Item&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;topic.creation.groups&lt;/code&gt; defines a comma-separated list of additional group names. Here we only
define our &lt;code&gt;productlog&lt;/code&gt; group.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;2&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;The &lt;code&gt;topic.creation.productlog.include&lt;/code&gt; field holds a comma-separated list of regular expressions
that match the topic names where the &lt;code&gt;productlog&lt;/code&gt; group config should be applied. The &lt;code&gt;productlog&lt;/code&gt;
group matches all topics starting with &lt;code&gt;dbserver1.inventory.product&lt;/code&gt;.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;exploring-the-results&quot;&gt;Exploring the Results&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When we now start our connector and use &lt;code&gt;kafka-topics.sh&lt;/code&gt; to see how the topics were created, we can
see that all worked as defined:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight nowrap&quot;&gt;&lt;code&gt;## the `dbserver1.inventory.products` topic has the config from the `productlog` group:
$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --describe --topic dbserver1.inventory.products

Topic: dbserver1.inventory.products     PartitionCount: 20      ReplicationFactor: 1
Configs: compression.type=producer,cleanup.policy=delete,retention.ms=7776000000,segment.bytes=1073741824

## the `dbserver1.inventory.orders` topic has the config from the `default` group:
$ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --describe --topic dbserver1.inventory.orders

Topic: dbserver1.inventory.orders       PartitionCount: 10       ReplicationFactor: 3
Configs: compression.type=lz4,cleanup.policy=compact,segment.bytes=1073741824,delete.retention.ms=2592000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In many, especially in production environments we often don&amp;#8217;t want topic auto creation to be enabled
on the Kafka broker side, or we need a different configuration than the default topic config.&lt;br&gt;
Prior Kafka 2.6 this was only possible when manually creating topics upfront or by some custom setup
process, maybe during deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since Kafka 2.6 Kafka Connect comes with built-in topic creation for connector topics and this article
shows how to use it with Debezium.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can find an example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/topic-auto-create&quot;&gt;here&lt;/a&gt;
in the Debezium examples repository on GitHub.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>René Kerner</name></author><category term="kafka" /><category term="topics" /><category term="production" /><category term="news" /><category term="discussion" /><summary type="html">When you are working with Kafka Connect Distributed then you might have realized that once you start Kafka Connect there are already some internal Kafka Connect related topics created for you: $ kafka-topics.sh --bootstrap-server $HOSTNAME:9092 --list connect_configs connect_offsets connect_statuses This is done automatically for you by Kafka Connect with a sane, customized default topic configuration that fits the needs of these internal topics. When you start a Debezium connector the topics for the captured events are created by the Kafka broker based on a default, maybe customized, configuration in the broker if auto.create.topics.enable = true is enabled in the broker config: auto.create.topics.enable = true default.replication.factor = 1 num.partitions = 1 compression.type = producer log.cleanup.policy = delete log.retention.ms = 604800000 ## 7 days But often, when you use Debezium and Kafka in a production environment you might choose to disable Kafka&amp;#8217;s topic auto creation capability with auto.create.topics.enable = false, or you want the connector topics to be configured differently from the default. In this case you have to create topics for Debezium&amp;#8217;s captured data sources upfront. But there&amp;#8217;s good news! Beginning with Kafka Connect version 2.6.0, this can be automated since KIP-158 is implemented to enable customizable topic creation with Kafka Connect.</summary></entry><entry><title type="html">Debezium 1.3.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Beta1 Released" /><published>2020-09-03T16:19:59+00:00</published><updated>2020-09-03T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/09/03/debezium-1-3-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.3.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release upgrades to the recently released Apache Kafka version 2.6.0, fixes several critical bugs and comes with a renaming of the connector configuration options for selecting the tables to be captured.
We&amp;#8217;ve also released Debezium 1.2.2.Final, which is a drop-in replacement for all users of earlier 1.2.x releases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;revised-filter-options-and-documentation-wording&quot;&gt;Revised Filter Options and Documentation Wording&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since the beginning of the Debezium project, there was support for specifying the tables and columns to capture.
This is done via a range of configuration options like &lt;code&gt;schema.whitelist&lt;/code&gt;, &lt;code&gt;column.blacklist&lt;/code&gt;, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While nothing was wrong with those options from a technical perspective,
we&amp;#8217;ve come to realize that the terms &quot;whitelist&quot; and &quot;blacklist&quot; are problematic and that they may even be hurtful to some members of our community.
This is why we&amp;#8217;ve decided to deprecate the existing option names and replace them with counterparts which are not only more inclusive, but also more expressive when it comes to describing their purpose.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The following changes have been made:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Old Name&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;New Name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;database.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;schema.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;table.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.whitelist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.include.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.blacklist&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;column.exclude.list&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The renaming has been done for all the stable Debezium connectors as of this release;
the options of the incubator connectors (Oracle, Db2, Cassandra) will be renamed in the next Debezium 1.3.x preview release.
Note that for the sake of backwards-compatibility, the old option names still can be used during a transition period.
In this case, e.g. when upgrading an existing connector instance to the new version,
a warning will be logged upon connector start-up, and you should update your configuration accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides renaming these filter options, we&amp;#8217;ve also updated our documentation;
in particular the description of supported database topologies has been updated from the previously used terms &quot;master&quot; and &quot;slave&quot; to &quot;primary&quot; (node) and &quot;replica&quot; (node).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This change is part of a larger effort &lt;a href=&quot;https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language&quot;&gt;across Red Hat&lt;/a&gt; and the industry as a whole,
and we&amp;#8217;re very happy that we can contribute our share for making the world of open-source projects and its communities more welcoming and inclusive.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bug-fixes&quot;&gt;Bug Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release fixes a number of critical bugs:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Potentially lost change events with the Postgres connector, in case of connector restarts (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2338&quot;&gt;DBZ-2338&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2397&quot;&gt;DBZ-2397&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NullPointerException in the logical table router (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2412&quot;&gt;DBZ-2412&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Snapshot fails if table or schema contain hyphens (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2452&quot;&gt;DBZ-2452&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Misc. MySQL DDL parser fixes (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2413&quot;&gt;DBZ-2413&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2415&quot;&gt;DBZ-2415&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2425&quot;&gt;DBZ-2425&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%2012317320%20AND%20fixVersion%20%3D%2012346874%20ORDER%20BY%20priority%20DESC%2C%20key%20ASC&quot;&gt;20 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-beta1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to community members &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt; and &lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt; for their contributions to this release!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As you&amp;#8217;d expect it, things went a bit slower during the summer with several folks taking some well-deserved time off.
Now that everyone is back, Debezium development moves forward with full steam again,
and you can expect some exciting new features coming soon:
the &lt;a href=&quot;https://github.com/debezium/debezium-incubator/pull/185&quot;&gt;ongoing work&lt;/a&gt; by the community towards a LogMiner-based implementation for Oracle should soon reach a state where it can be merged into the upstream Debezium repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And a brand-new connector contributed by the community is showing up on the horizon, too;
&lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt; engineers &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt; and &lt;a href=&quot;https://github.com/rgibaiev&quot;&gt;Ruslan Gibaiev&lt;/a&gt; have been working on a &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/pull/1&quot;&gt;CDC connector for the Vitess database&lt;/a&gt; and announced that they&amp;#8217;d like to open-source and continue to evolve it under the Debezium umbrella.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Exciting times for open-source change data capture and Debezium 🎉!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.3.0.Beta1! This release upgrades to the recently released Apache Kafka version 2.6.0, fixes several critical bugs and comes with a renaming of the connector configuration options for selecting the tables to be captured. We&amp;#8217;ve also released Debezium 1.2.2.Final, which is a drop-in replacement for all users of earlier 1.2.x releases.</summary></entry><entry><title type="html">Debezium 1.3.0.Alpha1 Released</title><link href="https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.3.0.Alpha1 Released" /><published>2020-08-06T16:19:59+00:00</published><updated>2020-08-06T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/08/06/debezium-1-3-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This initial pass in the 1.3 release line provides a number of useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A new Debezium Server sink adapter for Azure Event Hubs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new SQL Server connector snapshot mode, &lt;code&gt;initial_only&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional connection timeout options for the MongoDB Connector&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.0.Alpha1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;31 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of them in the remainder of this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;azure-event-hubs-sink-adapter&quot;&gt;Azure Event Hubs sink adapter&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium&amp;#8217;s &lt;a href=&quot;/documentation/reference/1.3/operations/debezium-server.html&quot;&gt;standalone server&lt;/a&gt; is one of the newest features in the Debezium ecosystem.
The standalone server provides a ready-to-use application that can stream change events from a source database to a variety of messaging infrastructures.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Driven by the community, the Debezium Server now supports Azure Event Hubs (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2282&quot;&gt;DBZ-2282&lt;/a&gt;).
This now enables the Debezium Server to stream change events to Amazon Kinesis, Apache Pulsar, Google Cloud Pub/Sub, and Azure Event Hubs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;additional-mongodb-connection-options&quot;&gt;Additional MongoDB connection options&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium MongoDB connector has traditionally used the driver default connection options and timeouts.
There are use cases where customization of these defaults are necessary to support latency or performance concerns in your deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There additional configuration options are now available for MongoDB:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.connect.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver waits for a new conneciton before the attempt is aborted.&lt;br&gt;
Defaults to &lt;code&gt;10000&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.server.selection.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver will wait to select a server before it times out, throwing an error.&lt;br&gt;
Defaults to &lt;code&gt;30000&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;mongodb.socket.timeout.ms&lt;/code&gt;&lt;br&gt;
&lt;em&gt;The number of milliseconds the driver waits before a send/receive on the socket may timeout.&lt;br&gt;
A value of &lt;code&gt;0&lt;/code&gt; disables this behavior.
Defaults to &lt;code&gt;0&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other-features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a number of other new features coming with the 1.3.0.Alpha1 release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New SQL Server snapshot mode &lt;code&gt;initial_only&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2379&quot;&gt;DBZ-2379&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Postgres and possibly other DB connections are not properly shutdown when the task encounters thread interrupt (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2133&quot;&gt;DBZ-2133&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ignore non-existing table reported on Aurora via SHOW TABLES (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1939&quot;&gt;DBZ-1939&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra connector not getting events (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2086&quot;&gt;DBZ-2086&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PubSub Sink sends empty records (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2277&quot;&gt;DBZ-2277&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skipping LSN is inefficient and does not forward slot position (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2310&quot;&gt;DBZ-2310&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;message size is at least 68x larger for changes with bit varying columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2315&quot;&gt;DBZ-2315&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change events lost when connnector is restarted while processing transaction with PK update (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2329&quot;&gt;DBZ-2329&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Error when processing commitLogs related to list-type columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2345&quot;&gt;DBZ-2345&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix dependency groupId on Outbox Quarkus Extension documentation (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2367&quot;&gt;DBZ-2367&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cannot detect Azure Sql Version (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2373&quot;&gt;DBZ-2373&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ParallelSnapshotReader sometimes throws NPE  (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2387&quot;&gt;DBZ-2387&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.0-alpha1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading from earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/abhirockzz&quot;&gt;Abhishek Gupta&lt;/a&gt;,
&lt;a href=&quot;https://github.com/coryharperbind&quot;&gt;Cory Harper&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mtagle&quot;&gt;Moira Tagle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Victor Xiang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grzegorz8&quot;&gt;Grzegorz Kołakowski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bjoernhaeuser&quot;&gt;Björn Häuser&lt;/a&gt;,
&lt;a href=&quot;https://github.com/korzenek&quot;&gt;Lukasz Korzeniowski&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/jonaslins&quot;&gt;Jonas Lins&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.0.Alpha1! This initial pass in the 1.3 release line provides a number of useful new features: A new Debezium Server sink adapter for Azure Event Hubs A new SQL Server connector snapshot mode, initial_only Additional connection timeout options for the MongoDB Connector Overall, the community fixed not less than 31 issues for this release. Let&amp;#8217;s take a closer look at some of them in the remainder of this post.</summary></entry><entry><title type="html">Hello Debezium Team!</title><link href="https://debezium.io/blog/2020/07/28/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium Team!" /><published>2020-07-28T16:19:59+00:00</published><updated>2020-07-28T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/07/28/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/07/28/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hello everyone, my name is René Kerner and I recently joined Red Hat and the Debezium team.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I was working at trivago since 2011, and in 2016 we started using Debezium at version 0.4/0.5 for
capturing clickstreams in the offshore datacenters into Kafka and aggregate them in the central cluster.
We really intensified Debezium usage within one year and in 2017 we also used it for trivago&amp;#8217;s main data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In 2014 I did my first OSS contributions to Composer, PHP&amp;#8217;s dependency management and gave my first talk
on it at the Developer Conference (called code.talks for many years now).
Then in 2017 I did my first contributions to Debezium with work on the MySQL snapshot process
and fixing a MySQL TIME data type issue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In 2018 I left trivago and started working at Codecentric as a consultant for software architecture and
development (mainly JVM focus) and Apache Kafka, doing many trainings and workshops at German &quot;Fortune 500&quot;
companies (insurances, industrial sector, media). I was doing lots of networking at that time, where I
learned how awesome the community around Kafka is. I was always quite sad I didn&amp;#8217;t have more time
to focus on OSS projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let me share a bit more of trivago&amp;#8217;s story to Kafka and Debezium. Back in 2015/2016 we introduced Kafka
(version 0.9, 0.10 times) at trivago to handle the transport of our clickstream data from offshore
datacenters (US + Asia) into our central datacenter (EU).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first solution that we tried did its job, but getting messages in our desired
format, which was Google Protocol Buffers / Protobuf, into Kafka was relatively
hard. Furthermore the codebase of that tool wasn&amp;#8217;t very clean and extensions were
ugly and kind of hard.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With Kafka 0.9.0.0 Kafka Connect was introduced and stabilized over the next months. And in
winter 2016/2017 we discovered Debezium. A tool that was based on Kafka Connect, with a
much cleaner codebase and an easy, extendible way to apply our requirements regarding
Protobuf format and behaviour (with SMTs/Single Message Transforms, released in Kafka 0.10.2)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since these &quot;old times&quot; Debezium made very big development with many new connectors and
since July I&amp;#8217;m now part of the Debezium team, and I am proud and excited to work on such a great
OSS project because there are still awesome things on &lt;a href=&quot;https://debezium.io/roadmap/&quot;&gt;Debezium&amp;#8217;s Roadmap&lt;/a&gt;:
the new IBM Db2 connector will leave incubation state, Debezium Server will be easier to
operate on Kubernetes, and a PoC for a future Debezium management UI, and more and more to come.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Furthermore, I&amp;#8217;ve been dedicating my work to many things around OSS, Kafka and Debezium for years,
I always advocated people to use OSS, Kafka and Debezium, and supported them in different jobs and
roles to introduce it or extend its usage. That&amp;#8217;s why I&amp;#8217;m really excited that I am able to focus
my work to support Debezium and the Debezium community now!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;--René&lt;/p&gt;
&lt;/div&gt;</content><author><name>René Kerner</name></author><category term="community" /><category term="news" /><summary type="html">Hello everyone, my name is René Kerner and I recently joined Red Hat and the Debezium team. I was working at trivago since 2011, and in 2016 we started using Debezium at version 0.4/0.5 for capturing clickstreams in the offshore datacenters into Kafka and aggregate them in the central cluster. We really intensified Debezium usage within one year and in 2017 we also used it for trivago&amp;#8217;s main data. In 2014 I did my first OSS contributions to Composer, PHP&amp;#8217;s dependency management and gave my first talk on it at the Developer Conference (called code.talks for many years now). Then in 2017 I did my first contributions to Debezium with work on the MySQL snapshot process and fixing a MySQL TIME data type issue. In 2018 I left trivago and started working at Codecentric as a consultant for software architecture and development (mainly JVM focus) and Apache Kafka, doing many trainings and workshops at German &quot;Fortune 500&quot; companies (insurances, industrial sector, media). I was doing lots of networking at that time, where I learned how awesome the community around Kafka is. I was always quite sad I didn&amp;#8217;t have more time to focus on OSS projects.</summary></entry><entry><title type="html">Debezium 1.2.1.Final Released</title><link href="https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.2.1.Final Released" /><published>2020-07-16T16:19:59+00:00</published><updated>2020-07-16T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/07/16/debezium-1-2-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am happy to announce the release of Debezium &lt;strong&gt;1.2.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release includes several bug fixes to different Debezium connectors, and we highly recommend the upgrade from 1.2.0.Final and earlier versions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Debezium Postgres connector may have missed events from concurrent transactions when transitioning from snapshotting to streaming events from the WAL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2288&quot;&gt;DBZ-2288&lt;/a&gt;);
this is fixed now when using the &lt;a href=&quot;/documentation/reference/connectors/postgresql.html#postgresql-property-snapshot-mode&quot;&gt;exported snapshotting mode&lt;/a&gt;;
this mode should preferably be used, and for Debezium 1.3 we&amp;#8217;re planning for this to be the basis for all the existing snapshotting modes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Postgres JDBC driver got upgraded to 42.2.14 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2317&quot;&gt;DBZ-2317&lt;/a&gt;),
which fixes a CVE in the driver related to processing XML column values sourced from untrusted XML input&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium MySQL connector MariaDB&amp;#8217;s supports &lt;code&gt;ALTER TABLE&lt;/code&gt; statements with &lt;code&gt;IF EXISTS&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2219&quot;&gt;DBZ-2219&lt;/a&gt;);
it also handles single dimension &lt;code&gt;DECIMAL&lt;/code&gt; columns in &lt;code&gt;CAST&lt;/code&gt; expressions (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2305&quot;&gt;DBZ-2305&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The MySQL connector automatically filters out specific DML binlog entries from internal tables when using it with Amazon RDS (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2275&quot;&gt;DBZ-2275&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium MongoDB connector got more resilient against connection losses (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2141&quot;&gt;DBZ-2141&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;re using the &lt;a href=&quot;https://www.apicur.io/registry/&quot;&gt;Apicurio&lt;/a&gt; open-source API and schema registry for &lt;a href=&quot;/documentation/reference/configuration/avro.html&quot;&gt;managing the JSON and Avro schemas&lt;/a&gt; of your Debezium connectors,
then things got a bit simpler for you:
the Debezium container image for Kafka Connect comes with the required converters out of the box now
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2083&quot;&gt;DBZ-2083&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, 34 issues were fixed for this release; please refer to the &lt;a href=&quot;/releases/1.2/release-notes/#release-1.2.1-final&quot;&gt;release notes&lt;/a&gt; for the full list of addressed issues, upgrade procedures, and notes on any backward compatibility changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the members from the Debezium community contributing to this release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/frankkoornstra&quot;&gt;Frank Koornstra&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jgraf50&quot;&gt;John Graf&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhuiting&quot;&gt;Jos Huiting&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jhiza&quot;&gt;Justin Hiza&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/omarsmak&quot;&gt;Omar Al-Safi&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/rhauch&quot;&gt;Randall Hauch&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="testcontainers" /><category term="debezium-server" /><summary type="html">I am happy to announce the release of Debezium 1.2.1.Final! This release includes several bug fixes to different Debezium connectors, and we highly recommend the upgrade from 1.2.0.Final and earlier versions: The Debezium Postgres connector may have missed events from concurrent transactions when transitioning from snapshotting to streaming events from the WAL (DBZ-2288); this is fixed now when using the exported snapshotting mode; this mode should preferably be used, and for Debezium 1.3 we&amp;#8217;re planning for this to be the basis for all the existing snapshotting modes The Postgres JDBC driver got upgraded to 42.2.14 (DBZ-2317), which fixes a CVE in the driver related to processing XML column values sourced from untrusted XML input The Debezium MySQL connector MariaDB&amp;#8217;s supports ALTER TABLE statements with IF EXISTS (DBZ-2219); it also handles single dimension DECIMAL columns in CAST expressions (DBZ-2305) The MySQL connector automatically filters out specific DML binlog entries from internal tables when using it with Amazon RDS (DBZ-2275) The Debezium MongoDB connector got more resilient against connection losses (DBZ-2141)</summary></entry></feed>