<!DOCTYPE html> <html lang="en"> <head> <title>Building Audit Logs with Change Data Capture and Stream Processing Â· Debezium</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="https://static.jboss.org/theme/css/bootstrap-community/3.2.0.2/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="https://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="https://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="https://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="https://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="https://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="https://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
      @media (min-width: 980px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
      }
      @media (max-width: 979px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
      }
      @media (max-width: 650px) {
        .banner { width: 100%; margin: 0px auto; }
      }
      @media (max-width: 450px) {
        .banner { height: 90px; }
      }
    </style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
      hljs.initHighlightingOnLoad();
    </script> <script src="https://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
      /* adjusting the vertical spacing for when a stickynav is engaged */
      .breadcrumb-fixed > .active {
        color: #8c8f91;
      }
      .breadcrumb-fixed {
        margin: 70px 0 10px;
        padding: 8px 15px;
        margin-bottom: 20px;
        list-style: none;
        background-color: #f5f5f5;
        border-radius: 4px;
      }
      
      .breadcrumb-fixed > li {
        display: inline-block;
      }
    </style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="https://www.jboss.org/projects/about"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> <img src="/images/color_white_debezium_type_600px.svg" style="height: 32px; margin-right: 5px; margin-top: -5px;"> </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/documentation/faq/">FAQ</a></li> <li class=""><a href="/documentation/">DOCUMENTATION</a></li> <li class=""><a href="/releases/">RELEASES</a></li> <li class=""><a href="/community/">COMMUNITY</a></li> <li class="active"><a href="/blog/">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav" style="padding-left: 15px; padding-right: 15px;"> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a href="/blog">Home</a> <div class="icon"> <span class="icon-home"></span> </div> </li> <li class="item"> <a href="/blog.atom">Feed</a> <div class="icon"> <span class="icon-rss"></span> </div> </li> </ul> </div> <p></p> <div class="featured-posts"> <div id="featured" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Featured Posts </div> <ul style="padding-inline-start: 22px;"> <li style="margin-bottom: 3px;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/" style="font-size: 95%;"> Building Audit Logs with Change Data Capture and Stream Processing </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/07/12/streaming-cassandra-at-wepay-part-1/" style="font-size: 95%;"> Streaming Cassandra at WePay - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/" style="font-size: 95%;"> Reliable Microservices Data Exchange With the Outbox Pattern </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/" style="font-size: 95%;"> Automating Cache Invalidation With Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" style="font-size: 95%;"> Materializing Aggregate Views With Hibernate and Debezium </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/" style="font-size: 95%;"> Five Advantages of Log-Based Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/" style="font-size: 95%;"> Creating DDD aggregates with Debezium and Kafka Streams </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/" style="font-size: 95%;"> Streaming Data Changes from Your Database to Elasticsearch </a> </li> </ul> </div> <p></p> <div class="cloud-tags"> <div id="tags" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Tags </div> <div class="tag-cloud"> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/apache-kafka/">apache-kafka</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/avro/">avro</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/cassandra/">cassandra</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/community/">community</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/discussion/">discussion</a> </span> <span class="tag tag-6"> <a href="https://debezium.io/blog/tags/docker/">docker</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/elasticsearch/">elasticsearch</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/example/">example</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/examples/">examples</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/featured/">featured</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/fedora/">fedora</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/introduction/">introduction</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/json/">json</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/kafka/">kafka</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/kafka-streams/">kafka-streams</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/ksql/">ksql</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/kubernetes/">kubernetes</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/microservices/">microservices</a> </span> <span class="tag tag-4"> <a href="https://debezium.io/blog/tags/mongodb/">mongodb</a> </span> <span class="tag tag-6"> <a href="https://debezium.io/blog/tags/mysql/">mysql</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/news/">news</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/newsletter/">newsletter</a> </span> <span class="tag tag-2"> <a href="https://debezium.io/blog/tags/oracle/">oracle</a> </span> <span class="tag tag-5"> <a href="https://debezium.io/blog/tags/postgres/">postgres</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/presentation/">presentation</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/quarkus/">quarkus</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/rds/">rds</a> </span> <span class="tag tag-6"> <a href="https://debezium.io/blog/tags/releases/">releases</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/sentry/">sentry</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/serialization/">serialization</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/smt/">smt</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/sql/">sql</a> </span> <span class="tag tag-2"> <a href="https://debezium.io/blog/tags/sqlserver/">sqlserver</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/vagrant/">vagrant</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/website/">website</a> </span> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="post"> <div class="row" style="margin-left: 0; margin-right: 0; margin-bottom: 10px;"> <div class="col-sm-12" style="padding-left: 0px;"> <div style="display: table-cell; vertical-align: top;"> <div style="width: 72px; border: 1px solid #ccc; padding: 3px; display: inline-block;"> <img src="/images/gmorling.jpg" style="width: 64px;"> </div> </div> <div style="display: table-cell; vertical-align: top;"> <div style="margin-left: 8px;"> <span class="hidden-sm hidden-xs" style="font-size: 2.75rem; line-height: 1;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/">Building Audit Logs with Change Data Capture and Stream Processing</a> </span> <span class="hidden-md hidden-lg" style="font-size: 2rem; line-height: 1;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/">Building Audit Logs with Change Data Capture and Stream Processing</a> </span> <div class="byline" style="line-height: 1;"> <em> October 01, 2019 by Gunnar Morling </em> <div class="hidden-xs" style="margin-top: 5px;"> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/discussion/">discussion</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/examples/">examples</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/apache-kafka/">apache-kafka</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/kafka-streams/">kafka-streams</a> </div> </div> </div> </div> </div> </div> <div class="row" style="margin-left: 0; margin-right: 0;"> <div id="preamble"> <div class="sectionbody"> <div class="openblock teaser"> <div class="content"> <div class="paragraph"> <p>It is a common requirement for business applications to maintain some form of audit log, i.e. a persistent trail of all the changes to the application&#8217;s data. If you squint a bit, a Kafka topic with Debezium data change events is quite similar to that: sourced from database transaction logs, it describes all the changes to the records of an application. What&#8217;s missing though is some metadata: why, when and by whom was the data changed? In this post we&#8217;re going to explore how that metadata can be provided and exposed via change data capture (CDC), and how stream processing can be used to enrich the actual data change events with such metadata.</p> </div> </div> </div> <div class="paragraph"> <p>Reasons for maintaining data audit trails are manifold: e.g. regulatory requirements may mandate businesses to keep complete historic information of their customer, purchase order, invoice or other data. Also for an enterprise&#8217;s own purposes it can be very useful to have insight into why and how certain data has changed, e.g. allowing to improve business processes or analyze errors.</p> </div> <div class="paragraph"> <p>One common approach for creating audit trails are application-side libraries. Hooked into the chosen persistence library, they&#8217;d maintain specific column(s) in the data tables ("createdBy", "lastUpdated" etc.), and/or copy earlier record versions into some form of history tables.</p> </div> <div class="paragraph"> <p>There are some disadvantages to this, though:</p> </div> <div class="ulist"> <ul> <li> <p>writing records in history tables as part of OLTP transactions increases the number of executed statements within the transaction (for each update or delete, also an insert must be written into the corresponding history table) and thus may cause longer response times of the application</p> </li> <li> <p>oftentimes no audit events can be provided in case of bulk updates and deletes (e.g. <code>DELETE from purchaseorders where status = 'SHIPPED'</code>), as the listeners used to hook the library into the persistence framework are not aware of all the affected records</p> </li> <li> <p>changes done directly in the database cannot be tracked, e.g. when running a data load or bypassing the application during an emergency data patch</p> </li> </ul> </div> <div class="paragraph"> <p>Another technique are database triggers. They won&#8217;t miss any operations, no matter whether issued from the application or the database itself. They&#8217;ll also be able to process each record affected by a bulk statement. On the downside, there&#8217;s still is the problem of increased latency when executing triggers as part of OLTP transactions. Also, a process must be in place for installing and updating the triggers for each table.</p> </div> </div> </div> <div class="sect1"> <h2 id="audit_logs_based_on_change_data_capture"><a class="anchor" href="#audit_logs_based_on_change_data_capture"></a>Audit Logs Based on Change Data Capture</h2> <div class="sectionbody"> <div class="paragraph"> <p>The aforementioned problems don&#8217;t exist when leveraging the transaction log as the source for an audit trail and using change data capture for retrieving the change information and sending it into a message broker or log such as Apache Kafka.</p> </div> <div class="paragraph"> <p>Running asynchronously, the CDC process can extract the change data without impacting OLTP transactions. The transaction logs contain one entry whenever there&#8217;s a data change, be it issued from the application or directly executed in the database. There&#8217;ll be a log entry for each record updated or deleted in a bulk operation, so a change event for each of them can be produced. Also there is no impact on the data model, i.e. no special columns or history tables must be created.</p> </div> <div class="paragraph"> <p>But how can CDC access the metadata we&#8217;d discussed initially? This could for instance be data such as the application user that performed a data change, their IP address and device configuration, a tracing span id, or an identifier for the application use case.</p> </div> <div class="paragraph"> <p>As that metadata typically isn&#8217;t (nor shouldn&#8217;t) be stored in the actual business tables of an application, it must be provided separately. One approach is to have a separate table where this metadata is stored. For each executed transaction, the business application produces one record in that table, containing all the required metadata and using the transaction id as a primary key. When running manual data changes, it is easy to also provide the metadata record with an additional insert. As Debezium&#8217;s data change events contain the id of the transaction causing the specific change, the data change events and the metadata records can be correlated.</p> </div> <div class="paragraph"> <p>In the remainder of this post we&#8217;re going to take a closer look at how a business application can provide the transaction-scoped metadata and how data change events can be enriched with the corresponding metadata using the Kafka Streams API.</p> </div> </div> </div> <div class="sect1"> <h2 id="solution_overview"><a class="anchor" href="#solution_overview"></a>Solution Overview</h2> <div class="sectionbody"> <div class="paragraph"> <p>The following image shows the overall solution design, based on the example of a microservice for managing vegetable data:</p> </div> <div class="imageblock centered-image"> <img src="/images/auditing_overview.png" style="max-width:100%; margin-bottom:10px; margin-top:10px;" class="responsive-image" alt="Auditing With Change Data Capture and Stream Processing"> </div> <div class="paragraph"> <p>There are two services involved:</p> </div> <div class="ulist"> <ul> <li> <p><em>vegetables-service</em>: a simple REST service for inserting and updating vegetable data into a Postgres database; as part of its processing, it will not only update its actual "business table" <code>vegetable</code>, but also insert some auditing metadata into a dedicated metadata table <code>transaction_context_data</code>; Debezium is used to stream change events from the two tables into corresponding topics in Apache Kafka</p> </li> <li> <p><em>log-enricher</em>: a stream processing application built with Kafka Streams and Quarkus, which enriches the messages from the CDC topic containing the vegetable change events (<code>dbserver1.inventory.vegetable</code>) with the corresponding metadata in the <code>dbserver1.inventory.transaction_context_data</code> topic and writes the enriched vegetable change event back to Kafka into the <code>dbserver1.inventory.vegetable.enriched</code> topic.</p> </li> </ul> </div> <div class="paragraph"> <p>You can find a <a href="https://github.com/debezium/debezium-examples/tree/master/auditlog">complete example</a> with all the components and instruction for running them on GitHub.</p> </div> </div> </div> <div class="sect1"> <h2 id="providing_auditing_metadata"><a class="anchor" href="#providing_auditing_metadata"></a>Providing Auditing Metadata</h2> <div class="sectionbody"> <div class="paragraph"> <p>Let&#8217;s first discuss how an application such as the vegetable service can provide the required auditing metadata. As an example, the following metadata should be made available for auditing purposes:</p> </div> <div class="ulist"> <ul> <li> <p>The application user that did a data change, as represented by the <code>sub</code> claim of a JWT token (<a href="https://tools.ietf.org/html/rfc7519">JSON Web Token</a>)</p> </li> <li> <p>The request timestamp, as represented by the <code>Date</code> HTTP header</p> </li> <li> <p>A use case identifier, as provided via a custom Java annotation on the invoked REST resource method</p> </li> </ul> </div> <div class="paragraph"> <p>Here is a basic implementation of a REST resource for persisting a new vegetable using the <a href="https://jcp.org/en/jsr/detail?id=370">JAX-RS API</a>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Path("/vegetables")&#x000A;@RequestScoped&#x000A;@Produces(MediaType.APPLICATION_JSON)&#x000A;@Consumes(MediaType.APPLICATION_JSON)&#x000A;public class VegetableResource {&#x000A;&#x000A;    @Inject&#x000A;    VegetableService vegetableService;&#x000A;&#x000A;    @POST&#x000A;    @RolesAllowed({"farmers"})&#x000A;    @Transactional&#x000A;    @Audited(useCase="CREATE VEGETABLE")&#x000A;    public Response createVegetable(Vegetable vegetable) {&#x000A;        if (vegetable.getId() != null) {&#x000A;            return Response.status(Status.BAD_REQUEST.getStatusCode()).build();&#x000A;        }&#x000A;&#x000A;        vegetable = vegetableService.createVegetable(vegetable);&#x000A;&#x000A;        return Response.ok(vegetable).status(Status.CREATED).build();&#x000A;    }&#x000A;&#x000A;    // update, delete ...&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>If you&#8217;ve ever built REST services with JAX-RS before, the implementation will look familiar to you: a resource method annotated with <code>@POST</code> takes the incoming request payload and passes it to a service bean which is injected via CDI. The <code>@Audited</code> annotation is special, though. It is a custom annotation type which serves two purposes:</p> </div> <div class="ulist"> <ul> <li> <p>Specifying the use case that should be referenced in the audit log ("CREATE VEGETABLE")</p> </li> <li> <p>Binding an <a href="https://jcp.org/en/jsr/detail?id=318">interceptor</a> which will be triggered for each invocation of a method annotated with <code>@Audited</code></p> </li> </ul> </div> <div class="paragraph"> <p>That interceptor kicks in whenever a method annotated with <code>@Audited</code> is invoked and implements the logic for writing the transaction-scoped audit metadata. It looks like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Interceptor <i class="conum" data-value="1"></i><b>(1)</b>&#x000A;@Audited(useCase = "")&#x000A;@Priority(value = Interceptor.Priority.APPLICATION + 100) <i class="conum" data-value="2"></i><b>(2)</b>&#x000A;public class TransactionInterceptor {&#x000A;&#x000A;    @Inject&#x000A;    JsonWebToken jwt; <i class="conum" data-value="3"></i><b>(3)</b>&#x000A;&#x000A;    @Inject&#x000A;    EntityManager entityManager;&#x000A;&#x000A;    @Inject&#x000A;    HttpServletRequest request;&#x000A;&#x000A;    @AroundInvoke&#x000A;    public Object manageTransaction(InvocationContext ctx) throws Exception {&#x000A;        BigInteger txtId = (BigInteger) entityManager <i class="conum" data-value="4"></i><b>(4)</b>&#x000A;            .createNativeQuery("SELECT txid_current()")&#x000A;            .getSingleResult();&#x000A;        String useCase = ctx.getMethod().getAnnotation(Audited.class).useCase();&#x000A;&#x000A;        TransactionContextData context = new TransactionContextData(); <i class="conum" data-value="5"></i><b>(5)</b>&#x000A;&#x000A;        context.transactionId = txtId.longValueExact();&#x000A;        context.userName = jwt.&lt;String&gt;claim("sub").orElse("anonymous");&#x000A;        context.clientDate = getRequestDate();&#x000A;        context.useCase = useCase;&#x000A;&#x000A;        entityManager.persist(context);&#x000A;&#x000A;        return ctx.proceed(); <i class="conum" data-value="6"></i><b>(6)</b>&#x000A;    }&#x000A;&#x000A;    private ZonedDateTime getRequestDate() {&#x000A;        String requestDate = request.getHeader(HttpHeaders.DATE);&#x000A;        return requestDate != null ?&#x000A;            ZonedDateTime.parse(requestDate, DateTimeFormatter.RFC_1123_DATE_TIME) :&#x000A;            null;&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="colist arabic"> <table> <tr> <td><i class="conum" data-value="1"></i><b>1</b></td> <td><code>@Interceptor</code> and <code>@Audited</code> mark this as an interceptor bound to our custom <code>@Audited</code> annotion.</td> </tr> <tr> <td><i class="conum" data-value="2"></i><b>2</b></td> <td>The <code>@Priority</code> annotation controls at which point in the interceptor stack the auditing interceptor should be invoked. Any application-provided interceptors should have a priority larger than <code>Priority.APPLICATION</code> (2000); in particular, this ensures that a transaction will have been started before by means of the <code>@Transactional</code> annotation and its accompanying interceptor which run in the <code>Priority.PLATFORM_BEFORE</code> range (&lt; 1000).</td> </tr> <tr> <td><i class="conum" data-value="3"></i><b>3</b></td> <td>The caller&#8217;s JWT token injected via the <a href="https://microprofile.io/project/eclipse/microprofile-jwt-auth">MicroProfile JWT RBAC</a> API</td> </tr> </table> </div> <div class="paragraph"> <p>For each audited method the interceptor fires and will</p> </div> <div class="ulist"> <ul> <li> <p>obtain the current transaction id (the exact way for doing so is database-specific, in the example the <code>txid_current()</code> function from Postgres is called) <i class="conum" data-value="4"></i></p> </li> <li> <p>persist a <code>TransactionContextData</code> entity via JPA; its primary key value is the transaction id selected before, and it has attributes for the user name (obtained from the JWT token), the request date (obtained from the <code>DATE</code> HTTP request header) and the use case identifier (obtained from the <code>@Audited</code> annotation of the invoked method) <i class="conum" data-value="5"></i></p> </li> <li> <p>continue the call flow of the invoked method <i class="conum" data-value="6"></i></p> </li> </ul> </div> <div class="paragraph"> <p>When invoking the REST service to create and update a few vegetables, the following records should be created in the database (refer to the README in the provided example for instructions on building the example code and <a href="https://github.com/debezium/debezium-examples/tree/master/auditlog#inserting-some-data-and-observing-the-audit-log">invoking the vegetable service</a> with a suitable JWT token):</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-sql" data-lang="sql">vegetablesdb&gt; select * from inventory.vegetable;&#x000A;+------+---------------+---------+&#x000A;| id   | description   | name    |&#x000A;|------+---------------+---------|&#x000A;| 1    | Spicy!        | Potatoe |&#x000A;| 11   | Delicious!    | Pumpkin |&#x000A;| 10   | Tasty!        | Tomatoe |&#x000A;+------+---------------+---------+</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-sql" data-lang="sql">vegetablesdb&gt; select * from inventory.transaction_context_data;&#x000A;+------------------+---------------------+------------------+----------------+&#x000A;| transaction_id   | client_date         | usecase          | user_name      |&#x000A;|------------------+---------------------+------------------+----------------|&#x000A;| 608              | 2019-08-22 08:12:31 | CREATE VEGETABLE | farmerbob      |&#x000A;| 609              | 2019-08-22 08:12:31 | CREATE VEGETABLE | farmerbob      |&#x000A;| 610              | 2019-08-22 08:12:31 | UPDATE VEGETABLE | farmermargaret |&#x000A;+------------------+---------------------+------------------+----------------+</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="enriching_change_events_with_auditing_metadata"><a class="anchor" href="#enriching_change_events_with_auditing_metadata"></a>Enriching Change Events with Auditing Metadata</h2> <div class="sectionbody"> <div class="paragraph"> <p>With the business data (vegetables) and the transaction-scoped metadata being stored in the database, it&#8217;s time to set up the <a href="/documentation/reference/0.10/connectors/postgresql.html">Debezium Postgres connector</a> and stream the data changes from the <code>vegetable</code> and <code>transaction_context_data</code> tables into corresponding Kafka topics. Again refer to the example README file for the details of <a href="https://github.com/debezium/debezium-examples/tree/master/auditlog#deploy-the-debezium-postgres-connector">deploying the connector</a>.</p> </div> <div class="paragraph"> <p>The <code>dbserver1.inventory.vegetable</code> topic should contain change events for created, updated and deleted vegetable records, whereas the <code>dbserver1.inventory.transaction_context_data</code> topic should only contain create messages for each inserted metadata record.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Topic Retention</div> <div class="paragraph"> <p>In order to manage the growth of involved topics, the retention policy for each topic should be well-defined. For instance for the actual audit log topic with the enriched change events, a time based retention policy might be suitable, keeping each log event for as long as needed as per your requirements. The transaction metadata topic on the other hand can be fairly short-lived, as its entries are not needed any longer, once all corresponding data change events have been processed. It may be a good idea to set up some monitoring of the end-to-end lag in order to make sure the log enricher stream application keeps up with the incoming messages and doesn&#8217;t fall behind that far so it is at risk of transaction messages being discarded before processing the corresponding change events.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Now, if we look at messages from the two topics, we can see that they can be correlated based on the transaction id. It is part of the <code>source</code> structure of vegetable change events, and it is the message key of transaction metadata events:</p> </div> <div class="imageblock centered-image"> <img src="/images/auditing_input_messages.png" style="max-width:100%; margin-bottom:10px; margin-top:10px;" class="responsive-image" alt="Vegetable and Transaction Metadata Messages"> </div> <div class="paragraph"> <p>Once we&#8217;ve found the corresponding transaction event for a given vegetable change event, the <code>client_date</code>, <code>usecase</code> and <code>user_name</code> attributes from the former can be added to the latter:</p> </div> <div class="imageblock centered-image"> <img src="/images/auditing_output_message.png" style="max-width:100%; margin-bottom:10px; margin-top:10px;" class="responsive-image" alt="Enriched Vegetable Message"> </div> <div class="paragraph"> <p>This kind of message transformation is a perfect use case for <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a>, a Java API for implementing stream processing applications on top of Kafka topics, providing operators that let you filter, transform, aggregate and join Kafka messages.</p> </div> <div class="paragraph"> <p>As runtime environment for our stream processing application we&#8217;re going to use <a href="https://quarkus.io/">Quarkus</a>, which is "a Kubernetes Native Java stack tailored for GraalVM &amp; OpenJDK HotSpot, crafted from the best of breed Java libraries and standards".</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Building Kafka Streams with Quarkus</div> <div class="paragraph"> <p>Amongst many others, Quarkus comes with an <a href="https://quarkus.io/guides/kafka-streams-guide">extension for Kafka Streams</a>, which allows to build stream processing applications running on the JVM and as native code compiled ahead-of-time. It takes care of the lifecycle of the streaming topology, so you don&#8217;t have to deal with details like registering JVM shutdown hooks, awaiting the creation of all input topics and more.</p> </div> <div class="paragraph"> <p>The extension also comes with "live development" support, which automatically reloads the stream processing application while you&#8217;re working on it, allowing for very fast turnaround cycles during development.</p> </div> </td> </tr> </table> </div> <div class="sect2"> <h3 id="the_joining_logic"><a class="anchor" href="#the_joining_logic"></a>The Joining Logic</h3> <div class="paragraph"> <p>When thinking about the actual implementation of the enrichment logic, a <a href="https://kafka.apache.org/23/documentation/streams/developer-guide/dsl-api.html#kstream-kstream-join">stream-to-stream</a> join might appear as a suitable solution. By creating <code>KStream</code>s for the two topics, we may try and implement the joining functionality. One challenge though is how to define a suitable <a href="https://kafka.apache.org/23/documentation/streams/developer-guide/dsl-api.html#windowing-sliding">joining window</a>, as there is no timing guarantees between messages on the two topics, and we must not miss any event.</p> </div> <div class="paragraph"> <p>Another problem arises in regards to ordering guarantees of the change events. By default, Debezium will use a table&#8217;s primary key as the message key for the corresponding Kafka messages. This means that all messages for the same vegetable record will have the same key and thus will go into the same partition of the vegetables Kafka topic. This in turn guarantees that a consumer of these events sees all the messages pertaining to the same vegetable record in the exact same order as they were created.</p> </div> <div class="paragraph"> <p>Now, in order to join the two streams, the message key must be the same on both sides. This means the vegetables topic must be re-keyed by transaction id (we cannot re-key the transaction metadata topic, as there&#8217;s no information about concerned vegetables contained in the metadata events; and even if that were the case, one transaction might impact multiple vegetable records). By doing so, we&#8217;d loose the original ordering guarantees, though. One vegetable record might be modified in two subsequent transactions, and its change events may end up in different partitions of the re-keyed topic, which may cause a consumer to receive the second change event before the first one.</p> </div> <div class="paragraph"> <p>If a <code>KStream</code>-<code>KStream</code> join isn&#8217;t feasible, what else could be done? <a href="https://kafka.apache.org/23/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-joins-kstream-globalktable">A join</a> between a <code>KStream</code> and <code>GlobalKTable</code> looks promising, too. It doesn&#8217;t have the <a href="https://kafka.apache.org/23/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-joins-co-partitioning">co-partitioning requirements</a> of stream-to-stream joins, as all partitions of the <code>GlobalKTable</code> are present on all nodes of a distributed Kafka Streams application. This seems like an acceptable trade-off, because the messages from the transaction metadata topic can be discarded rather quickly and the size of the corresponding table should be within reasonable bounds. So we could have a <code>KStream</code> sourced from the vegetables topic and a <code>GlobalKTable</code> based on the transaction metadata topic.</p> </div> <div class="paragraph"> <p>But unfortunately, there is a timing issue: as the messages are consumed from multiple topics, it may happen that at the point in time when an element from the vegetables stream is processed, the corresponding transaction metadata message isn&#8217;t available yet. So depending on whether we&#8217;d be using an inner join or a left join, we&#8217;d in this case either skip change events or propagate them without having enriched them with the transaction metadata. Both outcomes are not desirable.</p> </div> </div> <div class="sect2"> <h3 id="customized_joins_with_buffering"><a class="anchor" href="#customized_joins_with_buffering"></a>Customized Joins With Buffering</h3> <div class="paragraph"> <p>The combination of <code>KStream</code> and <code>GlobalKTable</code> still hints into the right direction. Only that instead of relying on the built-in join operators we&#8217;ll have to implement a custom joining logic. The basic idea is to buffer messages arriving on the vegetable <code>KStream</code> until the corresponding transaction metadata message is available from the <code>GlobalKTable</code>s state store. This can be achieved by creating a custom <a href="https://kafka.apache.org/23/javadoc/org/apache/kafka/streams/kstream/KStream.html#transform-org.apache.kafka.streams.kstream.TransformerSupplier-java.lang.String&#8230;&#8203;-">transformer</a> which implements the required buffering logic and is applied to the vegetable <code>KStream</code>.</p> </div> <div class="paragraph"> <p>Let&#8217;s begin with the streaming topology itself. Thanks to the Quarkus Kafka Streams extension, a CDI producer method returning the <code>Topology</code> object is all that&#8217;s needed for that:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class TopologyProducer {&#x000A;&#x000A;    static final String STREAM_BUFFER_NAME = "stream-buffer-state-store";&#x000A;    static final String STORE_NAME = "transaction-meta-data";&#x000A;&#x000A;    @ConfigProperty(name = "audit.context.data.topic")&#x000A;    String txContextDataTopic;&#x000A;&#x000A;    @ConfigProperty(name = "audit.vegetables.topic")&#x000A;    String vegetablesTopic;&#x000A;&#x000A;    @ConfigProperty(name = "audit.vegetables.enriched.topic")&#x000A;    String vegetablesEnrichedTopic;&#x000A;&#x000A;    @Produces&#x000A;    public Topology buildTopology() {&#x000A;        StreamsBuilder builder = new StreamsBuilder();&#x000A;&#x000A;        StoreBuilder&lt;KeyValueStore&lt;Long, JsonObject&gt;&gt; streamBufferStateStore =&#x000A;                Stores&#x000A;                    .keyValueStoreBuilder(&#x000A;                        Stores.persistentKeyValueStore(STREAM_BUFFER_NAME),&#x000A;                        new Serdes.LongSerde(),&#x000A;                        new JsonObjectSerde()&#x000A;                    )&#x000A;                    .withCachingDisabled();&#x000A;            builder.addStateStore(streamBufferStateStore); <i class="conum" data-value="1"></i><b>(1)</b>&#x000A;&#x000A;        builder.globalTable(txContextDataTopic, Materialized.as(STORE_NAME)); <i class="conum" data-value="2"></i><b>(2)</b>&#x000A;&#x000A;        builder.&lt;JsonObject, JsonObject&gt;stream(vegetablesTopic) <i class="conum" data-value="3"></i><b>(3)</b>&#x000A;                .filter((id, changeEvent) -&gt; changeEvent != null)&#x000A;                .filter((id, changeEvent) -&gt; !changeEvent.getString("op").equals("r"))&#x000A;                .transform(() -&gt; new ChangeEventEnricher(), STREAM_BUFFER_NAME)&#x000A;                .to(vegetablesEnrichedTopic);&#x000A;&#x000A;        return builder.build();&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="colist arabic"> <table> <tr> <td><i class="conum" data-value="1"></i><b>1</b></td> <td>State store which will serve as the buffer for change events that cannot be processed yet</td> </tr> <tr> <td><i class="conum" data-value="2"></i><b>2</b></td> <td><code>GlobalKTable</code> based on the transaction metadata topic</td> </tr> <tr> <td><i class="conum" data-value="3"></i><b>3</b></td> <td><code>KStream</code> based on the vegetables topic; on this stream, any incoming tombstone markers are filtered, the reasoning being that the retention policy for an audit trail topic typically should be time-based than based on log compaction; <div class="paragraph"> <p>similarly, snapshot events are filtered, assuming they are not relevant for an audit trail and there wouldn&#8217;t be any corresponding metadata provided by the application for the snapshot transaction initiated by the Debezium connector</p> </div> <div class="paragraph"> <p>Any other messages are enriched with the corresponding transaction metadata via a custom <code>Transformer</code> (see below) and finally are written to an output topic</p> </div></td> </tr> </table> </div> <div class="paragraph"> <p>The topic names are injected using the <a href="https://microprofile.io/project/eclipse/microprofile-config">MicroProfile Config API</a>, with the values being provided in Quarkus <em>application.properties</em> configuration file. Besides the topic names, this file also has the information about the Kafka bootstrap server, default serdes any more:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>audit.context.data.topic=dbserver1.inventory.transaction_context_data&#x000A;audit.vegetables.topic=dbserver1.inventory.vegetable&#x000A;audit.vegetables.enriched.topic=dbserver1.inventory.vegetable.enriched&#x000A;&#x000A;# may be overridden with env vars&#x000A;quarkus.kafka-streams.bootstrap-servers=localhost:9092&#x000A;quarkus.kafka-streams.application-id=auditlog-enricher&#x000A;quarkus.kafka-streams.topics=${audit.context.data.topic},${audit.vegetables.topic}&#x000A;&#x000A;# pass-through&#x000A;kafka-streams.cache.max.bytes.buffering=10240&#x000A;kafka-streams.commit.interval.ms=1000&#x000A;kafka-streams.metadata.max.age.ms=500&#x000A;kafka-streams.auto.offset.reset=earliest&#x000A;kafka-streams.metrics.recording.level=DEBUG&#x000A;kafka-streams.default.key.serde=io.debezium.demos.auditing.enricher.JsonObjectSerde&#x000A;kafka-streams.default.value.serde=io.debezium.demos.auditing.enricher.JsonObjectSerde&#x000A;kafka-streams.processing.guarantee=exactly_once</code></pre> </div> </div> <div class="paragraph"> <p>In the next step let&#8217;s take a look at the <code>ChangeEventEnricher</code> class, our custom transformer. The implemention is based on the assumption that change events are serialized as JSON, but of course it could be done equally well using other formats such as Avro or Protocol Buffers.</p> </div> <div class="paragraph"> <p>This is a bit of code, but hopefully its decomposition into multiple smaller methods makes it comprehensible:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">class ChangeEventEnricher implements Transformer&#x000A;        &lt;JsonObject, JsonObject, KeyValue&lt;JsonObject, JsonObject&gt;&gt; {&#x000A;&#x000A;    private static final Long BUFFER_OFFSETS_KEY = -1L;&#x000A;&#x000A;    private static final Logger LOG = LoggerFactory.getLogger(ChangeEventEnricher.class);&#x000A;&#x000A;    private ProcessorContext context;&#x000A;    private KeyValueStore&lt;JsonObject, JsonObject&gt; txMetaDataStore;&#x000A;    private KeyValueStore&lt;Long, JsonObject&gt; streamBuffer; <i class="conum" data-value="5"></i><b>(5)</b>&#x000A;&#x000A;    @Override&#x000A;    @SuppressWarnings("unchecked")&#x000A;    public void init(ProcessorContext context) {&#x000A;        this.context = context;&#x000A;        streamBuffer = (KeyValueStore&lt;Long, JsonObject&gt;) context.getStateStore(&#x000A;            TopologyProducer.STREAM_BUFFER_NAME&#x000A;        );&#x000A;        txMetaDataStore = (KeyValueStore&lt;JsonObject, JsonObject&gt;) context.getStateStore(&#x000A;            TopologyProducer.STORE_NAME&#x000A;        );&#x000A;&#x000A;        context.schedule(&#x000A;            Duration.ofSeconds(1),&#x000A;            PunctuationType.WALL_CLOCK_TIME, ts -&gt; enrichAndEmitBufferedEvents()&#x000A;        ); <i class="conum" data-value="4"></i><b>(4)</b>&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public KeyValue&lt;JsonObject, JsonObject&gt; transform(JsonObject key, JsonObject value) {&#x000A;        boolean enrichedAllBufferedEvents = enrichAndEmitBufferedEvents(); <i class="conum" data-value="3"></i><b>(3)</b>&#x000A;&#x000A;        if (!enrichedAllBufferedEvents) {&#x000A;            bufferChangeEvent(key, value);&#x000A;            return null;&#x000A;        }&#x000A;&#x000A;        KeyValue&lt;JsonObject, JsonObject&gt; enriched = enrichWithTxMetaData(key, value); <i class="conum" data-value="1"></i><b>(1)</b>&#x000A;        if (enriched == null) { <i class="conum" data-value="2"></i><b>(2)</b>&#x000A;            bufferChangeEvent(key, value);&#x000A;        }&#x000A;&#x000A;        return enriched;&#x000A;    }&#x000A;&#x000A;    /**&#x000A;     * Enriches the buffered change event(s) with the metadata from the associated&#x000A;     * transactions and forwards them.&#x000A;     *&#x000A;     * @return {@code true}, if all buffered events were enriched and forwarded,&#x000A;     *         {@code false} otherwise.&#x000A;     */&#x000A;    private boolean enrichAndEmitBufferedEvents() { <i class="conum" data-value="3"></i><b>(3)</b>&#x000A;        Optional&lt;BufferOffsets&gt; seq = bufferOffsets();&#x000A;&#x000A;        if (!seq.isPresent()) {&#x000A;            return true;&#x000A;        }&#x000A;&#x000A;        BufferOffsets sequence = seq.get();&#x000A;&#x000A;        boolean enrichedAllBuffered = true;&#x000A;&#x000A;        for(long i = sequence.getFirstValue(); i &lt; sequence.getNextValue(); i++) {&#x000A;            JsonObject buffered = streamBuffer.get(i);&#x000A;&#x000A;            LOG.info("Processing buffered change event for key {}",&#x000A;                    buffered.getJsonObject("key"));&#x000A;&#x000A;            KeyValue&lt;JsonObject, JsonObject&gt; enriched = enrichWithTxMetaData(&#x000A;                    buffered.getJsonObject("key"), buffered.getJsonObject("changeEvent"));&#x000A;            if (enriched == null) {&#x000A;                enrichedAllBuffered = false;&#x000A;                break;&#x000A;            }&#x000A;&#x000A;            context.forward(enriched.key, enriched.value);&#x000A;            streamBuffer.delete(i);&#x000A;            sequence.incrementFirstValue();&#x000A;        }&#x000A;&#x000A;        if (sequence.isModified()) {&#x000A;            streamBuffer.put(BUFFER_OFFSETS_KEY, sequence.toJson());&#x000A;        }&#x000A;&#x000A;        return enrichedAllBuffered;&#x000A;    }&#x000A;&#x000A;    /**&#x000A;     * Adds the given change event to the stream-side buffer.&#x000A;     */&#x000A;    private void bufferChangeEvent(JsonObject key, JsonObject changeEvent) { <i class="conum" data-value="2"></i><b>(2)</b>&#x000A;        LOG.info("Buffering change event for key {}", key);&#x000A;&#x000A;        BufferOffsets sequence = bufferOffsets().orElseGet(BufferOffsets::initial);&#x000A;&#x000A;        JsonObject wrapper = Json.createObjectBuilder()&#x000A;                .add("key", key)&#x000A;                .add("changeEvent", changeEvent)&#x000A;                .build();&#x000A;&#x000A;        streamBuffer.putAll(Arrays.asList(&#x000A;                KeyValue.pair(sequence.getNextValueAndIncrement(), wrapper),&#x000A;                KeyValue.pair(BUFFER_OFFSETS_KEY, sequence.toJson())&#x000A;        ));&#x000A;    }&#x000A;&#x000A;    /**&#x000A;     * Enriches the given change event with the metadata from the associated&#x000A;     * transaction.&#x000A;     *&#x000A;     * @return The enriched change event or {@code null} if no metadata for the&#x000A;     *         associated transaction was found.&#x000A;     */&#x000A;    private KeyValue&lt;JsonObject, JsonObject&gt; enrichWithTxMetaData(JsonObject key,&#x000A;            JsonObject changeEvent) { <i class="conum" data-value="1"></i><b>(1)</b>&#x000A;        JsonObject txId = Json.createObjectBuilder()&#x000A;                .add("transaction_id", changeEvent.get("source").asJsonObject()&#x000A;                        .getJsonNumber("txId").longValue())&#x000A;                .build();&#x000A;&#x000A;        JsonObject metaData = txMetaDataStore.get(txId);&#x000A;&#x000A;        if (metaData != null) {&#x000A;            LOG.info("Enriched change event for key {}", key);&#x000A;&#x000A;            metaData = Json.createObjectBuilder(metaData.get("after").asJsonObject())&#x000A;                    .remove("transaction_id")&#x000A;                    .build();&#x000A;&#x000A;            return KeyValue.pair(&#x000A;                    key,&#x000A;                    Json.createObjectBuilder(changeEvent)&#x000A;                        .add("audit", metaData)&#x000A;                        .build()&#x000A;            );&#x000A;        }&#x000A;&#x000A;        LOG.warn("No metadata found for transaction {}", txId);&#x000A;        return null;&#x000A;    }&#x000A;&#x000A;    private Optional&lt;BufferOffsets&gt; bufferOffsets() {&#x000A;        JsonObject bufferOffsets = streamBuffer.get(BUFFER_OFFSETS_KEY);&#x000A;        if (bufferOffsets == null) {&#x000A;            return Optional.empty();&#x000A;        }&#x000A;        else {&#x000A;            return Optional.of(BufferOffsets.fromJson(bufferOffsets));&#x000A;        }&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public void close() {&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="colist arabic"> <table> <tr> <td><i class="conum" data-value="1"></i><b>1</b></td> <td>When a vegetables change event arrives, look up the corresponding metadata in the state store of the transaction topic&#8217;s <code>GlobalKTable</code>, using the transaction id from the <code>source</code> block of the change event as the key; if the metadata could be found, add the metadata to change event (under the <code>audit</code> field) and return that enriched event</td> </tr> <tr> <td><i class="conum" data-value="2"></i><b>2</b></td> <td>If the metadata could not be found, add the incoming event into the buffer of change events and return</td> </tr> <tr> <td><i class="conum" data-value="3"></i><b>3</b></td> <td>Before actually getting to the incoming event, all buffered events are processed; this is required to make sure that the original change events is retained; only if all could be enriched, the incoming event will be processed, too</td> </tr> <tr> <td><i class="conum" data-value="4"></i><b>4</b></td> <td>In order to emit buffered events also if no new change event is coming in, a punctuation is scheduled that periodically processes the buffer</td> </tr> <tr> <td><i class="conum" data-value="5"></i><b>5</b></td> <td>A buffer for vegetable events whose corresponding metadata hasn&#8217;t arrived yet</td> </tr> </table> </div> <div class="paragraph"> <p>The key piece is the buffer for unprocessable change events. To maintain the order of events, the buffer must be processed in order of insertion, beginning with the event inserted first (think of a FIFO queue). As there&#8217;s no guaranteed traversing order when getting all the entries from a <code>KeyValueStore</code>, this is implemented by using the values of a strictly increasing sequence as the keys. A <a href="https://github.com/debezium/debezium-examples/blob/master/auditlog/log-enricher/src/main/java/io/debezium/demos/auditing/enricher/BufferOffsets.java">special entry</a> in the key value store is used to store the information about the current "oldest" index in the buffer and the next sequence value.</p> </div> <div class="paragraph"> <p>One could also think of alternative implementations for such buffer, e.g. based on a Kafka topic or a custom <code>KeyValueStore</code> implementation that ensures iteration order from oldest to newest entry. Ultimately, it could also be useful if Kafka Streams came with built-in means of retrying a stream element that cannot be joined yet; this would avoid any custom buffering implementation.</p> </div> <div class="paragraph"> <p>With the custom transformer logic in place, we can build the Quarkus project and run the stream processing application. You should see messages like this in the <code>dbserver1.inventory.vegetable.enriched</code> topic:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">{"id":10}&#x000A;{&#x000A;    "before": {&#x000A;        "id": 10,&#x000A;        "description": "Yummy!",&#x000A;        "name": "Tomatoe"&#x000A;    },&#x000A;    "after": {&#x000A;        "id": 10,&#x000A;        "description": "Tasty!",&#x000A;        "name": "Tomatoe"&#x000A;    },&#x000A;    "source": {&#x000A;        "version": "0.10.0-SNAPSHOT",&#x000A;        "connector": "postgresql",&#x000A;        "name": "dbserver1",&#x000A;        "ts_ms": 1569700445392,&#x000A;        "snapshot": "false",&#x000A;        "db": "vegetablesdb",&#x000A;        "schema": "inventory",&#x000A;        "table": "vegetable",&#x000A;        "txId": 610,&#x000A;        "lsn": 34204240,&#x000A;        "xmin": null&#x000A;    },&#x000A;    "op": "u",&#x000A;    "ts_ms": 1569700445537,&#x000A;    "audit": {&#x000A;        "client_date": 1566461551000000,&#x000A;        "usecase": "UPDATE VEGETABLE",&#x000A;        "user_name": "farmermargaret"&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Of course, the buffer processing logic may be adjusted as per your specific requirements; for instance instead of indefinitely waiting for corresponding transaction metadata, we may also decide that it makes more sense to propagate change events unenriched after some waiting time or to raise an exception indicating the missing metadata.</p> </div> <div class="paragraph"> <p>In order to see whether the buffering works as expected, you could do a small experiment: modify a vegetable record using SQL directly in the database. Debezium will capture the event, but as there&#8217;s no corresponding transaction metadata provided, the event will not be forwarded to the enriched vegetables topic. If you add another vegetable using the REST API, this one also will not be propagated: although there is a metadata record for it, it&#8217;s blocked by the other change event. Only once you have inserted a metadata record for the first change&#8217;s transaction into the <code>transaction_context_data</code> table, both change events will be processed and sent to the output topic.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this blog post we&#8217;ve discussed how change data capture in combination with stream processing can be used to build audit logs in an efficient, low-overhead way. In contrast to library and trigger-based approaches, the events that form the audit trail are retrieved via CDC from the database&#8217;s transaction logs, and apart from the insertion of a single metadata record per transaction (which in similar form would be required for any kind of audit log), no overhead to OLTP transactions is incurred. Also audit log entries can be obtained when data records are subject to bulk updates or deletes, something typically not possible with library-based auditing solutions.</p> </div> <div class="paragraph"> <p>Additional metadata that typically should be part of an audit log, can be provided by the application via a separate table, which also is captured via Debezium. With the help of Kafka Streams the actual data change events can be enriched with the data from that metadata table.</p> </div> <div class="paragraph"> <p>One aspect we haven&#8217;t discussed yet is querying the audit trail entries, e.g. to examine specific earlier versions of the data. To do so, the enriched change data events typically would be stored in a queryable database. Unlike a basic data replication pipeline, not only the latest version of each record would be stored in the database in that case, but all the versions, i.e. the primary keys typically would be amended with the transaction id of each change. This would allow to select single data records or even joins of multiple tables to get the data valid as per a given transaction id. How this could be implemented in detail may be discussed in a future post.</p> </div> <div class="paragraph"> <p>Your feedback on this approach for building audit logs is very welcomed, just post a comment below. To get started with your own implementation, you can check out <a href="https://github.com/debezium/debezium-examples/tree/master/auditlog">the code</a> in the Debezium examples repository on GitHub.</p> </div> <div class="paragraph"> <p><em>Many thanks to <a href="https://twitter.com/crancran77">Chris Cranford</a>, <a href="https://twitter.com/hpgrahsl">Hans-Peter Grahsl</a>, <a href="https://twitter.com/hashhar">Ashhar Hasan</a>, <a href="https://twitter.com/jbfletch_">Anna McDonald</a> and Jiri Pechanec for their feedback while working on this post and the accompanying example code!</em></p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> </div> <div class="well"> <div class="row"> <div class="col-md-8"> <h2>Gunnar Morling</h2> <p> <span class="bio-size">Gunnar is a software engineer at Red Hat and open-source enthusiast by heart. A long-time Hibernate core team member, he's now the project lead of Debezium. Gunnar is the spec lead for Bean Validation 2.0 (JSR 380). Heâs based in Hamburg, Germany.</span> </p> <p class="bio-size"> <a href="https://twitter.com/gunnarmorling"> <i class="icon-twitter"></i> </a> &nbsp; <a href="https://github.com/gunnarmorling"> <i class="icon-github"></i> </a> &nbsp; </p> </div> <div class="col-md-4"> <img alt="" class="img-responsive pull-right portrait" src="/images/gmorling.jpg"> </div> </div> </div> <div class="comments"> <div id="disqus_thread"></div> <script type="text/javascript">
                            var disqus_shortname = 'Debezium';
                            var disqus_url = "https://debezium.io/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/";
                            var disqus_developer = null;
                            var disqus_identifier = null;
                            (function() {
                              var dsq = document.createElement("script"); dsq.type = "text/javascript"; dsq.async = true;
                              dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                              (document.getElementsByTagName("head")[0] || document.getElementsByTagName("body")[0]).appendChild(dsq);
                            })();
                            </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript=Debezium">comments powered by Disqus.</a></noscript> </div> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2019 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/documentation/features" title="Features">Features</a> </li> <li> <a href="/documentation/install/stable/" title="Install">Install</a> </li> <li> <a href="/documentation/architecture/" title="Architecture">Architecture</a> </li> <li> <a href="/documentation/faq/" title="FAQ">FAQ</a> </li> <li> <a href="/community/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/user" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="https://www.redhat.com/"><img src="/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="https://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.2/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
        var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
        var urlSplit = coreUrl.toLowerCase().split(/\//);
        var urlLast = urlSplit[urlSplit.length-1];
        var pageNameString = "";
        var siteName = "";
        var minorSectionIndex = 3
        if (urlLast == "") {
            urlSplit.splice(-1,1);
        }
        if (urlLast.search(/\./) >= 0) {
            if (urlLast == "index.html") {
                urlSplit.splice(-1,1);
            }
            else {
                urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
            }
        }
        siteName = urlSplit[2].split(".")[1];
        s.prop14 = s.eVar27 = siteName || "";
        s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
        s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
        pageNameString = urlSplit.splice(3).join(" | ");
        s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
        s.server = "jboss";
        s.channel = "jboss | community";
        s.prop4 = s.eVar23 = encodeURI(document.URL);
        s.prop21 = s.eVar18 = coreUrl;
        s.prop2 = s.eVar22 = "en";
        s.prop3 = s.eVar19 = "us";
        //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
        if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
        //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
      document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script> <script type="text/javascript">
      try {
      var pageTracker = _gat._getTracker("UA-10656779-1");
      pageTracker._trackPageview();
      } catch(err) {}</script> <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       
      ga('create', 'UA-76464546-1', 'auto');
      ga('send', 'pageview');
      ga('set', 'anonymizeIp', true);
      ga('require', 'linkid', 'linkid.js');
      
      </script> </div> </body> </html>