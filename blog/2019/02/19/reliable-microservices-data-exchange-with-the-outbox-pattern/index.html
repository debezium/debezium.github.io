<!DOCTYPE html> <html lang="en"> <head> <title>Reliable Microservices Data Exchange With the Outbox Pattern Â· Debezium</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="https://static.jboss.org/theme/css/bootstrap-community/3.2.0.2/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="https://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="https://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="https://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="https://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="https://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="https://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
  @media (min-width: 980px) {
    .banner { background-image: url(https://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
  }
  @media (max-width: 979px) {
    .banner { background-image: url(https://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
  }
  @media (max-width: 650px) {
    .banner { width: 100%; margin: 0px auto; }
  }
  @media (max-width: 450px) {
    .banner { height: 90px; }
  }
</style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
hljs.initHighlightingOnLoad();
</script> <script src="https://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
  /* adjusting the vertical spacing for when a stickynav is engaged */
  .breadcrumb-fixed > .active {
    color: #8c8f91;
  }
  .breadcrumb-fixed {
    margin: 70px 0 10px;
    padding: 8px 15px;
    margin-bottom: 20px;
    list-style: none;
    background-color: #f5f5f5;
    border-radius: 4px;
  }
  
  .breadcrumb-fixed > li {
    display: inline-block;
  }
</style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="https://www.jboss.org/projects/about"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> <img src="/images/color_white_debezium_type_600px.svg" style="height: 32px; margin-right: 5px; margin-top: -5px;"> </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/documentation/faq/">FAQ</a></li> <li class=""><a href="/documentation/">DOCUMENTATION</a></li> <li class=""><a href="/releases/">RELEASES</a></li> <li class=""><a href="/community/">COMMUNITY</a></li> <li class="active"><a href="/blog/">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav" style="padding-left: 15px; padding-right: 15px;"> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a href="/blog">Home</a> <div class="icon"> <span class="icon-home"></span> </div> </li> <li class="item"> <a href="/blog.atom">Feed</a> <div class="icon"> <span class="icon-rss"></span> </div> </li> </ul> </div> <p></p> <div class="featured-posts"> <div id="featured" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Featured Posts </div> <ul style="padding-inline-start: 22px;"> <li style="margin-bottom: 3px;"> <a href="/blog/2019/10/22/audit-logs-with-kogito/" style="font-size: 95%;"> Admin Service for Audit Logs with Kogito </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/" style="font-size: 95%;"> Building Audit Logs with Change Data Capture and Stream Processing </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/07/12/streaming-cassandra-at-wepay-part-1/" style="font-size: 95%;"> Streaming Cassandra at WePay - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/" style="font-size: 95%;"> Reliable Microservices Data Exchange With the Outbox Pattern </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/" style="font-size: 95%;"> Automating Cache Invalidation With Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" style="font-size: 95%;"> Materializing Aggregate Views With Hibernate and Debezium </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/" style="font-size: 95%;"> Five Advantages of Log-Based Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/" style="font-size: 95%;"> Creating DDD aggregates with Debezium and Kafka Streams </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/" style="font-size: 95%;"> Streaming Data Changes from Your Database to Elasticsearch </a> </li> </ul> </div> <p></p> <div class="cloud-tags"> <div id="tags" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Tags </div> <div class="tag-cloud"> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/apache-kafka/">apache-kafka</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/avro/">avro</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/cassandra/">cassandra</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/community/">community</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/discussion/">discussion</a> </span> <span class="tag tag-5"> <a href="https://debezium.io/blog/tags/docker/">docker</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/elasticsearch/">elasticsearch</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/example/">example</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/examples/">examples</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/featured/">featured</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/fedora/">fedora</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/introduction/">introduction</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/json/">json</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/kafka/">kafka</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/kafka-streams/">kafka-streams</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/kogito/">kogito</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/ksql/">ksql</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/kubernetes/">kubernetes</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/microservices/">microservices</a> </span> <span class="tag tag-4"> <a href="https://debezium.io/blog/tags/mongodb/">mongodb</a> </span> <span class="tag tag-6"> <a href="https://debezium.io/blog/tags/mysql/">mysql</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/news/">news</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/newsletter/">newsletter</a> </span> <span class="tag tag-2"> <a href="https://debezium.io/blog/tags/oracle/">oracle</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/outbox/">outbox</a> </span> <span class="tag tag-5"> <a href="https://debezium.io/blog/tags/postgres/">postgres</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/presentation/">presentation</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/quarkus/">quarkus</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/rds/">rds</a> </span> <span class="tag tag-6"> <a href="https://debezium.io/blog/tags/releases/">releases</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/secrets/">secrets</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/sentry/">sentry</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/serialization/">serialization</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/smt/">smt</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/sql/">sql</a> </span> <span class="tag tag-3"> <a href="https://debezium.io/blog/tags/sqlserver/">sqlserver</a> </span> <span class="tag tag-0"> <a href="https://debezium.io/blog/tags/vagrant/">vagrant</a> </span> <span class="tag tag-1"> <a href="https://debezium.io/blog/tags/website/">website</a> </span> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="post"> <div class="row" style="margin-left: 0; margin-right: 0; margin-bottom: 10px;"> <div class="col-sm-12" style="padding-left: 0px;"> <div style="display: table-cell; vertical-align: top;"> <div style="width: 72px; border: 1px solid #ccc; padding: 3px; display: inline-block;"> <img src="/images/gmorling.jpg" style="width: 64px;"> </div> </div> <div style="display: table-cell; vertical-align: top;"> <div style="margin-left: 8px;"> <span class="hidden-sm hidden-xs" style="font-size: 2.75rem; line-height: 1;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">Reliable Microservices Data Exchange With the Outbox Pattern</a> </span> <span class="hidden-md hidden-lg" style="font-size: 2rem; line-height: 1;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">Reliable Microservices Data Exchange With the Outbox Pattern</a> </span> <div class="byline" style="line-height: 1;"> <em> February 19, 2019 by Gunnar Morling </em> <div class="hidden-xs" style="margin-top: 5px;"> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/discussion/">discussion</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/examples/">examples</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/microservices/">microservices</a> <a class="hidden-sm hidden-xs label label-info" href="/blog/tags/apache-kafka/">apache-kafka</a> </div> </div> </div> </div> </div> </div> <div class="row" style="margin-left: 0; margin-right: 0;"> <div id="preamble"> <div class="sectionbody"> <div class="openblock teaser"> <div class="content"> <div class="paragraph"> <p>As part of their business logic, microservices often do not only have to update their own local data store, but they also need to notify other services about data changes that happened. The outbox pattern describes an approach for letting services execute these two tasks in a safe and consistent manner; it provides source services with instant "read your own writes" semantics, while offering reliable, eventually consistent data exchange across service boundaries.</p> </div> </div> </div> <div class="paragraph"> <p><em>Update (13 Sept. 2019):</em> To simplify usage of the outbox pattern, Debezium now provides a ready-to-use <a href="/documentation/reference/0.9/configuration/outbox-event-router.html">SMT for routing outbox events</a>. The custom SMT discussed in this blog post is not needed any longer.</p> </div> <div class="paragraph"> <p>If you&#8217;ve built a couple of microservices, you&#8217;ll probably agree that the <a href="https://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/">hardest part about them is data</a>: microservices don&#8217;t exist in isolation and very often they need to propagate data and data changes amongst each other.</p> </div> <div class="paragraph"> <p>For instance consider a microservice that manages purchase orders: when a new order is placed, information about that order may have to be relayed to a shipment service (so it can assemble shipments of one or more orders) and a customer service (so it can update things like the customer&#8217;s total credit balance based on the new order).</p> </div> <div class="paragraph"> <p>There are different approaches for letting the order service know the other two about new purchase orders; e.g. it could invoke some <a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST</a>, <a href="https://grpc.io/">grpc</a> or other (synchronous) API provided by these services. This might create some undesired coupling, though: the sending service must know which other services to invoke and where to find them. It also must be prepared for these services temporarily not being available. Service meshes such as <a href="https://istio.io/">Istio</a> can come in helpful here, by providing capabilities like request routing, retries, circuit breakers and much more.</p> </div> <div class="paragraph"> <p>The general issue of any synchronous approach is that one service cannot really function without the other services which it invokes. While buffering and retrying might help in cases where other services only need to be <em>notified</em> of certain events, this is not the case if a service actually needs to <em>query</em> other services for information. For instance, when a purchase order is placed, the order service might need to obtain the information how many times the purchased item is on stock from an inventory service.</p> </div> <div class="paragraph"> <p>Another downside of such a synchronous approach is that it lacks re-playability, i.e. the possibility for new consumers to arrive after events have been sent and still be able to consume the entire event stream from the beginning.</p> </div> <div class="paragraph"> <p>Both problems can be addressed by using an asynchronous data exchange approach instead: i.e having the order, inventory and other services propagate events through a durable message log such as <a href="http://kafka.apache.org/">Apache Kafka</a>. By subscribing to these event streams, each service will be notified about the data change of other services. It can react to these events and, if needed, create a local representation of that data in its own data store, using a representation tailored towards its own needs. For instance, such view might be denormalized to efficiently support specific access patterns, or it may only contain a subset of the original data that&#8217;s relevant to the consuming service.</p> </div> <div class="paragraph"> <p>Durable logs also support re-playability, i.e. new consumers can be added as needed, enabling use cases you might not have had in mind originally, and without touching the source service. E.g. consider a data warehouse which should keep information about all the orders ever placed, or some full-text search functionality on purchase orders based on <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a>. Once the purchase order events are in a Kafka topic (Kafka&#8217;s topic&#8217;s retention policy settings can be used to ensure that events remain in a topic as long as its needed for the given use cases and business requirements), new consumers can subscribe, process the topic from the very beginning and materialize a view of all the data in a microservice&#8217;s database, search index, data warehouse etc.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Dealing with Topic Growth</div> <div class="paragraph"> <p>Depending on the amount of data (number and size of records, frequency of changes), it may or may not be feasible to keep events in topics for a long or even indefinite time. Very often, some or even all events pertaining to a given data item (e.g. a specific purchase order) might be eligible for deletion from a business point of view after a given point in time. See the box "Deletion of Events from Kafka Topics" further below for some more thoughts on the deletion of events from Kafka topics in order to keep their size within bounds.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="the_issue_of_dual_writes"><a class="anchor" href="#the_issue_of_dual_writes"></a>The Issue of Dual Writes</h2> <div class="sectionbody"> <div class="paragraph"> <p>In order to provide their functionality, microservices will typically have their own local data store. For instance, the order service may use a relational database to persist the information about purchase orders. When a new order is placed, this may result in an <code>INSERT</code> operation in a table <code>PurchaseOrder</code> in the service&#8217;s database. At the same time, the service may wish to send an event about the new order to Apache Kafka, so to propagate that information to other interested services.</p> </div> <div class="paragraph"> <p>Simply issuing these two requests may lead to potential inconsistencies, though. The reason being that we cannot have one shared transaction that would span the service&#8217;s database as well as Apache Kafka, as the latter doesn&#8217;t support to be enlisted in distributed (XA) transactions. So in unfortunate circumstances it might happen that we end up with having the new purchase order persisted in the local database, but not having sent the corresponding message to Kafka (e.g. due to some networking issue). Or, the other way around, we might have sent the message to Kafka but failed to persist the purchase order in the local database. Both situations are undesirable; this may cause no shipment to be created for a seemingly successfully placed order. Or a shipment gets created, but then there&#8217;d be no trace about the corresponding purchase order in the order service itself.</p> </div> <div class="paragraph"> <p>So how can this situation be avoided? The answer is to only modify <em>one</em> of the two resources (the database <em>or</em> Apache Kafka) and drive the update of the second one based on that, in an eventually consistent manner. Let&#8217;s first consider the case of only writing to Apache Kafka.</p> </div> <div class="paragraph"> <p>When receiving a new purchase order, the order service would not do the <code>INSERT</code> into its database synchronously; instead, it would only send an event describing the new order to a Kafka topic. So only one resource gets modified at a time, and if something goes wrong with that, we&#8217;ll find out about it instantly and report back to the caller of the order service that the request failed.</p> </div> <div class="paragraph"> <p>At the same time, the service itself would subscribe to that Kafka topic. That way, it will be notified when a new message arrives in the topic and it can persist the new purchase order in its database. There&#8217;s one subtle challenge here, though, and that is the lack of "read your own write" semantics. E.g. let&#8217;s assume the order service also has an API for searching for all the purchase orders of a given customer. When invoking that API right after placing a new order, due to the asynchronous nature of processing messages from the Kafka topic, it might happen that the purchase order has not yet been persisted in the service&#8217;s database and thus will not be returned by that query. That can lead to a very confusing user experience, as users for instance may miss newly placed orders in their shopping history. There are ways to deal with this situation, e.g. the service could keep newly placed purchase orders in memory and answer subsequent queries based on that. This gets quickly non-trivial though when implementing more complex queries or considering that the order service might also comprise multiple nodes in a clustered set-up, which would require propagation of that data within the cluster.</p> </div> <div class="paragraph"> <p>Now how would things look like when only writing to the database synchronously and driving the export of a message to Apache Kafka based on that? This is where the outbox pattern comes in.</p> </div> </div> </div> <div class="sect1"> <h2 id="the_outbox_pattern"><a class="anchor" href="#the_outbox_pattern"></a>The Outbox Pattern</h2> <div class="sectionbody"> <div class="paragraph"> <p>The idea of this approach is to have an "outbox" table in the service&#8217;s database. When receiving a request for placing a purchase order, not only an <code>INSERT</code> into the <code>PurchaseOrder</code> table is done, but, as part of the same transaction, also a record representing the event to be sent is inserted into that outbox table.</p> </div> <div class="paragraph"> <p>The record describes an event that happened in the service, for instance it could be a JSON structure representing the fact that a new purchase order has been placed, comprising data on the order itself, its order lines as well as contextual information such as a use case identifier. By explicitly emitting events via records in the outbox table, it can be ensured that events are structured in a way suitable for external consumers. This also helps to make sure that event consumers won&#8217;t break when for instance altering the internal domain model or the <code>PurchaseOrder</code> table.</p> </div> <div class="paragraph"> <p>An asynchronous process monitors that table for new entries. If there are any, it propagates the events as messages to Apache Kafka. This gives us a very nice balance of characteristics: By synchronously writing to the <code>PurchaseOrder</code> table, the source service benefits from "read your own writes" semantics. A subsequent query for purchase orders will return the newly persisted order, as soon as that first transaction has been committed. At the same time, we get reliable, asynchronous, eventually consistent data propagation to other services via Apache Kafka.</p> </div> <div class="paragraph"> <p>Now, the outbox pattern isn&#8217;t actually a new idea. It has been in use for quite some time. In fact, even when using JMS-style message brokers, which actually could participate in distributed transactions, it can be a preferable option to avoid any coupling and potential impact by downtimes of remote resources such as a message broker. You can also find a description of the pattern on Chris Richardson&#8217;s excellent <a href="https://microservices.io/patterns/data/application-events.html">microservices.io</a> site.</p> </div> <div class="paragraph"> <p>Nevertheless, the pattern gets much less attention than it deserves and it is especially useful in the context of microservices. As we&#8217;ll see, the outbox pattern can be implemented in a very elegant and efficient way using change data capture and Debezium. In the following, let&#8217;s explore how.</p> </div> </div> </div> <div class="sect1"> <h2 id="an_implementation_based_on_change_data_capture"><a class="anchor" href="#an_implementation_based_on_change_data_capture"></a>An Implementation Based on Change Data Capture</h2> <div class="sectionbody"> <div class="paragraph"> <p><a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/">Log-based Change Data Capture</a> (CDC) is a great fit for capturing new entries in the outbox table and stream them to Apache Kafka. As opposed to any polling-based approach, event capture happens with a very low overhead in near-realtime. Debezium comes with <a href="/docs/connectors/">CDC connectors</a> for several databases such as MySQL, Postgres and SQL Server. The following example will use the <a href="/docs/connectors/postgresql">Debezium connector for Postgres</a>.</p> </div> <div class="paragraph"> <p>You can find the complete <a href="https://github.com/debezium/debezium-examples/tree/master/outbox">source code of the example</a> on GitHub. Refer to the <a href="https://github.com/debezium/debezium-examples/blob/master/outbox/README.md">README.md</a> for details on building and running the example code. The example is centered around two microservices, <a href="https://github.com/debezium/debezium-examples/tree/master/outbox/order-service">order-service</a> and <a href="https://github.com/debezium/debezium-examples/tree/master/outbox/shipment-service">shipment-service</a>. Both are implemented in Java, using <a href="http://cdi-spec.org/">CDI</a> as the component model and JPA/Hibernate for accessing their respective databases. The order service runs on <a href="http://wildfly.org/">WildFly</a> and exposes a simple REST API for placing purchase orders and canceling specific order lines. It uses a Postgres database as its local data store. The shipment service is based on <a href="http://thorntail.io/">Thorntail</a>; via Apache Kafka, it receives events exported by the order service and creates corresponding shipment entries in its own MySQL database. Debezium tails the transaction log ("write-ahead log", WAL) of the order service&#8217;s Postgres database in order to capture any new events in the outbox table and propagates them to Apache Kafka.</p> </div> <div class="paragraph"> <p>The overall architecture of the solution can be seen in the following picture:</p> </div> <div class="imageblock centered-image"> <img src="/images/outbox_pattern.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Outbox Pattern Overview"> </div> <div class="paragraph"> <p>Note that the pattern is in no way tied to these specific implementation choices. It could equally well be realized using alternative technologies such as Spring Boot (e.g. leveraging Spring Data&#8217;s <a href="https://docs.spring.io/spring-data/commons/docs/current/api/index.html?org/springframework/data/domain/DomainEvents.html">support for domain events</a>), plain JDBC or other programming languages than Java altogether.</p> </div> <div class="paragraph"> <p>Now let&#8217;s take a closer look at some of the relevant components of the solution.</p> </div> <div class="sect2"> <h3 id="the_outbox_table"><a class="anchor" href="#the_outbox_table"></a>The Outbox Table</h3> <div class="paragraph"> <p>The <code>outbox</code> table resides in the database of the order service and has the following structure:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>Column        |          Type          | Modifiers&#x000A;--------------+------------------------+-----------&#x000A;id            | uuid                   | not null&#x000A;aggregatetype | character varying(255) | not null&#x000A;aggregateid   | character varying(255) | not null&#x000A;type          | character varying(255) | not null&#x000A;payload       | jsonb                  | not null</code></pre> </div> </div> <div class="paragraph"> <p>Its columns are these:</p> </div> <div class="ulist"> <ul> <li> <p><code>id</code>: unique id of each message; can be used by consumers to detect any duplicate events, e.g. when restarting to read messages after a failure. Generated when creating a new event.</p> </li> <li> <p><code>aggregatetype</code>: the type of the <em>aggregate root</em> to which a given event is related; the idea being, leaning on the same concept of domain-driven design, that exported events should refer to an aggregate (<a href="https://martinfowler.com/bliki/DDD_Aggregate.html">"a cluster of domain objects that can be treated as a single unit"</a>), where the aggregate root provides the sole entry point for accessing any of the entities within the aggregate. This could for instance be "purchase order" or "customer".</p> <div class="paragraph"> <p>This value will be used to route events to corresponding topics in Kafka, so there&#8217;d be a topic for all events related to purchase orders, one topic for all customer-related events etc. Note that also events pertaining to a child entity contained within one such aggregate should use that same type. So e.g. an event representing the cancelation of an individual order line (which is part of the purchase order aggregate) should also use the type of its aggregate root, "order", ensuring that also this event will go into the "order" Kafka topic.</p> </div> </li> <li> <p><code>aggregateid</code>: the id of the aggregate root that is affected by a given event; this could for instance be the id of a purchase order or a customer id; Similar to the aggregate type, events pertaining to a sub-entity contained within an aggregate should use the id of the containing aggregate root, e.g. the purchase order id for an order line cancelation event. This id will be used as the key for Kafka messages later on. That way, all events pertaining to one aggregate root or any of its contained sub-entities will go into the same partition of that Kafka topic, which ensures that consumers of that topic will consume all the events related to one and the same aggregate in the exact order as they were produced.</p> </li> <li> <p><code>type</code>: the type of event, e.g. "Order Created" or "Order Line Canceled". Allows consumers to trigger suitable event handlers.</p> </li> <li> <p><code>payload</code>: a JSON structure with the actual event contents, e.g. containing a purchase order, information about the purchaser, contained order lines, their price etc.</p> </li> </ul> </div> </div> <div class="sect2"> <h3 id="sending_events_to_the_outbox"><a class="anchor" href="#sending_events_to_the_outbox"></a>Sending Events to the Outbox</h3> <div class="paragraph"> <p>In order to "send" events to the outbox, code in the order service could in general just do an <code>INSERT</code> into the outbox table. However, it&#8217;s a good idea to go for a slightly more abstract API, allowing to adjust implementation details of the outbox later on more easily, if needed. <a href="https://docs.jboss.org/weld/reference/latest/en-US/html/events.html">CDI events</a> come in very handy for this. They can be raised in the application code and will be processed <em>synchronously</em> by the outbox event sender, which will do the required <code>INSERT</code> into the outbox table.</p> </div> <div class="paragraph"> <p>All outbox event types should implement the following contract, resembling the structure of the outbox table shown before:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">public interface ExportedEvent {&#x000A;&#x000A;    String getAggregateId();&#x000A;    String getAggregateType();&#x000A;    JsonNode getPayload();&#x000A;    String getType();&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>To produce such event, application code uses an injected <code>Event</code> instance, as e.g. here in the <code>OrderService</code> class:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class OrderService {&#x000A;&#x000A;    @PersistenceContext&#x000A;    private EntityManager entityManager;&#x000A;&#x000A;    @Inject&#x000A;    private Event&lt;ExportedEvent&gt; event;&#x000A;&#x000A;    @Transactional&#x000A;    public PurchaseOrder addOrder(PurchaseOrder order) {&#x000A;        order = entityManager.merge(order);&#x000A;&#x000A;        event.fire(OrderCreatedEvent.of(order));&#x000A;        event.fire(InvoiceCreatedEvent.of(order));&#x000A;&#x000A;        return order;&#x000A;    }&#x000A;&#x000A;    @Transactional&#x000A;    public PurchaseOrder updateOrderLine(long orderId, long orderLineId,&#x000A;            OrderLineStatus newStatus) {&#x000A;        // ...&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>In the <code>addOrder()</code> method, the JPA entity manager is used to persist the incoming order in the database and the injected <code>event</code> is used to fire a corresponding <code>OrderCreatedEvent</code> and an <code>InvoiceCreatedEvent</code>. Again, keep in mind that, despite the notion of "event", these two things happen within one and the same transaction. i.e. within this transaction, three records will be inserted into the database: one in the table with purchase orders and two in the outbox table.</p> </div> <div class="paragraph"> <p>Actual event implementations are straight-forward; as an example, here&#8217;s the <code>OrderCreatedEvent</code> class:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">public class OrderCreatedEvent implements ExportedEvent {&#x000A;&#x000A;    private static ObjectMapper mapper = new ObjectMapper();&#x000A;&#x000A;    private final long id;&#x000A;    private final JsonNode order;&#x000A;&#x000A;    private OrderCreatedEvent(long id, JsonNode order) {&#x000A;        this.id = id;&#x000A;        this.order = order;&#x000A;    }&#x000A;&#x000A;    public static OrderCreatedEvent of(PurchaseOrder order) {&#x000A;        ObjectNode asJson = mapper.createObjectNode()&#x000A;                .put("id", order.getId())&#x000A;                .put("customerId", order.getCustomerId())&#x000A;                .put("orderDate", order.getOrderDate().toString());&#x000A;&#x000A;        ArrayNode items = asJson.putArray("lineItems");&#x000A;&#x000A;        for (OrderLine orderLine : order.getLineItems()) {&#x000A;        items.add(&#x000A;                mapper.createObjectNode()&#x000A;                .put("id", orderLine.getId())&#x000A;                .put("item", orderLine.getItem())&#x000A;                .put("quantity", orderLine.getQuantity())&#x000A;                .put("totalPrice", orderLine.getTotalPrice())&#x000A;                .put("status", orderLine.getStatus().name())&#x000A;            );&#x000A;        }&#x000A;&#x000A;        return new OrderCreatedEvent(order.getId(), asJson);&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public String getAggregateId() {&#x000A;        return String.valueOf(id);&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public String getAggregateType() {&#x000A;        return "Order";&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public String getType() {&#x000A;        return "OrderCreated";&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public JsonNode getPayload() {&#x000A;        return order;&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Note how <a href="https://github.com/FasterXML/jackson">Jackson&#8217;s</a> <code>ObjectMapper</code> is used to create a JSON representation of the event&#8217;s payload.</p> </div> <div class="paragraph"> <p>Now let&#8217;s take a look at the code that consumes any fired <code>ExportedEvent</code> and does the corresponding write to the outbox table:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class EventSender {&#x000A;&#x000A;    @PersistenceContext&#x000A;    private EntityManager entityManager;&#x000A;&#x000A;    public void onExportedEvent(@Observes ExportedEvent event) {&#x000A;        OutboxEvent outboxEvent = new OutboxEvent(&#x000A;                event.getAggregateType(),&#x000A;                event.getAggregateId(),&#x000A;                event.getType(),&#x000A;                event.getPayload()&#x000A;        );&#x000A;&#x000A;        entityManager.persist(outboxEvent);&#x000A;        entityManager.remove(outboxEvent);&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>It&#8217;s rather simple: for each event the CDI runtime will invoke the <code>onExportedEvent()</code> method. An instance of the <code>OutboxEvent</code> entity is persisted in the database&#8201;&#8212;&#8201;and removed right away!</p> </div> <div class="paragraph"> <p>This might be surprising at first. But it makes sense when remembering how log-based CDC works: it doesn&#8217;t examine the actual contents of the table in the database, but instead it tails the append-only transaction log. The calls to <code>persist()</code> and <code>remove()</code> will create an <code>INSERT</code> and a <code>DELETE</code> entry in the log once the transaction commits. After that, Debezium will process these events: for any <code>INSERT</code>, a message with the event&#8217;s payload will be sent to Apache Kafka. <code>DELETE</code> events on the other hand can be ignored, as the removal from the outbox table is a mere technicality that doesn&#8217;t require any propagation to the message broker. So we are able to capture the event added to the outbox table by means of CDC, but when looking at the contents of the table itself, it will always be empty. This means that no additional disk space is needed for the table (apart from the log file elements which will automatically be discarded at some point) and also no separate house-keeping process is required to stop it from growing indefinitely.</p> </div> </div> <div class="sect2"> <h3 id="registering_the_debezium_connector"><a class="anchor" href="#registering_the_debezium_connector"></a>Registering the Debezium Connector</h3> <div class="paragraph"> <p>With the outbox implementation in place, it&#8217;s time to register the Debezium Postgres connector, so it can capture any new events in the outbox table and relay them to Apache Kafka. That can be done by POST-ing the following JSON request to the REST API of Kafka Connect:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "name": "outbox-connector",&#x000A;    "config": {&#x000A;        "connector.class" : "io.debezium.connector.postgresql.PostgresConnector",&#x000A;        "tasks.max" : "1",&#x000A;        "database.hostname" : "order-db",&#x000A;        "database.port" : "5432",&#x000A;        "database.user" : "postgresuser",&#x000A;        "database.password" : "postgrespw",&#x000A;        "database.dbname" : "orderdb",&#x000A;        "database.server.name" : "dbserver1",&#x000A;        "schema.whitelist" : "inventory",&#x000A;        "table.whitelist" : "inventory.outboxevent",&#x000A;        "tombstones.on.delete" : "false",&#x000A;        "transforms" : "router",&#x000A;        "transforms.router.type" : "io.debezium.examples.outbox.routingsmt.EventRouter"&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>This sets up an instance of <code>io.debezium.connector.postgresql.PostgresConnector</code>, capturing changes from the specified Postgres instance. Note that by means of a table whitelist, only changes from the <code>outboxevent</code> table are captured. It also applies a single message transform (SMT) named <code>EventRouter</code>.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Deletion of Events from Kafka Topics</div> <div class="paragraph"> <p>By setting the <code>tombstones.on.delete</code> to <code>false</code>, no deletion markers ("tombstones") will be emitted by the connector when an event record gets deleted from the outbox table. That makes sense, as the deletion from the outbox table shouldn&#8217;t affect the retention of events in the corresponding Kafka topics. Instead, a specific retention time for the event topics may be configured in Kafka, e.g. to retain all purchase order events for 30 days.</p> </div> <div class="paragraph"> <p>Alternatively, one could work with <a href="https://kafka.apache.org/documentation/#compaction">compacted topics</a>. This would require some changes to the design of events in the outbox table:</p> </div> <div class="ulist"> <ul> <li> <p>they must describe the entire aggregate; so for instance also an event representing the cancelation of a single order line should describe the complete current state of the containing purchase order; that way consumers will be able to obtain the entire state of the purchase order also when only seeing the last event pertaining to a given order, after log compaction ran.</p> </li> <li> <p>they must have one more <code>boolean</code> attribute indicating whether a particular event represents the deletion of the event&#8217;s aggregate root. Such an event (e.g. of type <code>OrderDeleted</code>) could then be used by the event routing SMT described in the next section to produce a deletion marker for that aggregate root. Log compaction would then remove all events pertaining to the given purchase order when its <code>OrderDeleted</code> event has been written to the topic.</p> </li> </ul> </div> <div class="paragraph"> <p>Naturally, when deleting events, the event stream will not be re-playable from its very beginning any longer. Depending on the specific business requirements, it might be sufficient to just keep the final state of a given purchase order, customer etc. This could be achieved using compacted topics and a sufficiently value for the topic&#8217;s <code>delete.retention.ms</code> setting. Another option could be to move historic events to some sort of cold storage (e.g. an Amazon S3 bucket), from where they can be retrieved if needed, followed by reading the latest events from the Kafka topics. Which approach to follow depends on the specific requirements, expected amount of data and expertise in the team developing and operating the solution.</p> </div> </td> </tr> </table> </div> </div> <div class="sect2"> <h3 id="topic_routing"><a class="anchor" href="#topic_routing"></a>Topic Routing</h3> <div class="paragraph"> <p>By default, the Debezium connectors will send all change events originating from one given table to the same topic, i.e. we&#8217;d end up with a single Kafka topic named <code>dbserver1.inventory.outboxevent</code> which would contain all events, be it order events, customer events etc.</p> </div> <div class="paragraph"> <p>To simplify the implementation of consumers which are only interested in specific event types it makes more sense, though, to have multiple topics, e.g. <code>OrderEvents</code>, <code>CustomerEvents</code> and so on. For instance the shipment service might not be interested in any customer events. By only subscribing to the <code>OrderEvents</code> topic, it will be sure to never receive any customer events.</p> </div> <div class="paragraph"> <p>In order to route the change events captured from the outbox table to different topics, that custom SMT <code>EventRouter</code> is used. Here is the code of its <code>apply()</code> method, which will be invoked by Kafka Connect for each record emitted by the Debezium connector:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Override&#x000A;public R apply(R record) {&#x000A;    // Ignoring tombstones just in case&#x000A;    if (record.value() == null) {&#x000A;        return record;&#x000A;    }&#x000A;&#x000A;    Struct struct = (Struct) record.value();&#x000A;    String op = struct.getString("op");&#x000A;&#x000A;    // ignoring deletions in the outbox table&#x000A;    if (op.equals("d")) {&#x000A;        return null;&#x000A;    }&#x000A;    else if (op.equals("c")) {&#x000A;        Long timestamp = struct.getInt64("ts_ms");&#x000A;        Struct after = struct.getStruct("after");&#x000A;&#x000A;        String key = after.getString("aggregateid");&#x000A;        String topic = after.getString("aggregatetype") + "Events";&#x000A;&#x000A;        String eventId = after.getString("id");&#x000A;        String eventType = after.getString("type");&#x000A;        String payload = after.getString("payload");&#x000A;&#x000A;        Schema valueSchema = SchemaBuilder.struct()&#x000A;            .field("eventType", after.schema().field("type").schema())&#x000A;            .field("ts_ms", struct.schema().field("ts_ms").schema())&#x000A;            .field("payload", after.schema().field("payload").schema())&#x000A;            .build();&#x000A;&#x000A;        Struct value = new Struct(valueSchema)&#x000A;            .put("eventType", eventType)&#x000A;            .put("ts_ms", timestamp)&#x000A;            .put("payload", payload);&#x000A;&#x000A;        Headers headers = record.headers();&#x000A;        headers.addString("eventId", eventId);&#x000A;&#x000A;        return record.newRecord(topic, null, Schema.STRING_SCHEMA, key, valueSchema, value,&#x000A;                record.timestamp(), headers);&#x000A;    }&#x000A;    // not expecting update events, as the outbox table is "append only",&#x000A;    // i.e. event records will never be updated&#x000A;    else {&#x000A;        throw new IllegalArgumentException("Record of unexpected op type: " + record);&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>When receiving a delete event (<code>op</code> = <code>d</code>), it will discard that event, as that deletion of event records from the outbox table is not relevant to downstream consumers. Things get more interesting, when receiving a create event (<code>op</code> = <code>c</code>). Such record will be propagated to Apache Kafka.</p> </div> <div class="paragraph"> <p>Debezium&#8217;s change events have a complex structure, that contain the old (<code>before</code>) and new (<code>after</code>) state of the represented row. The event structure to propagate is obtained from the <code>after</code> state. The <code>aggregatetype</code> value from the captured event record is used to build the name of the topic to send the event to. For instance, events with <code>aggregatetype</code> set to <code>Order</code> will be sent to the <code>OrderEvents</code> topic. <code>aggregateid</code> is used as the message key, making sure all messages of that aggregate will go into the same partition of that topic. The message value is a structure comprising the original event payload (encoded as JSON), the timestamp indicating when the event was produced and the event type. Finally, the event UUID is propagated as a Kafka header field. This allows for efficient duplicate detection by consumers, without having to examine the actual message contents.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="events_in_apache_kafka"><a class="anchor" href="#events_in_apache_kafka"></a>Events in Apache Kafka</h2> <div class="sectionbody"> <div class="paragraph"> <p>Now let&#8217;s take a look into the <code>OrderEvents</code> and <code>CustomerEvents</code> topics.</p> </div> <div class="paragraph"> <p>If you have checked out the example sources and started all the components via Docker Compose (see the <em>README.md</em> file in the example project for more details), you can place purchase orders via the order service&#8217;s REST API like so:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>cat resources/data/create-order-request.json | http POST http://localhost:8080/order-service/rest/orders</code></pre> </div> </div> <div class="paragraph"> <p>Similarly, specific order lines can be canceled:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>cat resources/data/cancel-order-line-request.json | http PUT http://localhost:8080/order-service/rest/orders/1/lines/2</code></pre> </div> </div> <div class="paragraph"> <p>When using a tool such as the very practical <a href="https://github.com/edenhill/kafkacat">kafkacat</a> utility, you should now see messages like these in the <code>OrderEvents</code> topic:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>kafkacat -b kafka:9092 -C -o beginning -f 'Headers: %h\nKey: %k\nValue: %s\n' -q -t OrderEvents</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>Headers: eventId=d03dfb18-8af8-464d-890b-09eb8b2dbbdd&#x000A;Key: "4"&#x000A;Value: {"eventType":"OrderCreated","ts_ms":1550307598558,"payload":"{\"id\": 4, \"lineItems\": [{\"id\": 7, \"item\": \"Debezium in Action\", \"status\": \"ENTERED\", \"quantity\": 2, \"totalPrice\": 39.98}, {\"id\": 8, \"item\": \"Debezium for Dummies\", \"status\": \"ENTERED\", \"quantity\": 1, \"totalPrice\": 29.99}], \"orderDate\": \"2019-01-31T12:13:01\", \"customerId\": 123}"}&#x000A;Headers: eventId=49f89ea0-b344-421f-b66f-c635d212f72c&#x000A;Key: "4"&#x000A;Value: {"eventType":"OrderLineUpdated","ts_ms":1550308226963,"payload":"{\"orderId\": 4, \"newStatus\": \"CANCELLED\", \"oldStatus\": \"ENTERED\", \"orderLineId\": 7}"}</code></pre> </div> </div> <div class="paragraph"> <p>The <code>payload</code> field with the message values is the string-ified JSON representation of the original events. The Debezium Postgres connector emits <code>JSONB</code> columns as a string (using the <code>io.debezium.data.Json</code> logical type name), which is why the quotes are escaped. The <a href="https://stedolan.github.io/jq/">jq</a> utility, and more specifically, its <code>fromjson</code> operator, come in handy for displaying the event payload in a more readable way:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>kafkacat -b kafka:9092 -C -o beginning -t Order | jq '.payload | fromjson'</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;  "id": 4,&#x000A;  "lineItems": [&#x000A;    {&#x000A;      "id": 7,&#x000A;      "item": "Debezium in Action",&#x000A;      "status": "ENTERED",&#x000A;      "quantity": 2,&#x000A;      "totalPrice": 39.98&#x000A;    },&#x000A;    {&#x000A;      "id": 8,&#x000A;      "item": "Debezium for Dummies",&#x000A;      "status": "ENTERED",&#x000A;      "quantity": 1,&#x000A;      "totalPrice": 29.99&#x000A;    }&#x000A;  ],&#x000A;  "orderDate": "2019-01-31T12:13:01",&#x000A;  "customerId": 123&#x000A;}&#x000A;{&#x000A;  "orderId": 4,&#x000A;  "newStatus": "CANCELLED",&#x000A;  "oldStatus": "ENTERED",&#x000A;  "orderLineId": 7&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>You can also take a look at the <code>CustomerEvents</code> topic to inspect the events representing the creation of an invoice when a purchase order is added.</p> </div> <div class="sect2"> <h3 id="duplicate_detection_in_the_consuming_service"><a class="anchor" href="#duplicate_detection_in_the_consuming_service"></a>Duplicate Detection in the Consuming Service</h3> <div class="paragraph"> <p>At this point, our implementation of the outbox pattern is fully functional; when the order service receives a request to place an order (or cancel an order line), it will persist the corresponding state in the <code>purchaseorder</code> and <code>orderline</code> tables of its database. At the same time, within the same transaction, corresponding event entries will be added to the outbox table in the same database. The Debezium Postgres connector captures any insertions into that table and routes the events into the Kafka topic corresponding to the aggregate type represented by a given event.</p> </div> <div class="paragraph"> <p>To wrap things up, let&#8217;s explore how another microservice such as the shipment service can consume these messages. The entry point into that service is a regular Kafka consumer implementation, which is not too exciting and hence omitted here for the sake of brevity. You can find its <a href="https://github.com/debezium/debezium-examples/blob/master/outbox/shipment-service/src/main/java/io/debezium/examples/outbox/shipment/facade/KafkaEventConsumer.java">source code</a> in the example repository. For each incoming message on the <code>Order</code> topic, the consumer calls the <code>OrderEventHandler</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class OrderEventHandler {&#x000A;&#x000A;    private static final Logger LOGGER = LoggerFactory.getLogger(OrderEventHandler.class);&#x000A;&#x000A;    @Inject&#x000A;    private MessageLog log;&#x000A;&#x000A;    @Inject&#x000A;    private ShipmentService shipmentService;&#x000A;&#x000A;    @Transactional&#x000A;    public void onOrderEvent(UUID eventId, String key, String event) {&#x000A;        if (log.alreadyProcessed(eventId)) {&#x000A;            LOGGER.info("Event with UUID {} was already retrieved, ignoring it", eventId);&#x000A;            return;&#x000A;        }&#x000A;&#x000A;        JsonObject json = Json.createReader(new StringReader(event)).readObject();&#x000A;        JsonObject payload = json.containsKey("schema") ? json.getJsonObject("payload") :json;&#x000A;&#x000A;        String eventType = payload.getString("eventType");&#x000A;        Long ts = payload.getJsonNumber("ts_ms").longValue();&#x000A;        String eventPayload = payload.getString("payload");&#x000A;&#x000A;        JsonReader payloadReader = Json.createReader(new StringReader(eventPayload));&#x000A;        JsonObject payloadObject = payloadReader.readObject();&#x000A;&#x000A;        if (eventType.equals("OrderCreated")) {&#x000A;            shipmentService.orderCreated(payloadObject);&#x000A;        }&#x000A;        else if (eventType.equals("OrderLineUpdated")) {&#x000A;            shipmentService.orderLineUpdated(payloadObject);&#x000A;        }&#x000A;        else {&#x000A;            LOGGER.warn("Unkown event type");&#x000A;        }&#x000A;&#x000A;        log.processed(eventId);&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>The first thing done by <code>onOrderEvent()</code> is to check whether the event with the given UUID has been processed before. If so, any further calls for that same event will be ignored. This is to prevent any duplicate processing of events caused by the "at least once" semantics of this data pipeline. For instance it could happen that the Debezium connector or the consuming service fail before acknowledging the retrieval of a specific event with the source database or the messaging broker, respectively. In that case, after a restart of Debezium or the consuming service, a few events may be processed a second time. Propagating the event UUID as a Kafka message header allows for an efficient detection and exclusion of duplicates in the consumer.</p> </div> <div class="paragraph"> <p>If a message is received for the first time, the message value is parsed and the business method of the <code>ShippingService</code> method corresponding to the specific event type is invoked with the event payload. Finally, the message is marked as processed with the message log.</p> </div> <div class="paragraph"> <p>This <code>MessageLog</code> simply keeps track of all consumed events in a table within the service&#8217;s local database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class MessageLog {&#x000A;&#x000A;    @PersistenceContext&#x000A;    private EntityManager entityManager;&#x000A;&#x000A;    @Transactional(value=TxType.MANDATORY)&#x000A;    public void processed(UUID eventId) {&#x000A;        entityManager.persist(new ConsumedMessage(eventId, Instant.now()));&#x000A;    }&#x000A;&#x000A;    @Transactional(value=TxType.MANDATORY)&#x000A;    public boolean alreadyProcessed(UUID eventId) {&#x000A;        return entityManager.find(ConsumedMessage.class, eventId) != null;&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>That way, should the transaction be rolled back for some reason, also the original message will not be marked as processed and an exception would bubble up to the Kafka event consumer loop. This allows for re-trying to process the message later on.</p> </div> <div class="paragraph"> <p>Note that a more complete implementation should take care of re-trying given messages only for a certain number of times, before re-routing any unprocessable messages to a dead-letter queue or similar. Also there should be some house-keeping on the message log table; periodically, all events older than the consumer&#8217;s current offset committed with the broker may be deleted, as it&#8217;s ensured that such messages won&#8217;t be propagated to the consumer another time.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>The outbox pattern is a great way for propagating data amongst different microservices.</p> </div> <div class="paragraph"> <p>By only modifying a single resource - the source service&#8217;s own database - it avoids any potential inconsistencies of altering multiple resources at the same time which don&#8217;t share one common transactional context (the database and Apache Kafka). By writing to the database first, the source service has instant "read your own writes" semantics, which is important for a consistent user experience, allowing query methods invoked following to a write to instantly reflect any data changes.</p> </div> <div class="paragraph"> <p>At the same time, the pattern enables asynchronous event propagation to other microservices. Apache Kafka acts as a highly scalable and reliable backbone for the messaging amongst the services. Given the right topic retention settings, new consumers may come up long after an event has been originally produced, and build up their own local state based on the event history.</p> </div> <div class="paragraph"> <p>Putting Apache Kafka into the center of the overall architecture also ensures a decoupling of involved services. If for instance single components of the solution fail or are not available for some time, e.g. during an update, events will simply be processed later on: after a restart, the Debezium connector will continue to tail the outbox table from the point where it left off before. Similarly, any consumer will continue to process topics from its previous offset. By keeping track of already successfully processed messages, duplicates can be detected and excluded from repeated handling.</p> </div> <div class="paragraph"> <p>Naturally, such event pipeline between different services is eventually consistent, i.e. consumers such as the shipping service may lag a bit behind producers such as the order service. Usually, that&#8217;s just fine, though, and can be handled in terms of the application&#8217;s business logic. For instance there&#8217;ll typically be no need to create a shipment within the very same second as an order has been placed. Also, end-to-end delays of the overall solution are typically low (seconds or even sub-second range), thanks to log-based change data capture which allows for emission of events in near-realtime.</p> </div> <div class="paragraph"> <p>One last thing to keep in mind is that the structure of the events exposed via the outbox should be considered a part of the emitting service&#8217;s API. I.e. when needed, their structure should be adjusted carefully and with compatibility considerations in mind. This is to ensure to not accidentally break any consumers when upgrading the producing service. At the same time, consumers should be lenient when handling messages and for instance not fail when encountering unknown attributes within received events.</p> </div> <div class="paragraph"> <p><em>Many thanks to Hans-Peter Grahsl, Jiri Pechanec, Justin Holmes and RenÃ© Kerner for their feedback while writing this post!</em></p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.redhat.com/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> </div> <div class="well"> <div class="row"> <div class="col-md-8"> <h2>Gunnar Morling</h2> <p> <span class="bio-size">Gunnar is a software engineer at Red Hat and open-source enthusiast by heart. A long-time Hibernate core team member, he's now the project lead of Debezium. Gunnar is the spec lead for Bean Validation 2.0 (JSR 380). Heâs based in Hamburg, Germany.</span> </p> <p class="bio-size"> <a href="https://twitter.com/gunnarmorling"> <i class="icon-twitter"></i> </a> &nbsp; <a href="https://github.com/gunnarmorling"> <i class="icon-github"></i> </a> &nbsp; </p> </div> <div class="col-md-4"> <img alt="" class="img-responsive pull-right portrait" src="/images/gmorling.jpg"> </div> </div> </div> <div class="comments"> <div id="disqus_thread"></div> <script type="text/javascript">
            var disqus_shortname = 'Debezium';
            var disqus_url = "https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/";
            var disqus_developer = null;
            var disqus_identifier = null;
            (function() {
              var dsq = document.createElement("script"); dsq.type = "text/javascript"; dsq.async = true;
              dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
              (document.getElementsByTagName("head")[0] || document.getElementsByTagName("body")[0]).appendChild(dsq);
            })();
            </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript=Debezium">comments powered by Disqus.</a></noscript> </div> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2020 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/documentation/features" title="Features">Features</a> </li> <li> <a href="/documentation/install/stable/" title="Install">Install</a> </li> <li> <a href="/documentation/architecture/" title="Architecture">Architecture</a> </li> <li> <a href="/documentation/faq/" title="FAQ">FAQ</a> </li> <li> <a href="/community/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/user" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="https://www.redhat.com/"><img src="/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="https://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.2/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
  var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
  var urlSplit = coreUrl.toLowerCase().split(/\//);
  var urlLast = urlSplit[urlSplit.length-1];
  var pageNameString = "";
  var siteName = "";
  var minorSectionIndex = 3
  if (urlLast == "") {
      urlSplit.splice(-1,1);
  }
  if (urlLast.search(/\./) >= 0) {
      if (urlLast == "index.html") {
          urlSplit.splice(-1,1);
      }
      else {
          urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
      }
  }
  siteName = urlSplit[2].split(".")[1];
  s.prop14 = s.eVar27 = siteName || "";
  s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
  s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
  pageNameString = urlSplit.splice(3).join(" | ");
  s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
  s.server = "jboss";
  s.channel = "jboss | community";
  s.prop4 = s.eVar23 = encodeURI(document.URL);
  s.prop21 = s.eVar18 = coreUrl;
  s.prop2 = s.eVar22 = "en";
  s.prop3 = s.eVar19 = "us";
  //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
  if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
  //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script> <script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-10656779-1");
pageTracker._trackPageview();
} catch(err) {}</script> <script>
 (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
 
ga('create', 'UA-76464546-1', 'auto');
ga('send', 'pageview');
ga('set', 'anonymizeIp', true);
ga('require', 'linkid', 'linkid.js');

</script> </div> </body> </html>