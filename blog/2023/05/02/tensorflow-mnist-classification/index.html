<!DOCTYPE html> <html> <head> <title>Image classification with Debezium and TensorFlow</title> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta content="Debezium" property="og:site_name"> <meta content="Image classification with Debezium and TensorFlow" property="og:title"> <meta content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png" property="og:image" name="image"> <meta property="og:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta property="og:url" content="https://debezium.io/blog/2023/05/02/tensorflow-mnist-classification/"> <meta name="twitter:site" content="@debezium"> <meta name="twitter:title" content="Image classification with Debezium and TensorFlow"> <meta name="twitter:creator" content="@vjuranek"> <meta name="twitter:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:image" content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png"> <meta property="twitter:url" content="https://debezium.io/blog/2023/05/02/tensorflow-mnist-classification/"> <link rel="alternate" type="application/rss+xml" title="Debezium Blog" href="/blog.atom"> <link rel="shortcut icon" type="image/png" href="/favicon.ico"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css"/> <link rel="stylesheet" href="/assets/css/custom.css"/> <link rel="stylesheet" href="/assets/css/highlight.min.css"/> <link rel="stylesheet" href="/assets/css/coderay.css"/> </head> <body class="post"> <div id="rhbar"> <a class="jbdevlogo" href="https://developers.redhat.com"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id> <div class="container" id="content"> <nav class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed border-0" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"><img class="project-logo" src="/assets/images/color_white_debezium_type_600px.svg" style="height: 32px; margin-right: 5px; margin-top: -5px;"></a> </div> <div class="collapse navbar-collapse collapsed" id="navigation"> <ul class="nav navbar-nav pull-right"> <li> <a href="/documentation/faq" class="">FAQ</a> </li> <li class="item"> <a href="/documentation/" class="">Documentation</a> </li> <li> <a href="/releases/" class="">Releases</a> </li> <li> <a href="/community/" class="">Community</a> </li> <li class="active"> <a href="/blog/" class="active">Blog</a> </li> </ul> </div> </div> </nav> <div class="row post-text-padding row-no-expand"> <div class="col-md-3"><div id="leftdocnav"> <div class="hidden-lg hidden-md hidden-sm"> <button class="navbar-toggle docssubmenu-toggle collapsed" data-target="#docssubmenu" data-toggle="collapse" style=" float: none; background-color: #656565; border-color: #656565; width: 100%; color: #fff; "> Navigation Menu </button> </div> <div class="collapse" id="docssubmenu"> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a href="/blog">Home</a> <div class="icon"><span class="icon-home"></span></div> </li> <li class="item"> <a href="/archives">Archive</a> <div class="icon"><span class="icon-arrow-down"></span></div> </li> <li class="item"> <a href="/blog.atom">Feed</a> <div class="icon"><span class="icon-rss"></span></div> </li> </ul> </div> <p></p> <div class="featured-posts"> <div id="#featured" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;">Featured Posts</div> <ul style="padding-inline-start: 22px;"> <li style="margin-bottom: 3px;"> <a href="/blog/2024/01/11/Debezium-and-TimescaleDB/" style="font-size: 95%;"> Debezium and TimescaleDB </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/12/20/JDBC-sink-connector-batch-support/" style="font-size: 95%;"> Streamlined Performance: Debezium JDBC connector batch support </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/10/19/Debezium-Operator-Takes-off-to-the-Clouds/" style="font-size: 95%;"> Debezium Operator Takes off to the Clouds </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/10/05/Debezium-JMX-signaling-and-notifications/" style="font-size: 95%;"> Debezium signaling and notifications - Part 3: JMX channel </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/09/23/flink-spark-online-learning/" style="font-size: 95%;"> Online machine learning with the data streams from the database </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/07/10/custom-http-signaling-notification/" style="font-size: 95%;"> Debezium signaling and notifications - Part 2: Customisation </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/06/27/Debezium-signaling-and-notifications/" style="font-size: 95%;"> Debezium signaling and notifications - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/05/02/tensorflow-mnist-classification/" style="font-size: 95%;"> Image classification with Debezium and TensorFlow </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2020/11/04/streaming-vitess-at-bolt/" style="font-size: 95%;"> Streaming Vitess at Bolt </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2020/02/10/event-sourcing-vs-cdc/" style="font-size: 95%;"> Distributed Data for Microservices — Event Sourcing vs. Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/" style="font-size: 95%;"> Building Audit Logs with Change Data Capture and Stream Processing </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/07/12/streaming-cassandra-at-wepay-part-1/" style="font-size: 95%;"> Streaming Cassandra at WePay - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/" style="font-size: 95%;"> Reliable Microservices Data Exchange With the Outbox Pattern </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/" style="font-size: 95%;"> Automating Cache Invalidation With Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" style="font-size: 95%;"> Materializing Aggregate Views With Hibernate and Debezium </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/" style="font-size: 95%;"> Five Advantages of Log-Based Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/" style="font-size: 95%;"> Creating DDD aggregates with Debezium and Kafka Streams </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/" style="font-size: 95%;"> Streaming Data Changes from Your Database to Elasticsearch </a> </li> </ul> </div> <p></p> <p></p> <div class="cloud-tags"> <div id="tags" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Tags </div> <div class="tag-cloud"> <span class="site-tag"> <a href="/tag/apache-kafka/" style="font-size: 82%"> apache kafka </a> </span> <span class="site-tag"> <a href="/tag/apache-kafka/" style="font-size: 94%"> apache kafka </a> </span> <span class="site-tag"> <a href="/tag/apicurio/" style="font-size: 82%"> apicurio </a> </span> <span class="site-tag"> <a href="/tag/avro/" style="font-size: 84%"> avro </a> </span> <span class="site-tag"> <a href="/tag/aws/" style="font-size: 82%"> aws </a> </span> <span class="site-tag"> <a href="/tag/batch/" style="font-size: 82%"> batch </a> </span> <span class="site-tag"> <a href="/tag/caassandra/" style="font-size: 86%"> caassandra </a> </span> <span class="site-tag"> <a href="/tag/camel/" style="font-size: 82%"> camel </a> </span> <span class="site-tag"> <a href="/tag/cassandra/" style="font-size: 288%"> cassandra </a> </span> <span class="site-tag"> <a href="/tag/cdc/" style="font-size: 82%"> cdc </a> </span> <span class="site-tag"> <a href="/tag/channels/" style="font-size: 82%"> channels </a> </span> <span class="site-tag"> <a href="/tag/community/" style="font-size: 124%"> community </a> </span> <span class="site-tag"> <a href="/tag/community-stories/" style="font-size: 84%"> community stories </a> </span> <span class="site-tag"> <a href="/tag/connectors/" style="font-size: 82%"> connectors </a> </span> <span class="site-tag"> <a href="/tag/containers/" style="font-size: 82%"> containers </a> </span> <span class="site-tag"> <a href="/tag/cqrs/" style="font-size: 84%"> cqrs </a> </span> <span class="site-tag"> <a href="/tag/custom/" style="font-size: 82%"> custom </a> </span> <span class="site-tag"> <a href="/tag/datalake/" style="font-size: 82%"> datalake </a> </span> <span class="site-tag"> <a href="/tag/db2/" style="font-size: 272%"> db2 </a> </span> <span class="site-tag"> <a href="/tag/ddd/" style="font-size: 82%"> ddd </a> </span> <span class="site-tag"> <a href="/tag/debezium/" style="font-size: 104%"> debezium </a> </span> <span class="site-tag"> <a href="/tag/debezium-server/" style="font-size: 92%"> debezium server </a> </span> <span class="site-tag"> <a href="/tag/debezium-ui/" style="font-size: 90%"> debezium ui </a> </span> <span class="site-tag"> <a href="/tag/deduplication/" style="font-size: 82%"> deduplication </a> </span> <span class="site-tag"> <a href="/tag/discussion/" style="font-size: 114%"> discussion </a> </span> <span class="site-tag"> <a href="/tag/docker/" style="font-size: 186%"> docker </a> </span> <span class="site-tag"> <a href="/tag/elasticsearch/" style="font-size: 82%"> elasticsearch </a> </span> <span class="site-tag"> <a href="/tag/event-sourcing/" style="font-size: 82%"> event sourcing </a> </span> <span class="site-tag"> <a href="/tag/exactly-once-semantics/" style="font-size: 82%"> exactly once semantics </a> </span> <span class="site-tag"> <a href="/tag/example/" style="font-size: 88%"> example </a> </span> <span class="site-tag"> <a href="/tag/examples/" style="font-size: 116%"> examples </a> </span> <span class="site-tag"> <a href="/tag/features/" style="font-size: 92%"> features </a> </span> <span class="site-tag"> <a href="/tag/fedora/" style="font-size: 82%"> fedora </a> </span> <span class="site-tag"> <a href="/tag/flink/" style="font-size: 82%"> flink </a> </span> <span class="site-tag"> <a href="/tag/hiring/" style="font-size: 84%"> hiring </a> </span> <span class="site-tag"> <a href="/tag/ibmi/" style="font-size: 96%"> ibmi </a> </span> <span class="site-tag"> <a href="/tag/iceberg/" style="font-size: 82%"> iceberg </a> </span> <span class="site-tag"> <a href="/tag/informix/" style="font-size: 106%"> informix </a> </span> <span class="site-tag"> <a href="/tag/integration/" style="font-size: 86%"> integration </a> </span> <span class="site-tag"> <a href="/tag/introduction/" style="font-size: 84%"> introduction </a> </span> <span class="site-tag"> <a href="/tag/jaeger/" style="font-size: 82%"> jaeger </a> </span> <span class="site-tag"> <a href="/tag/jdbc/" style="font-size: 108%"> jdbc </a> </span> <span class="site-tag"> <a href="/tag/json/" style="font-size: 82%"> json </a> </span> <span class="site-tag"> <a href="/tag/kafka/" style="font-size: 94%"> kafka </a> </span> <span class="site-tag"> <a href="/tag/kafka-streams/" style="font-size: 82%"> kafka streams </a> </span> <span class="site-tag"> <a href="/tag/kafka-streams/" style="font-size: 86%"> kafka streams </a> </span> <span class="site-tag"> <a href="/tag/kogito/" style="font-size: 82%"> kogito </a> </span> <span class="site-tag"> <a href="/tag/ksql/" style="font-size: 82%"> ksql </a> </span> <span class="site-tag"> <a href="/tag/kubernetes/" style="font-size: 84%"> kubernetes </a> </span> <span class="site-tag"> <a href="/tag/lakehouse/" style="font-size: 82%"> lakehouse </a> </span> <span class="site-tag"> <a href="/tag/machine-learning/" style="font-size: 84%"> machine learning </a> </span> <span class="site-tag"> <a href="/tag/mariadb/" style="font-size: 104%"> mariadb </a> </span> <span class="site-tag"> <a href="/tag/microservices/" style="font-size: 84%"> microservices </a> </span> <span class="site-tag"> <a href="/tag/mongo/" style="font-size: 86%"> mongo </a> </span> <span class="site-tag"> <a href="/tag/mongodb/" style="font-size: 290%"> mongodb </a> </span> <span class="site-tag"> <a href="/tag/mysql/" style="font-size: 426%"> mysql </a> </span> <span class="site-tag"> <a href="/tag/news/" style="font-size: 112%"> news </a> </span> <span class="site-tag"> <a href="/tag/newsletter/" style="font-size: 88%"> newsletter </a> </span> <span class="site-tag"> <a href="/tag/notifications/" style="font-size: 86%"> notifications </a> </span> <span class="site-tag"> <a href="/tag/online-learning/" style="font-size: 82%"> online learning </a> </span> <span class="site-tag"> <a href="/tag/operator/" style="font-size: 82%"> operator </a> </span> <span class="site-tag"> <a href="/tag/oracle/" style="font-size: 322%"> oracle </a> </span> <span class="site-tag"> <a href="/tag/outbox/" style="font-size: 260%"> outbox </a> </span> <span class="site-tag"> <a href="/tag/performance/" style="font-size: 82%"> performance </a> </span> <span class="site-tag"> <a href="/tag/postgres/" style="font-size: 396%"> postgres </a> </span> <span class="site-tag"> <a href="/tag/presentation/" style="font-size: 84%"> presentation </a> </span> <span class="site-tag"> <a href="/tag/production/" style="font-size: 82%"> production </a> </span> <span class="site-tag"> <a href="/tag/quarkus/" style="font-size: 92%"> quarkus </a> </span> <span class="site-tag"> <a href="/tag/questdb/" style="font-size: 82%"> questdb </a> </span> <span class="site-tag"> <a href="/tag/rds/" style="font-size: 84%"> rds </a> </span> <span class="site-tag"> <a href="/tag/releases/" style="font-size: 408%"> releases </a> </span> <span class="site-tag"> <a href="/tag/schema/" style="font-size: 82%"> schema </a> </span> <span class="site-tag"> <a href="/tag/scylla/" style="font-size: 82%"> scylla </a> </span> <span class="site-tag"> <a href="/tag/secrets/" style="font-size: 82%"> secrets </a> </span> <span class="site-tag"> <a href="/tag/sentry/" style="font-size: 82%"> sentry </a> </span> <span class="site-tag"> <a href="/tag/serialization/" style="font-size: 82%"> serialization </a> </span> <span class="site-tag"> <a href="/tag/signaling/" style="font-size: 86%"> signaling </a> </span> <span class="site-tag"> <a href="/tag/smt/" style="font-size: 84%"> smt </a> </span> <span class="site-tag"> <a href="/tag/snapshots/" style="font-size: 84%"> snapshots </a> </span> <span class="site-tag"> <a href="/tag/spanner/" style="font-size: 148%"> spanner </a> </span> <span class="site-tag"> <a href="/tag/spark/" style="font-size: 82%"> spark </a> </span> <span class="site-tag"> <a href="/tag/sql/" style="font-size: 84%"> sql </a> </span> <span class="site-tag"> <a href="/tag/sqlserver/" style="font-size: 336%"> sqlserver </a> </span> <span class="site-tag"> <a href="/tag/tensorflow/" style="font-size: 82%"> tensorflow </a> </span> <span class="site-tag"> <a href="/tag/testcontainers/" style="font-size: 88%"> testcontainers </a> </span> <span class="site-tag"> <a href="/tag/tests/" style="font-size: 82%"> tests </a> </span> <span class="site-tag"> <a href="/tag/time-series/" style="font-size: 82%"> time series </a> </span> <span class="site-tag"> <a href="/tag/timescaledb/" style="font-size: 82%"> timescaledb </a> </span> <span class="site-tag"> <a href="/tag/topics/" style="font-size: 82%"> topics </a> </span> <span class="site-tag"> <a href="/tag/tracing/" style="font-size: 82%"> tracing </a> </span> <span class="site-tag"> <a href="/tag/transactions/" style="font-size: 82%"> transactions </a> </span> <span class="site-tag"> <a href="/tag/vagrant/" style="font-size: 82%"> vagrant </a> </span> <span class="site-tag"> <a href="/tag/vitess/" style="font-size: 252%"> vitess </a> </span> <span class="site-tag"> <a href="/tag/website/" style="font-size: 84%"> website </a> </span> </div> </div> </div> </div> </div> <div class="col-md-9"> <div class="post"> <div class="row" style="margin-left: 0; margin-right: 0; margin-bottom: 10px"> <div class="col-sm-12" style="padding-left: 0px"> <div style="display: table-cell; vertical-align: top"> <div style=" width: 72px; border: 1px solid #ccc; padding: 3px; display: inline-block; "> <img src="/assets/images/vjuranek.jpg" style="width: 64px;"> </div> </div> <div style="display: table-cell; vertical-align: top"> <div style="margin-left: 8px"> <span class="hidden-sm hidden-xs" style="font-size: 2.75rem; line-height: 1"> <a href="/blog/2023/05/02/tensorflow-mnist-classification/">Image classification with Debezium and TensorFlow</a> </span> <span class="hidden-md hidden-lg" style="font-size: 2rem; line-height: 1"> <a href="/blog/2023/05/02/tensorflow-mnist-classification/">Image classification with Debezium and TensorFlow</a> </span> <div class="byline" style="line-height: 1"> <em> May 2, 2023 by </em> <em> Vojtěch Juránek </em> <div class="hidden-xs" style="margin-top: 5px"> <a class="label label-info hidden-sm hidden-xs" href="/tag/machine-learning/">machine-learning</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/tensorflow/">tensorflow</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/examples/">examples</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/apache-kafka/">apache-kafka</a> </div> </div> </div> </div> </div> </div> <div class="grid__item width-12-12"><div class="paragraph"> <p>With the recent success of ChatGPT, we can observe another wave of interest in the AI field and machine learning in general. The previous wave of interest in this field was, at least to a certain extent, caused by the fact that excellent ML frameworks like <a href="https://www.tensorflow.org/">TensorFlow</a>, <a href="https://pytorch.org/">PyTorch</a> or general data processing frameworks like <a href="https://spark.apache.org/">Spark</a> became available and made the writing of ML models much more straightforward. Since that time, these frameworks have matured, and writing models are even more accessible, as you will see later in this blog. However, data set preparation and gathering data from various sources can sometimes take time and effort. Creating a complete pipeline that would pull existing or newly created data, adjust it, and ingest it into selected ML libraries can be challenging. Let&#8217;s investigate if Debezium can help with this task and explore how we can leverage Debezium&#8217;s capabilities to make it easier.</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="change_data_capture_and_debezium_in_ml_pipelines">Change data capture and Debezium in ML pipelines</h2> <div class="sectionbody"> <div class="paragraph"> <p>Change data capture (CDC) can be a compelling concept in machine learning, especially in online machine learning. However, using pre-trained models, CDC can also be an essential part of the pipeline. We can use CDC to deliver new data immediately into a pre-trained model, which can evaluate it, and other parts of the pipeline can take any action based on the model output in real-time.</p> </div> <div class="paragraph"> <p>Besides these use cases, Debezium is a perfect fit for any pipeline, including loading data from databases. Debezium can capture existing data as well as stream any newly created data. Another vital feature of Debezium is support for single message transforms. We can adjust the data at the very beginning of the whole pipeline. When applying transformations or filters, we can restrict data transmission over the wire to only that is of interest, saving bandwidth and speed within the pipeline. Additionally, Debezium can deliver records to several message brokers, and more brokers are being added (several new ones are available in the recent 2.2.0 release). These continued improvements increase the opportunity to integrate Debezium with other toolchains or data pipelines. The possibilities are endless, and Debezium&#8217;s common connector framework could allow for CDC beyond just databases.</p> </div> <div class="paragraph"> <p>So, this is the theory. Now let&#8217;s explore how it works in reality. This blog post will look at how to stream data into TensorFlow. Based on the interest from the community, this may result in a series of blog posts where we explore possible integrations with other ML libraries and frameworks.</p> </div> </div> </div> <div class="sect1"> <h2 id="debezium_and_tensorflow_integration">Debezium and TensorFlow integration</h2> <div class="sectionbody"> <div class="paragraph"> <p>TensorFlow is one of the most popular machine learning frameworks. It provides a comprehensive platform for building, training, and deploying machine learning models across various applications.</p> </div> <div class="paragraph"> <p>To keep things simple, we will implement a model for recognizing handwritten digits, which is more or less the Hello World equivalent in the neural networks field. The ultimate goal of this demo is to use Debezium to load MNIST data samples from Postgres that are continuously stored, pass it to our model implemented in Tensorflow for training, and use this trained model for real-time classification of images</p> </div> <div class="paragraph"> <p>The diagram below depicts the complete pipeline:</p> </div> <div class="imageblock centered-image"> <img src="/assets/images/2023-04-21-tensorflow-mnist-classification/pipeline.png" class="responsive-image" alt="Debezium TensorFlow integration pipeline"> </div> <div class="paragraph"> <p>All the code mentioned later in this blog is available as a Debezium example in <a href="https://github.com/debezium/debezium-examples/tree/main/tensorflow-mnist">Debezium example repository</a>.</p> </div> <div class="sect2"> <h3 id="the_data_sample">The data sample</h3> <div class="paragraph"> <p>We will use <a href="http://yann.lecun.com/exdb/mnist/">MNIST data sample</a>. The training sample contains 60,000 images with handwritten digits from 0 to 9 and the same amount of labels with corresponding digits. The test sample contains 1,000 images. The samples are available as gzip binaries. As we assume a use case where the data of interest are in the database, we need to load the data into the database first.</p> </div> <div class="paragraph"> <p>We need to generate two SQL files, one for the train data set, <code>mnist_train.sql</code>, and one for a test data sample, <code>mnist_test.sql</code>. Each file would contain SQL commands for creating a table with two columns: <code>pixels</code> column of type <code>BYTEA</code>, which would contain raw image bytes, and <code>labels</code> column of type <code>SMALLINT</code>, which would contain digit corresponding to the image in given table row. The rest of the file would contain commands for populating the table. Image bytes can be decoded as a HEX string.</p> </div> <div class="paragraph"> <p>As we will show how to leverage Debezium for data streaming later in this post, we will initially load the training data set into the database. The SQL file with training data will be used directly by the Postgres container - when it starts, it will load this data into the training table. We will use the test data SQL file later. However, the preparation of the data is the same for training as well as test samples, and we can prepare both of them in one go.</p> </div> <div class="paragraph"> <p>To prepare these SQL files, you can use <code>mnist2sql.py</code> script from <a href="https://github.com/debezium/debezium-examples/tree/main/tensorflow-mnist">Debezium tensorflow-mnist example</a>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ ./mnist2sql.py --download</code></pre> </div> </div> <div class="paragraph"> <p>The script assumes MNIST data sets are available in the <code>postgres</code> directory. When using the <code>--download</code> parameter, the script first downloads MNIST data samples into the <code>postgres</code> directory. The <code>postgres</code> directory will contain the resulting SQL files.</p> </div> </div> <div class="sect2"> <h3 id="loading_streamed_data_into_tensorflow">Loading streamed data into Tensorflow</h3> <div class="paragraph"> <p>The most common Debezium usage is the streaming of records to Kafka. TensorFlow provides <a href="https://www.tensorflow.org/io">TensorFlow I/O</a> module for loading data from various sources. Besides other sources, it also allows loading the data from Kafka. There are several ways to do it. <a href="https://www.tensorflow.org/io/api_docs/python/tfio/IODataset#from_kafka">IODataset.from_kafka()</a> method loads only existing data from specified Kafka topics. Two experimental classes support streaming data, <a href="https://www.tensorflow.org/io/api_docs/python/tfio/experimental/streaming/KafkaBatchIODataset">KafkaBatchIODataset</a> and <a href="https://www.tensorflow.org/io/api_docs/python/tfio/experimental/streaming/KafkaGroupIODataset">KafkaGroupIODataset</a>. Both are very similar and allow them to work with streaming data, i.e., they not only read the existing data from a Kafka topic but also wait for new data and eventually pass new records into the TensorFlow. Streaming concludes when there are no new events within a specified time frame.</p> </div> <div class="paragraph"> <p>In all cases, a <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">Dataset</a> represents all loaded records in Tensorflow. This Tensorflow data structure provides convenience for building <a href="https://www.tensorflow.org/guide/data">data pipelines</a>, which may include further data transformations or preprocessing.</p> </div> <div class="paragraph"> <p>This sounds great. However, the most significant caveat is the representation of records within the Dataset. These Kafka loaders completely ignore the schema of the records provided by Kafka, meaning that keys and values are raw bytes of data. Additionally, the ingestion pipeline complicates the process by converting these into strings (i.e., <code>toString()</code> on the object called). So if you pass, e.g., raw image bytes via Kafka, using Kafka <code>BYTES_SCHEMA</code>, it would result in something like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>&lt;tf.Tensor: shape=(64,), dtype=string, numpy=
 array([b'[B@418b353d', b'[B@6aa28a4c', b'[B@b626485', b'[B@6d7491cd',
        b'[B@13fa86c5', b'[B@7c3bc352', b'[B@64e5d61c', b'[B@2dd6d9b4',
        b'[B@6addae65', b'[B@48ded13f', b'[B@2c1bb0e', b'[B@19c1d99b',
        b'[B@1ee8f240', b'[B@20019f8b', b'[B@2f17494e', b'[B@380d4036',
        b'[B@61aecf85', b'[B@4d7fe9fc', b'[B@58b79424', b'[B@ae963f4',
        b'[B@1dac57cb', b'[B@2fae7d8b', b'[B@4b5ccaee', b'[B@aebf6b2',
        b'[B@7506ea2b', b'[B@29989325', b'[B@43e2742', b'[B@51350f11',
        b'[B@13a0f0ae', b'[B@7e4c4844', b'[B@b3d64f8', b'[B@7209bf09',
        b'[B@66380466', b'[B@7aaa7e8d', b'[B@1ad0cf84', b'[B@259eca20',
        b'[B@3a3f1c1', b'[B@36e4ff1f', b'[B@6578fc29', b'[B@79c924be',
        b'[B@765b7f70', b'[B@67567aa3', b'[B@456d4bd4', b'[B@75317b13',
        b'[B@58bc3a3a', b'[B@c6bc0ec', b'[B@2377095e', b'[B@5de017c0',
        b'[B@64b48bac', b'[B@360a5b76', b'[B@2d2c9910', b'[B@70afd562',
        b'[B@3006c930', b'[B@54b3e5ad', b'[B@1d1e0232', b'[B@1394d036',
        b'[B@155dd43d', b'[B@5e88d5b6', b'[B@33ea53c7', b'[B@64a30ec',
        b'[B@7dcdf024', b'[B@6570bf4e', b'[B@4e5bc4c', b'[B@537f216c'],
       dtype=object)&gt;,</code></pre> </div> </div> <div class="paragraph"> <p>Instead of getting a batch of raw image bytes which you can further transform in TensorFlow, you get only string representation of Java byte arrays, which is not very useful.</p> </div> <div class="paragraph"> <p>The most straightforward solution would be to convert the raw image bytes into numbers before sending them to Kafka to mitigate the problem. As TensorFlow provides methods for parsing CSV input, we can convert each image into one CSV line of numbers. Since Tensorflow primarily works with numbers, we would be required to convert the images to numbers regardless. We can pass the number on the image as a message key. Now, a single message transform supported by Debezium comes in handy. The transformation can look like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">    <span class="annotation">@Override</span>
    <span class="directive">public</span> R apply(R r) {
        <span class="directive">final</span> <span class="predefined-type">Struct</span> value = (<span class="predefined-type">Struct</span>) r.value();
        <span class="predefined-type">String</span> key = value.getInt16(labelFieldName).toString();

        <span class="predefined-type">StringBuilder</span> builder = <span class="keyword">new</span> <span class="predefined-type">StringBuilder</span>();
        <span class="keyword">for</span> (<span class="type">byte</span> pixel : value.getBytes(pixlesFieldName)) {
            builder.append(pixel &amp; <span class="hex">0xFF</span>).append(<span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span>);
        }
        <span class="keyword">if</span> (builder.length() &gt; <span class="integer">0</span>) {
            builder.deleteCharAt(builder.length() - <span class="integer">1</span>);
        }
        <span class="predefined-type">String</span> newValue = builder.toString();

        <span class="keyword">return</span> r.newRecord(r.topic(), r.kafkaPartition(), <span class="predefined-type">Schema</span>.STRING_SCHEMA, key, <span class="predefined-type">Schema</span>.STRING_SCHEMA, newValue, r.timestamp());
    }</code></pre> </div> </div> <div class="paragraph"> <p>On the TensorFlow side, we must convert bytes obtained from Kafka messages into numbers. The following illustrates a map function to handle this easily:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">def</span> <span class="function">decode_kafka_record</span>(record):
    img_int = tf.io.decode_csv(record.message, [[<span class="float">0.0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(NUM_COLUMNS)])
    img_norm = tf.cast(img_int, tf.float32) / <span class="float">255.</span>
    label_int = tf.strings.to_number(record.key, out_type=tf.dtypes.int32)
    <span class="keyword">return</span> (img_norm, label_int)</code></pre> </div> </div> <div class="paragraph"> <p>Here we parse CSV lines, potentially provided as the raw bytes, and immediately scale the numbers within the &lt;0, 1&gt; interval, which is convenient for training our model later. Loading the data and creating data batches is very straightforward:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">train_ds = tfio.IODataset.from_kafka(KAFKA_TRAIN_TOPIC, partition=<span class="integer">0</span>, offset=<span class="integer">0</span>, servers=KAFKA_SERVERS)
train_ds = train_ds.map(decode_kafka_record)
train_ds = train_ds.batch(BATCH_SIZE)</code></pre> </div> </div> <div class="paragraph"> <p>Here we use <code>IODataset.from_kafka()</code> for loading existing data from the Kafka topic, use our map function to convert bytes into numbers, and scale the numbers. As a last step, we create batches from the data set for more efficient processing. Parameters of <code>tfio.IODataset.from_kafka()</code> are self-explanatory and probably don&#8217;t need further comments.</p> </div> <div class="paragraph"> <p>As a result, we have a data set formed by two-dimensional tensors. The first dimension is a vector of floats representing the image, while the second dimension is a single number (scalar) describing the number on the picture. Once we have prepared our training data set, we can define our neural network model.</p> </div> </div> <div class="sect2"> <h3 id="defining_the_model">Defining the model</h3> <div class="paragraph"> <p>To keep things simple, as the main goal of this post is not to show the best handwritten digit classifier, but to show how to create the data pipeline, let&#8217;s use a very simple model:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(<span class="integer">128</span>, activation=<span class="string"><span class="delimiter">'</span><span class="content">relu</span><span class="delimiter">'</span></span>),
    tf.keras.layers.Dense(<span class="integer">10</span>)
])</code></pre> </div> </div> <div class="paragraph"> <p>This model contains only two layers. Although this model is really simple, it still does a pretty good job in recognition of handwritten digits. Probably more interesting than the model itself is how easy it is to write a mode in TensorFlow (or actually <a href="https://keras.io/">Keras</a>, but it&#8217;s now part of TensorFlow).</p> </div> <div class="paragraph"> <p>Similarly easy is to define model optimizer and the loss function:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">model.compile(
    optimizer=tf.keras.optimizers.Adam(<span class="float">0.001</span>),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="predefined-constant">True</span>),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)</code></pre> </div> </div> <div class="paragraph"> <p>It&#8217;s outside of this post&#8217;s scope to explain these functions, and you can check almost any machine learning online course or textbook on this topic for a detailed explanation.</p> </div> <div class="paragraph"> <p>Once we have our model ready, we can train it on the trained dataset prepared in the previous section:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">model.fit(train_ds,epochs=MAX_EPOCHS)</code></pre> </div> </div> <div class="paragraph"> <p>This step may take quite some time to finish. However, once finished, our model is ready to recognize handwritten digits!</p> </div> </div> <div class="sect2"> <h3 id="streaming_the_data_into_the_model">Streaming the data into the model</h3> <div class="paragraph"> <p>Let&#8217;s see how good our model is in digit recognition. But as our primary goal here is to explore the means how to ingest data into TensorFlow, we will start model evaluation on an empty (or, more accurately, even non-existing) Kafka topic and see if we will be able to evaluate the data on the fly as they will pop-up first in the database and then in the corresponding Kafka topic. For this purpose, we can use one of the streaming classes mentioned above:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">test_ds = tfio.experimental.streaming.KafkaGroupIODataset(
    topics=[KAFKA_TEST_TOPIC],
    group_id=KAFKA_CONSUMER_GROUP,
    servers=KAFKA_SERVERS,
    stream_timeout=<span class="integer">9000</span>,
    configuration=[
        <span class="string"><span class="delimiter">&quot;</span><span class="content">session.timeout.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">max.poll.interval.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">auto.offset.reset=earliest</span><span class="delimiter">&quot;</span></span>
    ],
)</code></pre> </div> </div> <div class="paragraph"> <p>Again, arguments are mostly self-explanatory. Two things may need further explanation: <code>stream_timeout</code> and <code>configuration</code> parameters. <code>stream_timeout</code> determines the interval of inactivity (in milliseconds) after which the streaming would terminate. <code>configuration</code> is <a href="https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md">librdkafka configuration</a>. It&#8217;s a configuration of the Kafka client; you should configure at least the session timeout (<code>session.timeout.ms</code>), and it&#8217;s poll interval (<code>max.poll.interval.ms</code>). The values of these parameters should be higher than the value of <code>stream_timeout</code>.</p> </div> <div class="paragraph"> <p>The dataset this loader provides is slightly different - instead of providing a single record containing the message and its key, we get the key and message already split. Therefore, we have to define a slightly modified map function with two arguments:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">def</span> <span class="function">decode_kafka_stream_record</span>(message, key):
    img_int = tf.io.decode_csv(message, [[<span class="float">0.0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(NUM_COLUMNS)])
    img_norm = tf.cast(img_int, tf.float32) / <span class="float">255.</span>
    label_int = tf.strings.to_number(key, out_type=tf.dtypes.int32)
    <span class="keyword">return</span> (img_norm, label_int)</code></pre> </div> </div> <div class="paragraph"> <p>With this function, we can adjust the dataset and create batches as before:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">test_ds = test_ds.map(decode_kafka_stream_record)
test_ds = test_ds.batch(BATCH_SIZE)</code></pre> </div> </div> <div class="paragraph"> <p>and evaluate the model:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">model.evaluate(test_ds)</code></pre> </div> </div> <div class="paragraph"> <p>You can execute a cell with model evaluation in the Jupyter notebook. The execution will wait because there is no such topic in Kafka and no table with test data in the database. The streaming timeout is 9 seconds, so data must be provided within this time frame after launching the model evaluation. At the start of this demo, we created a SQL file in the <code>postgres</code> directory called <code>mnist_test.sql</code>, which can generate the test data we need:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ export PGPASSWORD=postgres
$ psql -h localhost -U postgres -f postgres/mnist_test.sql</code></pre> </div> </div> <div class="paragraph"> <p>After a short while, you should see in the Jupyter notebook output that some data arrived into the model and, a few moments later final evaluation of the model.</p> </div> <div class="paragraph"> <p>To make the results closer to humans, let&#8217;s define an image manually and serve it to the model. We can also easily show the image in the Jypiter notebook. The function for plotting the images and providing model predictions as a plot title can look like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">def</span> <span class="function">plot_and_predict</span>(pixels):
    test = tf.constant([pixels])
    tf.shape(test)
    test_norm = tf.cast(test, tf.float32) / <span class="float">255.</span>

    prediction = model.predict(test_norm)
    number = tf.nn.softmax(prediction).numpy().argmax()

    pixels_array = np.asarray(pixels)
    raw_img = np.split(pixels_array, <span class="integer">28</span>)
    plt.imshow(raw_img)
    plt.title(number)
    plt.axis(<span class="string"><span class="delimiter">&quot;</span><span class="content">off</span><span class="delimiter">&quot;</span></span>)</code></pre> </div> </div> <div class="paragraph"> <p>Probably the only cryptic line in this function is the one containing the <code>softmax()</code> function. This function converts the resulting vector into a vector of probabilities. Elements of this vector express the probability that the number on a given position is the one on the image. Therefore, the position with the highest probability is the model&#8217;s prediction, where <code>argmax()</code> is derived.</p> </div> <div class="paragraph"> <p>We can try it, e.g., for this image, which contains the handwritten number 3:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>pixels = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,43,6,6,6,6,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,84,248,254,254,254,254,254,241,45,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,254,254,254,223,173,173,173,253,156,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,79,157,228,245,251,188,63,17,0,0,54,252,132,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,254,254,254,244,131,0,0,0,0,13,220,254,122,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,254,225,160,47,0,0,0,0,59,211,254,206,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,21,14,0,0,0,2,17,146,245,250,194,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,140,140,171,254,254,254,203,55,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,211,254,254,254,254,179,211,254,254,202,171,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,167,233,193,69,16,3,9,16,107,231,248,195,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,229,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,99,252,254,146,0,0,0,0,0,0,0,0,79,142,0,0,0,0,0,0,0,0,0,26,28,116,147,247,254,239,150,22,0,0,0,0,0,0,0,0,175,230,174,155,66,66,132,174,174,174,174,250,255,254,192,189,99,36,0,0,0,0,0,0,0,0,0,0,106,226,254,254,254,254,254,254,254,254,217,151,80,43,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,7,114,114,114,46,5,5,5,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
plot_and_predict(pixels)</code></pre> </div> </div> <div class="paragraph"> <p>The result would be as follows:</p> </div> <div class="imageblock centered-image"> <img src="/assets/images/2023-04-21-tensorflow-mnist-classification/tensorflow_mnist_digit.png" class="responsive-image" alt="TensorFlow digit recognition"> </div> <div class="paragraph"> <p>You can do the same by reading from a Kafka stream, and we can reuse existing topics for this purpose. As we already read all records from the test stream, we need to change the Kafka consumer group if we want to reread it using streaming <code>KafkaGroupIODataset</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">manual_ds = tfio.experimental.streaming.KafkaGroupIODataset(
    topics=[KAFKA_TEST_TOPIC],
    group_id=<span class="string"><span class="delimiter">&quot;</span><span class="content">mnistcg2</span><span class="delimiter">&quot;</span></span>,
    servers=KAFKA_SERVERS,
    stream_timeout=<span class="integer">9000</span>,
    configuration=[
        <span class="string"><span class="delimiter">&quot;</span><span class="content">session.timeout.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">max.poll.interval.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">auto.offset.reset=earliest</span><span class="delimiter">&quot;</span></span>
    ],
)

manual_ds = manual_ds.map(decode_kafka_stream_record)</code></pre> </div> </div> <div class="paragraph"> <p>If you want to create a new stream and verify that our model can provide prediction as the new data arrives, you can easily do so:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ head -5 mnist_test.sql | sed s/test/manual/ &gt; mnist_manual.sql
$ psql -h localhost -U postgres -f postgres/mnist_manual.sql</code></pre> </div> </div> <div class="paragraph"> <p>In such case you don&#8217;t need to change Kafka consumer group, but you have to change the Kafka topic:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="python">manual_ds = tfio.experimental.streaming.KafkaGroupIODataset(
    topics=[<span class="string"><span class="delimiter">&quot;</span><span class="content">tf.public.mnist_manual</span><span class="delimiter">&quot;</span></span>],
    group_id=KAFKA_CONSUMER_GROUP,
    servers=KAFKA_SERVERS,
    stream_timeout=<span class="integer">9000</span>,
    configuration=[
        <span class="string"><span class="delimiter">&quot;</span><span class="content">session.timeout.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">max.poll.interval.ms=10000</span><span class="delimiter">&quot;</span></span>,
        <span class="string"><span class="delimiter">&quot;</span><span class="content">auto.offset.reset=earliest</span><span class="delimiter">&quot;</span></span>
    ],
)

manual_ds = manual_ds.map(decode_kafka_stream_record)</code></pre> </div> </div> <div class="paragraph"> <p>In either case, the result should look like this:</p> </div> <div class="imageblock centered-image"> <img src="/assets/images/2023-04-21-tensorflow-mnist-classification/tensorflow_mnist_streaming.png" class="responsive-image" alt="TensorFlow digit recognition from streaming"> </div> </div> </div> </div> <div class="sect1"> <h2 id="conclusions">Conclusions</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this demo, we have shown how to load existing data from the database, transform it on the fly, ingest it into the TensorFlow model via Kafka, and use it for model training. Later on, we ingested newly created data into this pre-trained model using CDC and data streaming and obtained meaningful results. Debezium can provide valuable service not only for use cases like the one described in this post but can also play a key role in ingesting data to online machine learning pipelines.</p> </div> <div class="paragraph"> <p>While the whole pipeline is relatively easy to implement, some areas can be improved to improve the user experience and/or make the entire pipeline more smooth. As our (Debezium developers) background is not primarily in machine learning and data science, we would appreciate any input from the community on how Debezium can aid machine learning pipelines (or is already used, if there are any such cases) and where are the rooms for improvements. We would also appreciate any new ideas on how Debezium, or in general, change data capture, can be helpful in this area. These ideas further reveal Debezium&#8217;s potential to ingest data into machine learning pipelines and contribute to better user experience in the whole process. In case you have any input any this regard, don&#8217;t hesitate to reach out to us on the <a href="http://debezium.zulipchat.com/">Zulip chat</a>, <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> or you can transform your ideas directly into <a href="http://issues.redhat.com/projects/DBZ/issues">Jira feature requests</a>.</p> </div> </div> </div></div> </div> <div class="well"> <div class="row"> <div class="col-md-8"> <h2>Vojtěch Juránek</h2> <p> <span class="bio-size">Vojta is a software engineer at Red Hat. He lives in the Czech Republic.</span> </p> <p class="bio-size"> <a href="https://github.com/vjuranek"> <i class="icon-github"></i> </a> &nbsp; </p> </div> <div class="col-md-4"> <img alt="" class="img-responsive pull-right portrait" src="/assets/images/vjuranek.jpg"/> </div> </div> </div> <ul class="pager pager-blog"> <li class="previous"> <a href="/blog/2023/04/25/container-images-quayio/" class="previous"> &laquo; Previous</a> </li> <li class="next"><a href="/blog/2023/05/15/debezium-2-3-alpha1-released/">Next &raquo; </a></li> </ul> <div class="row"> <div class="col-md-12"> <hr> <h2>About Debezium</h2> <p> Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>. </p> </div> </div> <div class="row"> <div class="col-md-12"> <h2>Get involved</h2> <p> We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://debezium.zulipchat.com/#narrow/stream/302529-users">chat with us on Zulip</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.redhat.com/projects/DBZ/issues/">log an issue</a>. </p> </div> </div> <div id="disqus_thread"></div> <script>var disqus_config=function(){this.page.url="https://debezium.io/blog/2023/05/02/tensorflow-mnist-classification/",this.page.identifier="https://debezium.io/blog/2023/05/02/tensorflow-mnist-classification/"};!function(){var t=document,i=t.createElement("script");i.src="https://Debezium.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(i)}();</script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript> </div> </div> </div> <footer class="container"> <div> <div class="row mr-0 ml-0"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2024 Debezium Community <br/> <br/> <i class="icon-fire"></i> Mixed with <a href="https://getbootstrap.com/">Bootstrap</a>, baked by <a href="https://jekyllrb.com/">Jekyll</a>. <br/> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br/> <i class="icon-flag-alt"></i> Code released under <a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br/> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> <p>Rev: <a target="_blank" href="https://github.com/debezium/debezium.github.io/commit/7e4cac3e6ff79c09248c2ce5a2d9ae03e4f31c69">7e4cac3</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li><a href="/documentation/reference/stable/features.html" title="Features">Features</a></li> <li> <a href="/documentation/reference/stable/install.html" title="Install">Install</a> </li> <li> <a href="/documentation/reference/stable/architecture.html" title="Architecture">Architecture</a> </li> <li><a href="/documentation/faq/" title="FAQ">FAQ</a></li> <li> <a href="/community/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li><a href="/blog" title="Blog">Blog</a></li> <li> <a href="https://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li><a href="https://github.com/debezium" title="GitHub">GitHub</a></li> <li><a href="https://debezium.zulipchat.com/#narrow/stream/302529-users" title="Chat">Chat</a></li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="https://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <a href="https://www.redhat.com/"> <img src="/assets/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"/> </a> </div> </div> </div> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-76464546-1"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-76464546-1");</script> <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> <script type="text/javascript" src="/assets/javascript/vanilla-back-to-top.min.js"></script> <script type="text/javascript" src="/assets/javascript/highlight.min.js"></script> <script>addBackToTop({scrollDuration:400}),hljs.initHighlightingOnLoad();</script> </body> </html>