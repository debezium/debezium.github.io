<!DOCTYPE html> <html> <head> <title>Online machine learning with the data streams from the database</title> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta content="Debezium" property="og:site_name"> <meta content="Online machine learning with the data streams from the database" property="og:title"> <meta content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png" property="og:image" name="image"> <meta property="og:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta property="og:url" content="https://debezium.io/blog/2023/09/23/flink-spark-online-learning/"> <meta name="twitter:site" content="@debezium"> <meta name="twitter:title" content="Online machine learning with the data streams from the database"> <meta name="twitter:creator" content="@vjuranek"> <meta name="twitter:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:image" content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png"> <meta property="twitter:url" content="https://debezium.io/blog/2023/09/23/flink-spark-online-learning/"> <link rel="alternate" type="application/rss+xml" title="Debezium Blog" href="/blog.atom"> <link rel="shortcut icon" type="image/png" href="/favicon.ico"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css"/> <link rel="stylesheet" href="/assets/css/custom.css"/> <link rel="stylesheet" href="/assets/css/highlight.min.css"/> <link rel="stylesheet" href="/assets/css/coderay.css"/> </head> <body class="post"> <div id="rhbar"> <a class="jbdevlogo" href="https://developers.redhat.com"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id> <div class="container" id="content"> <nav class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed border-0" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"><img class="project-logo" src="/assets/images/color_white_debezium_type_600px.svg" style="height: 32px; margin-right: 5px; margin-top: -5px;"></a> </div> <div class="collapse navbar-collapse collapsed" id="navigation"> <ul class="nav navbar-nav pull-right"> <li> <a href="/documentation/faq" class="">FAQ</a> </li> <li class="item"> <a href="/documentation/" class="">Documentation</a> </li> <li> <a href="/releases/" class="">Releases</a> </li> <li> <a href="/community/" class="">Community</a> </li> <li class="active"> <a href="/blog/" class="active">Blog</a> </li> </ul> </div> </div> </nav> <div class="row post-text-padding row-no-expand"> <div class="col-md-3"><div id="leftdocnav"> <div class="hidden-lg hidden-md hidden-sm"> <button class="navbar-toggle docssubmenu-toggle collapsed" data-target="#docssubmenu" data-toggle="collapse" style=" float: none; background-color: #656565; border-color: #656565; width: 100%; color: #fff; "> Navigation Menu </button> </div> <div class="collapse" id="docssubmenu"> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a href="/blog">Home</a> <div class="icon"><span class="icon-home"></span></div> </li> <li class="item"> <a href="/archives">Archive</a> <div class="icon"><span class="icon-arrow-down"></span></div> </li> <li class="item"> <a href="/blog.atom">Feed</a> <div class="icon"><span class="icon-rss"></span></div> </li> </ul> </div> <p></p> <div class="featured-posts"> <div id="#featured" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;">Featured Posts</div> <ul style="padding-inline-start: 22px;"> <li style="margin-bottom: 3px;"> <a href="/blog/2024/07/08/async-embedded-engine/" style="font-size: 95%;"> Debezium asynchronous engine </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2024/01/11/Debezium-and-TimescaleDB/" style="font-size: 95%;"> Debezium and TimescaleDB </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/12/20/JDBC-sink-connector-batch-support/" style="font-size: 95%;"> Streamlined Performance: Debezium JDBC connector batch support </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/10/19/Debezium-Operator-Takes-off-to-the-Clouds/" style="font-size: 95%;"> Debezium Operator Takes off to the Clouds </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/10/05/Debezium-JMX-signaling-and-notifications/" style="font-size: 95%;"> Debezium signaling and notifications - Part 3: JMX channel </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/09/23/flink-spark-online-learning/" style="font-size: 95%;"> Online machine learning with the data streams from the database </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/07/10/custom-http-signaling-notification/" style="font-size: 95%;"> Debezium signaling and notifications - Part 2: Customisation </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/06/27/Debezium-signaling-and-notifications/" style="font-size: 95%;"> Debezium signaling and notifications - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2023/05/02/tensorflow-mnist-classification/" style="font-size: 95%;"> Image classification with Debezium and TensorFlow </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2020/11/04/streaming-vitess-at-bolt/" style="font-size: 95%;"> Streaming Vitess at Bolt </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2020/02/10/event-sourcing-vs-cdc/" style="font-size: 95%;"> Distributed Data for Microservices — Event Sourcing vs. Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/" style="font-size: 95%;"> Building Audit Logs with Change Data Capture and Stream Processing </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/07/12/streaming-cassandra-at-wepay-part-1/" style="font-size: 95%;"> Streaming Cassandra at WePay - Part 1 </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/" style="font-size: 95%;"> Reliable Microservices Data Exchange With the Outbox Pattern </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/" style="font-size: 95%;"> Automating Cache Invalidation With Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" style="font-size: 95%;"> Materializing Aggregate Views With Hibernate and Debezium </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/" style="font-size: 95%;"> Five Advantages of Log-Based Change Data Capture </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/" style="font-size: 95%;"> Creating DDD aggregates with Debezium and Kafka Streams </a> </li> <li style="margin-bottom: 3px;"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/" style="font-size: 95%;"> Streaming Data Changes from Your Database to Elasticsearch </a> </li> </ul> </div> <p></p> <p></p> <div class="cloud-tags"> <div id="tags" style="margin-bottom: 4px; border-bottom: 1px solid #ccc; font-size: 115%; margin-left: 2px;"> Tags </div> <div class="tag-cloud"> <span class="site-tag"> <a href="/tag/apache-kafka/" style="font-size: 82%"> apache kafka </a> </span> <span class="site-tag"> <a href="/tag/apache-kafka/" style="font-size: 96%"> apache kafka </a> </span> <span class="site-tag"> <a href="/tag/apicurio/" style="font-size: 82%"> apicurio </a> </span> <span class="site-tag"> <a href="/tag/avro/" style="font-size: 84%"> avro </a> </span> <span class="site-tag"> <a href="/tag/aws/" style="font-size: 82%"> aws </a> </span> <span class="site-tag"> <a href="/tag/batch/" style="font-size: 82%"> batch </a> </span> <span class="site-tag"> <a href="/tag/caassandra/" style="font-size: 86%"> caassandra </a> </span> <span class="site-tag"> <a href="/tag/camel/" style="font-size: 82%"> camel </a> </span> <span class="site-tag"> <a href="/tag/cassandra/" style="font-size: 296%"> cassandra </a> </span> <span class="site-tag"> <a href="/tag/cdc/" style="font-size: 82%"> cdc </a> </span> <span class="site-tag"> <a href="/tag/channels/" style="font-size: 82%"> channels </a> </span> <span class="site-tag"> <a href="/tag/community/" style="font-size: 124%"> community </a> </span> <span class="site-tag"> <a href="/tag/community-stories/" style="font-size: 84%"> community stories </a> </span> <span class="site-tag"> <a href="/tag/connectors/" style="font-size: 82%"> connectors </a> </span> <span class="site-tag"> <a href="/tag/containers/" style="font-size: 82%"> containers </a> </span> <span class="site-tag"> <a href="/tag/cqrs/" style="font-size: 84%"> cqrs </a> </span> <span class="site-tag"> <a href="/tag/custom/" style="font-size: 82%"> custom </a> </span> <span class="site-tag"> <a href="/tag/datalake/" style="font-size: 82%"> datalake </a> </span> <span class="site-tag"> <a href="/tag/db2/" style="font-size: 280%"> db2 </a> </span> <span class="site-tag"> <a href="/tag/ddd/" style="font-size: 82%"> ddd </a> </span> <span class="site-tag"> <a href="/tag/debezium/" style="font-size: 106%"> debezium </a> </span> <span class="site-tag"> <a href="/tag/debezium-server/" style="font-size: 94%"> debezium server </a> </span> <span class="site-tag"> <a href="/tag/debezium-ui/" style="font-size: 90%"> debezium ui </a> </span> <span class="site-tag"> <a href="/tag/deduplication/" style="font-size: 82%"> deduplication </a> </span> <span class="site-tag"> <a href="/tag/discussion/" style="font-size: 114%"> discussion </a> </span> <span class="site-tag"> <a href="/tag/docker/" style="font-size: 186%"> docker </a> </span> <span class="site-tag"> <a href="/tag/elasticsearch/" style="font-size: 82%"> elasticsearch </a> </span> <span class="site-tag"> <a href="/tag/event-sourcing/" style="font-size: 82%"> event sourcing </a> </span> <span class="site-tag"> <a href="/tag/exactly-once-semantics/" style="font-size: 82%"> exactly once semantics </a> </span> <span class="site-tag"> <a href="/tag/example/" style="font-size: 88%"> example </a> </span> <span class="site-tag"> <a href="/tag/examples/" style="font-size: 118%"> examples </a> </span> <span class="site-tag"> <a href="/tag/features/" style="font-size: 94%"> features </a> </span> <span class="site-tag"> <a href="/tag/fedora/" style="font-size: 82%"> fedora </a> </span> <span class="site-tag"> <a href="/tag/flink/" style="font-size: 84%"> flink </a> </span> <span class="site-tag"> <a href="/tag/hiring/" style="font-size: 84%"> hiring </a> </span> <span class="site-tag"> <a href="/tag/ibmi/" style="font-size: 104%"> ibmi </a> </span> <span class="site-tag"> <a href="/tag/iceberg/" style="font-size: 82%"> iceberg </a> </span> <span class="site-tag"> <a href="/tag/informix/" style="font-size: 114%"> informix </a> </span> <span class="site-tag"> <a href="/tag/integration/" style="font-size: 86%"> integration </a> </span> <span class="site-tag"> <a href="/tag/introduction/" style="font-size: 84%"> introduction </a> </span> <span class="site-tag"> <a href="/tag/jaeger/" style="font-size: 82%"> jaeger </a> </span> <span class="site-tag"> <a href="/tag/jdbc/" style="font-size: 116%"> jdbc </a> </span> <span class="site-tag"> <a href="/tag/json/" style="font-size: 82%"> json </a> </span> <span class="site-tag"> <a href="/tag/kafka/" style="font-size: 94%"> kafka </a> </span> <span class="site-tag"> <a href="/tag/kafka-streams/" style="font-size: 82%"> kafka streams </a> </span> <span class="site-tag"> <a href="/tag/kafka-streams/" style="font-size: 86%"> kafka streams </a> </span> <span class="site-tag"> <a href="/tag/kogito/" style="font-size: 82%"> kogito </a> </span> <span class="site-tag"> <a href="/tag/ksql/" style="font-size: 82%"> ksql </a> </span> <span class="site-tag"> <a href="/tag/kubernetes/" style="font-size: 86%"> kubernetes </a> </span> <span class="site-tag"> <a href="/tag/lakehouse/" style="font-size: 82%"> lakehouse </a> </span> <span class="site-tag"> <a href="/tag/machine-learning/" style="font-size: 86%"> machine learning </a> </span> <span class="site-tag"> <a href="/tag/mariadb/" style="font-size: 112%"> mariadb </a> </span> <span class="site-tag"> <a href="/tag/microservices/" style="font-size: 84%"> microservices </a> </span> <span class="site-tag"> <a href="/tag/mongo/" style="font-size: 86%"> mongo </a> </span> <span class="site-tag"> <a href="/tag/mongodb/" style="font-size: 298%"> mongodb </a> </span> <span class="site-tag"> <a href="/tag/mysql/" style="font-size: 434%"> mysql </a> </span> <span class="site-tag"> <a href="/tag/news/" style="font-size: 112%"> news </a> </span> <span class="site-tag"> <a href="/tag/newsletter/" style="font-size: 88%"> newsletter </a> </span> <span class="site-tag"> <a href="/tag/notifications/" style="font-size: 86%"> notifications </a> </span> <span class="site-tag"> <a href="/tag/online-learning/" style="font-size: 84%"> online learning </a> </span> <span class="site-tag"> <a href="/tag/operator/" style="font-size: 84%"> operator </a> </span> <span class="site-tag"> <a href="/tag/oracle/" style="font-size: 330%"> oracle </a> </span> <span class="site-tag"> <a href="/tag/outbox/" style="font-size: 268%"> outbox </a> </span> <span class="site-tag"> <a href="/tag/performance/" style="font-size: 82%"> performance </a> </span> <span class="site-tag"> <a href="/tag/postgres/" style="font-size: 404%"> postgres </a> </span> <span class="site-tag"> <a href="/tag/presentation/" style="font-size: 84%"> presentation </a> </span> <span class="site-tag"> <a href="/tag/production/" style="font-size: 82%"> production </a> </span> <span class="site-tag"> <a href="/tag/quarkus/" style="font-size: 92%"> quarkus </a> </span> <span class="site-tag"> <a href="/tag/questdb/" style="font-size: 82%"> questdb </a> </span> <span class="site-tag"> <a href="/tag/rds/" style="font-size: 84%"> rds </a> </span> <span class="site-tag"> <a href="/tag/releases/" style="font-size: 416%"> releases </a> </span> <span class="site-tag"> <a href="/tag/schema/" style="font-size: 82%"> schema </a> </span> <span class="site-tag"> <a href="/tag/scylla/" style="font-size: 82%"> scylla </a> </span> <span class="site-tag"> <a href="/tag/secrets/" style="font-size: 82%"> secrets </a> </span> <span class="site-tag"> <a href="/tag/sentry/" style="font-size: 82%"> sentry </a> </span> <span class="site-tag"> <a href="/tag/serialization/" style="font-size: 82%"> serialization </a> </span> <span class="site-tag"> <a href="/tag/signaling/" style="font-size: 86%"> signaling </a> </span> <span class="site-tag"> <a href="/tag/smt/" style="font-size: 84%"> smt </a> </span> <span class="site-tag"> <a href="/tag/snapshots/" style="font-size: 84%"> snapshots </a> </span> <span class="site-tag"> <a href="/tag/spanner/" style="font-size: 156%"> spanner </a> </span> <span class="site-tag"> <a href="/tag/spark/" style="font-size: 84%"> spark </a> </span> <span class="site-tag"> <a href="/tag/sql/" style="font-size: 84%"> sql </a> </span> <span class="site-tag"> <a href="/tag/sqlserver/" style="font-size: 344%"> sqlserver </a> </span> <span class="site-tag"> <a href="/tag/tensorflow/" style="font-size: 82%"> tensorflow </a> </span> <span class="site-tag"> <a href="/tag/testcontainers/" style="font-size: 88%"> testcontainers </a> </span> <span class="site-tag"> <a href="/tag/tests/" style="font-size: 82%"> tests </a> </span> <span class="site-tag"> <a href="/tag/time-series/" style="font-size: 82%"> time series </a> </span> <span class="site-tag"> <a href="/tag/timescaledb/" style="font-size: 82%"> timescaledb </a> </span> <span class="site-tag"> <a href="/tag/topics/" style="font-size: 82%"> topics </a> </span> <span class="site-tag"> <a href="/tag/tracing/" style="font-size: 82%"> tracing </a> </span> <span class="site-tag"> <a href="/tag/transactions/" style="font-size: 82%"> transactions </a> </span> <span class="site-tag"> <a href="/tag/ui/" style="font-size: 82%"> ui </a> </span> <span class="site-tag"> <a href="/tag/vagrant/" style="font-size: 82%"> vagrant </a> </span> <span class="site-tag"> <a href="/tag/vitess/" style="font-size: 260%"> vitess </a> </span> <span class="site-tag"> <a href="/tag/website/" style="font-size: 84%"> website </a> </span> </div> </div> </div> </div> </div> <div class="col-md-9"> <div class="post"> <div class="row" style="margin-left: 0; margin-right: 0; margin-bottom: 10px"> <div class="col-sm-12" style="padding-left: 0px"> <div style="display: table-cell; vertical-align: top"> <div style=" width: 72px; border: 1px solid #ccc; padding: 3px; display: inline-block; "> <img src="/assets/images/vjuranek.jpg" style="width: 64px;"> </div> </div> <div style="display: table-cell; vertical-align: top"> <div style="margin-left: 8px"> <span class="hidden-sm hidden-xs" style="font-size: 2.75rem; line-height: 1"> <a href="/blog/2023/09/23/flink-spark-online-learning/">Online machine learning with the data streams from the database</a> </span> <span class="hidden-md hidden-lg" style="font-size: 2rem; line-height: 1"> <a href="/blog/2023/09/23/flink-spark-online-learning/">Online machine learning with the data streams from the database</a> </span> <div class="byline" style="line-height: 1"> <em> September 23, 2023 by </em> <em> Vojtěch Juránek </em> <div class="hidden-xs" style="margin-top: 5px"> <a class="label label-info hidden-sm hidden-xs" href="/tag/machine-learning/">machine-learning</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/flink/">flink</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/spark/">spark</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/online-learning/">online-learning</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/examples/">examples</a> <a class="label label-info hidden-sm hidden-xs" href="/tag/apache-kafka/">apache-kafka</a> </div> </div> </div> </div> </div> </div> <div class="grid__item width-12-12"><div class="paragraph"> <p>In <a href="https://debezium.io/blog/2023/05/02/tensorflow-mnist-classification/">the previous blog post</a>, we have shown how to leverage Debezium to train neural-network model with the existing data from the database and use this pre-trained model to classify images newly stored into the database. In this blog post, we will move it one step further - we will use Debezium to create multiple data streams from the database and use one of the streams for continuous learning and to improve our model, and the second one for making predictions on the data. When the model is constantly improved or adjusted to recent data samples, this approach is known as <a href="https://en.wikipedia.org/wiki/Online_machine_learning">online machine learning</a>. Online learning is only suitable for some use cases, and implementing an online variant of a given algorithm may be challenging or even impossible. However, in situations where online learning is possible, it becomes a very powerful tool as it allows one to react to the changes in the data in real-time and avoids the need to re-train and re-deploy new models, thus saving the hardware and operational costs. As the streams of data become more and more common, e.g. with the advent of IoT, we can expect online learning to become more and more popular. It&#8217;s usually a perfect fit for analyzing streaming data in use cases where it&#8217;s possible.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>As mentioned in the previous blog, our goal here is not to build the best possible model for a given use case but to investigate how we can build a complete pipeline from inserting the data into the database through delivering it to the model and using it for model training and predictions. To keep things simple, we will use another well-known data sample often used in ML tutorials. We will explore how to classify various species of the Iris flower using an online variant of <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-mean clustering algorithm</a>. We use <a href="https://flink.apache.org/">Apache Flink</a> and <a href="https://spark.apache.org/">Apache Spark</a> to process the data streams. Both these frameworks are very popular data processing frameworks and include a machine learning library, which, besides others, implements online k-means algorithms. Thus, we can focus on building a complete pipeline for delivering the data from the database into a given model, processing it in real time, and not having to deal with the algorithm&#8217;s implementation details.</p> </div> <div class="paragraph"> <p>All the code mentioned later in this blog post is available as a Debezium example in <a href="https://github.com/debezium/debezium-examples/tree/blog_flink_spark_ml/machine-learning/flink-spark-iris">Debezium example repository</a>, with all other useful stuff, like Docker composes and step-by-step instructions in the <a href="https://github.com/debezium/debezium-examples/blob/blog_flink_spark_ml/machine-learning/flink-spark-iris/README.adoc">README</a> file.</p> </div> <div class="sect1"> <h2 id="data_set_preparation">Data set preparation</h2> <div class="sectionbody"> <div class="paragraph"> <p>We will use <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris flower data set</a>. Our goal is to determine the Iris species based on a couple of measurements of the Iris flower: its sepal length, sepal width, petal length, and petal width.</p> </div> <div class="imageblock centered-image"> <figure> <img src="/assets/images/2023-09-23-flink-spark-online-learning/iris_versicolor.jpg" class="responsive-image" alt="Iris versicolor"> <figcaption>Iris versicolor, source <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set#/media/File:Iris_versicolor_3.jpg">Wikipedia</a></figcaption> </figure> </div> <div class="paragraph"> <p>The data set can be downloaded from various sources. We can take advantage of the fact that it&#8217;s available already pre-processed in e.g. <a href="https://scikit-learn.org">scikit-learn</a> toolkit and use it from there. Each sample row contains a data point (sepal length, sepal width, petal length, and petal width) and a label. Label is number 0, 1, or 2, where 0 stands for Iris setosa, 1 stands for Iris versicolor, and 2 for Iris virginica. The data set is small - containing only 150 data points.</p> </div> <div class="paragraph"> <p>As we load the data into the database, we will first prepare SQL files, which we will later pass to the database. We need to divide the original data sample into three sub-samples - two for training and one for testing. The initial training will use the first training data sample. This data sample is intentionally small to not generate good predictions when we test the model for the first time so that we can see how the model&#8217;s prediction will increase in real-time when we feed it with more data.</p> </div> <div class="paragraph"> <p>You can use the following Python script from the accompanying demo repository for generating all three SQL files.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>$ ./iris2sql.py</code></pre> </div> </div> <div class="paragraph"> <p>The <code>postgres</code> directory contains the files used for this demo. <code>train1.sql</code> will be loaded automatically into the Postgres database upon its start. <code>test.sql</code> and <code>train2.sql</code> will be loaded manually into the database later.</p> </div> </div> </div> <div class="sect1"> <h2 id="classification_with_apache_flink">Classification with Apache Flink</h2> <div class="sectionbody"> <div class="paragraph"> <p>First, let&#8217;s look at how to do online Iris flower classification and learning in Apache Flink. The following figure depicts the high-level schema for the entire pipeline.</p> </div> <div class="imageblock centered-image"> <img src="/assets/images/2023-09-23-flink-spark-online-learning/postgres_to_flink.png" class="responsive-image" alt="Postgres to Flink schema"> </div> <div class="paragraph"> <p>We will use Postgres as our source database. Debezium, deployed as a Kafka Connect source connector, tracks the changes in the database and creates the streams of data sent to Kafka from newly inserted data. Kafka sends these streams to Apache Flink, which employs the streaming k-means algorithm for model fitting and data classification. The predictions of the model for test data streams are produced as another stream and sent back to Kafka.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>You can also ingest database changes directly into the Flink without using Kafka. Ververika&#8217;s implementation of CDC source connectors embeds the Debezium directly into the Flink. See Flink CDC connectors <a href="https://ververica.github.io/flink-cdc-connectors/">documentation</a> for more details.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Our database contains two tables. The first stores our training data, while the second stores the test data. Therefore, there are two data streams, each corresponding to one table - one data stream for learning and one with data points that need to be classified. In real applications, you can use only one table or, on the contrary, many more tables. You can even deploy more Debezium connectors and thus combine data from several databases.</p> </div> <div class="sect2"> <h3 id="using_debezium_and_kafka_as_a_source_data_stream">Using Debezium and Kafka as a source data stream</h3> <div class="paragraph"> <p>Apache Flink has excellent integration with Kafka. We can pass the Debezium records as e.g. JSON records. For creating Flink tables, it even has support for Debezium&#8217;s record format, but for streams, we need to extract part of the Debezium message, which contains the newly stored row of the table. However, this is very easy as Debezium provides SMT, <a href="https://debezium.io/documentation/reference/nightly/transformations/event-flattening.html">extract new record state SMT</a>, which does precisely this. The complete Debezium configuration can look like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">iris-connector-flink</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">connector.class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.connector.postgresql.PostgresConnector</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">tasks.max</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.hostname</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.port</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">5432</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.user</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.password</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.dbname</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">topic.prefix</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">flink</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">table.include.list</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">public.iris_.*</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">key.converter</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.json.JsonConverter</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">value.converter</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.json.JsonConverter</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">unwrap</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.unwrap.type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.transforms.ExtractNewRecordState</span><span class="delimiter">&quot;</span></span>
    }
}</code></pre> </div> </div> <div class="paragraph"> <p>The configuration captures all tables in the <code>public</code> schema with tables that begin with the <code>iris_</code> prefix. Since we are storing training and test data in two tables, two Kafka topics named <code>flink.public.iris_train</code> and <code>flink.public.iris_test</code> are created, respectively. Flink&#8217;s <code>DataStreamSource</code> represents the incoming stream of data. As we encode the records as a JSON, it will be a stream of JSON <code>ObjectNode</code> objects. Constructing the source stream is very straightforward:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">KafkaSource&lt;ObjectNode&gt; train = KafkaSource.&lt;ObjectNode&gt;builder()
    .setBootstrapServers(<span class="string"><span class="delimiter">&quot;</span><span class="content">kafka:9092</span><span class="delimiter">&quot;</span></span>)
    .setTopics(<span class="string"><span class="delimiter">&quot;</span><span class="content">flink.public.iris_train</span><span class="delimiter">&quot;</span></span>)
    .setClientIdPrefix(<span class="string"><span class="delimiter">&quot;</span><span class="content">train</span><span class="delimiter">&quot;</span></span>)
    .setGroupId(<span class="string"><span class="delimiter">&quot;</span><span class="content">dbz</span><span class="delimiter">&quot;</span></span>)
    .setStartingOffsets(OffsetsInitializer.earliest())
    .setDeserializer(KafkaRecordDeserializationSchema.of(<span class="keyword">new</span> JSONKeyValueDeserializationSchema(<span class="predefined-constant">false</span>)))
    .build();
DataStreamSource&lt;ObjectNode&gt; trainStream = env.fromSource(train, WatermarkStrategy.noWatermarks(), <span class="string"><span class="delimiter">&quot;</span><span class="content">Debezium train</span><span class="delimiter">&quot;</span></span>);</code></pre> </div> </div> <div class="paragraph"> <p>Flink operates primarily on the <code>Table</code> abstraction object. Also, ML models accept only tables as input, and predictions are produced as tables too. Therefore, we must first convert our input stream into a <code>Table</code> object. We will start by transforming our input data stream into a stream of table rows. We need to define a map function that would return a <code>Row</code> object with a vector containing one data point. As the k-means algorithm belongs to <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised learning</a> algorithms, i.e. the model doesn&#8217;t need corresponding "right answers" for the data points, we can skip the <code>label</code> field from the vector:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="directive">private</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">RecordMapper</span> <span class="directive">implements</span> MapFunction&lt;ObjectNode, Row&gt; {
    <span class="annotation">@Override</span>
    <span class="directive">public</span> Row map(ObjectNode node) {
        JsonNode payload = node.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">value</span><span class="delimiter">&quot;</span></span>).get(<span class="string"><span class="delimiter">&quot;</span><span class="content">payload</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">StringBuffer</span> sb = <span class="keyword">new</span> <span class="predefined-type">StringBuffer</span>();
        <span class="keyword">return</span> Row.of(Vectors.dense(
                        payload.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">sepal_length</span><span class="delimiter">&quot;</span></span>).asDouble(),
                        payload.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">sepal_width</span><span class="delimiter">&quot;</span></span>).asDouble(),
                        payload.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">petal_length</span><span class="delimiter">&quot;</span></span>).asDouble(),
                        payload.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">petal_width</span><span class="delimiter">&quot;</span></span>).asDouble()));
    }
}</code></pre> </div> </div> <div class="paragraph"> <p>Various parts of the internal Flink pipeline can run on different worker nodes, and therefore, we also need to provide type information about the table. With that, we are ready to create the table object:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);
TypeInformation&lt;?&gt;<span class="type">[]</span> types = {DenseVectorTypeInfo.INSTANCE};
<span class="predefined-type">String</span> names<span class="type">[]</span> = {<span class="string"><span class="delimiter">&quot;</span><span class="content">features</span><span class="delimiter">&quot;</span></span>};
RowTypeInfo typeInfo = <span class="keyword">new</span> RowTypeInfo(types, names);

DataStream&lt;Row&gt; inputStream = trainStream.map(<span class="keyword">new</span> RecordMapper()).returns(typeInfo);
Table trainTable = tEnv.fromDataStream(inputStream).as(<span class="string"><span class="delimiter">&quot;</span><span class="content">features</span><span class="delimiter">&quot;</span></span>);</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="building_flink_stream_k_means">Building Flink stream k-means</h3> <div class="paragraph"> <p>Once we have a <code>Table</code> object, we can pass it to our model. So let&#8217;s create one and pass a train stream to it for continuous model training:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">OnlineKMeans onlineKMeans = <span class="keyword">new</span> OnlineKMeans()
    .setFeaturesCol(<span class="string"><span class="delimiter">&quot;</span><span class="content">features</span><span class="delimiter">&quot;</span></span>)
    .setPredictionCol(<span class="string"><span class="delimiter">&quot;</span><span class="content">prediction</span><span class="delimiter">&quot;</span></span>)
    .setInitialModelData(tEnv.fromDataStream(env.fromElements(<span class="integer">1</span>).map(<span class="keyword">new</span> IrisInitCentroids())))
    .setK(<span class="integer">3</span>);
OnlineKMeansModel model = onlineKMeans.fit(trainTable);</code></pre> </div> </div> <div class="paragraph"> <p>To make things more straightforward, we directly set the number of desired clusters to 3 instead of finding the optimal number of clusters by digging into the data (using e.g. <a href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)">elbow method</a>). We also set some initial values for the centers of the clusters instead of using random numbers (Flink provides a convenient method for it - <code>KMeansModelData.generateRandomModelData()</code> if you want to try with random centers).</p> </div> <div class="paragraph"> <p>To obtain the predictions for our test data, we again need to convert our test stream into a table. The model transforms the table with test data into a table with predictions. Finally, convert the prediction into a stream and persisted, e.g. in a Kafka topic:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">DataStream&lt;Row&gt; testInputStream = testStream.map(<span class="keyword">new</span> RecordMapper()).returns(typeInfo);
Table testTable = tEnv.fromDataStream(testInputStream).as(<span class="string"><span class="delimiter">&quot;</span><span class="content">features</span><span class="delimiter">&quot;</span></span>);
Table outputTable = model.transform(testTable)[<span class="integer">0</span>];

DataStream&lt;Row&gt; resultStream = tEnv.toChangelogStream(outputTable);
resultStream.map(<span class="keyword">new</span> ResultMapper()).sinkTo(kafkaSink);</code></pre> </div> </div> <div class="paragraph"> <p>Now, we are ready to build our application and almost ready to submit it to Flink for execution. Before we do, we need to create the required Kafka topics first. While the topics can be empty, Flink requires that they at least exist. As we include a small set of data in the Postgres training table when the database starts, Debezium will create a corresponding topic when registering the Debezium Postgres connector in Kafka Connect. Since the test data table does not yet exist, we need to create the topic in Kafka manually:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ docker compose -f docker-compose-flink.yaml exec kafka /kafka/bin/kafka-topics.sh --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1  --topic flink.public.iris_test</code></pre> </div> </div> <div class="paragraph"> <p>Now, we are ready to submit our application to Flink. For the complete code, please see the corresponding source code in Debezium <a href="https://github.com/debezium/debezium-examples/blob/blog_flink_spark_ml/machine-learning/flink-spark-iris/iris-flink/src/main/java/io/github/vjuranek/FlinkKafkaKmeans.java">example repository</a></p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>If you don&#8217;t use Docker compose provided as part of the source code for this demo, please include <a href="https://nightlies.apache.org/flink/flink-ml-docs-master/">Flink ML library</a> in the Flink <code>lib</code> folder, as the ML library is not part of default Flink distribution.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Flink provides a friendly UI, which is available on <a href="http://localhost:8081/" class="bare">http://localhost:8081/</a>. There, you can check, besides other things, the status of your jobs and also, e.g. job execution plan in an excellent graphical representation:</p> </div> <div class="imageblock centered-image"> <a href="/assets/images/2023-09-23-flink-spark-online-learning/flink_dag.png" target="_blank"><img src="/assets/images/2023-09-23-flink-spark-online-learning/flink_dag.png" class="responsive-image" alt="Postgres to Flink schema"></a> </div> </div> <div class="sect2"> <h3 id="evaluating_the_model">Evaluating the model</h3> <div class="paragraph"> <p>From the user&#8217;s point of view, all the interactions with our model occur by inserting new records into the database or reading Kafka topics with predictions. As we already created a very small initial training data sample in the database when it started, we can directly check our model predictions by inserting our test data sample into the database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ psql -h localhost -U postgres -f postgres/iris_test.sql</code></pre> </div> </div> <div class="paragraph"> <p>The insert results in an immediate data stream of test data in Kafka, passing it into the model and sending the prediction back to the <code>iris_predictions</code> Kafka topic. The predictions are not accurate when training the model on a very small data set with just two clusters. The following shows our initial predictions:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>[5.4, 3.7, 1.5, 0.2] is classified as 0
[4.8, 3.4, 1.6, 0.2] is classified as 0
[7.6, 3.0, 6.6, 2.1] is classified as 2
[6.4, 2.8, 5.6, 2.2] is classified as 2
[6.0, 2.7, 5.1, 1.6] is classified as 2
[5.4, 3.0, 4.5, 1.5] is classified as 2
[6.7, 3.1, 4.7, 1.5] is classified as 2
[5.5, 2.4, 3.8, 1.1] is classified as 2
[6.1, 2.8, 4.7, 1.2] is classified as 2
[4.3, 3.0, 1.1, 0.1] is classified as 0
[5.8, 2.7, 3.9, 1.2] is classified as 2</code></pre> </div> </div> <div class="paragraph"> <p>In our case, the correct answer should be:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>[5.4, 3.7, 1.5, 0.2] is 0
[4.8, 3.4, 1.6, 0.2] is 0
[7.6, 3.0, 6.6, 2.1] is 2
[6.4, 2.8, 5.6, 2.2] is 2
[6.0, 2.7, 5.1, 1.6] is 1
[5.4, 3.0, 4.5, 1.5] is 1
[6.7, 3.1, 4.7, 1.5] is 1
[5.5, 2.4, 3.8, 1.1] is 1
[6.1, 2.8, 4.7, 1.2] is 1
[4.3, 3.0, 1.1, 0.1] is 0
[5.8, 2.7, 3.9, 1.2] is 1</code></pre> </div> </div> <div class="paragraph"> <p>When comparing the result, we only have 5 of 11 data points correctly classified due to the initial sample training data size. On the other hand, as we didn&#8217;t start with completely random clusters, our predictions are also not completely wrong.</p> </div> <div class="paragraph"> <p>Let&#8217;s see how things change when we supply more training data into the model:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ psql -h localhost -U postgres -f postgres/iris_train2.sql</code></pre> </div> </div> <div class="paragraph"> <p>To see the updated predictions, we insert the same test data sample again into the database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ psql -h localhost -U postgres -f postgres/iris_test.sql</code></pre> </div> </div> <div class="paragraph"> <p>The following predictions are much better since we have all three categories present. We have also correctly classified 7 out of the 11 data points.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>[5.4, 3.7, 1.5, 0.2] is classified as 0
[4.8, 3.4, 1.6, 0.2] is classified as 0
[7.6, 3.0, 6.6, 2.1] is classified as 2
[6.4, 2.8, 5.6, 2.2] is classified as 2
[6.0, 2.7, 5.1, 1.6] is classified as 2
[5.4, 3.0, 4.5, 1.5] is classified as 2
[6.7, 3.1, 4.7, 1.5] is classified as 2
[5.5, 2.4, 3.8, 1.1] is classified as 1
[6.1, 2.8, 4.7, 1.2] is classified as 2
[4.3, 3.0, 1.1, 0.1] is classified as 0
[5.8, 2.7, 3.9, 1.2] is classified as 1</code></pre> </div> </div> <div class="paragraph"> <p>As the whole data sample is pretty small, for further model training we can re-use our second train data sample:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="bash">$ psql -h localhost -U postgres -f postgres/iris_train2.sql
$ psql -h localhost -U postgres -f postgres/iris_test.sql</code></pre> </div> </div> <div class="paragraph"> <p>This results in the following prediction.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>[5.4, 3.7, 1.5, 0.2] is classified as 0
[4.8, 3.4, 1.6, 0.2] is classified as 0
[7.6, 3.0, 6.6, 2.1] is classified as 2
[6.4, 2.8, 5.6, 2.2] is classified as 2
[6.0, 2.7, 5.1, 1.6] is classified as 2
[5.4, 3.0, 4.5, 1.5] is classified as 1
[6.7, 3.1, 4.7, 1.5] is classified as 2
[5.5, 2.4, 3.8, 1.1] is classified as 1
[6.1, 2.8, 4.7, 1.2] is classified as 1
[4.3, 3.0, 1.1, 0.1] is classified as 0
[5.8, 2.7, 3.9, 1.2] is classified as 1</code></pre> </div> </div> <div class="paragraph"> <p>We now find we have 9 out of 11 data points correctly classified. While this is still not an excellent result, we expect only partially accurate results as this is simply a prediction. The primary motivation here is to show the whole pipeline and demonstrate that the model improves the predictions without re-training and re-deploying the model when adding new data.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="classification_with_apache_spark">Classification with Apache Spark</h2> <div class="sectionbody"> <div class="paragraph"> <p>From the user&#8217;s point of view, Apache Spark is very similar to Flink, and the implementation would be quite similar. This chapter is briefer to make this blog post more digestible.</p> </div> <div class="paragraph"> <p>Spark has two streaming models: the older <a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">DStreams</a>, which is now in legacy state, and the more recent and recommended <a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">structured streaming</a>. However, as the streaming k-means algorithm contained in the Spark ML library works only with the DStreams, for simplicity, DStreams are used in this example. A better approach would be to use structured streaming and implement the streaming k-means ourselves. This is, however, outside this blog post&#8217;s scope and main goal.</p> </div> <div class="paragraph"> <p>Spark supports streaming from Kafka using DStreams. However, writing DStreams back to Kafka is not supported, although it is possible but isn&#8217;t straightforward.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Structured streaming supports both directions, reading and writing to Kafka, very easily.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Again, for the sake of simplicity, we skip the final part and will write the predictions only to the console instead of writing them back to Kafka. The big picture of our pipelines thus looks like this:</p> </div> <div class="imageblock centered-image"> <img src="/assets/images/2023-09-23-flink-spark-online-learning/postgres_to_spark.png" class="responsive-image" alt="Postgres to Spark schema"> </div> <div class="sect2"> <h3 id="defining_the_data_streams">Defining the data streams</h3> <div class="paragraph"> <p>Similarly to Flink, creating Spark streams from Kafka streams is straightforward, and most of the parameters are self-explanatory:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Set</span>&lt;<span class="predefined-type">String</span>&gt; trainTopic = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">spark.public.iris_train</span><span class="delimiter">&quot;</span></span>));
<span class="predefined-type">Set</span>&lt;<span class="predefined-type">String</span>&gt; testTopic = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">spark.public.iris_test</span><span class="delimiter">&quot;</span></span>));
<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; kafkaParams = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
kafkaParams.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">kafka:9092</span><span class="delimiter">&quot;</span></span>);
kafkaParams.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">dbz</span><span class="delimiter">&quot;</span></span>);
kafkaParams.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">earliest</span><span class="delimiter">&quot;</span></span>);
kafkaParams.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
kafkaParams.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

JavaInputDStream&lt;ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt;&gt; trainStream = KafkaUtils.createDirectStream(
        jssc,
        LocationStrategies.PreferConsistent(),
        ConsumerStrategies.Subscribe(trainTopic, kafkaParams));
JavaDStream&lt;LabeledPoint&gt; train = trainStream.map(ConsumerRecord::value)
        .map(SparkKafkaStreamingKmeans::toLabeledPointString)
        .map(LabeledPoint::parse);</code></pre> </div> </div> <div class="paragraph"> <p>On the last line, we transform the Kafka stream to a labeled point stream, which the Spark ML library uses for working with its ML models. Labeled points are expected as the strings formatted as data point labels separated by the comma from space-separated data point values. So the map function looks like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="directive">private</span> <span class="directive">static</span> <span class="predefined-type">String</span> toLabeledPointString(<span class="predefined-type">String</span> json) <span class="directive">throws</span> <span class="exception">ParseException</span> {
    JSONParser jsonParser = <span class="keyword">new</span> JSONParser();
    JSONObject o = (JSONObject)jsonParser.parse(json);
    <span class="keyword">return</span> <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">%s, %s %s %s %s</span><span class="delimiter">&quot;</span></span>,
            o.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">iris_class</span><span class="delimiter">&quot;</span></span>),
            o.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">sepal_length</span><span class="delimiter">&quot;</span></span>),
            o.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">sepal_width</span><span class="delimiter">&quot;</span></span>),
            o.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">petal_length</span><span class="delimiter">&quot;</span></span>),
            o.get(<span class="string"><span class="delimiter">&quot;</span><span class="content">petal_width</span><span class="delimiter">&quot;</span></span>));
}</code></pre> </div> </div> <div class="paragraph"> <p>It still applies that k-means is an unsupervised algorithm and doesn&#8217;t use the data point labels. However, it&#8217;s convenient to pass them to <code>LabeledPoint</code> class as later on, we can show them together with model predictions.</p> </div> <div class="paragraph"> <p>We chain one more map function to parse the string and create a labeled data point from it. In this case, it&#8217;s a built-in function of Spark <code>LabeledPoint</code>.</p> </div> <div class="paragraph"> <p>Contrary to Flink, Spark doesn&#8217;t require Kafka topics to exist in advance, so when deploying the model, we don&#8217;t have to create the topics. We can let Debezium create them once the table with the test data is created and populated with the data.</p> </div> </div> <div class="sect2"> <h3 id="defining_and_evaluating_the_model">Defining and evaluating the model</h3> <div class="paragraph"> <p>Defining the streaming k-means model is very similar to Flink:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">StreamingKMeans model = <span class="keyword">new</span> StreamingKMeans()
        .setK(<span class="integer">3</span>)
        .setInitialCenters(initCenters, weights);
model.trainOn(train.map(lp -&gt; lp.getFeatures()));</code></pre> </div> </div> <div class="paragraph"> <p>Also, in this case, we directly set the number of clusters to 3 and provide the same initial central points to the clusters. We also only pass the data points for training, not the labels.</p> </div> <div class="paragraph"> <p>As mentioned above, we can use the labels to show them together with the predictions:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java">JavaPairDStream&lt;<span class="predefined-type">Double</span>, <span class="predefined-type">Vector</span>&gt; predict = test.mapToPair(lp -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(lp.label(), lp.features()));
model.predictOnValues(predict).print(<span class="integer">11</span>);</code></pre> </div> </div> <div class="paragraph"> <p>We print 11 stream elements to the console on the resulting stream with the predictions, as this is the size of our test sample. Like Flink, the results after initial training on a very small data sample could be better. The first number in the tuple is the data point label, while the second one is the corresponding prediction done by our model:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>spark_1      | (0.0,0)
spark_1      | (0.0,0)
spark_1      | (2.0,2)
spark_1      | (2.0,2)
spark_1      | (1.0,0)
spark_1      | (1.0,0)
spark_1      | (1.0,2)
spark_1      | (1.0,0)
spark_1      | (1.0,0)
spark_1      | (0.0,0)
spark_1      | (1.0,0)</code></pre> </div> </div> <div class="paragraph"> <p>However, when we provide more training data, predictions are much better:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>spark_1      | (0.0,0)
spark_1      | (0.0,0)
spark_1      | (2.0,2)
spark_1      | (2.0,2)
spark_1      | (1.0,1)
spark_1      | (1.0,1)
spark_1      | (1.0,2)
spark_1      | (1.0,0)
spark_1      | (1.0,1)
spark_1      | (0.0,0)
spark_1      | (1.0,0)</code></pre> </div> </div> <div class="paragraph"> <p>If we pass the second training data sample once again for the training, our model makes correct predictions for the whole test sample:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>---
spark_1      | (0.0,0)
spark_1      | (0.0,0)
spark_1      | (2.0,2)
spark_1      | (2.0,2)
spark_1      | (1.0,1)
spark_1      | (1.0,1)
spark_1      | (1.0,1)
spark_1      | (1.0,1)
spark_1      | (1.0,1)
spark_1      | (0.0,0)
spark_1      | (1.0,1)
----</code></pre> </div> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>The prediction is a number of the cluster which k-means algorithm created and has no relation to labels in our data sample. That means that e.g. <code>(0.0,1)</code> doesn&#8217;t have to be a wrong prediction. It can happen that a data point with label 0 was assigned to the correct cluster, however, Spark internally marked it as a cluster number 1. This needs to be kept in mind when evaluating the model.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>So, similar to Flink, we get better results as we pass more training data without the need to re-train and re-deploy the model. In this case, we get even better results than Flink&#8217;s model.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="conclusions">Conclusions</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this blog post, we continued exploring how Debezium can help make data ingestion into various ML frameworks seamless. We have shown how to pass the data from the database to Apache Flink and Apache Spark in real time as a stream of the data. The integration is easy to set up in both cases and works well. We demonstrated it in an example that allows us to use an online learning algorithm, namely the online k-means algorithm, to highlight the power of data streaming. Online machine learning allows us to make real-time predictions on the data stream and improve or adjust the model immediately as the new training data arrives. Model adjustment doesn&#8217;t require any model re-training on a separate compute cluster and re-deploying a new model, making ML-ops more straightforward and cost-effective.</p> </div> <div class="paragraph"> <p>As usual, we would appreciate any feedback on this blog post. Do you have any ideas on how Debezium or change data capture can be helpful in this area? What would be helpful to investigate, whether integration with another ML framework, integration with a specific ML feature store, etc.? In case you have any input any this regard, don&#8217;t hesitate to reach out to us on the <a href="http://debezium.zulipchat.com/">Zulip chat</a>, <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> or you can transform your ideas directly into <a href="http://issues.redhat.com/projects/DBZ/issues">Jira feature requests</a>.</p> </div> </div> </div></div> </div> <div class="well"> <div class="row"> <div class="col-md-8"> <h2>Vojtěch Juránek</h2> <p> <span class="bio-size">Vojta is a software engineer at Red Hat. He lives in the Czech Republic.</span> </p> <p class="bio-size"> <a href="https://github.com/vjuranek"> <i class="icon-github"></i> </a> &nbsp; </p> </div> <div class="col-md-4"> <img alt="" class="img-responsive pull-right portrait" src="/assets/images/vjuranek.jpg"/> </div> </div> </div> <ul class="pager pager-blog"> <li class="previous"> <a href="/blog/2023/09/22/debezium-2-4-cr1-released/" class="previous"> &laquo; Previous</a> </li> <li class="next"><a href="/blog/2023/10/03/debezium-2-4-final-released/">Next &raquo; </a></li> </ul> <div class="row"> <div class="col-md-12"> <hr> <h2>About Debezium</h2> <p> Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>. </p> </div> </div> <div class="row"> <div class="col-md-12"> <h2>Get involved</h2> <p> We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://debezium.zulipchat.com/#narrow/stream/302529-users">chat with us on Zulip</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.redhat.com/projects/DBZ/issues/">log an issue</a>. </p> </div> </div> <div id="disqus_thread"></div> <script>var disqus_config=function(){this.page.url="https://debezium.io/blog/2023/09/23/flink-spark-online-learning/",this.page.identifier="https://debezium.io/blog/2023/09/23/flink-spark-online-learning/"};!function(){var e=document,i=e.createElement("script");i.src="https://Debezium.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)}();</script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript> </div> </div> </div> <footer class="container"> <div> <div class="row mr-0 ml-0"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2024 Debezium Community <br/> <br/> <i class="icon-fire"></i> Mixed with <a href="https://getbootstrap.com/">Bootstrap</a>, baked by <a href="https://jekyllrb.com/">Jekyll</a>. <br/> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br/> <i class="icon-flag-alt"></i> Code released under <a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br/> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> <p>Rev: <a target="_blank" href="https://github.com/debezium/debezium.github.io/commit/040f96f2c57775fbb1615fdeb9c8910f48b85195">040f96f</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li><a href="/documentation/reference/stable/features.html" title="Features">Features</a></li> <li> <a href="/documentation/reference/stable/install.html" title="Install">Install</a> </li> <li> <a href="/documentation/reference/stable/architecture.html" title="Architecture">Architecture</a> </li> <li><a href="/documentation/faq/" title="FAQ">FAQ</a></li> <li> <a href="/community/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li><a href="/blog" title="Blog">Blog</a></li> <li> <a href="https://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li><a href="https://github.com/debezium" title="GitHub">GitHub</a></li> <li><a href="https://debezium.zulipchat.com/#narrow/stream/302529-users" title="Chat">Chat</a></li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="https://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <a href="https://www.redhat.com/"> <img src="/assets/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"/> </a> </div> </div> </div> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-76464546-1"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-76464546-1");</script> <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> <script type="text/javascript" src="/assets/javascript/vanilla-back-to-top.min.js"></script> <script type="text/javascript" src="/assets/javascript/highlight.min.js"></script> <script>addBackToTop({scrollDuration:400}),hljs.initHighlightingOnLoad();</script> </body> </html>