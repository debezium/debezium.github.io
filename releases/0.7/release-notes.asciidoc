= Release Notes for Debezium 0.7
:toc:
:toc-placement: macro
:toclevels: 1
:sectanchors:
:linkattrs:
:icons: font

All notable changes for Debezium releases are documented in this file.
Release numbers follow http://semver.org[Semantic Versioning].

toc::[]


[[release-0-7-5]]
== *Release 0.7.5* _(March 20th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12337159[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.1 and has been tested with version 1.0.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.5 from any of the earlier 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.5 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.5 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

The MySQL connector in Debezium 0.7.3 and 0.7.4 was creating database history topic with an infinite time-based log retention but a broker default one for topic size log retention.
This was fixed in https://issues.redhat.com/browse/DBZ-663[DBZ-663].
See our https://debezium.io/blog/2018/03/16/note-on-database-history-topic-configuration/[blogpost] for more details,
in particular how you should adjust your database history topic configuration, if you're affected by this issue.

MySQL snapshot JMX metrics were removed after the snapshot was completed.
This was changed in https://issues.redhat.com/browse/DBZ-640[DBZ-640] and the metrics are available till next connector restart.

=== New Features

This release includes the following new features:

* Keep SnapshotReaderMetrics bean registered after snapshot completed https://issues.redhat.com/browse/DBZ-640[DBZ-640]
* Cache replaced topic names and shard ids in ByLogicalTableRouter SMT https://issues.redhat.com/browse/DBZ-655[DBZ-655]
* Filter out useless commands from the history topic https://issues.redhat.com/browse/DBZ-661[DBZ-661]
* Apache Kafka 1.0.1 updates https://issues.redhat.com/browse/DBZ-647[DBZ-647]

=== Fixes

This release includes the following fixes:

* io.debezium.text.ParsingException for TokuDB table https://issues.redhat.com/browse/DBZ-646[DBZ-646]
* MongoDB connector continues to try to connect to invalid host even after deletion https://issues.redhat.com/browse/DBZ-648[DBZ-648]
* Streaming stopped due to JsonParseException https://issues.redhat.com/browse/DBZ-657[DBZ-657]
* 'ALTER TABLE tbl_name ADD CONSTRAINT UNIQUE KEY key_name (colname)' throwing exception https://issues.redhat.com/browse/DBZ-660[DBZ-660]
* Missing setting for the automatic history topic creation https://issues.redhat.com/browse/DBZ-663[DBZ-663]
* EmbeddedEngine passes time of last commit to policy, not time since https://issues.redhat.com/browse/DBZ-665[DBZ-665]

=== Other changes

This release includes also other changes:

* "snapshot" attribute should be false instead of null for events based on the binlog https://issues.redhat.com/browse/DBZ-592[DBZ-592]
* Describe limitations of wal2json version currently used on RDS https://issues.redhat.com/browse/DBZ-619[DBZ-619]

[[release-0-7-4]]
== *Release 0.7.4* _(March 7th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12336214[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.0 and has been tested with version 1.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.4 from any of the earlier 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.4 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.4 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

`NUMERIC` and geo-spatial schema types were optional regardless of database column configuration. This was fixed in https://issues.redhat.com/browse/DBZ-635[DBZ-635].

PostgresSQL decoder plug-in now uses text to transfer decimal values instead of double - https://issues.redhat.com/browse/DBZ-351[DBZ-351].
Debezium is backward compatible with the old version.
It is thus necessary first to upgrade Debezium and after that upgrade logical decoder plug-in.


=== New Features

This release includes the following new features:

* Provide MySQL snapshot mode that does not require table locks https://issues.redhat.com/browse/DBZ-602[DBZ-602]
* Add support for columns of type "bytea" https://issues.redhat.com/browse/DBZ-605[DBZ-605]
* Add string as an option for decimal.handling.mode https://issues.redhat.com/browse/DBZ-611[DBZ-611]
* Support CREATE TABLE statements with PARTITION ... ENGINE=InnoDB https://issues.redhat.com/browse/DBZ-641[DBZ-641]
* Document VariableScaleDecimal in PG connector docs https://issues.redhat.com/browse/DBZ-631[DBZ-631]
* Propagate schema validator by passing AvroValidator instance instead of Function<String, String> https://issues.redhat.com/browse/DBZ-626[DBZ-626]
* Move MAX_QUEUE_SIZE, MAX_BATCH_SIZE and POLL_INTERVAL_MS to CommonConnectorConfig https://issues.redhat.com/browse/DBZ-628[DBZ-628]
* Unify common start-up logic across connectors https://issues.redhat.com/browse/DBZ-630[DBZ-630]
* Removing unused code from database history classes https://issues.redhat.com/browse/DBZ-632[DBZ-632]

=== Fixes

This release includes the following fixes:

* Numeric datatype is transferred with lost precision https://issues.redhat.com/browse/DBZ-351[DBZ-351]
* Cannot Serialize NaN value(numeric field) in Postgres https://issues.redhat.com/browse/DBZ-606[DBZ-606]
* Decimal datatype DDL issues https://issues.redhat.com/browse/DBZ-615[DBZ-615]
* Avoid NPE if confirmed_flush_lsn is null https://issues.redhat.com/browse/DBZ-623[DBZ-623]
* REAL column values are omitted if value is an exact integer https://issues.redhat.com/browse/DBZ-625[DBZ-625]
* Fix intermittent error in BinlogReaderIT https://issues.redhat.com/browse/DBZ-629[DBZ-629]
* Schema for NUMERIC and geo-spatial array columns shouldn't be optional by default https://issues.redhat.com/browse/DBZ-635[DBZ-635]
* Fix typo in README of debezium/connect-base image https://issues.redhat.com/browse/DBZ-636[DBZ-636]
* Avoid repeated creation of Envelope schema https://issues.redhat.com/browse/DBZ-620[DBZ-620]

[[release-0-7-3]]
== *Release 0.7.3* _(February 14th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12336643[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.0 and has been tested with version 1.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.3 from any of the earlier 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.3 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.3 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

A new namespace for parameters was https://issues.redhat.com/browse/DBZ-576[created] - `internal` - that is used for parameters that are not documented and should not be used as they are subject of changes without warning.
As a result of this change the undocumented parameter `database.history.ddl.filter` was renamed to `internal.database.history.ddl.filter`.

OpenShift deployment now uses templates and images from [Strimzi project](https://issues.redhat.com/browse/DBZ-545).

=== New Features

This release includes the following new features:

* MySQL connector should automatically create database history topic https://issues.redhat.com/browse/DBZ-278[DBZ-278]
* Change OpenShift instructions to use Strimzi https://issues.redhat.com/browse/DBZ-545[DBZ-545]
* Create an internal namespace for configuration options not intended for general usage https://issues.redhat.com/browse/DBZ-576[DBZ-576]
* Make ChainedReader immutable https://issues.redhat.com/browse/DBZ-583[DBZ-583]
* Snapshots are not interruptable with the Postgres connector https://issues.redhat.com/browse/DBZ-586[DBZ-586]
* Add optional field with Debezium version to "source" element of messages https://issues.redhat.com/browse/DBZ-593[DBZ-593]
* Add the ability to control the strategy for committing offsets by the offset store https://issues.redhat.com/browse/DBZ-537[DBZ-537]
* Create support for arrays of PostGIS types https://issues.redhat.com/browse/DBZ-571[DBZ-571]
* Add option for controlling whether to produce tombstone records on DELETE operations https://issues.redhat.com/browse/DBZ-582[DBZ-582]
* Add example for using the MongoDB event flattening SMT https://issues.redhat.com/browse/DBZ-567[DBZ-567]
* Prefix the names of all threads spawned by Debezium with "debezium-" https://issues.redhat.com/browse/DBZ-587[DBZ-587]

=== Fixes

This release includes the following fixes:

* Force DBZ to commit regularly https://issues.redhat.com/browse/DBZ-220[DBZ-220]
* Carry over SourceInfo.restartEventsToSkip to next binlog file handling cause binlog events are not written to kafka https://issues.redhat.com/browse/DBZ-572[DBZ-572]
* Numeric arrays not handled correctly https://issues.redhat.com/browse/DBZ-577[DBZ-577]
* Debezium skipping binlog events silently https://issues.redhat.com/browse/DBZ-588[DBZ-588]
* Stop the connector if WALs to continue from aren't available https://issues.redhat.com/browse/DBZ-590[DBZ-590]
* Producer thread of DB history topic leaks after connector shut-down https://issues.redhat.com/browse/DBZ-595[DBZ-595]
* Integration tests should have completely isolated environment and configuration/setup files https://issues.redhat.com/browse/DBZ-300[DBZ-300]
* MongoDB integration tests should have completely isolated environment and configuration/setup files https://issues.redhat.com/browse/DBZ-579[DBZ-579]
* Extract a separate change event class to be re-used across connectors https://issues.redhat.com/browse/DBZ-580[DBZ-580]
* Propagate producer errors to Kafka Connect in MongoDB connector https://issues.redhat.com/browse/DBZ-581[DBZ-581]
* Shutdown thread pool used for MongoDB snaphots once it's not needed anymore https://issues.redhat.com/browse/DBZ-594[DBZ-594]
* Refactor type and array handling for Postgres https://issues.redhat.com/browse/DBZ-609[DBZ-609]
* Avoid unneccessary schema refreshs https://issues.redhat.com/browse/DBZ-616[DBZ-616]
* Incorrect type retrieved by stream producer for column TIMESTAMP (0) WITH TIME ZONE https://issues.redhat.com/browse/DBZ-618[DBZ-618]

[[release-0-7-2]]
== *Release 0.7.2* _(January 25th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?version=12336456&projectId=12317320[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.0 and has been tested with version 1.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.2 from any of the earlier 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.2 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.2 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.

=== New Features

This release includes the following new features:

* As a Debezium user, I would like MySQL Connector to support 'Spatial' data types https://issues.redhat.com/browse/DBZ-208[DBZ-208]
* Allow easy consumption of MongoDB CDC events by other connectors https://issues.redhat.com/browse/DBZ-409[DBZ-409]
* New snapshotting mode for recovery of DB history topic https://issues.redhat.com/browse/DBZ-443[DBZ-443]
* Add support for Postgres VARCHAR array columns https://issues.redhat.com/browse/DBZ-506[DBZ-506]
* Unified Geometry type support https://issues.redhat.com/browse/DBZ-507[DBZ-507]
* Add support for "snapshot.select.statement.overrides" option for Postgres https://issues.redhat.com/browse/DBZ-510[DBZ-510]
* Make PostGIS optional in Postgres Docker images https://issues.redhat.com/browse/DBZ-526[DBZ-526]
* Provide an option to only store DDL statements referring to captured tables in DB history topic https://issues.redhat.com/browse/DBZ-541[DBZ-541]
* Add ToC to tutorial and make section captions linkable https://issues.redhat.com/browse/DBZ-369[DBZ-369]
* Remove Zulu JDK images https://issues.redhat.com/browse/DBZ-449[DBZ-449]
* Add example for sending CDC events to Elasticsearch https://issues.redhat.com/browse/DBZ-502[DBZ-502]
* Adapt examples to MongoDB 3.6 https://issues.redhat.com/browse/DBZ-509[DBZ-509]
* Backport add-ons definition from add-ons repo https://issues.redhat.com/browse/DBZ-520[DBZ-520]
* Set up pull request build job for testing the PG connector with wal2json https://issues.redhat.com/browse/DBZ-568[DBZ-568]

=== Fixes

This release includes the following fixes:

* Debezium MySQL connector only works for lower-case table names on case-insensitive file systems https://issues.redhat.com/browse/DBZ-392[DBZ-392]
* Numbers after decimal point are different between source and destination https://issues.redhat.com/browse/DBZ-423[DBZ-423]
* Fix support for date arrays https://issues.redhat.com/browse/DBZ-494[DBZ-494]
* Changes in type contraints will not trigger new schema https://issues.redhat.com/browse/DBZ-504[DBZ-504]
* Task is still running after connector is paused https://issues.redhat.com/browse/DBZ-516[DBZ-516]
* NPE happened for PAUSED task https://issues.redhat.com/browse/DBZ-519[DBZ-519]
* Possibility of commit LSN before record is consumed/notified https://issues.redhat.com/browse/DBZ-521[DBZ-521]
* Snapshot fails when encountering null MySQL TIME fields https://issues.redhat.com/browse/DBZ-522[DBZ-522]
* Debezium unable to parse DDLs in MySql with RESTRICT contstraint https://issues.redhat.com/browse/DBZ-524[DBZ-524]
* DateTimeFormatter Exception in wal2json https://issues.redhat.com/browse/DBZ-525[DBZ-525]
* Multiple partitions does not work in ALTER TABLE https://issues.redhat.com/browse/DBZ-530[DBZ-530]
* Incorrect lookup in List in MySqlDdlParser.parseCreateView https://issues.redhat.com/browse/DBZ-534[DBZ-534]
* Improve invalid DDL statement logging https://issues.redhat.com/browse/DBZ-538[DBZ-538]
* Fix required protobuf version in protobuf decoder documentation https://issues.redhat.com/browse/DBZ-542[DBZ-542]
* EmbeddedEngine strips settings required to use KafkaOffsetBackingStore https://issues.redhat.com/browse/DBZ-555[DBZ-555]
* Handling of date arrays collides with handling of type changes via wal2json https://issues.redhat.com/browse/DBZ-558[DBZ-558]
* ROLLBACK to savepoint cannot be parsed https://issues.redhat.com/browse/DBZ-411[DBZ-411]
* Avoid usage of deprecated numeric types constructors https://issues.redhat.com/browse/DBZ-455[DBZ-455]
* Don't add source and JavaDoc JARs to Kafka image https://issues.redhat.com/browse/DBZ-489[DBZ-489]

[[release-0-7-1]]
== *Release 0.7.1* _(December 20th, 2017)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?version=12336215&projectId=12317320[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.0 and has been tested with version 1.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.1 from any of the earlier 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.1 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.1 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.

=== New Features

This release includes the following new features:

* Provide a wal2json plug-in mode enforcing RDS environment https://issues.redhat.com/browse/DBZ-517[DBZ-517]

=== Fixes

This release includes the following fixes:

* For old connector OID should be used to detect schema change https://issues.redhat.com/browse/DBZ-512[DBZ-512]
* AWS RDS Postgresql 9.6.5 not supporting "include-not-null" = "true" in connector setup https://issues.redhat.com/browse/DBZ-513[DBZ-513]
* RecordsStreamProducerIT.shouldNotStartAfterStop can make subsequent test dependent https://issues.redhat.com/browse/DBZ-518[DBZ-518]

=== Known issues
* PostgreSQL Connector does not detect schema changes in type constraints - e.g. the length of `array` datatype https://issues.redhat.com/browse/DBZ-504[DBZ-504]

[[release-0-7-0]]
== *Release 0.7.0* _(December 15th, 2017)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?version=12335366&projectId=12317320[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.0.0 and has been tested with version 1.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.7.0 from any of the earlier 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.7.0 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.7.0 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

=== Breaking changes

This release includes the following changes that can affect existing installations:

* Change default setting for BIGINT UNSIGNED handling https://issues.redhat.com/browse/DBZ-461[DBZ-461];
`UNSIGNED BIGINT` is treated by default as `int64`, not as `Decimal` before. Set `bigint.unsigned.handling.mode` if you need to continue with the original behaviour.
* Invalid value for HourOfDay ConnectException when the value of MySQL TIME filed is above 23:59:59 https://issues.redhat.com/browse/DBZ-342[DBZ-342]; The default mapping for MySQL TIME(0-3) columns has changed. Such columns can store values from -838:59:59.000000 to 838:59:59.000000, which cannot be stored as milliseconds in an int32 field (the previous default mapping).
Hence the default mapping has changed to int64 and the semantic type io.debezium.time.MicroTime, i.e. values represent microseconds. +
If you prefer to keep the previous mapping (which only should be done if it's guaranteed that no values are stored in that column whose milliseconds value exceeds int32), you can do so by specifying the connector option time.precision.mode=adaptive (see the connector documentation for further details). +
This change does not affect other connectors.
* Postgres connectors stops to work after concurrent schema changes and updates https://issues.redhat.com/browse/DBZ-379[DBZ-379]; PostgreSQL connector was using JDBC metadata to get additional type information when it was processing logical events.
This could lead to a race condition when database schema was updated and Debezium was still processing events with old schema structure. +
To mitigate the problem a new version of https://github.com/debezium/postgres-decoderbufs[Protocol Buffers decoder plugin] was introduced that passes additional type metadata with each event.
The connector is backward compatible with the old decoder plugin (using the original approach) but we strongly recommend to upgrade it to the latest one as soon as possible. +
The race condition issue can still happen when primary key structure is changed for the table as this information is still obtained from JDBC metadata.
To properly handle primary key change you should follow the rules
** Application should be placed in a _read-only_ mode, not writing any new data actively
** PostgreSQL connector must consume all remaining events from the database
** Primary key change is executed
** Application can switch back to regular mode
* Hardcoded schema version overrides schema registry version https://issues.redhat.com/browse/DBZ-466[DBZ-466]; The schema version returned for CDC message values (schema type dbserver1.inventory.customers.Envelope) has changed. While always `1` was returned in earlier versions, the schema version as managed by the schema registry will be returned in case the Avro serializer/deserializer is used. `Null` will be returned when using the JSON serializer/deserializer. Note that the schema version is only set during Avro message serialization, i.e. an SMT applied on the source side will also get null when querying for the schema version, as SMTs will be applied before the serialization.

=== New Features

This release includes the following new features:

* PostgreSQL connector should work on Amazon RDS and be able to use the available plugin https://issues.redhat.com/browse/DBZ-256[DBZ-256]
* Build Debezium against Kafka 1.0.0 https://issues.redhat.com/browse/DBZ-432[DBZ-432]
* Build Debezium images with Kafka 1.0.0 https://issues.redhat.com/browse/DBZ-433[DBZ-433]
* Protobuf message should contain type modifiers https://issues.redhat.com/browse/DBZ-485[DBZ-485]
* Protobuf message should contain optional flags https://issues.redhat.com/browse/DBZ-486[DBZ-486]
* Better support for large append-only tables by making the snapshotting process restartable https://issues.redhat.com/browse/DBZ-349[DBZ-349]
* Support new wal2json type specifiers https://issues.redhat.com/browse/DBZ-453[DBZ-453]
* Optionally return raw value for unsupported column types https://issues.redhat.com/browse/DBZ-498[DBZ-498]
* Provide Postgres example image for 0.7 https://issues.redhat.com/browse/DBZ-382[DBZ-382]
* Create an automated build for Postgres example image in Docker Hub https://issues.redhat.com/browse/DBZ-383[DBZ-383]
* Move configuration of ProtoBuf code generation to Postgres module https://issues.redhat.com/browse/DBZ-416[DBZ-416]
* Provide MongoDB example image for Debezium 0.7 https://issues.redhat.com/browse/DBZ-451[DBZ-451]
* Upgrade to Confluent Platform 4.0 https://issues.redhat.com/browse/DBZ-492[DBZ-492]
* Set up CI job for testing Postgres with new wal2json type identifiers https://issues.redhat.com/browse/DBZ-495[DBZ-495]
* Change PostgreSQL connector to support multiple plugins https://issues.redhat.com/browse/DBZ-257[DBZ-257]
* PostgreSQL connector should support the wal2json logical decoding plugin https://issues.redhat.com/browse/DBZ-258[DBZ-258]
* Provide instructions for using Debezium on Minishift https://issues.redhat.com/browse/DBZ-364[DBZ-364]
* Modify BinlogReader to process transactions via buffer https://issues.redhat.com/browse/DBZ-405[DBZ-405]
* Modify BinlogReader to support transactions of unlimited size https://issues.redhat.com/browse/DBZ-406[DBZ-406]

=== Fixes

This release includes the following fixes:

* Data are read from the binlog and not written into Kafka https://issues.redhat.com/browse/DBZ-390[DBZ-390]
* MySQL connector may not read database history to end https://issues.redhat.com/browse/DBZ-464[DBZ-464]
* connect-base image advertises wrong port by default https://issues.redhat.com/browse/DBZ-467[DBZ-467]
* INSERT statements being written to db history topic https://issues.redhat.com/browse/DBZ-469[DBZ-469]
* MySQL Connector does not handle properly startup/shutdown https://issues.redhat.com/browse/DBZ-473[DBZ-473]
* Cannot parse NOT NULL COLLATE in DDL https://issues.redhat.com/browse/DBZ-474[DBZ-474]
* Failed to parse the sql statement of RENAME user https://issues.redhat.com/browse/DBZ-475[DBZ-475]
* Exception when parsing enum field with escaped characters values https://issues.redhat.com/browse/DBZ-476[DBZ-476]
* All to insert null value into numeric array columns https://issues.redhat.com/browse/DBZ-478[DBZ-478]
* produceStrings method slow down on sending messages https://issues.redhat.com/browse/DBZ-479[DBZ-479]
* Failing unit tests when run in EST timezone https://issues.redhat.com/browse/DBZ-491[DBZ-491]
* PostgresConnector falls with RejectedExecutionException https://issues.redhat.com/browse/DBZ-501[DBZ-501]
* Docker images cannot be re-built when a new version of ZooKeeper/Kafka is released https://issues.redhat.com/browse/DBZ-503[DBZ-503]
* Insert ids as long instead of float for MongoDB example image https://issues.redhat.com/browse/DBZ-470[DBZ-470]
* Port changes in 0.6 Docker files into 0.7 files https://issues.redhat.com/browse/DBZ-463[DBZ-463]
* Add check to release process to make sure all issues are assigned to a component https://issues.redhat.com/browse/DBZ-468[DBZ-468]
* Document requirement for database history topic to be not partitioned https://issues.redhat.com/browse/DBZ-482[DBZ-482]
* Remove dead code from MySqlSchema https://issues.redhat.com/browse/DBZ-483[DBZ-483]
* Remove redundant calls to pfree https://issues.redhat.com/browse/DBZ-496[DBZ-496]

=== Known issues
* PostgreSQL Connector does not detect schema changes in type constraints - e.g. the length of `array` datatype https://issues.redhat.com/browse/DBZ-504[DBZ-504]
