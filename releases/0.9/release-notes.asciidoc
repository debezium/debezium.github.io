= Release Notes for Debezium 0.9
:awestruct-layout: doc
:awestruct-documentation_version: "0.9"
:toc:
:toc-placement: macro
:toclevels: 1
:sectanchors:
:linkattrs:
:icons: font

All notable changes for Debezium releases are documented in this file.
Release numbers follow http://semver.org[Semantic Versioning].

toc::[]

[[release-0-9-5-final]]
== *Release 0.9.5.Final* _(May 2nd, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12341657[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.2.0 and has been tested with version 2.2.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, PostgreSQL or SQL Server connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.5.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.5.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.5.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Upgrade to Kafka 2.2.0 https://issues.redhat.com/browse/DBZ-1227[DBZ-1227]
* Ability to specify batch size during snapshot https://issues.redhat.com/browse/DBZ-1247[DBZ-1247]
* Postgresql ARRAY support https://issues.redhat.com/browse/DBZ-1076[DBZ-1076]
* Add support macaddr and macaddr8 PostgreSQL column types https://issues.redhat.com/browse/DBZ-1193[DBZ-1193]


=== Fixes

This release includes the following fixes:

* Failing to specify value for database.server.name results in invalid Kafka topic name https://issues.redhat.com/browse/DBZ-212[DBZ-212]
* Escape sequence handling needs to be unified https://issues.redhat.com/browse/DBZ-481[DBZ-481]
* Postgres Connector times out in schema discovery for DBs with many tables https://issues.redhat.com/browse/DBZ-1214[DBZ-1214]
* Oracle connector: JDBC transaction can only capture single DML record  https://issues.redhat.com/browse/DBZ-1223[DBZ-1223]
* Enable enumeration options to contain escaped characters or commas. https://issues.redhat.com/browse/DBZ-1226[DBZ-1226]
* Antlr parser fails on column named with MODE keyword https://issues.redhat.com/browse/DBZ-1233[DBZ-1233]
* Lost precision for timestamp with timezone https://issues.redhat.com/browse/DBZ-1236[DBZ-1236]
* NullpointerException due to optional value for commitTime https://issues.redhat.com/browse/DBZ-1241[DBZ-1241]
* Default value for datetime(0) is  incorrectly handled https://issues.redhat.com/browse/DBZ-1243[DBZ-1243]
* Postgres connector failing because empty state data is being stored in offsets topic https://issues.redhat.com/browse/DBZ-1245[DBZ-1245]
* Default value for Bit does not work for larger values https://issues.redhat.com/browse/DBZ-1249[DBZ-1249]
* Microsecond precision is lost when reading timetz data from Postgres. https://issues.redhat.com/browse/DBZ-1260[DBZ-1260]


=== Other changes

This release includes also other changes:

* Zookeeper image documentation does not describe txns mountpoint https://issues.redhat.com/browse/DBZ-1231[DBZ-1231]
* Parse enum and set options with Antlr https://issues.redhat.com/browse/DBZ-739[DBZ-739]


[[release-0-9-4-final]]
== *Release 0.9.4.Final* _(April 11th, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12341407[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.1 and has been tested with version 2.1.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, PostgreSQL or SQL Server connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.4.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.4.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.4.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Add MySQL Connector metric to expose "number of filtered events" https://issues.redhat.com/browse/DBZ-1206[DBZ-1206]
* Support TLS 1.2 for MySQL https://issues.redhat.com/browse/DBZ-1208[DBZ-1208]
* Create new MysqlConnector metric exposing if the connector is tracking offsets using GTIDs or not. https://issues.redhat.com/browse/DBZ-1221[DBZ-1221]
* Add support for columns of type INET https://issues.redhat.com/browse/DBZ-1189[DBZ-1189]


=== Fixes

This release includes the following fixes:

* Incorrect value for datetime field for '0001-01-01 00:00:00' https://issues.redhat.com/browse/DBZ-1143[DBZ-1143]
* PosgreSQL DecoderBufs crash when working with geometries in "public" schema https://issues.redhat.com/browse/DBZ-1144[DBZ-1144]
* [postgres] differing logic between snapsnot and streams for create record https://issues.redhat.com/browse/DBZ-1163[DBZ-1163]
* Error while deserializing binlog event https://issues.redhat.com/browse/DBZ-1191[DBZ-1191]
* MySQL connector throw an exception when captured invalid datetime https://issues.redhat.com/browse/DBZ-1194[DBZ-1194]
* Error when alter Enum column with CHARACTER SET https://issues.redhat.com/browse/DBZ-1203[DBZ-1203]
* Mysql: Getting ERROR `Failed due to error: connect.errors.ConnectException: For input string: "false"` https://issues.redhat.com/browse/DBZ-1204[DBZ-1204]
* MySQL connection timeout after bootstrapping a new table https://issues.redhat.com/browse/DBZ-1207[DBZ-1207]
* SLF4J usage issues https://issues.redhat.com/browse/DBZ-1212[DBZ-1212]
* JDBC Connection Not Closed in MySQL Connector Snapshot Reader https://issues.redhat.com/browse/DBZ-1218[DBZ-1218]
* Support FLOAT(p) column definition style https://issues.redhat.com/browse/DBZ-1220[DBZ-1220]


=== Other changes

This release includes also other changes:

* Add WhitespaceAfter check to Checkstyle https://issues.redhat.com/browse/DBZ-362[DBZ-362]
* Document RDS Postgres wal_level behavior https://issues.redhat.com/browse/DBZ-1219[DBZ-1219]


[[release-0-9-3-final]]
== *Release 0.9.3.Final* _(March 25th, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12340751[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.1 and has been tested with version 2.1.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, PostgreSQL or SQL Server connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.3.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.3.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.3.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Support Outbox SMT as part of Debezium core https://issues.redhat.com/browse/DBZ-1169[DBZ-1169]
* Add support for partial recovery from lost slot in postgres https://issues.redhat.com/browse/DBZ-1082[DBZ-1082]


=== Fixes

This release includes the following fixes:

* Postgresql Snapshot with a table that has > 8192records hangs https://issues.redhat.com/browse/DBZ-1161[DBZ-1161]
* HStores fail to Snapshot properly  https://issues.redhat.com/browse/DBZ-1162[DBZ-1162]
* NullPointerException When there are multiple tables in different schemas in the whitelist  https://issues.redhat.com/browse/DBZ-1166[DBZ-1166]
* Cannot set offset.flush.interval.ms via docker entrypoint https://issues.redhat.com/browse/DBZ-1167[DBZ-1167]
* Missing Oracle OCI library is not reported as error https://issues.redhat.com/browse/DBZ-1170[DBZ-1170]
* RecordsStreamProducer forgets to convert commitTime from nanoseconds to microseconds https://issues.redhat.com/browse/DBZ-1174[DBZ-1174]
* MongoDB Connector doesn't fail on invalid hosts configuration https://issues.redhat.com/browse/DBZ-1177[DBZ-1177]
* Handle NPE errors when trying to create history topic against confluent cloud https://issues.redhat.com/browse/DBZ-1179[DBZ-1179]
* The Postgres wal2json streaming and non-streaming decoders do not process empty events https://issues.redhat.com/browse/DBZ-1181[DBZ-1181]
* Can't continue after snapshot is done https://issues.redhat.com/browse/DBZ-1184[DBZ-1184]
* ParsingException for SERIAL keyword https://issues.redhat.com/browse/DBZ-1185[DBZ-1185]
* STATS_SAMPLE_PAGES config cannot be parsed https://issues.redhat.com/browse/DBZ-1186[DBZ-1186]
* MySQL Connector generates false alarm for empty password https://issues.redhat.com/browse/DBZ-1188[DBZ-1188]


=== Other changes

This release includes also other changes:

* Ensure no brace-less if() blocks are used in the code base https://issues.redhat.com/browse/DBZ-1039[DBZ-1039]
* Align Oracle DDL parser code to use the same structure as MySQL https://issues.redhat.com/browse/DBZ-1192[DBZ-1192]


[[release-0-9-2-final]]
== *Release 0.9.2.Final* _(February 22nd, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12340752[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.1 and has been tested with version 2.1.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, PostgreSQL or SQL Server connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.2.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.2.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.2.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Add snapshotting mode NEVER for MongoDB connector https://issues.redhat.com/browse/DBZ-867[DBZ-867]
* Allow passing of arbitrary parameters when replication slot is started https://issues.redhat.com/browse/DBZ-1130[DBZ-1130]


=== Fixes

This release includes the following fixes:

* Integer default value for DECIMAL column fails with Avro Converter https://issues.redhat.com/browse/DBZ-1077[DBZ-1077]
* connect binds only to hostname interface https://issues.redhat.com/browse/DBZ-1108[DBZ-1108]
* Connector fails to connect to binlog on connectors rebalance, throws ServerException https://issues.redhat.com/browse/DBZ-1132[DBZ-1132]
* Fail to parse MySQL TIME with values bigger than 23:59:59.999999 https://issues.redhat.com/browse/DBZ-1137[DBZ-1137]
* Test dependencies shouldn't be part of the SQL Server connector archive https://issues.redhat.com/browse/DBZ-1138[DBZ-1138]
* Emit correctly-typed fallback values for replica identity DEFAULT https://issues.redhat.com/browse/DBZ-1141[DBZ-1141]
* Unexpected exception while streaming changes from row with unchanged toast https://issues.redhat.com/browse/DBZ-1146[DBZ-1146]
* SQL syntax error near '"gtid_purged"' https://issues.redhat.com/browse/DBZ-1147[DBZ-1147]
* Postgres delete operations throwing DataException https://issues.redhat.com/browse/DBZ-1149[DBZ-1149]
* Antlr parser fails on column names that are keywords https://issues.redhat.com/browse/DBZ-1150[DBZ-1150]
* SqlServerConnector doesn't work with table names with "special characters" https://issues.redhat.com/browse/DBZ-1153[DBZ-1153]


=== Other changes

This release includes also other changes:

* Describe topic-level settings to ensure event consumption when log compaction is enabled https://issues.redhat.com/browse/DBZ-1136[DBZ-1136]
* Upgrade binlog client to 0.19.0 https://issues.redhat.com/browse/DBZ-1140[DBZ-1140]
* Upgrade kafkacat to 1.4.0-RC1 https://issues.redhat.com/browse/DBZ-1148[DBZ-1148]
* Upgrade Avro connector version to 5.1.2 https://issues.redhat.com/browse/DBZ-1156[DBZ-1156]
* Upgrade to Kafka 2.1.1 https://issues.redhat.com/browse/DBZ-1157[DBZ-1157]


[[release-0-9-1-final]]
== *Release 0.9.1.Final* _(February 13th, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12340576[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.0 and has been tested with version 2.1.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.1.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.1.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.1.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Provide new container image with tooling for examples and demos https://issues.redhat.com/browse/DBZ-1125[DBZ-1125]


=== Fixes

This release includes the following fixes:

* BigDecimal has mismatching scale value for given Decimal schema error due to permissive mysql ddl https://issues.redhat.com/browse/DBZ-983[DBZ-983]
* Primary key changes cause UnsupportedOperationException https://issues.redhat.com/browse/DBZ-997[DBZ-997]
* java.lang.IllegalArgumentException: timeout value is negative https://issues.redhat.com/browse/DBZ-1019[DBZ-1019]
* Connector consumes huge amount of memory https://issues.redhat.com/browse/DBZ-1065[DBZ-1065]
* Strings.join() doesn't apply conversation for first element https://issues.redhat.com/browse/DBZ-1112[DBZ-1112]
* NPE if database history filename has no parent folder https://issues.redhat.com/browse/DBZ-1122[DBZ-1122]
* Generated columns not supported by DDL parser https://issues.redhat.com/browse/DBZ-1123[DBZ-1123]
* Advancing LSN in the first iteration - possible data loss https://issues.redhat.com/browse/DBZ-1128[DBZ-1128]
* Incorrect LSN comparison can cause out of order processing https://issues.redhat.com/browse/DBZ-1131[DBZ-1131]


=== Other changes

This release includes also other changes:

* io.debezium.connector.postgresql.PostgisGeometry shouldn't use DatatypeConverter https://issues.redhat.com/browse/DBZ-962[DBZ-962]
* Schema change events should be of type ALTER when table is modified https://issues.redhat.com/browse/DBZ-1121[DBZ-1121]
* Wal2json ISODateTimeFormatTest fails with a locale other than Locale.ENGLISH https://issues.redhat.com/browse/DBZ-1126[DBZ-1126]


=== Known issues

A potential https://github.com/shyiko/mysql-binlog-connector-java/pull/260[race condition] was identified in upstream library for MySQL's binary log processing.
The problem exhibits as the issue https://issues.redhat.com/projects/DBZ/issues/DBZ-1132[DBZ-1132].
If you are affected by it we propose as the workaround to increase Kafka Connect configuration options `task.shutdown.graceful.timeout.ms` and `connect.rebalance.timeout.ms`.
If the problem persists please disable keepalive thread via Debezium configration option `connect.keep.alive`.


[[release-0-9-0-final]]
== *Release 0.9.0.Final* _(February 5th, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12340275[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.0 and has been tested with version 2.1.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.Final from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.Final plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.Final connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

There are no breaking changes in this release.


=== New Features

* Expose more useful metrics and improve Grafana dashboard https://issues.redhat.com/browse/DBZ-1040[DBZ-1040]


=== Fixes

This release includes the following fixes:

* Allow to use drop-slot-on-close option with wal2json https://issues.redhat.com/browse/DBZ-1111[DBZ-1111]
* MySqlDdlParser does not support adding multiple partitions in a single ALTER TABLE ... ADD PARTITION statement  https://issues.redhat.com/browse/DBZ-1113[DBZ-1113]
* Debezium fails to take a lock during snapshot https://issues.redhat.com/browse/DBZ-1115[DBZ-1115]
* Data from Postgres partitioned table written to wrong topic during snapshot https://issues.redhat.com/browse/DBZ-1118[DBZ-1118]


=== Other changes

This release includes also other changes:

* Clarify whether DDL parser is actually needed for SQL Server connector https://issues.redhat.com/browse/DBZ-1096[DBZ-1096]
* Add design description to SqlServerStreamingChangeEventSource https://issues.redhat.com/browse/DBZ-1097[DBZ-1097]
* Put out message about missing LSN at WARN level https://issues.redhat.com/browse/DBZ-1116[DBZ-1116]


[[release-0-9-0-cr1]]
== *Release 0.9.0.CR1* _(January 19th, 2019)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12340263[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.0 and has been tested with version 2.1.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.CR1 from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.CR1 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.CR1 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

SQL Server connector has re-worked semantics of snapshot modes (https://issues.redhat.com/browse/DBZ-947[DBZ-947]). +
SQL Server connector also adds a new field to offsets in the streaming mode (https://issues.redhat.com/browse/DBZ-1090[DBZ-1090]) which could prevent seamless upgrading of versions.
We recommend to re-register and restart the connector. +
SQL Server connector has changed the schema name of messages schemas (https://issues.redhat.com/browse/DBZ-1089[DBZ-1089]), superfluous database name has been dropped.


=== New Features

* Snapshot isolation level overhaul https://issues.redhat.com/browse/DBZ-947[DBZ-947]
* Kafka docker image - support for topic cleanup policy https://issues.redhat.com/browse/DBZ-1038[DBZ-1038]
* Optimize sys.fn_cdc_map_lsn_to_time() calls https://issues.redhat.com/browse/DBZ-1078[DBZ-1078]
* Fallback to restart_lsn if confirmed_flush_lsn is not found https://issues.redhat.com/browse/DBZ-1081[DBZ-1081]
* table.whitelist option update for an existing connector doesn't work https://issues.redhat.com/browse/DBZ-175[DBZ-175]
* EmbeddedEngine should allow for more flexible record consumption https://issues.redhat.com/browse/DBZ-1080[DBZ-1080]
* Client-side column blacklisting in SQL Server connector https://issues.redhat.com/browse/DBZ-1067[DBZ-1067]
* column.propagate.source.type missing scale https://issues.redhat.com/browse/DBZ-1073[DBZ-1073]


=== Fixes

This release includes the following fixes:

* ArrayIndexOutOfBoundsException when a column is deleted (Postgres) https://issues.redhat.com/browse/DBZ-996[DBZ-996]
* Messages from tables without PK and with REPLICA IDENTITY FULL https://issues.redhat.com/browse/DBZ-1029[DBZ-1029]
* Inconsistent schema name in streaming and snapshotting phase https://issues.redhat.com/browse/DBZ-1051[DBZ-1051]
* "watch-topic" and "create-topic" commands fail https://issues.redhat.com/browse/DBZ-1057[DBZ-1057]
* Antlr Exception: mismatched input '.' expecting {<EOF>, '--'} https://issues.redhat.com/browse/DBZ-1059[DBZ-1059]
* MySQL JDBC Context sets the wrong truststore password https://issues.redhat.com/browse/DBZ-1062[DBZ-1062]
* Unsigned smallint column in mysql failing due to out of range error https://issues.redhat.com/browse/DBZ-1063[DBZ-1063]
* NULL Values are replaced by default values even in NULLABLE fields https://issues.redhat.com/browse/DBZ-1064[DBZ-1064]
* Uninformative "Found previous offset" log https://issues.redhat.com/browse/DBZ-1066[DBZ-1066]
* SQL Server connector does not persist LSNs in Kafka https://issues.redhat.com/browse/DBZ-1069[DBZ-1069]
* [debezium] ERROR: option \"include-unchanged-toast\" = \"0\" is unknown https://issues.redhat.com/browse/DBZ-1083[DBZ-1083]
* Debezium fails when consuming table without primary key with turned on topic routing https://issues.redhat.com/browse/DBZ-1086[DBZ-1086]
* Wrong message key and event used when primary key is updated https://issues.redhat.com/browse/DBZ-1088[DBZ-1088]
* Connect schema name is wrong for SQL Server https://issues.redhat.com/browse/DBZ-1089[DBZ-1089]
* Incorrect LSN tracking - possible data loss https://issues.redhat.com/browse/DBZ-1090[DBZ-1090]
* Race condition in EmbeddedEngine shutdown https://issues.redhat.com/browse/DBZ-1103[DBZ-1103]


=== Other changes

This release includes also other changes:

* Intermittent failures in RecordsStreamProducerIT#shouldPropagateSourceColumnTypeToSchemaParameter() https://issues.redhat.com/browse/DBZ-781[DBZ-781]
* Assert MongoDB supported versions https://issues.redhat.com/browse/DBZ-988[DBZ-988]
* Describe how to do DDL changes for SQL Server https://issues.redhat.com/browse/DBZ-993[DBZ-993]
* Verify version of wal2json on RDS https://issues.redhat.com/browse/DBZ-1056[DBZ-1056]
* Move SQL Server connector to main repo https://issues.redhat.com/browse/DBZ-1084[DBZ-1084]
* Don't enqueue further records when connector is stopping https://issues.redhat.com/browse/DBZ-1099[DBZ-1099]
* Race condition in SQLServer tests during snapshot phase https://issues.redhat.com/browse/DBZ-1101[DBZ-1101]
* Remove columnNames field from TableImpl https://issues.redhat.com/browse/DBZ-1105[DBZ-1105]
* column.propagate.source.type missing scale https://issues.redhat.com/browse/DBZ-387[DBZ-387]
* write catch-up binlog reader https://issues.redhat.com/browse/DBZ-388[DBZ-388]
* changes to Snapshot and Binlog readers to allow for concurrent/partial running https://issues.redhat.com/browse/DBZ-389[DBZ-389]


[[release-0-9-0-beta2]]
== *Release 0.9.0.Beta2* _(December 19th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12339976[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.1.0 and has been tested with version 2.1.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.Beta2 from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.Beta2 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.Beta2 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

The link:/docs/configuration/mongodb-event-flattening/[MongoDB CDC Event Flattening] transformation now by default removes deletion messages (https://issues.redhat.com/browse/DBZ-563[DBZ-563]).
The previous default was to keep them.

=== New Features

* Add support for Oracle 11g https://issues.redhat.com/browse/DBZ-954[DBZ-954]
* UnwrapFromMongoDbEnvelope refactor https://issues.redhat.com/browse/DBZ-1020[DBZ-1020]
* Add option for dropping deletes and tombstone events to MongoDB struct recreation SMT https://issues.redhat.com/browse/DBZ-563[DBZ-563]
* Expose "snapshot.delay.ms" option for all connectors https://issues.redhat.com/browse/DBZ-966[DBZ-966]
* Convey original operation type when using flattening SMTs https://issues.redhat.com/browse/DBZ-971[DBZ-971]
* Provide last event and captured tables in metrics https://issues.redhat.com/browse/DBZ-978[DBZ-978]
* Skip MySQL BinLog Event in case of Invalid Cell Values https://issues.redhat.com/browse/DBZ-1010[DBZ-1010]

=== Fixes

This release includes the following fixes:

* BinaryLogClient can't disconnect when adding records after shutdown has been initiated https://issues.redhat.com/browse/DBZ-604[DBZ-604]
* UnwrapFromMongoDbEnvelope fails when encountering $unset operator https://issues.redhat.com/browse/DBZ-612[DBZ-612]
* "no known snapshots" error when DBs rows are large https://issues.redhat.com/browse/DBZ-842[DBZ-842]
* MongoDB connector stops processing oplog events after encountering "new primary" event https://issues.redhat.com/browse/DBZ-848[DBZ-848]
* MySQL active-passive: brief data loss on failover when Debezium encounters new GTID channel https://issues.redhat.com/browse/DBZ-923[DBZ-923]
* ConnectException: Only REPEATABLE READ isolation level is supported for START TRANSACTION WITH CONSISTENT SNAPSHOT in RocksDB Storage Engine https://issues.redhat.com/browse/DBZ-960[DBZ-960]
* ConnectException during ALTER TABLE for non-whitelisted table https://issues.redhat.com/browse/DBZ-977[DBZ-977]
* UnwrapFromMongoDbEnvelope fails when encountering full updates https://issues.redhat.com/browse/DBZ-987[DBZ-987]
* UnwrapFromMongoDbEnvelope fails when encountering Tombstone messages https://issues.redhat.com/browse/DBZ-989[DBZ-989]
* Postgres schema changes detection (not-null constraint) https://issues.redhat.com/browse/DBZ-1000[DBZ-1000]
* NPE in SqlServerConnectorTask#cleanupResources() if connector failed to start https://issues.redhat.com/browse/DBZ-1002[DBZ-1002]
* Explicitly initialize history topic in HistorizedRelationalDatabaseSchema https://issues.redhat.com/browse/DBZ-1003[DBZ-1003]
* BinlogReader ignores GTIDs for empty database https://issues.redhat.com/browse/DBZ-1005[DBZ-1005]
* NPE in MySqlConnectorTask.stop() https://issues.redhat.com/browse/DBZ-1006[DBZ-1006]
* The name of captured but not whitelisted table is not logged https://issues.redhat.com/browse/DBZ-1007[DBZ-1007]
* GTID set is not properly initialized after DB failover https://issues.redhat.com/browse/DBZ-1008[DBZ-1008]
* Postgres Connector fails on none nullable MACADDR field during initial snapshot https://issues.redhat.com/browse/DBZ-1009[DBZ-1009]
* Connector crashes with java.lang.NullPointerException when using multiple sinks to consume the messages https://issues.redhat.com/browse/DBZ-1017[DBZ-1017]
* Postgres connector fails upon event of recently deleted table https://issues.redhat.com/browse/DBZ-1021[DBZ-1021]
* ORA-46385: DML and DDL operations are not allowed on table "AUDSYS"."AUD$UNIFIED" https://issues.redhat.com/browse/DBZ-1023[DBZ-1023]
* Postgres plugin does not signal the end of snapshot properly https://issues.redhat.com/browse/DBZ-1024[DBZ-1024]
* MySQL Antlr runtime.NoViableAltException https://issues.redhat.com/browse/DBZ-1028[DBZ-1028]
* Debezium 0.8.2 and 0.8.3.Final Not Available on Confluent Hub https://issues.redhat.com/browse/DBZ-1030[DBZ-1030]
* Snapshot of tables with reserved names fails https://issues.redhat.com/browse/DBZ-1031[DBZ-1031]
* UnwrapFromMongoDbEnvelope doesn't support operation header on tombstone messages https://issues.redhat.com/browse/DBZ-1032[DBZ-1032]
* Mysql binlog reader lost data if restart task when last binlog event is QUERY event. https://issues.redhat.com/browse/DBZ-1033[DBZ-1033]
* The same capture instance name is logged twice https://issues.redhat.com/browse/DBZ-1047[DBZ-1047]


=== Other changes

This release includes also other changes:

* MySQL 8 compatibility https://issues.redhat.com/browse/DBZ-688[DBZ-688]
* Don't hard code list of supported MySQL storage engines in Antlr grammar https://issues.redhat.com/browse/DBZ-992[DBZ-992]
* Provide updated KSQL example https://issues.redhat.com/browse/DBZ-999[DBZ-999]
* Update to Kafka 2.1 https://issues.redhat.com/browse/DBZ-1001[DBZ-1001]
* Skipt Antlr tests when tests are skipped https://issues.redhat.com/browse/DBZ-1004[DBZ-1004]
* Fix expected records counts in MySQL tests https://issues.redhat.com/browse/DBZ-1016[DBZ-1016]
* Cannot run tests against Kafka 1.x https://issues.redhat.com/browse/DBZ-1037[DBZ-1037]
* Configure MySQL Matrix testing job to test with and without GTID https://issues.redhat.com/browse/DBZ-1050[DBZ-1050]


[[release-0-9-0-beta1]]
== *Release 0.9.0.Beta1* _(November 20th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12339372[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.0.1 and has been tested with version 2.0.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.Beta1 from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.Beta1 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.Beta1 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

MySQL Connector now uses Antlr parser as https://issues.redhat.com/browse/DBZ-990[the default].

=== New Features

* Add STATUS_STORAGE_TOPIC environment variable to container images https://issues.redhat.com/browse/DBZ-893[DBZ-893]
* Support Postgres 11 in Decoderbufs https://issues.redhat.com/browse/DBZ-955[DBZ-955]
* Define the data directory where tests are storing their data https://issues.redhat.com/browse/DBZ-963[DBZ-963]
* Upgrade Kafka to 2.0.1 https://issues.redhat.com/browse/DBZ-979[DBZ-979]
* Implement unified metrics across connectors https://issues.redhat.com/browse/DBZ-776[DBZ-776]
* Initial snapshot using snapshot isolation level https://issues.redhat.com/browse/DBZ-941[DBZ-941]
* Add decimal.handling.mode for SQLServer Configuration https://issues.redhat.com/browse/DBZ-953[DBZ-953]
* Support pass-through of "database." properties to JDBC driver https://issues.redhat.com/browse/DBZ-964[DBZ-964]
* Handle changes of table definitions and tables created while streaming https://issues.redhat.com/browse/DBZ-812[DBZ-812]


=== Fixes

This release includes the following fixes:

* Error while parsing JSON column type for MySQL https://issues.redhat.com/browse/DBZ-935[DBZ-935]
* wal2json CITEXT columns set to empty strings https://issues.redhat.com/browse/DBZ-937[DBZ-937]
* Base docker image is deprecated https://issues.redhat.com/browse/DBZ-939[DBZ-939]
* Mysql connector failed to parse add partition statement https://issues.redhat.com/browse/DBZ-959[DBZ-959]
* PostgreSQL replication slots not updated in transactions https://issues.redhat.com/browse/DBZ-965[DBZ-965]
* wal2json_streaming decoder does not provide the right plugin name https://issues.redhat.com/browse/DBZ-970[DBZ-970]
* Create topics command doesn't work in Kafka docker image https://issues.redhat.com/browse/DBZ-976[DBZ-976]
* Antlr parser: support quoted engine names in DDL https://issues.redhat.com/browse/DBZ-990[DBZ-990]


=== Other changes

This release includes also other changes:

* Switch to Antlr-based parser implementation by default https://issues.redhat.com/browse/DBZ-757[DBZ-757]
* Support RENAME column syntax from MySQL 8.0 https://issues.redhat.com/browse/DBZ-780[DBZ-780]
* Fix documentation of 'array.encoding' option https://issues.redhat.com/browse/DBZ-925[DBZ-925]
* Support MongoDB 4.0 https://issues.redhat.com/browse/DBZ-974[DBZ-974]


[[release-0-9-0-alpha2]]
== *Release 0.9.0.Alpha2* _(October 4th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12338766[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 2.0.0 and has been tested with version 2.0.0 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.Alpha2 from any of the earlier 0.9.x, 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.Alpha2 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.Alpha2 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

MySQL JDBC driver was https://issues.redhat.com/browse/DBZ-763[upgraded] to version 8.x.
Kafka has been https://issues.redhat.com/browse/DBZ-858[upgraded] to version 2.0.0.

=== New Features

* Build Alpine Linux versions of the PostgreSQL containers https://issues.redhat.com/browse/DBZ-705[DBZ-705]
* Refactor methods to read MySQL sytem variables https://issues.redhat.com/browse/DBZ-849[DBZ-849]
* Correct param name for excludeColumns(String fullyQualifiedTableNames) https://issues.redhat.com/browse/DBZ-854[DBZ-854]
* Make BinlogReader#informAboutUnknownTableIfRequired() log with tableId https://issues.redhat.com/browse/DBZ-855[DBZ-855]
* MySQL identifier with dot or space could not be parsed https://issues.redhat.com/browse/DBZ-878[DBZ-878]
* Use postgres:10 instead of postgres:10.0 as base docker image https://issues.redhat.com/browse/DBZ-929[DBZ-929]
* Support temporary replication slots with Postgres >= 10 https://issues.redhat.com/browse/DBZ-934[DBZ-934]
* Support white/black-listing Mongo fields https://issues.redhat.com/browse/DBZ-633[DBZ-633]
* Postgres connector - add database, schema and table names to "source" section of records https://issues.redhat.com/browse/DBZ-866[DBZ-866]
* Support renaming Mongo fields https://issues.redhat.com/browse/DBZ-881[DBZ-881]
* use tcpKeepAlive by default https://issues.redhat.com/browse/DBZ-895[DBZ-895]
* Hstore support in Postgresql-connector https://issues.redhat.com/browse/DBZ-898[DBZ-898]
* Add connector type to source info https://issues.redhat.com/browse/DBZ-918[DBZ-918]


=== Fixes

This release includes the following fixes:

* Global read lock not release when exception raised during snapshot https://issues.redhat.com/browse/DBZ-769[DBZ-769]
* Abort loops in MongoPrimary#execute() if the connector is stopped https://issues.redhat.com/browse/DBZ-784[DBZ-784]
* Initial synchronization is not interrupted https://issues.redhat.com/browse/DBZ-838[DBZ-838]
* Kafka database history miscounting attempts even if there are more database history records to consume https://issues.redhat.com/browse/DBZ-853[DBZ-853]
* Schema_only snapshot on idle server - offsets not stored after snapshot https://issues.redhat.com/browse/DBZ-859[DBZ-859]
* DDL parsing in MySQL - default value of primary key is set to null https://issues.redhat.com/browse/DBZ-860[DBZ-860]
* Antlr DDL parser exception for "create database ... CHARSET=..." https://issues.redhat.com/browse/DBZ-864[DBZ-864]
* Error when MongoDB collection contains characters not compatible with kafka topic naming https://issues.redhat.com/browse/DBZ-865[DBZ-865]
* AlterTableParserListener does not remove column definition listeners https://issues.redhat.com/browse/DBZ-869[DBZ-869]
* MySQL parser does not recognize 0 as default value for date/time https://issues.redhat.com/browse/DBZ-870[DBZ-870]
* Antlr parser ignores table whitelist filter https://issues.redhat.com/browse/DBZ-872[DBZ-872]
* A new column might not be added with ALTER TABLE antlr parser https://issues.redhat.com/browse/DBZ-877[DBZ-877]
* MySQLConnectorTask always reports it has the required Binlog file from MySQL https://issues.redhat.com/browse/DBZ-880[DBZ-880]
* Execution of RecordsStreamProducer.closeConnections() is susceptible to race condition https://issues.redhat.com/browse/DBZ-887[DBZ-887]
* Watch-topic command in docker image uses unsupported parameter https://issues.redhat.com/browse/DBZ-890[DBZ-890]
* SQLServer should use only schema and table name in table naming https://issues.redhat.com/browse/DBZ-894[DBZ-894]
* Prevent resending of duplicate change events after restart https://issues.redhat.com/browse/DBZ-897[DBZ-897]
* PostgresConnection.initTypeRegistry() takes ~24 mins https://issues.redhat.com/browse/DBZ-899[DBZ-899]
* java.time.format.DateTimeParseException: Text '1970-01-01 00:00:00' in mysql ALTER https://issues.redhat.com/browse/DBZ-901[DBZ-901]
* org.antlr.v4.runtime.NoViableAltException on CREATE DEFINER=`web`@`%` PROCEDURE `... https://issues.redhat.com/browse/DBZ-903[DBZ-903]
* MySQL default port is wrong in tutorial link https://issues.redhat.com/browse/DBZ-904[DBZ-904]
* RecordsStreamProducer should report refresh of the schema due to different column count https://issues.redhat.com/browse/DBZ-907[DBZ-907]
* MongoDbConnector returns obsolete config values during validation https://issues.redhat.com/browse/DBZ-908[DBZ-908]
* Can't parse create definition on the mysql connector https://issues.redhat.com/browse/DBZ-910[DBZ-910]
* RecordsStreamProducer#columnValues() does not take into account unchanged TOASTed columns, refreshing table schemas unnecessarily https://issues.redhat.com/browse/DBZ-911[DBZ-911]
* Wrong type in timeout call for Central wait release https://issues.redhat.com/browse/DBZ-914[DBZ-914]
* Exception while parsing table schema with invalid default value for timestamp field https://issues.redhat.com/browse/DBZ-927[DBZ-927]
* Discard null fields in MongoDB event flattening SMT https://issues.redhat.com/browse/DBZ-928[DBZ-928]


=== Other changes

This release includes also other changes:

* Create Travis CI build for debezium-incubator repository https://issues.redhat.com/browse/DBZ-817[DBZ-817]
* Cache prepared statements in JdbcConnection https://issues.redhat.com/browse/DBZ-819[DBZ-819]
* Upgrade to Kafka 2.0.0 https://issues.redhat.com/browse/DBZ-858[DBZ-858]
* Upgrad SQL Server image to CU9 GDR2 release https://issues.redhat.com/browse/DBZ-873[DBZ-873]
* Speed-up Travis builds using parallel build https://issues.redhat.com/browse/DBZ-874[DBZ-874]
* Add version format check into the release pipeline https://issues.redhat.com/browse/DBZ-884[DBZ-884]
* Handle non-complete list of plugins https://issues.redhat.com/browse/DBZ-885[DBZ-885]
* Parametrize wait time for Maven central sync https://issues.redhat.com/browse/DBZ-889[DBZ-889]
* Assert non-empty release in release script https://issues.redhat.com/browse/DBZ-891[DBZ-891]
* Upgrade Postgres driver to 42.2.5 https://issues.redhat.com/browse/DBZ-912[DBZ-912]
* Upgrade MySQL JDBC driver to version 8.0.x https://issues.redhat.com/browse/DBZ-763[DBZ-763]
* Upgrade MySQL binlog connector https://issues.redhat.com/browse/DBZ-764[DBZ-764]

[[release-0-9-0-alpha1]]
== *Release 0.9.0.Alpha1* _(July 26th, 2018)_

See the https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&version=12338152[complete list of issues].

=== Kafka compatibility

This release has been built against Kafka Connect 1.1.1 and has been tested with version 1.1.1 of the Kafka brokers.
See the https://kafka.apache.org/documentation/#upgrade[Kafka documentation] for compatibility with other versions of Kafka brokers.

=== Upgrading

Before upgrading the MySQL, MongoDB, or PostgreSQL connectors, be sure to check the backward-incompatible changes that have been made since the release you were using.

When you decide to upgrade one of these connectors to 0.9.0.Alpha1 from any of the earlier 0.8.x, 0.7.x, 0.6.x, 0.5.x, 0.4.x, 0.3.x, 0.2.x, or 0.1.x versions,
first check the upgrading notes for the version you're using.
Gracefully stop the running connector, remove the old plugin files, install the 0.9.0.Alpha1 plugin files, and restart the connector using the same configuration.
Upon restart, the 0.9.0.Alpha1 connectors will continue where the previous connector left off.
As one might expect, all change events previously written to Kafka by the old connector will not be modified.

If you are using our docker images then do not forget to pull them fresh from Docker registry.

=== Breaking changes

The Oracle connector was storing event timestamp in the `source` block in field `ts_sec`. The time stamp is in fact measured in milliseconds to so the field was https://issues.redhat.com/browse/DBZ-795[renamed] to `ts_ms`.

=== New Features

* Ingest change data from SQL Server databases https://issues.redhat.com/browse/DBZ-40[DBZ-40]
* Oracle connector implementation cont'd (initial snapshotting etc.) https://issues.redhat.com/browse/DBZ-716[DBZ-716]
* Implement initial snapshotting for Oracle https://issues.redhat.com/browse/DBZ-720[DBZ-720]
* Implement capturing of streamed changes https://issues.redhat.com/browse/DBZ-787[DBZ-787]
* Implement initial snapshotting for SQL Server https://issues.redhat.com/browse/DBZ-788[DBZ-788]
* Emit NUMBER columns as Int32/Int64 if precision and scale allow https://issues.redhat.com/browse/DBZ-804[DBZ-804]
* Support heartbeat messages for Oracle https://issues.redhat.com/browse/DBZ-815[DBZ-815]
* Upgrade to Kafka 1.1.1 https://issues.redhat.com/browse/DBZ-829[DBZ-829]


=== Fixes

This release includes the following fixes:

* Offset remains with "snapshot" set to true after completing schema only snapshot https://issues.redhat.com/browse/DBZ-803[DBZ-803]
* Misleading timestamp field name https://issues.redhat.com/browse/DBZ-795[DBZ-795]
* Adjust scale of decimal values to column's scale if present https://issues.redhat.com/browse/DBZ-818[DBZ-818]
* Avoid NPE if commit is called before any offset is prepared https://issues.redhat.com/browse/DBZ-826[DBZ-826]


=== Other changes

This release includes also other changes:

* Make DatabaseHistory set-up code re-usable https://issues.redhat.com/browse/DBZ-816[DBZ-816]
* Use TableFilter contract instead of Predicate<TableId> https://issues.redhat.com/browse/DBZ-793[DBZ-793]
* Expand SourceInfo https://issues.redhat.com/browse/DBZ-719[DBZ-719]
* Provide Maven module and Docker set-up https://issues.redhat.com/browse/DBZ-786[DBZ-786]
* Avoid a few raw type warnings https://issues.redhat.com/browse/DBZ-801[DBZ-801]
