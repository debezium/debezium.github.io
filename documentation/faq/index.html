<!DOCTYPE html> <html> <head> <title>Frequently Asked Questions</title> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta content="Debezium" property="og:site_name"> <meta content="Frequently Asked Questions" property="og:title"> <meta content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png" property="og:image" name="image"> <meta property="og:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta property="og:url" content="https://debezium.io/documentation/faq/"> <meta name="twitter:site" content="@debezium"> <meta name="twitter:title" content="Frequently Asked Questions"> <meta name="twitter:creator" content="@debezium"> <meta name="twitter:description" content="Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong."> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:image" content="https://debezium.io/assets/images/color_black_debezium_type_1200px.png"> <meta property="twitter:url" content="https://debezium.io/documentation/faq/"> <link rel="alternate" type="application/rss+xml" title="Debezium Blog" href="/blog.atom"> <link rel="shortcut icon" type="image/png" href="/favicon.ico"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css"/> <link rel="stylesheet" href="/assets/css/custom.css"/> <link rel="stylesheet" href="/assets/css/highlight.min.css"/> <link rel="stylesheet" href="/assets/css/coderay.css"/> </head> <body class="page-menu"> <div id="rhbar"> <a class="jbdevlogo" href="https://developers.redhat.com"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id> <div class="container" id="content"> <nav class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed border-0" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"><img class="project-logo" src="/assets/images/color_white_debezium_type_600px.svg" style="height: 32px; margin-right: 5px; margin-top: -5px;"></a> </div> <div class="collapse navbar-collapse collapsed" id="navigation"> <ul class="nav navbar-nav pull-right"> <li> <a href="/documentation/faq" class="">FAQ</a> </li> <li class="item"> <a href="/documentation/" class="active">Documentation</a> </li> <li> <a href="/releases/" class="">Releases</a> </li> <li> <a href="/community/" class="">Community</a> </li> <li> <a href="/blog/" class="">Blog</a> </li> </ul> </div> </div> </nav> <div class="row post-text-padding row-no-expand"> <div class="col-md-3"> <div id="leftdocnav"> <div class="hidden-lg hidden-md hidden-sm"> <button class="navbar-toggle docssubmenu-toggle collapsed" data-target="#docssubmenu" data-toggle="collapse" style=" float: none; background-color: #656565; border-color: #656565; width: 100%; color: #fff; "> Navigation Menu </button> </div> <div class="collapse" id="docssubmenu"> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation</a> <div class="icon"><span class="caret-right"></span></div> <ul class="dropdown-menu nav nav-pills nav-stacked"> <li class="item"><a href="/documentation/">Overview</a></li> <li class="item"> <a href="/documentation/reference/3.0/"> <div class="version">3.0</div> <div class="version-label"> <span class="label label-development"> development </span> </div> </a> </li> <li class="item"> <a href="/documentation/reference/2.7/"> <div class="version">2.7</div> <div class="version-label"> <span class="label label-stable"> latest stable </span> </div> </a> </li> </ul> </li> <li class="item"> <a class="dropdown-toggle" data-toggle="dropdown" href="#">Releases</a> <div class="icon"><span class="caret-right"></span></div> <ul class="dropdown-menu nav nav-pills nav-stacked"> <li class="item"><a href="/releases/">Overview</a></li> <li class="item"> <a href="/releases/3.0/"> <div class="version">3.0</div> <div class="version-label"> <span class="label label-development"> development </span> </div> </a> </li> <li class="item"> <a href="/releases/2.7/"> <div class="version">2.7</div> <div class="version-label"> <span class="label label-stable"> stable </span> </div> </a> </li> </ul> </li> <li class="item"> <a href="/documentation/online-resources">Resources on the Web</a> <div class="icon"><i class="icon-globe"></i></div> </li> <li class="item"> <a href="/community/users">Who's using Debezium?</a> <div class="icon"><i class="icon-laptop"></i></div> </li> <li class="item"> <a href="/roadmap">Roadmap</a> <div class="icon"><i class="icon-road"></i></div> </li> <li class="item"> <a href="/community/contribute">Contribute</a> <div class="icon"><i class="icon-code"></i></div> </li> <li class="item"> <a href="/community/code-of-conduct">Code of Conduct</a> <div class="icon"><i class="icon-file"></i></div> </li> <li class="item"> <a href="/documentation/faq">FAQ</a> <div class="icon"><i class="icon-question-sign"></i></div> </li> </ul> </div> <p></p> <div class="doc-pills"> <ul class="nav nav-pills nav-stacked"> <li class="item"> <a href="http://www.github.com/debezium/">Source Code</a> <div class="icon"><i class="icon-github"></i></div> </li> <li class="item"> <a href="http://issues.redhat.com/projects/DBZ/issues">Issues</a> <div class="icon"><i class="icon-tasks"></i></div> </li> <li class="item"> <a href="http://www.twitter.com/debezium/">Twitter</a> <div class="icon"><i class="icon-twitter"></i></div> </li> <li class="item"> <a href="https://debezium.zulipchat.com/#narrow/stream/302529-users">Chat</a> <div class="icon"><i class="icon-comments"></i></div> </li> <li class="item"> <a href="https://groups.google.com/forum/#!forum/debezium">Mailing List</a> <div class="icon"><i class="icon-group"></i></div> </li> </ul> </div> </div> </div> </div> <div class="col-md-9"> <h1 class="section full"> Frequently Asked Questions</h1> <div id="toc" class="toc"> <div id="toctitle" class="title"></div> <ul class="sectlevel1"> <li><a href="#what_is_debezium">What is Debezium?</a></li> <li><a href="#where_did_the_name_debezium_come_from">Where did the name "Debezium" come from?</a></li> <li><a href="#what_is_change_data_capture">What is Change Data Capture?</a></li> <li><a href="#what_databases_can_debezium_monitor">What databases can Debezium monitor?</a></li> <li><a href="#what_are_some_uses_of_debezium">What are some uses of Debezium?</a></li> <li><a href="#why_is_debezium_a_distributed_system">Why is Debezium a distributed system?</a></li> <li><a href="#can_my_application_directly_monitor_a_single_database">Can my application directly monitor a single database?</a></li> <li><a href="#what_does_the_debezium_platform_look_like">What does the Debezium platform look like?</a></li> <li><a href="#how_many_databases_can_be_monitored">How many databases can be monitored?</a></li> <li><a href="#how_does_debezium_affect_source_databases">How does Debezium affect source databases?</a></li> <li><a href="#how_are_events_for_a_database_organized">How are events for a database organized?</a></li> <li><a href="#why-are-events-so-large">Why are events so large?</a></li> <li><a href="#avro-converter">How do I use a schema registry?</a></li> <li><a href="#what_happens_when_an_application_stops_or_crashes">What happens when an application stops or crashes?</a></li> <li><a href="#what_happens_when_debezium_stops_or_crashes">What happens when Debezium stops or crashes?</a></li> <li><a href="#what_happens_when_a_monitored_database_stops_or_crashes">What happens when a monitored database stops or crashes?</a></li> <li><a href="#why_must_consuming_applications_expect_duplicate_events">Why must consuming applications expect duplicate events?</a></li> <li><a href="#what_is_causing_intermittent_eventdatadeserializationexceptions_with_the_mysql_connector">What is causing intermittent <code>EventDataDeserializationException</code>s with the MySQL connector?</a></li> <li><a href="#what_is_kafka">What is Kafka?</a></li> <li><a href="#what_is_kafka_connect">What is Kafka Connect?</a></li> <li><a href="#how_to_connect_to_kafka_when_using_the_debezium_docker_images">How to connect to Kafka when using the Debezium Docker images?</a></li> <li><a href="#what_database_size_can_be_handled_with_the_default_memory_settings_for_the_connect_image">What database size can be handled with the default memory settings for the Connect image?</a></li> <li><a href="#how_to_retrieve_decimal_field_from_binary_representation">How to retrieve DECIMAL field from binary representation?</a></li> <li><a href="#how_to_change_the_offsets_of_the_source_database">How to change the offsets of the source database?</a></li> <li><a href="#how_to_remove_committed_offsets_for_a_connector">How to remove committed offsets for a connector?</a></li> <li><a href="#why_cant_tombstone_events_be_printed_with_ksql">Why can&#8217;t tombstone events be printed with KSQL?</a></li> <li><a href="#why_debezium_mysql_connector_crashes_with_schema_change_tools">Why Debezium MySQL connector crashes with schema change tools?</a></li> <li><a href="#how_to_decrease_memory_consumption_in_a_database_per_tenant_pattern">How to decrease memory consumption in a database-per-tenant pattern?</a></li> <li><a href="#how_to_solve_offset_flush_timeouts">How to solve offset flush timeouts?</a></li> <li><a href="#why_dont_i_see_delete_events_in_some_cases">Why don&#8217;t I see DELETE events in some cases?</a></li> <li><a href="#why_debezium_mysql_connector_fails_to_consume_data_from_a_rds_mysql_read_replica">Why Debezium MySQL connector fails to consume data from a RDS MySQL read replica?</a></li> <li><a href="#why_debezium_postgresql_connector_causes_abnormal_consumption_of_wal_database_disk_space">Why Debezium PostgreSQL connector causes abnormal consumption of WAL database disk space?</a></li> <li><a href="#why_is_no_new_schema_version_created_when_the_content_of_two_columns_in_a_table_is_swapped">Why is no new schema version created when the content of two columns in a table is swapped?</a></li> <li><a href="#how_to_enlarge_the_maximum_size_of_the_message_delivered_to_kafka">How to enlarge the maximum size of the message delivered to Kafka?</a></li> <li><a href="#why_do_json_messages_not_contain_schema">Why do JSON messages not contain schema?</a></li> <li><a href="#how_to_enable_case_insensitive_name_filtering">How to enable case insensitive name filtering?</a></li> <li><a href="#why_do_change_event_values_for_mysql_timestamp_columns_differ_between_snapshotting_and_streaming">Why do change event values for MySQL <code>TIMESTAMP</code> columns differ between snapshotting and streaming?</a></li> <li><a href="#mongodb_connector_fails_with_maximum_bson_size_error">MongoDB Connector fails with maximum BSON size error</a></li> </ul> </div> <div class="sect1"> <h2 id="what_is_debezium">What is Debezium?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is a set of distributed services that capture row-level changes in your databases so that your applications can see and respond to those changes. Debezium records in a transaction log all row-level changes committed to each database table. Each application simply reads the transaction logs they&#8217;re interested in, and they see all of the events in the same order in which they occurred.</p> </div> </div> </div> <div class="sect1"> <h2 id="where_did_the_name_debezium_come_from">Where did the name "Debezium" come from?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The name is a combination of "<em>DBs</em>", as in the abbreviation for multiple databases, and the "<em>-ium</em>" suffix used in the names of many elements of the periodic table. Say it fast: "<em>DBs-ium</em>". If it helps, we say it like "<em>dee-BEE-zee-uhm</em>".</p> </div> </div> </div> <div class="sect1"> <h2 id="what_is_change_data_capture">What is Change Data Capture?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Change Data Capture, or CDC, is an older term for a system that monitors and captures the changes in data so that other software can respond to those changes. Data warehouses often had built-in CDC support, since data warehouses need to stay up-to-date as the data changed in the upstream OLTP databases.</p> </div> <div class="paragraph"> <p>Debezium is essentially a modern, distributed open source <em>change data capture platform</em> that will eventually support monitoring a variety of database systems.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_databases_can_debezium_monitor">What databases can Debezium monitor?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The latest version of Debezium includes support for monitoring <a href="/documentation/reference/stable/connectors/mysql">MySQL database servers</a>, <a href="/documentation/reference/stable/connectors/mongodb">MongoDB replica sets or sharded clusters</a>, <a href="/documentation/reference/stable/connectors/postgresql">PostgreSQL servers</a>, <a href="/documentation/reference/stable/connectors/oracle">Oracle servers</a> (based on LogMiner and XStream), <a href="/documentation/reference/stable/connectors/db2">Db2 servers</a>, <a href="/documentation/reference/stable/connectors/cassandra">Cassandra databases</a> (3.x and 4.x) and <a href="/documentation/reference/stable/connectors/sqlserver">SQL Server databases</a>. In addition there are work-in-progress Debezium connectors for <a href="/documentation/reference/stable/connectors/vitess">Vitess servers</a>, and <a href="/documentation/reference/stable/connectors/spanner">Google Spanner</a> which are released as preview (incubating) versions as of Debezium 2.2.</p> </div> <div class="paragraph"> <p>Note that monitoring PostgreSQL requires installing an extension ("logical decoding plugin") into the PostgreSQL server. Debezium works with <a href="https://github.com/debezium/postgres-decoderbufs/">Decoderbufs</a> (maintained by the Debezium community) and pgoutput (maintained by the Postgres community).</p> </div> <div class="paragraph"> <p>If your database is hosted on a (managed) cloud service, one of these plug-ins must be installed (or you must be able to install it yourself). Otherwise, you&#8217;ll be unable to monitor your database with Debezium. pgoutput is part of Postgres 10 and later; whether it can be enabled depends on the particular database&#8217;s configuration.</p> </div> <div class="paragraph"> <p>On <a href="https://cloud.google.com/sql">CloudSQL</a>, pgoutput is a supported extension and can be installed, as described in <a href="https://cloud.google.com/sql/docs/postgres/extensions">Configure PostgreSQL extensions</a>.</p> </div> <div class="paragraph"> <p>On <a href="https://aws.amazon.com/rds/">Amazon RDS</a> as well as with <a href="https://docs.microsoft.com/en-us/azure/postgresql/">Azure Database for PostgreSQL</a>, pgoutput can be used. Both can be used with Debezium.</p> </div> <div class="paragraph"> <p>Support for other DBMSes will be added in future releases. See our <a href="/roadmap/">roadmap</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_are_some_uses_of_debezium">What are some uses of Debezium?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The primary use of Debezium is to enable applications to respond almost immediately whenever data in databases change. Applications can do anything with the insert, update, and delete events. They might use the events to know when to remove entries from a cache. They might update search indexes with the data. They might update a derived data store with the same information or with information computed from the changing data, such as with <a href="https://en.wikipedia.org/wiki/Command-query_separation">Command Query Responsibility Separation (CQRS)</a>. They might send a push notification to one or more mobile devices. They might aggregate the changes and produce a stream of patches for entities. They might be stored to form an audit log. They might drive streaming queries e.g. with Apache Flink or Kafka Streams. They might be used to propagate data between microservices, e.g. employing the <a href="/documentation/reference/configuration/outbox-event-router.html">outbox pattern</a>.</p> </div> <div class="paragraph"> <p>You can learn more about CDC use cases in <a href="https://speakerdeck.com/gunnarmorling/practical-change-data-streaming-use-cases-with-apache-kafka-and-debezium-qcon-san-francisco-2019">this presentation</a> from QCon San Francisco 2019.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_is_debezium_a_distributed_system">Why is Debezium a distributed system?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is architected to be tolerant of faults and failures, and the only effectively way to do that is with a distributed system. Debezium distributes the monitoring processes, or <em>connectors</em>, across multiple machines so that, if anything goes wrong, the connectors can be restarted. The events are recorded and replicated across multiple machines to minimize risk of information loss.</p> </div> </div> </div> <div class="sect1"> <h2 id="can_my_application_directly_monitor_a_single_database">Can my application directly monitor a single database?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Yes. Although we recommend most people use the full Debezium platform, it is possible for a single application to <a href="/docs/embedded/">embed</a> a Debezium connector so it can monitor a database and respond to the events. This approach is indeed far simpler with few moving parts, but it is more limited and far less tolerant of failures. If your application needs at-least-once delivery guarantees of all messages, please consider using the full distributed system.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_does_the_debezium_platform_look_like">What does the Debezium platform look like?</h2> <div class="sectionbody"> <div class="paragraph"> <p>A running Debezium system consists of several pieces. A cluster of <a href="http://kafka.apache.org">Apache Kafka</a> brokers provides the persistent, replicated, and partitioned transaction logs where Debezium records all events and from which applications consume all events. The number of Kafka brokers depends largely on the volume of events, the number of database tables being monitored, and the number of applications that are consuming the events. Kafka does rely upon a small cluster of <a href="http://zookeeper.apache.org">Zookeeper</a> nodes to manage responsibilities of each broker.</p> </div> <div class="paragraph"> <p>Each Debezium connector monitors one database cluster/server, and connectors are configured and deployed to a cluster of Kafka Connect services that ensure that each connector is always running, even as Kafka Connect service instances leave and join the cluster. Each Kafka Connect service cluster (a.k.a., group) is independent, so it is possible for each group within an organization to manage its own clusters.</p> </div> <div class="paragraph"> <p>All connectors record their events (and other information) to Apache Kafka, which persists, replicates, and partitions the events for each table in separate topics. Multiple Kafka Connect service clusters can share a single cluster of Kafka brokers, but the number of Kafka brokers depends largely on the volume of events, the number of database tables being monitored, and the number of applications that are consuming the events.</p> </div> <div class="paragraph"> <p>Applications connect to Kafka directly and consume the events within the appropriate topics.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_many_databases_can_be_monitored">How many databases can be monitored?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium can monitor any number of databases. The number of connectors that can be deployed to a single cluster of Kafka Connect services depends upon upon the volume and rate of events. However, Debezium supports multiple Kafka Connect service clusters and, if needed, multiple Kafka clusters as well.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_does_debezium_affect_source_databases">How does Debezium affect source databases?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Most databases have to be configured before Debezium can monitor them. For example, a MySQL server must be configured to use the row-level binlog, and to have a user privileged to read the binlog; the Debezium connector must be configured with the correct information, including the privileged user. See the specific connector documentation for details.</p> </div> <div class="paragraph"> <p>Debezium connectors do not store any information inside the upstream databases. However, running a connector may place additional load on the source database.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_are_events_for_a_database_organized">How are events for a database organized?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Most connectors will record all events for a single database table to a single topic. Additionally, all events within a topic are <em>totally-ordered</em>, meaning that the order of all of those events will be maintained. (Even if events are duplicated during failures, the end result after applying all of the events will remain the same.)</p> </div> <div class="paragraph"> <p>For example, a MySQL connector monitoring a MySQL server/cluster (logically named "dbserverA") records all of the changes to the "Addresses" table within the "Customers" database in the topic named <code>dbserverA.Customers.Addresses</code>. Likewise, all of the changes to the "PaymentMethods" table in the same database will be recorded in the topic named <code>dbserverA.customers.PaymentMethods</code>.</p> </div> </div> </div> <div class="sect1"> <h2 id="why-are-events-so-large">Why are events so large?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is designed to monitor upstream databases and produce for each row-level change one or more corresponding events that completely describe those changes. But Debezium connectors work <em>continuously</em>, and its events have to make sense even as the structure of the tables in the upstream databases change over time. A consumer is also much easier to write if it only has to deal with a single event at a time, rather than having to track state over the entire history of the event stream.</p> </div> <div class="paragraph"> <p>That means each event needs to be completely self-describing: an event&#8217;s key and value each contain a <em>payload</em> with the actual information and a <em>schema</em> that fully describes the structure of the information. Consuming applications can process each event, use the schema to understand the structure of the information in that event, and then correctly process the event&#8217;s payload. The consuming application can take advantage of the fact that the schema will remain the same for many events in a row, and only when the schema changes might the consuming application need to do a bit more work preparing for the changed structure.</p> </div> <div class="paragraph"> <p>Meanwhile, the Kafka Connect services serialize the connector&#8217;s events and record them in Kafka. The JSON converter is very generic and very simple, but it has no choice but to serialize the entire event information. Therefore, events represented in JSON are indeed verbose and large.</p> </div> <div class="paragraph"> <p>However, there&#8217;s an alternative: using a schema registry. That way, actual schema information is managed by the registry, while actual change events only contain the id of the corresponding schema in the registry. This results in a much more efficient representation of events as sent to Kafka. Schema registries can be used with different formats like JSON or Avro. Leveraging Avro as the message format has the additional advantage that payloads are serialized into a <a href="https://martin.kleppmann.com/2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html">very compact binary form</a>.</p> </div> <div class="paragraph"> <p>Using this approach, a Kafka Connect converter and the schema registry work together to track the history of each schema over time. Meanwhile, in the consumer, the same converter decodes the compact binary form of the event, reads the identifier of the schema version used by that message, if it hasn&#8217;t yet seen that schema version downloads the schema from the schema registry, and finally uses that schema to decode the payload of the event. Again, many events in sequence will share the same schema (and schema version), so most of the time the converter can simply decode the raw compact event into the same schema and payload expected by the consumer.</p> </div> </div> </div> <div class="sect1"> <h2 id="avro-converter">How do I use a schema registry?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Options for schema registries include the <a href="https://github.com/Apicurio/apicurio-registry">Apicurio API and Schema Registry</a> and the <a href="http://docs.confluent.io/{confluent-platform-version}/schema-registry/docs/index.html">Confluent Schema Registry</a>. Both come with converters for storing/obtaining JSON and Avro schemas in and from the registry.</p> </div> <div class="paragraph"> <p>If you are deploying Debezium connectors to a Kafka Connect worker service, simply make sure the converter JARs of your registry are available and configure the worker service to use the right Converter. You will, for example, need to point the converter to your Apicurio Schema Registry. Then, simply deploy the Debezium connectors (or really, any other Kafka Connect connectors) to your worker service. See <a href="/docs/configuration/avro/">Avro Serialization</a> for a detailed description of how to use the Avro converter with the Apicurio and Confluent registries.</p> </div> <div class="paragraph"> <p>The <a href="https://github.com/debezium/debezium-examples/tree/main/tutorial#using-mysql-and-the-avro-message-format">tutorial example</a> on GitHub shows in detail how to use a schema registry and the accompanying converters with Debezium.</p> </div> <div class="paragraph"> <p>Our Docker images for Kafka Connect include the Avro converter as an option.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_happens_when_an_application_stops_or_crashes">What happens when an application stops or crashes?</h2> <div class="sectionbody"> <div class="paragraph"> <p>To consume the change events for a database, an application creates a Kafka consumer that will connect to the Kafka brokers and consume all events for the topics associated with that database. The consumer is configured to periodically record its position (aka, offset) in each topic. When an application stops gracefully and closes the consumer, the consumer will record the offsets for the last event in each topic. When the application restarts at any later time, the consumer looks up those offsets and starts reading the very next events in each topic. Therefore, under normal operating scenarios, the application sees every event <strong>exactly one time</strong>.</p> </div> <div class="paragraph"> <p>If the application crashes unexpectedly, then upon restart the application&#8217;s consumer will look up the <em>last recorded offsets</em> for each topic, and start consume events from the last offset for each topic. In most cases, the application will see some of the same events it saw prior to the crash (but after it recorded the offset), followed by the events it had not yet seen. Thus, the application sees every event <strong>at least once</strong>. The application can reduce the number of events seen more than once by recording the offsets more frequently, although doing so will negatively affect performance and throughput of the client.</p> </div> <div class="paragraph"> <p>Note that a Kafka consumer can be configured to connect and start reading with the most recent offset in each topic. This can result in missed events, though this is perfectly acceptable for some use cases.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_happens_when_debezium_stops_or_crashes">What happens when Debezium stops or crashes?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The behavior of Debezium varies depending upon which components are stopped or crashed. If enough of the Kafka broker were to stop or crash such that the each topic partition is housed by fewer than the minimum number of in-sync replicas, then the connectors writing to those topics and the consuming applications reading from those topics will simply block until the Kafka brokers can be restarted or new brokers brought online. Therefore, the minimum number of in-sync replicas has a very large impact on availability, and for consistency reasons should always be at least 1 (if not 3).</p> </div> <div class="paragraph"> <p>The Kafka Connect service is configured to periodically record the position and offsets of each connector. If one of the Kafka Connect service instances in its cluster is <em>stopped gracefully</em>, all connectors running in that process will be stopped gracefully (meaning all positions and offsets will be recorded) and those same connectors will be restarted on other Kafka Connect service instances in the same cluster. When those connectors are restarted, they will continue recording events exactly where they left off, with no duplicate events being recorded.</p> </div> <div class="paragraph"> <p>When one of the connectors running in a Kafka Connect service cluster is stopped gracefully, it will complete its current work and record the latest positions and offsets in Kafka. Downstream applications consume from the topics will simply wait until new events are added.</p> </div> <div class="paragraph"> <p>If any of the Kafka Connect service instances in its cluster <em>crashes unexpectedly</em>, then all connectors that were running in the crashed process will be restarted on other Kafka Connect service instances in the same cluster. However, when those connectors are restarted, they will begin recording events from the database starting at the position/offset <em>last recorded by the connector before it crashed</em>. This means the newly-restarted connectors may likely record some of the same events it previously recorded prior to the crash, and these duplicates will always be visible to downstream consuming applications.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_happens_when_a_monitored_database_stops_or_crashes">What happens when a monitored database stops or crashes?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When a database server monitored by Debezium stops or crashes, the Debezium connector will likely try to re-establish communication. Debezium periodically records the connector&#8217;s positions and offsets in Kafka, so once the connector establishes communication the connector should continue to read from the last recorded position and offset.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_must_consuming_applications_expect_duplicate_events">Why must consuming applications expect duplicate events?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When all systems are running nominally or when some or all of the systems are gracefully shut down, then consuming applications can expect to see every event <strong>exactly one time</strong>. However, when things go wrong it is always possible for consuming applications to see events <strong>at least once</strong>.</p> </div> <div class="paragraph"> <p>When the Debezium&#8217;s systems crash, they are not always able to record their last position/offset. When they are restarted, they recover by starting where were last known to have been, and thus the consuming application will always see every event but may likely see at least some messages duplicated during recovery.</p> </div> <div class="paragraph"> <p>Additionally, network failures may cause the Debezium connectors to not receive confirmation of writes, resulting in the same event being recorded one or more times (until confirmation is received).</p> </div> </div> </div> <div class="sect1"> <h2 id="what_is_causing_intermittent_eventdatadeserializationexceptions_with_the_mysql_connector">What is causing intermittent <code>EventDataDeserializationException</code>s with the MySQL connector?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When you run into intermittent deserialization exceptions around 1 minute after starting connector, with a root cause of type <code>EOFException</code> or <code>java.net.SocketException: Connection reset</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>Caused by: com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException: Failed to deserialize data of EventHeaderV4{timestamp=1542193955000, eventType=GTID, serverId=91111, headerLength=19, dataLength=46, nextPosition=1058898202, flags=0}
Caused by: java.lang.RuntimeException: com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException: Failed to deserialize data of EventHeaderV4{timestamp=1542193955000, eventType=GTID, serverId=91111, headerLength=19, dataLength=46, nextPosition=1058898202, flags=0}
Caused by: java.io.EOFException

or

Caused by: java.net.SocketException: Connection reset</code></pre> </div> </div> <div class="paragraph"> <p>Then updating these MySQL server global properties like this will fix it:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>set global slave_net_timeout = 120; (default was 30sec)
set global thread_pool_idle_timeout = 120;</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="what_is_kafka">What is Kafka?</h2> <div class="sectionbody"> <div class="paragraph"> <p><a href="http://kafka.apache.org">Apache Kafka</a> is a fast, scalable, durable, and distributed messaging system that records all messages in replicated, partitioned, and totally-ordered transaction logs. Consumers keep track of their position in the logs, and can control this position indepdently of all other consumers. This means that some consumers can start from the very beginning of the log while others are keeping up with the most recently-recorded messages. Kafka operates as a dynamic cluster of brokers. Each log partition is replicated to multiple brokers so that, should any broker fail, the cluster still has multiple copies of the partition.</p> </div> <div class="paragraph"> <p>Debezium connectors record all events to a Kafka cluster, and applications consume those events through Kafka.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_is_kafka_connect">What is Kafka Connect?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Kafka Connect is a framework for scalably and reliably streaming data between Apache Kafka and other systems. It is a recent addition to the Kafka community, and it makes it simple to define connectors that move large collections of data into and out of Kafka, while the framework does most of the hard work of properly recording the offsets of the connectors. A Kafka Connect service has a RESTful API for managing and deploying connectors; the service can be clustered and will automatically distribute the connectors across the cluster, ensuring that the connector is always running.</p> </div> <div class="paragraph"> <p>Debezium use the Kafka Connect framework. All of Debezium&#8217;s connectors are Kafka Connector <em>source connectors</em>, and as such they can be deployed and managed using the Kafka Connect service.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_connect_to_kafka_when_using_the_debezium_docker_images">How to connect to Kafka when using the Debezium Docker images?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When using Docker for Mac or Docker for Windows, the Docker containers run within a light-weight VM. In order to connect to Kafka from your host system, e.g. with a Kafka Consumer started in a test in your IDE, you need to specify your host system&#8217;s IP address or host name as <code>ADVERTISED_HOST_NAME</code> for the Kafka container: <code>docker run -it --rm --name kafka -p 9092:9092 -e ADVERTISED_HOST_NAME=&lt;%YOUR_HOST_NAME%&gt; --link zookeeper:zookeeper debezium/kafka:{debezium-docker-label}</code>. This name will be published by Zookeeper to clients asking for the Kafka broker&#8217;s name.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_database_size_can_be_handled_with_the_default_memory_settings_for_the_connect_image">What database size can be handled with the default memory settings for the Connect image?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The memory consumption during start-up and runtime depends on the total number of tables in the database that is monitored by Debezium, the number of columns in each table and also the amount of events coming from the database. As a rule of thumb the default memory settings (maximum heap set to 256 MB) will manage to handle databases where the total count of columns across all tables is less than 10000.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_retrieve_decimal_field_from_binary_representation">How to retrieve DECIMAL field from binary representation?</h2> <div class="sectionbody"> <div class="paragraph"> <p>If Debezium is configured to handle DECIMAL values as precise then it encodes it as <code>org.apache.kafka.connect.data.Decimal</code>. This type is converted into a <code>BigInteger</code> and serialized as a byte array. To decode it back we need to know the scale of value either in advance or it has to be obtained from the schema. The code for unwrapping then can look like one of the following snippets depending whether the encoded value is available as a byte array or as a string.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="type">byte</span><span class="type">[]</span> encoded = ...;
<span class="type">int</span> scale = ...;
<span class="directive">final</span> <span class="predefined-type">BigDecimal</span> decoded = <span class="keyword">new</span> <span class="predefined-type">BigDecimal</span>(<span class="keyword">new</span> <span class="predefined-type">BigInteger</span>(encoded), scale);

<span class="predefined-type">String</span> encoded = ...;
<span class="type">int</span> scale = ...;
<span class="directive">final</span> <span class="predefined-type">BigDecimal</span> decoded = <span class="keyword">new</span> <span class="predefined-type">BigDecimal</span>(<span class="keyword">new</span> <span class="predefined-type">BigInteger</span>(Base64.getDecoder().decode(encoded)), scale);</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="how_to_change_the_offsets_of_the_source_database">How to change the offsets of the source database?</h2> <div class="sectionbody"> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> This is a highly technical operation manipulating Kafka Connect internals. Please use this only as the last resort solution. </td> </tr> </table> </div> <div class="paragraph"> <p>Sometimes the database log contains an invalid data (like invalid date) that needs to be skipped or it is necessary to reprocess part of the log from the past. There is generally no straight way (apart from <code>event.deserialization.failure.handling.mode</code> for MySQL connector) how to achieve this operation but there is a workaround that manipulates Kafka Connect&#8217;s internal data.</p> </div> <div class="paragraph"> <p>First step is to find out the name of the topic that contains plugin-offsets. This is configured in <code>offset.storage.topic</code> option.</p> </div> <div class="paragraph"> <p>Next step is to find out the last offset for the given connector, key under which it is stored and identify the partition used to store the offset. An example would be:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>$ kafkacat -b localhost -C -t my_connect_offsets -f 'Partition(%p) %k %s\n'
Partition(11) ["inventory-connector",{"server":"dbserver1"}] {"ts_sec":1530088501,"file":"mysql-bin.000003","pos":817,"row":1,"server_id":223344,"event":2}
Partition(11) ["inventory-connector",{"server":"dbserver1"}] {"ts_sec":1530168941,"file":"mysql-bin.000004","pos":3261,"row":1,"server_id":223344,"event":2}</code></pre> </div> </div> <div class="paragraph"> <p>The key for <code>inventory-connector</code> is <code>["inventory-connector",{"server":"dbserver1"}]</code>, the partition number is <code>11</code> and the last offset is <code>{"ts_sec":1530168941,"file":"mysql-bin.000004","pos":3261,"row":1,"server_id":223344,"event":2}</code>.</p> </div> <div class="paragraph"> <p>To move back to a previous offset the connector should be stopped and the following command has to be issued:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>$ echo '["inventory-connector",{"server":"dbserver1"}]|{"ts_sec":1530168950,"file":"mysql-bin.000003","pos":817,"row":1,"server_id":223344,"event":2}' | \
kafkacat -P -b localhost -t my_connect_offsets -K \| -p 11</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="how_to_remove_committed_offsets_for_a_connector">How to remove committed offsets for a connector?</h2> <div class="sectionbody"> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> This is a highly technical operation manipulating Kafka Connect internals. Please use this only as the last resort solution. </td> </tr> </table> </div> <div class="paragraph"> <p>Sometimes while doing experiments (or when a connector was misconfigured at the start) it is necessary to remove the connector offsets to start with a clean state.</p> </div> <div class="paragraph"> <p>The first step is to find out the name of the topic that contains plugin-offsets. This is configured in <code>offset.storage.topic</code> option.</p> </div> <div class="paragraph"> <p>The next step is to find out the last offset for the given connector, key under which it is stored and identify the partition used to store the offset. An example would be:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>$ kafkacat -b localhost -C -t my_connect_offsets -f 'Partition(%p) %k %s\n'
Partition(11) ["inventory-connector",{"server":"dbserver1"}] {"ts_sec":1530088501,"file":"mysql-bin.000003","pos":817,"row":1,"server_id":223344,"event":2}
Partition(11) ["inventory-connector",{"server":"dbserver1"}] {"ts_sec":1530168941,"file":"mysql-bin.000004","pos":3261,"row":1,"server_id":223344,"event":2}</code></pre> </div> </div> <div class="paragraph"> <p>The key for <code>inventory-connector</code> is <code>["inventory-connector",{"server":"dbserver1"}]</code>, the partition number is <code>11</code> and the last offset is <code>{"ts_sec":1530168941,"file":"mysql-bin.000004","pos":3261,"row":1,"server_id":223344,"event":2}</code>.</p> </div> <div class="paragraph"> <p>To delete connector offsets the connector should be stopped and the following command has to be issued:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>$ echo '["inventory-connector",{"server":"dbserver1"}]|' | \
kafkacat -P -Z -b localhost -t my_connect_offsets -K \| -p 11</code></pre> </div> </div> <div class="paragraph"> <p>This command writes a <code>NULL</code> message for the given key which is logically translated to removing stored offsets for the given connector.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_cant_tombstone_events_be_printed_with_ksql">Why can&#8217;t tombstone events be printed with KSQL?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When using the KSQL streaming query engine, tombstone events (as created by the Debezium connector by default when deleting a record in a captured table) are not supported:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>PRINT 'dbserver.inventory.orders' FROM BEGINNING;
com.fasterxml.jackson.databind.node.NullNode cannot be cast to com.fasterxml.jackson.databind.node.ObjectNode</code></pre> </div> </div> <div class="paragraph"> <p>Consider to remove tombstone events by using the <a href="/docs/configuration/event-flattening/">after state extraction SMT</a> and its options for dropping tombstones.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_debezium_mysql_connector_crashes_with_schema_change_tools">Why Debezium MySQL connector crashes with schema change tools?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When MySQL connector monitors a table to which a schema change tool like <strong>Gh-ost</strong> or <strong>pt-online-schema-change</strong> is applied then MySQL connector can crash with exception thrown from value converters. The tools are creating helper tables during migration process and these helper tables need to be included among whitelisted tables.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_decrease_memory_consumption_in_a_database_per_tenant_pattern">How to decrease memory consumption in a database-per-tenant pattern?</h2> <div class="sectionbody"> <div class="paragraph"> <p>If your multitenancy is based on single-tenant databases, your Debezium connectors will have to store metadata for columns and tables multiple times. You can decrease memory consumption using JVM <code>-XX:+UseStringDeduplication</code> flag. All JVM parameters can be passed using <code>KAFKA_OPTS</code> environment variable. An example in your Dockerfile would be:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>ENV KAFKA_OPTS="-XX:+UseStringDeduplication"</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="how_to_solve_offset_flush_timeouts">How to solve offset flush timeouts?</h2> <div class="sectionbody"> <div class="paragraph"> <p>When a log contains errors like <code>Failed to flush, timed out while waiting for producer to flush outstanding 218630 messages</code> it means that Kafka Connect is not able to record offsets into offset topic fast enough.</p> </div> <div class="paragraph"> <p>There can be multiple solutions and root causes of the problem</p> </div> <div class="ulist"> <ul> <li> <p>Kafka option <code>acks</code> is set to all and one of the replica brokers is slow with processing the writes</p> </li> <li> <p>Connect records are generated very fast, Kafka Connect options <code>offset.flush.interval.ms</code> and <code>offset.flush.timeout.ms</code> should be tuned. The interval should be shortened and timeout increased.</p> </li> <li> <p>Debezium is generating very large batches of records, reduce parameters <code>max.batch.size</code> and <code>max.queue.size</code></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="why_dont_i_see_delete_events_in_some_cases">Why don&#8217;t I see DELETE events in some cases?</h2> <div class="sectionbody"> <div class="paragraph"> <p>This may be caused by the usage of <code>CASCADE DELETE</code> statements. In this case the deletion events generated by the database <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-and-mysql-replication.html">are not part of the binlog</a> and thus cannot be captured by Debezium.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_debezium_mysql_connector_fails_to_consume_data_from_a_rds_mysql_read_replica">Why Debezium MySQL connector fails to consume data from a RDS MySQL read replica?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium MySQL requires enabling the server binlog. In the case of RDS MySQL, the <code>log_bin</code> property is managed directly by AWS and is set to <code>OFF</code> by default. When Debezium MySQL executes the <code>SHOW MASTER STATUS</code> command during a snapshot, the result set is empty and an exception is thrown:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>Caused by: java.lang.IllegalStateException: Cannot read the binlog filename and position via 'SHOW MASTER STATUS'. Make sure your server is correctly configured
    at io.debezium.connector.mysql.SnapshotReader.lambda$readBinlogPosition$16(SnapshotReader.java:761)
    at io.debezium.jdbc.JdbcConnection.query(JdbcConnection.java:444)
    at io.debezium.jdbc.JdbcConnection.query(JdbcConnection.java:385)
    at io.debezium.connector.mysql.SnapshotReader.readBinlogPosition(SnapshotReader.java:745)
    at io.debezium.connector.mysql.SnapshotReader.execute(SnapshotReader.java:370)</code></pre> </div> </div> <div class="paragraph"> <p>The solution is to indirectly enable the <code>log_bin</code> property, activating certain product features in RDS MySQL: read replicas and/or automated backups. Upon activating any of them, the <code>bin_log</code> property value will change to <code>ON</code> automatically and the connector will be able to complete snapshots successfully.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_debezium_postgresql_connector_causes_abnormal_consumption_of_wal_database_disk_space">Why Debezium PostgreSQL connector causes abnormal consumption of WAL database disk space?</h2> <div class="sectionbody"> <div class="paragraph"> <p>See <a href="/documentation/reference/stable/connectors/postgresql.html#postgresql-wal-disk-space">WAL Disk Space Consumption</a> in PostgreSQL connector documentation.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_is_no_new_schema_version_created_when_the_content_of_two_columns_in_a_table_is_swapped">Why is no new schema version created when the content of two columns in a table is swapped?</h2> <div class="sectionbody"> <div class="paragraph"> <p>If two columns in a table are swapped in that way that after the change the table schema is same as before, then no new version of the schema gets created in the schema registry. An example of such operation could be:</p> </div> <div class="ulist"> <ul> <li> <p>original table - <code>id</code>, <code>c1</code>, <code>c2</code> where <code>c1</code> and <code>c2</code> are of the same type</p> </li> <li> <p>column swap - <code>id</code>, <code>c2</code>, <code>c1</code></p> </li> <li> <p>column rename - <code>id</code>, <code>c1</code>, <code>c2</code></p> </li> </ul> </div> <div class="paragraph"> <p>The schema registry creates a new version of schema only if the schema logically changes, but in this case the schema is the same after the change for an external observer.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_enlarge_the_maximum_size_of_the_message_delivered_to_kafka">How to enlarge the maximum size of the message delivered to Kafka?</h2> <div class="sectionbody"> <div class="paragraph"> <p>For large transactions it is possible that Kafka Connect emits message that is larger then the pre-set maximum. The log usually contains an exception similar to:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>org.apache.kafka.common.errors.RecordTooLargeException: The message is 1740572 bytes when serialized which is larger than 1048576, which is the value of the max.request.size configuration.</code></pre> </div> </div> <div class="paragraph"> <p>To solve the issue the configuration option <code>producer.max.request.size</code> must be set in Kafka Connect worker config file <code>connect-distributed.properties</code>. If the global change is not desirable then the connector can override the default setting using configuration option <code>producer.override.max.request.size</code> set to a larger value.</p> </div> <div class="paragraph"> <p>In the latter case it is also necessary to configure <code>connector.client.config.override.policy=ALL</code> option in Kafka Connect worker config file <code>connect-distributed.properties</code>. For Debezium <code>connect</code> Docker image the environment variable <code>CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY</code> can be used to configure the option.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_do_json_messages_not_contain_schema">Why do JSON messages not contain schema?</h2> <div class="sectionbody"> <div class="paragraph"> <p>If you are using <code>JsonConverter</code> to convert and serialize the messages emitted by Debezium, the schema is not included in the messages by default. Schemas are enabled using the <code>schemas.enable</code> converter configuration parameter, set either at worker level (e.g. <code>connect-distibuted.properties</code>):</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>key.converter.schemas.enable=true
value.converter.schemas.enable=true</code></pre> </div> </div> <div class="paragraph"> <p>or at the connector level, depending on where the converter is configured.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_enable_case_insensitive_name_filtering">How to enable case insensitive name filtering?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Several configuration options like <code>table.include.list</code> that define a set of regular expressions are not case sensitive when applied to identifiers.</p> </div> <div class="paragraph"> <p>If your environment requires case-sensitive matching (e.g. two identifiers are differing in letter-case only), then you can use the regular expression flag <code>(?-i)</code> for a given expression to mandate case-sensitive matching.</p> </div> </div> </div> <div class="sect1"> <h2 id="why_do_change_event_values_for_mysql_timestamp_columns_differ_between_snapshotting_and_streaming">Why do change event values for MySQL <code>TIMESTAMP</code> columns differ between snapshotting and streaming?</h2> <div class="sectionbody"> <div class="paragraph"> <p>This may be the case if Debezium (or rather the MySQL JDBC driver) cannot retrieve the database&#8217;s timezone for some reason. In this case, <code>TIMESTAMP</code> values may fail to be normalized to UTC. The database timezone must be specified explicitly in this situation, using the <code>database.connectionTimeZone</code> pass-through connector option (<code>database.serverTimezone</code> must be used for Debezium versions older than 1.7).</p> </div> </div> </div> <div class="sect1"> <h2 id="mongodb_connector_fails_with_maximum_bson_size_error">MongoDB Connector fails with maximum BSON size error</h2> <div class="sectionbody"> <div class="paragraph"> <p>This may be the case when Debezium (or rather the MongoDB change stream cursor) encounters a change event document with total size exceeding the <a href="https://www.mongodb.com/docs/manual/reference/limits/#mongodb-limit-BSON-Document-Size">BSON document size limit of 16 megabytes</a>. Note that depending on the used <code>capture.mode</code> this issue can still manifest even when the actual value of the <strong>stored</strong> documents is significantly lower.</p> </div> <div class="paragraph"> <p>To mitigate this issue, refer to the documentation of <a href="/documentation/reference/stable/connectors/mongodb.html#mongodb-property-cursor-oversize-handling-mode">cursor.oversize.handling.mode</a> and <a href="/documentation/reference/stable/connectors/mongodb.html#mongodb-property-cursor-oversize-skip-threshold">cursor.oversize.skip.threshold</a> properties.</p> </div> </div> </div> </div> </div> </div> <footer class="container"> <div> <div class="row mr-0 ml-0"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2024 Debezium Community <br/> <br/> <i class="icon-fire"></i> Mixed with <a href="https://getbootstrap.com/">Bootstrap</a>, baked by <a href="https://jekyllrb.com/">Jekyll</a>. <br/> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br/> <i class="icon-flag-alt"></i> Code released under <a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br/> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> <p>Rev: <a target="_blank" href="https://github.com/debezium/debezium.github.io/commit/f8b29b9340e8a4092e4ece7fc4445e388ccb7be6">f8b29b9</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li><a href="/documentation/reference/stable/features.html" title="Features">Features</a></li> <li> <a href="/documentation/reference/stable/install.html" title="Install">Install</a> </li> <li> <a href="/documentation/reference/stable/architecture.html" title="Architecture">Architecture</a> </li> <li><a href="/documentation/faq/" title="FAQ">FAQ</a></li> <li> <a href="/community/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li><a href="/blog" title="Blog">Blog</a></li> <li> <a href="https://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li><a href="https://github.com/debezium" title="GitHub">GitHub</a></li> <li><a href="https://debezium.zulipchat.com/#narrow/stream/302529-users" title="Chat">Chat</a></li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="https://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <a href="https://www.redhat.com/"> <img src="/assets/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"/> </a> </div> </div> </div> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-76464546-1"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-76464546-1");</script> <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> <script type="text/javascript" src="/assets/javascript/vanilla-back-to-top.min.js"></script> <script type="text/javascript" src="/assets/javascript/highlight.min.js"></script> <script>addBackToTop({scrollDuration:400}),hljs.initHighlightingOnLoad();</script> </body> </html>